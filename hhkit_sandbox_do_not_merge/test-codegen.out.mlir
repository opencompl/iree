test-codegen.mlir:94:21: warning: tiling is not thread safe at axis #3
  %MAX, %SUM, %PV = iree_linalg_ext.exp_reduction {
                    ^
test-codegen.mlir:94:21: note: see current operation:
%15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%9, %6 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf32>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
^bb0(%arg0: f32, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32):
  %18 = arith.addf %arg0, %arg3 : f32
  %19 = arith.mulf %arg0, %arg1 : f32
  %20 = arith.addf %19, %arg4 : f32
  linalg.yield %arg2, %18, %20 : f32, f32, f32
} -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
// -----// IR Dump After TileAndDistributeToWorkgroupsUsingForallOpPass (iree-codegen-tile-and-distribute-to-workgroups-using-forall-op) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>> -> tensor<20x4096x64xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>> -> tensor<20x4096x64xf32>
  %6 = iree_tensor_ext.dispatch.tensor.load %2, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.mulf %in, %in_4 : f32
      %20 = arith.addf %19, %out : f32
      linalg.yield %20 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = tensor.empty() : tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %14, %16 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %19 = arith.addf %arg5, %arg8 : f32
      %20 = arith.mulf %arg5, %arg6 : f32
      %21 = arith.addf %20, %arg9 : f32
      linalg.yield %arg7, %19, %21 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%17#2, %17#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.divf %in, %in_4 : f32
      linalg.yield %19 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %18 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_tensor_ext.dispatch.tensor.store %8, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After BufferizeDispatchTensorLoadStorePass (iree-codegen-bufferize-dispatch-tensor-load-store) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf32>>
  %6 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %7 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %8 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %9 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %10 = iree_codegen.load_from_buffer %4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %11) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %8[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %9[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %13 = tensor.empty() : tensor<1x8x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%13 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %23 = arith.mulf %in, %in_4 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %10[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8xf32>
    %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %17 = tensor.empty() : tensor<1x8xf32>
    %18 = linalg.fill ins(%cst_0 : f32) outs(%17 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %19 = tensor.empty() : tensor<1x8x8xf32>
    %20 = linalg.fill ins(%cst_0 : f32) outs(%19 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %21:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%14, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%16, %18, %20 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %23 = arith.addf %arg5, %arg8 : f32
      %24 = arith.mulf %arg5, %arg6 : f32
      %25 = arith.addf %24, %arg9 : f32
      linalg.yield %arg7, %23, %25 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21#2, %21#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %23 = arith.divf %in, %in_4 : f32
      linalg.yield %23 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %22 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %12, %6 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CombineLayoutTransformationPass (iree-codegen-combine-layout-transformation) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.mulf %in, %in_4 : f32
      %20 = arith.addf %19, %out : f32
      linalg.yield %20 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = tensor.empty() : tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %14, %16 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %19 = arith.addf %arg5, %arg8 : f32
      %20 = arith.mulf %arg5, %arg6 : f32
      %21 = arith.addf %20, %arg9 : f32
      linalg.yield %arg7, %19, %21 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%17#2, %17#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.divf %in, %in_4 : f32
      linalg.yield %19 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %18 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.mulf %in, %in_4 : f32
      %20 = arith.addf %19, %out : f32
      linalg.yield %20 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = tensor.empty() : tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %14, %16 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %19 = arith.addf %arg5, %arg8 : f32
      %20 = arith.mulf %arg5, %arg6 : f32
      %21 = arith.addf %20, %arg9 : f32
      linalg.yield %arg7, %19, %21 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%17#2, %17#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %19 = arith.divf %in, %in_4 : f32
      linalg.yield %19 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %18 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.mulf %in, %in_4 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %13, %14 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %17 = arith.addf %arg5, %arg8 : f32
      %18 = arith.mulf %arg5, %arg6 : f32
      %19 = arith.addf %18, %arg9 : f32
      linalg.yield %arg7, %17, %19 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.divf %in, %in_4 : f32
      linalg.yield %17 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.mulf %in, %in_4 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %13, %14 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %17 = arith.addf %arg5, %arg8 : f32
      %18 = arith.mulf %arg5, %arg6 : f32
      %19 = arith.addf %18, %arg9 : f32
      linalg.yield %arg7, %17, %19 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.divf %in, %in_4 : f32
      linalg.yield %17 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.mulf %in, %in_4 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %13, %14 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %17 = arith.addf %arg5, %arg8 : f32
      %18 = arith.mulf %arg5, %arg6 : f32
      %19 = arith.addf %18, %arg9 : f32
      linalg.yield %arg7, %17, %19 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.divf %in, %in_4 : f32
      linalg.yield %17 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.mulf %in, %in_4 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} ins(%10, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%12, %13, %14 : tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>) {
    ^bb0(%arg5: f32, %arg6: f32, %arg7: f32, %arg8: f32, %arg9: f32):
      %17 = arith.addf %arg5, %arg8 : f32
      %18 = arith.mulf %arg5, %arg6 : f32
      %19 = arith.addf %18, %arg9 : f32
      linalg.yield %arg7, %17, %19 : f32, f32, f32
    } -> tensor<1x8xf32>, tensor<1x8xf32>, tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %17 = arith.divf %in, %in_4 : f32
      linalg.yield %17 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After DecomposeExpReductionPass (iree-linalg-ext-decompose-exp-reduction) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %23 = arith.mulf %in, %in_4 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.maximumf %in, %out : f32
      linalg.yield %23 : f32
    } -> tensor<1x8xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15 : tensor<1x8xf32>) outs(%10 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.subf %out, %in : f32
      %24 = math.exp2 %23 : f32
      linalg.yield %24 : f32
    } -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%15 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.subf %out, %in : f32
      %24 = math.exp2 %23 : f32
      linalg.yield %24 : f32
    } -> tensor<1x8xf32>
    %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%17 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.mulf %in, %out : f32
      linalg.yield %23 : f32
    } -> tensor<1x8xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%17 : tensor<1x8xf32>) outs(%14 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.mulf %in, %out : f32
      linalg.yield %23 : f32
    } -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%16 : tensor<1x8x8xf32>) outs(%18 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %23 = arith.addf %in, %out : f32
      linalg.yield %23 : f32
    } -> tensor<1x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%16, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%19 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %23 = arith.mulf %in, %in_4 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %20 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_3 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_4: f32, %out: f32):
      %23 = arith.divf %in, %in_4 : f32
      linalg.yield %23 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %22 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

test-codegen.mlir:94:21: warning: tiling is not thread safe at axis #3
  %MAX, %SUM, %PV = iree_linalg_ext.exp_reduction {
                    ^
test-codegen.mlir:94:21: note: see current operation:
%21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%16, %extracted_slice_2 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%19 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
^bb0(%in: f32, %in_4: f32, %out: f32):
  %23 = arith.mulf %in, %in_4 : f32
  %24 = arith.addf %23, %out : f32
  linalg.yield %24 : f32
} -> tensor<1x8x8xf32>
// -----// IR Dump After LLVMCPUTileRootAndFuseProducerConsumerPass (iree-llvmcpu-tile-root-and-fuse-producer-consumer) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%15 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %19 = linalg.fill ins(%cst_0 : f32) outs(%18 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%17, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%20 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConvertAttentionToOnlineAttentionPass (iree-linalg-ext-convert-attention-to-online-attention) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%15 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %19 = linalg.fill ins(%cst_0 : f32) outs(%18 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%17, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%20 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileRootAndFuseProducerConsumerPass (iree-llvmcpu-tile-root-and-fuse-producer-consumer) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%18 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%20, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%17 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After DecomposeWinogradTransformPass (iree-linalg-ext-decompose-winograd) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%18 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%20, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%17 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After DecomposeAttentionPass (iree-linalg-ext-decompose-attention) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%18 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%20, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%17 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ForallToForPass (iree-codegen-forall-to-for) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096x64xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %7) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_1 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %9 = tensor.empty() : tensor<1x8x8xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8xf32>
    %12 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%10 : tensor<1x8x8xf32>) outs(%12 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x8xf32>) outs(%13 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %extracted_slice_2 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %15 = tensor.empty() : tensor<1x8x8xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%15 : tensor<1x8x8xf32>) -> tensor<1x8x8xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x8xf32>) outs(%16 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    %18 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_3 = tensor.extract_slice %5[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_3 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%18 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<1x8xf32>) outs(%19 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %21 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%20, %extracted_slice_4 : tensor<1x8x8xf32>, tensor<1x8x8xf32>) outs(%17 : tensor<1x8x8xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [1, 8, 8, 8], vector_common_parallel = [0, 0, 8, 16], vector_reduction = [0, 0, 0, 16]>} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %22 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %23 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %24 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%22 : tensor<1x8x8xf32>) outs(%23 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %26 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%24 : tensor<1x8xf32>) outs(%25 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %27 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %28 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<1x8x64xf32>, tensor<1x8x64xf32>) outs(%9 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.mulf %in, %in_5 : f32
      %37 = arith.addf %36, %out : f32
      linalg.yield %37 : f32
    } -> tensor<1x8x8xf32>
    %29 = linalg.fill ins(%cst : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %30 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%28 : tensor<1x8x8xf32>) outs(%29 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.maximumf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %31 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%27 : tensor<1x8xf32>) outs(%30 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.subf %out, %in : f32
      %37 = math.exp2 %36 : f32
      linalg.yield %37 : f32
    } -> tensor<1x8xf32>
    %32 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<1x8xf32>) -> tensor<1x8xf32>
    %33 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%31 : tensor<1x8xf32>) outs(%32 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.mulf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %34 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%26 : tensor<1x8x8xf32>) outs(%33 : tensor<1x8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %36 = arith.addf %in, %out : f32
      linalg.yield %36 : f32
    } -> tensor<1x8xf32>
    %35 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%21, %34 : tensor<1x8x8xf32>, tensor<1x8xf32>) outs(%extracted_slice_2 : tensor<1x8x8xf32>) {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %36 = arith.divf %in, %in_5 : f32
      linalg.yield %36 : f32
    } -> tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %35 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After GenericVectorizationPass (iree-codegen-generic-vectorization) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %5[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %22 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %23 = vector.transfer_read %extracted_slice_4[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %24 = vector.transfer_read %21[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %25 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %22, %23, %24 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %26 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %27 = vector.transpose %26, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %28 = arith.subf %25, %27 : vector<1x8x8xf32>
    %29 = math.exp2 %28 : vector<1x8x8xf32>
    %extracted_slice_5 = tensor.extract_slice %7[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %30 = vector.transfer_read %extracted_slice_5[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %31 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %29, %30, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %32 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %33 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %34 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %35 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %32, %33, %34 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %36 = vector.multi_reduction <maximumf>, %35, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %37 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %38 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %39 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %40 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %37, %38, %39 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %41 = vector.broadcast %36 : vector<1x8xf32> to vector<8x1x8xf32>
    %42 = vector.transpose %41, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %43 = arith.subf %40, %42 : vector<1x8x8xf32>
    %44 = math.exp2 %43 : vector<1x8x8xf32>
    %45 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %46 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %47 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %48 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %45, %46, %47 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %49 = vector.multi_reduction <maximumf>, %48, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %50 = arith.subf %49, %cst_1 : vector<1x8xf32>
    %51 = math.exp2 %50 : vector<1x8xf32>
    %52 = arith.mulf %51, %cst_0 : vector<1x8xf32>
    %53 = vector.multi_reduction <add>, %44, %52 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %54 = vector.broadcast %53 : vector<1x8xf32> to vector<8x1x8xf32>
    %55 = vector.transpose %54, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %56 = arith.divf %31, %55 : vector<1x8x8xf32>
    %57 = vector.transfer_write %56, %extracted_slice_3[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %57 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %5[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = tensor.empty() : tensor<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %6[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %22 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %23 = vector.transfer_read %extracted_slice_4[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %24 = vector.transfer_read %21[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %25 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %22, %23, %24 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %26 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %27 = vector.transpose %26, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %28 = arith.subf %25, %27 : vector<1x8x8xf32>
    %29 = math.exp2 %28 : vector<1x8x8xf32>
    %extracted_slice_5 = tensor.extract_slice %7[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %30 = vector.transfer_read %extracted_slice_5[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %31 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %29, %30, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %32 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %33 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %34 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %35 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %32, %33, %34 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %36 = vector.multi_reduction <maximumf>, %35, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %37 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %38 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %39 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %40 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %37, %38, %39 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %41 = vector.broadcast %36 : vector<1x8xf32> to vector<8x1x8xf32>
    %42 = vector.transpose %41, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %43 = arith.subf %40, %42 : vector<1x8x8xf32>
    %44 = math.exp2 %43 : vector<1x8x8xf32>
    %45 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %46 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %47 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %48 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %45, %46, %47 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %49 = vector.multi_reduction <maximumf>, %48, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %50 = arith.subf %49, %cst_1 : vector<1x8xf32>
    %51 = math.exp2 %50 : vector<1x8xf32>
    %52 = arith.mulf %51, %cst_0 : vector<1x8xf32>
    %53 = vector.multi_reduction <add>, %44, %52 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %54 = vector.broadcast %53 : vector<1x8xf32> to vector<8x1x8xf32>
    %55 = vector.transpose %54, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %56 = arith.divf %31, %55 : vector<1x8x8xf32>
    %57 = vector.transfer_write %56, %extracted_slice_3[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %57 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %5[%arg0, %arg1, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %extracted_slice_2 = tensor.extract_slice %6[%arg0, %arg3, 0] [1, 8, 64] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x64xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %extracted_slice[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %extracted_slice_3 = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %extracted_slice_4 = tensor.extract_slice %7[%arg0, %arg3, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %25 = vector.transfer_read %extracted_slice_4[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice_3[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %25 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %25 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %25 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUVerifyVectorSizeLegalityPass (iree-llvmcpu-verify-vector-size-legality) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %10 = tensor.empty() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %25 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After EliminateEmptyTensorsPass (iree-eliminate-empty-tensors) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = iree_codegen.load_from_buffer %4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %9 = tensor.empty() : tensor<20x4096x64xf32>
  %10 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %11 = tensor.empty() : tensor<1x8x8xf32>
    %12 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %14 = vector.transfer_read %11[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %15 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %12, %13, %14 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %16 = vector.multi_reduction <maximumf>, %15, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %17 = arith.subf %16, %cst_1 : vector<1x8xf32>
    %18 = math.exp2 %17 : vector<1x8xf32>
    %19 = vector.broadcast %18 : vector<1x8xf32> to vector<8x1x8xf32>
    %20 = arith.mulf %19, %cst : vector<8x1x8xf32>
    %21 = vector.transpose %20, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %22 = vector.broadcast %16 : vector<1x8xf32> to vector<8x1x8xf32>
    %23 = vector.transpose %22, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %24 = arith.subf %15, %23 : vector<1x8x8xf32>
    %25 = math.exp2 %24 : vector<1x8x8xf32>
    %26 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %27 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %25, %26, %21 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %28 = arith.mulf %18, %cst_0 : vector<1x8xf32>
    %29 = vector.multi_reduction <add>, %25, %28 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %30 = vector.broadcast %29 : vector<1x8xf32> to vector<8x1x8xf32>
    %31 = vector.transpose %30, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %32 = arith.divf %27, %31 : vector<1x8x8xf32>
    %33 = vector.transfer_write %32, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %33 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %10, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After EmptyTensorToAllocTensorPass (empty-tensor-to-alloc-tensor) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %0 = ub.poison : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %6 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %7 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %8 = iree_codegen.load_from_buffer %4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) shared_outs(%arg4 = %8) -> (tensor<20x4096x64xf32>) {
    %extracted_slice = tensor.extract_slice %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<20x4096x64xf32> to tensor<1x8x8xf32>
    %10 = bufferization.alloc_tensor() : tensor<1x8x8xf32>
    %11 = vector.transfer_read %5[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %12 = vector.transfer_read %6[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x64xf32>
    %13 = vector.transfer_read %10[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x8x8xf32>, vector<1x8x8xf32>
    %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %13 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %15 = vector.multi_reduction <maximumf>, %14, %cst_1 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %16 = arith.subf %15, %cst_1 : vector<1x8xf32>
    %17 = math.exp2 %16 : vector<1x8xf32>
    %18 = vector.broadcast %17 : vector<1x8xf32> to vector<8x1x8xf32>
    %19 = arith.mulf %18, %cst : vector<8x1x8xf32>
    %20 = vector.transpose %19, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %21 = vector.broadcast %15 : vector<1x8xf32> to vector<8x1x8xf32>
    %22 = vector.transpose %21, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %23 = arith.subf %14, %22 : vector<1x8x8xf32>
    %24 = math.exp2 %23 : vector<1x8x8xf32>
    %25 = vector.transfer_read %7[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf32>, vector<1x8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %24, %25, %20 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %27 = arith.mulf %17, %cst_0 : vector<1x8xf32>
    %28 = vector.multi_reduction <add>, %24, %27 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %29 = vector.broadcast %28 : vector<1x8xf32> to vector<8x1x8xf32>
    %30 = vector.transpose %29, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %31 = arith.divf %26, %30 : vector<1x8x8xf32>
    %32 = vector.transfer_write %31, %extracted_slice[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, tensor<1x8x8xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %32 into %arg4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : tensor<1x8x8xf32> into tensor<20x4096x64xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x64xf32> into memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After IREEComprehensiveBufferizePass (iree-codegen-iree-comprehensive-bufferize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %1[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_2 = memref.subview %4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) outs(%4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After IREEInjectAssumeAlignmentPass (iree-codegen-inject-assume-alignment) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_5 = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_5 : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%assume_align_4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After ResolveShapedTypeResultDimsPass (resolve-shaped-type-result-dims) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_5 = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_5 : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%assume_align_4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_5 = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_5 : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_4[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %6 = vector.transfer_read %assume_align_2[%arg0, %arg3, %c0], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x64xf32>
    %7 = vector.transfer_read %alloca[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : memref<1x8x8xf32>, vector<1x8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<1x8x64xf32>, vector<1x8x64xf32> into vector<1x8x8xf32>
    %9 = vector.multi_reduction <maximumf>, %8, %cst [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %10 = arith.subf %9, %cst : vector<1x8xf32>
    %11 = math.exp2 %10 : vector<1x8xf32>
    %12 = vector.broadcast %11 : vector<1x8xf32> to vector<8x1x8xf32>
    %13 = arith.mulf %12, %cst_1 : vector<8x1x8xf32>
    %14 = vector.transpose %13, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %15 = vector.broadcast %9 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.transpose %15, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %17 = arith.subf %8, %16 : vector<1x8x8xf32>
    %18 = math.exp2 %17 : vector<1x8x8xf32>
    %19 = vector.transfer_read %assume_align_3[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<1x8x8xf32>
    %20 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %18, %19, %14 : vector<1x8x8xf32>, vector<1x8x8xf32> into vector<1x8x8xf32>
    %21 = arith.mulf %11, %cst_0 : vector<1x8xf32>
    %22 = vector.multi_reduction <add>, %18, %21 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %23 = vector.broadcast %22 : vector<1x8xf32> to vector<8x1x8xf32>
    %24 = vector.transpose %23, [1, 2, 0] : vector<8x1x8xf32> to vector<1x8x8xf32>
    %25 = arith.divf %20, %24 : vector<1x8x8xf32>
    vector.transfer_write %25, %subview[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x8x8xf32>, memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After DropVectorUnitDimsPass (iree-codegen-drop-vector-unit-dims) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %cst = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_1 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<1x8xf32>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align[%arg0, %arg1, %c0], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x64xf32>
    %6 = vector.transfer_read %assume_align_3[%arg0, %arg3, %c0], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %7 = vector.transfer_read %subview_6[%c0, %c0], %0 {in_bounds = [true, true]} : memref<8x8xf32>, vector<8x8xf32>
    %8 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %5, %6, %7 : vector<8x64xf32>, vector<8x64xf32> into vector<8x8xf32>
    %9 = vector.broadcast %8 : vector<8x8xf32> to vector<1x8x8xf32>
    %10 = vector.multi_reduction <maximumf>, %9, %cst_2 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %11 = vector.shape_cast %10 : vector<1x8xf32> to vector<8xf32>
    %12 = arith.subf %11, %cst_1 : vector<8xf32>
    %13 = math.exp2 %12 : vector<8xf32>
    %14 = vector.shape_cast %13 : vector<8xf32> to vector<1x8xf32>
    %15 = vector.broadcast %14 : vector<1x8xf32> to vector<8x1x8xf32>
    %16 = vector.shape_cast %15 : vector<8x1x8xf32> to vector<8x8xf32>
    %17 = arith.mulf %16, %cst_0 : vector<8x8xf32>
    %18 = vector.transpose %17, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %19 = vector.broadcast %10 : vector<1x8xf32> to vector<8x1x8xf32>
    %20 = vector.shape_cast %19 : vector<8x1x8xf32> to vector<8x8xf32>
    %21 = vector.transpose %20, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %22 = arith.subf %8, %21 : vector<8x8xf32>
    %23 = math.exp2 %22 : vector<8x8xf32>
    %24 = vector.shape_cast %23 : vector<8x8xf32> to vector<1x8x8xf32>
    %25 = vector.transfer_read %assume_align_4[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
    %26 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %23, %25, %18 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
    %27 = arith.mulf %13, %cst : vector<8xf32>
    %28 = vector.shape_cast %27 : vector<8xf32> to vector<1x8xf32>
    %29 = vector.multi_reduction <add>, %24, %28 [2] : vector<1x8x8xf32> to vector<1x8xf32>
    %30 = vector.broadcast %29 : vector<1x8xf32> to vector<8x1x8xf32>
    %31 = vector.shape_cast %30 : vector<8x1x8xf32> to vector<8x8xf32>
    %32 = vector.transpose %31, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %33 = arith.divf %26, %32 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    vector.transfer_write %33, %subview_7[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVirtualVectorLoweringPass (iree-llvmcpu-virtual-vector-lowering) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align_3[%arg0, %arg3, %c0], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %6 = vector.transfer_read %subview_6[%c0, %c0], %0 {in_bounds = [true, true]} : memref<8x8xf32>, vector<8x8xf32>
    %7 = vector.transpose %5, [1, 0] : vector<8x64xf32> to vector<64x8xf32>
    %8 = vector.extract %7[0] : vector<8xf32> from vector<64x8xf32>
    %9 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %10 = vector.broadcast %9 : f32 to vector<8xf32>
    %11 = vector.extract %6[0] : vector<8xf32> from vector<8x8xf32>
    %12 = vector.fma %10, %8, %11 : vector<8xf32>
    %13 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %14 = memref.load %assume_align[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %15 = vector.broadcast %14 : f32 to vector<8xf32>
    %16 = vector.extract %6[1] : vector<8xf32> from vector<8x8xf32>
    %17 = vector.fma %15, %8, %16 : vector<8xf32>
    %18 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %19 = memref.load %assume_align[%arg0, %18, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %20 = vector.broadcast %19 : f32 to vector<8xf32>
    %21 = vector.extract %6[2] : vector<8xf32> from vector<8x8xf32>
    %22 = vector.fma %20, %8, %21 : vector<8xf32>
    %23 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %24 = memref.load %assume_align[%arg0, %23, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %25 = vector.broadcast %24 : f32 to vector<8xf32>
    %26 = vector.extract %6[3] : vector<8xf32> from vector<8x8xf32>
    %27 = vector.fma %25, %8, %26 : vector<8xf32>
    %28 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %29 = memref.load %assume_align[%arg0, %28, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %30 = vector.broadcast %29 : f32 to vector<8xf32>
    %31 = vector.extract %6[4] : vector<8xf32> from vector<8x8xf32>
    %32 = vector.fma %30, %8, %31 : vector<8xf32>
    %33 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %34 = memref.load %assume_align[%arg0, %33, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %35 = vector.broadcast %34 : f32 to vector<8xf32>
    %36 = vector.extract %6[5] : vector<8xf32> from vector<8x8xf32>
    %37 = vector.fma %35, %8, %36 : vector<8xf32>
    %38 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %39 = memref.load %assume_align[%arg0, %38, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %40 = vector.broadcast %39 : f32 to vector<8xf32>
    %41 = vector.extract %6[6] : vector<8xf32> from vector<8x8xf32>
    %42 = vector.fma %40, %8, %41 : vector<8xf32>
    %43 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %44 = memref.load %assume_align[%arg0, %43, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %45 = vector.broadcast %44 : f32 to vector<8xf32>
    %46 = vector.extract %6[7] : vector<8xf32> from vector<8x8xf32>
    %47 = vector.fma %45, %8, %46 : vector<8xf32>
    %48 = vector.extract %7[1] : vector<8xf32> from vector<64x8xf32>
    %49 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %50 = vector.broadcast %49 : f32 to vector<8xf32>
    %51 = vector.fma %50, %48, %12 : vector<8xf32>
    %52 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %53 = memref.load %assume_align[%arg0, %52, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %54 = vector.broadcast %53 : f32 to vector<8xf32>
    %55 = vector.fma %54, %48, %17 : vector<8xf32>
    %56 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %57 = memref.load %assume_align[%arg0, %56, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %58 = vector.broadcast %57 : f32 to vector<8xf32>
    %59 = vector.fma %58, %48, %22 : vector<8xf32>
    %60 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %61 = memref.load %assume_align[%arg0, %60, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %62 = vector.broadcast %61 : f32 to vector<8xf32>
    %63 = vector.fma %62, %48, %27 : vector<8xf32>
    %64 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %65 = memref.load %assume_align[%arg0, %64, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %66 = vector.broadcast %65 : f32 to vector<8xf32>
    %67 = vector.fma %66, %48, %32 : vector<8xf32>
    %68 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %69 = memref.load %assume_align[%arg0, %68, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %70 = vector.broadcast %69 : f32 to vector<8xf32>
    %71 = vector.fma %70, %48, %37 : vector<8xf32>
    %72 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %73 = memref.load %assume_align[%arg0, %72, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %74 = vector.broadcast %73 : f32 to vector<8xf32>
    %75 = vector.fma %74, %48, %42 : vector<8xf32>
    %76 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %77 = memref.load %assume_align[%arg0, %76, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %78 = vector.broadcast %77 : f32 to vector<8xf32>
    %79 = vector.fma %78, %48, %47 : vector<8xf32>
    %80 = vector.extract %7[2] : vector<8xf32> from vector<64x8xf32>
    %81 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %82 = vector.broadcast %81 : f32 to vector<8xf32>
    %83 = vector.fma %82, %80, %51 : vector<8xf32>
    %84 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %85 = memref.load %assume_align[%arg0, %84, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %86 = vector.broadcast %85 : f32 to vector<8xf32>
    %87 = vector.fma %86, %80, %55 : vector<8xf32>
    %88 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %89 = memref.load %assume_align[%arg0, %88, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %90 = vector.broadcast %89 : f32 to vector<8xf32>
    %91 = vector.fma %90, %80, %59 : vector<8xf32>
    %92 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %93 = memref.load %assume_align[%arg0, %92, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %94 = vector.broadcast %93 : f32 to vector<8xf32>
    %95 = vector.fma %94, %80, %63 : vector<8xf32>
    %96 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %97 = memref.load %assume_align[%arg0, %96, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %98 = vector.broadcast %97 : f32 to vector<8xf32>
    %99 = vector.fma %98, %80, %67 : vector<8xf32>
    %100 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %101 = memref.load %assume_align[%arg0, %100, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %102 = vector.broadcast %101 : f32 to vector<8xf32>
    %103 = vector.fma %102, %80, %71 : vector<8xf32>
    %104 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %105 = memref.load %assume_align[%arg0, %104, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %106 = vector.broadcast %105 : f32 to vector<8xf32>
    %107 = vector.fma %106, %80, %75 : vector<8xf32>
    %108 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %109 = memref.load %assume_align[%arg0, %108, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %110 = vector.broadcast %109 : f32 to vector<8xf32>
    %111 = vector.fma %110, %80, %79 : vector<8xf32>
    %112 = vector.extract %7[3] : vector<8xf32> from vector<64x8xf32>
    %113 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %114 = vector.broadcast %113 : f32 to vector<8xf32>
    %115 = vector.fma %114, %112, %83 : vector<8xf32>
    %116 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %117 = memref.load %assume_align[%arg0, %116, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %118 = vector.broadcast %117 : f32 to vector<8xf32>
    %119 = vector.fma %118, %112, %87 : vector<8xf32>
    %120 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %121 = memref.load %assume_align[%arg0, %120, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %122 = vector.broadcast %121 : f32 to vector<8xf32>
    %123 = vector.fma %122, %112, %91 : vector<8xf32>
    %124 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %125 = memref.load %assume_align[%arg0, %124, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %126 = vector.broadcast %125 : f32 to vector<8xf32>
    %127 = vector.fma %126, %112, %95 : vector<8xf32>
    %128 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %129 = memref.load %assume_align[%arg0, %128, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %130 = vector.broadcast %129 : f32 to vector<8xf32>
    %131 = vector.fma %130, %112, %99 : vector<8xf32>
    %132 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %133 = memref.load %assume_align[%arg0, %132, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %134 = vector.broadcast %133 : f32 to vector<8xf32>
    %135 = vector.fma %134, %112, %103 : vector<8xf32>
    %136 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %137 = memref.load %assume_align[%arg0, %136, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %138 = vector.broadcast %137 : f32 to vector<8xf32>
    %139 = vector.fma %138, %112, %107 : vector<8xf32>
    %140 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %141 = memref.load %assume_align[%arg0, %140, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %142 = vector.broadcast %141 : f32 to vector<8xf32>
    %143 = vector.fma %142, %112, %111 : vector<8xf32>
    %144 = vector.extract %7[4] : vector<8xf32> from vector<64x8xf32>
    %145 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %146 = vector.broadcast %145 : f32 to vector<8xf32>
    %147 = vector.fma %146, %144, %115 : vector<8xf32>
    %148 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %149 = memref.load %assume_align[%arg0, %148, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %150 = vector.broadcast %149 : f32 to vector<8xf32>
    %151 = vector.fma %150, %144, %119 : vector<8xf32>
    %152 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %153 = memref.load %assume_align[%arg0, %152, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %154 = vector.broadcast %153 : f32 to vector<8xf32>
    %155 = vector.fma %154, %144, %123 : vector<8xf32>
    %156 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %157 = memref.load %assume_align[%arg0, %156, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %158 = vector.broadcast %157 : f32 to vector<8xf32>
    %159 = vector.fma %158, %144, %127 : vector<8xf32>
    %160 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %161 = memref.load %assume_align[%arg0, %160, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %162 = vector.broadcast %161 : f32 to vector<8xf32>
    %163 = vector.fma %162, %144, %131 : vector<8xf32>
    %164 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %165 = memref.load %assume_align[%arg0, %164, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %166 = vector.broadcast %165 : f32 to vector<8xf32>
    %167 = vector.fma %166, %144, %135 : vector<8xf32>
    %168 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %169 = memref.load %assume_align[%arg0, %168, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %170 = vector.broadcast %169 : f32 to vector<8xf32>
    %171 = vector.fma %170, %144, %139 : vector<8xf32>
    %172 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %173 = memref.load %assume_align[%arg0, %172, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %174 = vector.broadcast %173 : f32 to vector<8xf32>
    %175 = vector.fma %174, %144, %143 : vector<8xf32>
    %176 = vector.extract %7[5] : vector<8xf32> from vector<64x8xf32>
    %177 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %178 = vector.broadcast %177 : f32 to vector<8xf32>
    %179 = vector.fma %178, %176, %147 : vector<8xf32>
    %180 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %181 = memref.load %assume_align[%arg0, %180, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %182 = vector.broadcast %181 : f32 to vector<8xf32>
    %183 = vector.fma %182, %176, %151 : vector<8xf32>
    %184 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %185 = memref.load %assume_align[%arg0, %184, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %186 = vector.broadcast %185 : f32 to vector<8xf32>
    %187 = vector.fma %186, %176, %155 : vector<8xf32>
    %188 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %189 = memref.load %assume_align[%arg0, %188, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %190 = vector.broadcast %189 : f32 to vector<8xf32>
    %191 = vector.fma %190, %176, %159 : vector<8xf32>
    %192 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %193 = memref.load %assume_align[%arg0, %192, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %194 = vector.broadcast %193 : f32 to vector<8xf32>
    %195 = vector.fma %194, %176, %163 : vector<8xf32>
    %196 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %197 = memref.load %assume_align[%arg0, %196, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %198 = vector.broadcast %197 : f32 to vector<8xf32>
    %199 = vector.fma %198, %176, %167 : vector<8xf32>
    %200 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %201 = memref.load %assume_align[%arg0, %200, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %202 = vector.broadcast %201 : f32 to vector<8xf32>
    %203 = vector.fma %202, %176, %171 : vector<8xf32>
    %204 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %205 = memref.load %assume_align[%arg0, %204, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %206 = vector.broadcast %205 : f32 to vector<8xf32>
    %207 = vector.fma %206, %176, %175 : vector<8xf32>
    %208 = vector.extract %7[6] : vector<8xf32> from vector<64x8xf32>
    %209 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %210 = vector.broadcast %209 : f32 to vector<8xf32>
    %211 = vector.fma %210, %208, %179 : vector<8xf32>
    %212 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %213 = memref.load %assume_align[%arg0, %212, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %214 = vector.broadcast %213 : f32 to vector<8xf32>
    %215 = vector.fma %214, %208, %183 : vector<8xf32>
    %216 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %217 = memref.load %assume_align[%arg0, %216, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %218 = vector.broadcast %217 : f32 to vector<8xf32>
    %219 = vector.fma %218, %208, %187 : vector<8xf32>
    %220 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %221 = memref.load %assume_align[%arg0, %220, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %222 = vector.broadcast %221 : f32 to vector<8xf32>
    %223 = vector.fma %222, %208, %191 : vector<8xf32>
    %224 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %225 = memref.load %assume_align[%arg0, %224, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %226 = vector.broadcast %225 : f32 to vector<8xf32>
    %227 = vector.fma %226, %208, %195 : vector<8xf32>
    %228 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %229 = memref.load %assume_align[%arg0, %228, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %230 = vector.broadcast %229 : f32 to vector<8xf32>
    %231 = vector.fma %230, %208, %199 : vector<8xf32>
    %232 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %233 = memref.load %assume_align[%arg0, %232, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %234 = vector.broadcast %233 : f32 to vector<8xf32>
    %235 = vector.fma %234, %208, %203 : vector<8xf32>
    %236 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %237 = memref.load %assume_align[%arg0, %236, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %238 = vector.broadcast %237 : f32 to vector<8xf32>
    %239 = vector.fma %238, %208, %207 : vector<8xf32>
    %240 = vector.extract %7[7] : vector<8xf32> from vector<64x8xf32>
    %241 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %242 = vector.broadcast %241 : f32 to vector<8xf32>
    %243 = vector.fma %242, %240, %211 : vector<8xf32>
    %244 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %245 = memref.load %assume_align[%arg0, %244, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %246 = vector.broadcast %245 : f32 to vector<8xf32>
    %247 = vector.fma %246, %240, %215 : vector<8xf32>
    %248 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %249 = memref.load %assume_align[%arg0, %248, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %250 = vector.broadcast %249 : f32 to vector<8xf32>
    %251 = vector.fma %250, %240, %219 : vector<8xf32>
    %252 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %253 = memref.load %assume_align[%arg0, %252, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %254 = vector.broadcast %253 : f32 to vector<8xf32>
    %255 = vector.fma %254, %240, %223 : vector<8xf32>
    %256 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %257 = memref.load %assume_align[%arg0, %256, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %258 = vector.broadcast %257 : f32 to vector<8xf32>
    %259 = vector.fma %258, %240, %227 : vector<8xf32>
    %260 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %261 = memref.load %assume_align[%arg0, %260, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %262 = vector.broadcast %261 : f32 to vector<8xf32>
    %263 = vector.fma %262, %240, %231 : vector<8xf32>
    %264 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %265 = memref.load %assume_align[%arg0, %264, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %266 = vector.broadcast %265 : f32 to vector<8xf32>
    %267 = vector.fma %266, %240, %235 : vector<8xf32>
    %268 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %269 = memref.load %assume_align[%arg0, %268, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %270 = vector.broadcast %269 : f32 to vector<8xf32>
    %271 = vector.fma %270, %240, %239 : vector<8xf32>
    %272 = vector.extract %7[8] : vector<8xf32> from vector<64x8xf32>
    %273 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %274 = vector.broadcast %273 : f32 to vector<8xf32>
    %275 = vector.fma %274, %272, %243 : vector<8xf32>
    %276 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %277 = memref.load %assume_align[%arg0, %276, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %278 = vector.broadcast %277 : f32 to vector<8xf32>
    %279 = vector.fma %278, %272, %247 : vector<8xf32>
    %280 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %281 = memref.load %assume_align[%arg0, %280, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %282 = vector.broadcast %281 : f32 to vector<8xf32>
    %283 = vector.fma %282, %272, %251 : vector<8xf32>
    %284 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %285 = memref.load %assume_align[%arg0, %284, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %286 = vector.broadcast %285 : f32 to vector<8xf32>
    %287 = vector.fma %286, %272, %255 : vector<8xf32>
    %288 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %289 = memref.load %assume_align[%arg0, %288, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %290 = vector.broadcast %289 : f32 to vector<8xf32>
    %291 = vector.fma %290, %272, %259 : vector<8xf32>
    %292 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %293 = memref.load %assume_align[%arg0, %292, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %294 = vector.broadcast %293 : f32 to vector<8xf32>
    %295 = vector.fma %294, %272, %263 : vector<8xf32>
    %296 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %297 = memref.load %assume_align[%arg0, %296, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %298 = vector.broadcast %297 : f32 to vector<8xf32>
    %299 = vector.fma %298, %272, %267 : vector<8xf32>
    %300 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %301 = memref.load %assume_align[%arg0, %300, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %302 = vector.broadcast %301 : f32 to vector<8xf32>
    %303 = vector.fma %302, %272, %271 : vector<8xf32>
    %304 = vector.extract %7[9] : vector<8xf32> from vector<64x8xf32>
    %305 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %306 = vector.broadcast %305 : f32 to vector<8xf32>
    %307 = vector.fma %306, %304, %275 : vector<8xf32>
    %308 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %309 = memref.load %assume_align[%arg0, %308, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %310 = vector.broadcast %309 : f32 to vector<8xf32>
    %311 = vector.fma %310, %304, %279 : vector<8xf32>
    %312 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %313 = memref.load %assume_align[%arg0, %312, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %314 = vector.broadcast %313 : f32 to vector<8xf32>
    %315 = vector.fma %314, %304, %283 : vector<8xf32>
    %316 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %317 = memref.load %assume_align[%arg0, %316, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %318 = vector.broadcast %317 : f32 to vector<8xf32>
    %319 = vector.fma %318, %304, %287 : vector<8xf32>
    %320 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %321 = memref.load %assume_align[%arg0, %320, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %322 = vector.broadcast %321 : f32 to vector<8xf32>
    %323 = vector.fma %322, %304, %291 : vector<8xf32>
    %324 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %325 = memref.load %assume_align[%arg0, %324, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %326 = vector.broadcast %325 : f32 to vector<8xf32>
    %327 = vector.fma %326, %304, %295 : vector<8xf32>
    %328 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %329 = memref.load %assume_align[%arg0, %328, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %330 = vector.broadcast %329 : f32 to vector<8xf32>
    %331 = vector.fma %330, %304, %299 : vector<8xf32>
    %332 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %333 = memref.load %assume_align[%arg0, %332, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %334 = vector.broadcast %333 : f32 to vector<8xf32>
    %335 = vector.fma %334, %304, %303 : vector<8xf32>
    %336 = vector.extract %7[10] : vector<8xf32> from vector<64x8xf32>
    %337 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %338 = vector.broadcast %337 : f32 to vector<8xf32>
    %339 = vector.fma %338, %336, %307 : vector<8xf32>
    %340 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %341 = memref.load %assume_align[%arg0, %340, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %342 = vector.broadcast %341 : f32 to vector<8xf32>
    %343 = vector.fma %342, %336, %311 : vector<8xf32>
    %344 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %345 = memref.load %assume_align[%arg0, %344, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %346 = vector.broadcast %345 : f32 to vector<8xf32>
    %347 = vector.fma %346, %336, %315 : vector<8xf32>
    %348 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %349 = memref.load %assume_align[%arg0, %348, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %350 = vector.broadcast %349 : f32 to vector<8xf32>
    %351 = vector.fma %350, %336, %319 : vector<8xf32>
    %352 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %353 = memref.load %assume_align[%arg0, %352, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %354 = vector.broadcast %353 : f32 to vector<8xf32>
    %355 = vector.fma %354, %336, %323 : vector<8xf32>
    %356 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %357 = memref.load %assume_align[%arg0, %356, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %358 = vector.broadcast %357 : f32 to vector<8xf32>
    %359 = vector.fma %358, %336, %327 : vector<8xf32>
    %360 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %361 = memref.load %assume_align[%arg0, %360, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %362 = vector.broadcast %361 : f32 to vector<8xf32>
    %363 = vector.fma %362, %336, %331 : vector<8xf32>
    %364 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %365 = memref.load %assume_align[%arg0, %364, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %366 = vector.broadcast %365 : f32 to vector<8xf32>
    %367 = vector.fma %366, %336, %335 : vector<8xf32>
    %368 = vector.extract %7[11] : vector<8xf32> from vector<64x8xf32>
    %369 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %370 = vector.broadcast %369 : f32 to vector<8xf32>
    %371 = vector.fma %370, %368, %339 : vector<8xf32>
    %372 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %373 = memref.load %assume_align[%arg0, %372, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %374 = vector.broadcast %373 : f32 to vector<8xf32>
    %375 = vector.fma %374, %368, %343 : vector<8xf32>
    %376 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %377 = memref.load %assume_align[%arg0, %376, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %378 = vector.broadcast %377 : f32 to vector<8xf32>
    %379 = vector.fma %378, %368, %347 : vector<8xf32>
    %380 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %381 = memref.load %assume_align[%arg0, %380, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %382 = vector.broadcast %381 : f32 to vector<8xf32>
    %383 = vector.fma %382, %368, %351 : vector<8xf32>
    %384 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %385 = memref.load %assume_align[%arg0, %384, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %386 = vector.broadcast %385 : f32 to vector<8xf32>
    %387 = vector.fma %386, %368, %355 : vector<8xf32>
    %388 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %389 = memref.load %assume_align[%arg0, %388, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %390 = vector.broadcast %389 : f32 to vector<8xf32>
    %391 = vector.fma %390, %368, %359 : vector<8xf32>
    %392 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %393 = memref.load %assume_align[%arg0, %392, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %394 = vector.broadcast %393 : f32 to vector<8xf32>
    %395 = vector.fma %394, %368, %363 : vector<8xf32>
    %396 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %397 = memref.load %assume_align[%arg0, %396, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %398 = vector.broadcast %397 : f32 to vector<8xf32>
    %399 = vector.fma %398, %368, %367 : vector<8xf32>
    %400 = vector.extract %7[12] : vector<8xf32> from vector<64x8xf32>
    %401 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %402 = vector.broadcast %401 : f32 to vector<8xf32>
    %403 = vector.fma %402, %400, %371 : vector<8xf32>
    %404 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %405 = memref.load %assume_align[%arg0, %404, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %406 = vector.broadcast %405 : f32 to vector<8xf32>
    %407 = vector.fma %406, %400, %375 : vector<8xf32>
    %408 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %409 = memref.load %assume_align[%arg0, %408, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %410 = vector.broadcast %409 : f32 to vector<8xf32>
    %411 = vector.fma %410, %400, %379 : vector<8xf32>
    %412 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %413 = memref.load %assume_align[%arg0, %412, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %414 = vector.broadcast %413 : f32 to vector<8xf32>
    %415 = vector.fma %414, %400, %383 : vector<8xf32>
    %416 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %417 = memref.load %assume_align[%arg0, %416, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %418 = vector.broadcast %417 : f32 to vector<8xf32>
    %419 = vector.fma %418, %400, %387 : vector<8xf32>
    %420 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %421 = memref.load %assume_align[%arg0, %420, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %422 = vector.broadcast %421 : f32 to vector<8xf32>
    %423 = vector.fma %422, %400, %391 : vector<8xf32>
    %424 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %425 = memref.load %assume_align[%arg0, %424, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %426 = vector.broadcast %425 : f32 to vector<8xf32>
    %427 = vector.fma %426, %400, %395 : vector<8xf32>
    %428 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %429 = memref.load %assume_align[%arg0, %428, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %430 = vector.broadcast %429 : f32 to vector<8xf32>
    %431 = vector.fma %430, %400, %399 : vector<8xf32>
    %432 = vector.extract %7[13] : vector<8xf32> from vector<64x8xf32>
    %433 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %434 = vector.broadcast %433 : f32 to vector<8xf32>
    %435 = vector.fma %434, %432, %403 : vector<8xf32>
    %436 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %437 = memref.load %assume_align[%arg0, %436, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %438 = vector.broadcast %437 : f32 to vector<8xf32>
    %439 = vector.fma %438, %432, %407 : vector<8xf32>
    %440 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %441 = memref.load %assume_align[%arg0, %440, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %442 = vector.broadcast %441 : f32 to vector<8xf32>
    %443 = vector.fma %442, %432, %411 : vector<8xf32>
    %444 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %445 = memref.load %assume_align[%arg0, %444, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %446 = vector.broadcast %445 : f32 to vector<8xf32>
    %447 = vector.fma %446, %432, %415 : vector<8xf32>
    %448 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %449 = memref.load %assume_align[%arg0, %448, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %450 = vector.broadcast %449 : f32 to vector<8xf32>
    %451 = vector.fma %450, %432, %419 : vector<8xf32>
    %452 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %453 = memref.load %assume_align[%arg0, %452, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %454 = vector.broadcast %453 : f32 to vector<8xf32>
    %455 = vector.fma %454, %432, %423 : vector<8xf32>
    %456 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %457 = memref.load %assume_align[%arg0, %456, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %458 = vector.broadcast %457 : f32 to vector<8xf32>
    %459 = vector.fma %458, %432, %427 : vector<8xf32>
    %460 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %461 = memref.load %assume_align[%arg0, %460, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %462 = vector.broadcast %461 : f32 to vector<8xf32>
    %463 = vector.fma %462, %432, %431 : vector<8xf32>
    %464 = vector.extract %7[14] : vector<8xf32> from vector<64x8xf32>
    %465 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %466 = vector.broadcast %465 : f32 to vector<8xf32>
    %467 = vector.fma %466, %464, %435 : vector<8xf32>
    %468 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %469 = memref.load %assume_align[%arg0, %468, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %470 = vector.broadcast %469 : f32 to vector<8xf32>
    %471 = vector.fma %470, %464, %439 : vector<8xf32>
    %472 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %473 = memref.load %assume_align[%arg0, %472, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %474 = vector.broadcast %473 : f32 to vector<8xf32>
    %475 = vector.fma %474, %464, %443 : vector<8xf32>
    %476 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %477 = memref.load %assume_align[%arg0, %476, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %478 = vector.broadcast %477 : f32 to vector<8xf32>
    %479 = vector.fma %478, %464, %447 : vector<8xf32>
    %480 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %481 = memref.load %assume_align[%arg0, %480, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %482 = vector.broadcast %481 : f32 to vector<8xf32>
    %483 = vector.fma %482, %464, %451 : vector<8xf32>
    %484 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %485 = memref.load %assume_align[%arg0, %484, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %486 = vector.broadcast %485 : f32 to vector<8xf32>
    %487 = vector.fma %486, %464, %455 : vector<8xf32>
    %488 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %489 = memref.load %assume_align[%arg0, %488, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %490 = vector.broadcast %489 : f32 to vector<8xf32>
    %491 = vector.fma %490, %464, %459 : vector<8xf32>
    %492 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %493 = memref.load %assume_align[%arg0, %492, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %494 = vector.broadcast %493 : f32 to vector<8xf32>
    %495 = vector.fma %494, %464, %463 : vector<8xf32>
    %496 = vector.extract %7[15] : vector<8xf32> from vector<64x8xf32>
    %497 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %498 = vector.broadcast %497 : f32 to vector<8xf32>
    %499 = vector.fma %498, %496, %467 : vector<8xf32>
    %500 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %501 = memref.load %assume_align[%arg0, %500, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %502 = vector.broadcast %501 : f32 to vector<8xf32>
    %503 = vector.fma %502, %496, %471 : vector<8xf32>
    %504 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %505 = memref.load %assume_align[%arg0, %504, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %506 = vector.broadcast %505 : f32 to vector<8xf32>
    %507 = vector.fma %506, %496, %475 : vector<8xf32>
    %508 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %509 = memref.load %assume_align[%arg0, %508, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %510 = vector.broadcast %509 : f32 to vector<8xf32>
    %511 = vector.fma %510, %496, %479 : vector<8xf32>
    %512 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %513 = memref.load %assume_align[%arg0, %512, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %514 = vector.broadcast %513 : f32 to vector<8xf32>
    %515 = vector.fma %514, %496, %483 : vector<8xf32>
    %516 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %517 = memref.load %assume_align[%arg0, %516, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %518 = vector.broadcast %517 : f32 to vector<8xf32>
    %519 = vector.fma %518, %496, %487 : vector<8xf32>
    %520 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %521 = memref.load %assume_align[%arg0, %520, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %522 = vector.broadcast %521 : f32 to vector<8xf32>
    %523 = vector.fma %522, %496, %491 : vector<8xf32>
    %524 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %525 = memref.load %assume_align[%arg0, %524, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %526 = vector.broadcast %525 : f32 to vector<8xf32>
    %527 = vector.fma %526, %496, %495 : vector<8xf32>
    %528 = vector.extract %7[16] : vector<8xf32> from vector<64x8xf32>
    %529 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %530 = vector.broadcast %529 : f32 to vector<8xf32>
    %531 = vector.fma %530, %528, %499 : vector<8xf32>
    %532 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %533 = memref.load %assume_align[%arg0, %532, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %534 = vector.broadcast %533 : f32 to vector<8xf32>
    %535 = vector.fma %534, %528, %503 : vector<8xf32>
    %536 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %537 = memref.load %assume_align[%arg0, %536, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %538 = vector.broadcast %537 : f32 to vector<8xf32>
    %539 = vector.fma %538, %528, %507 : vector<8xf32>
    %540 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %541 = memref.load %assume_align[%arg0, %540, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %542 = vector.broadcast %541 : f32 to vector<8xf32>
    %543 = vector.fma %542, %528, %511 : vector<8xf32>
    %544 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %545 = memref.load %assume_align[%arg0, %544, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %546 = vector.broadcast %545 : f32 to vector<8xf32>
    %547 = vector.fma %546, %528, %515 : vector<8xf32>
    %548 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %549 = memref.load %assume_align[%arg0, %548, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %550 = vector.broadcast %549 : f32 to vector<8xf32>
    %551 = vector.fma %550, %528, %519 : vector<8xf32>
    %552 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %553 = memref.load %assume_align[%arg0, %552, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %554 = vector.broadcast %553 : f32 to vector<8xf32>
    %555 = vector.fma %554, %528, %523 : vector<8xf32>
    %556 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %557 = memref.load %assume_align[%arg0, %556, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %558 = vector.broadcast %557 : f32 to vector<8xf32>
    %559 = vector.fma %558, %528, %527 : vector<8xf32>
    %560 = vector.extract %7[17] : vector<8xf32> from vector<64x8xf32>
    %561 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %562 = vector.broadcast %561 : f32 to vector<8xf32>
    %563 = vector.fma %562, %560, %531 : vector<8xf32>
    %564 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %565 = memref.load %assume_align[%arg0, %564, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %566 = vector.broadcast %565 : f32 to vector<8xf32>
    %567 = vector.fma %566, %560, %535 : vector<8xf32>
    %568 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %569 = memref.load %assume_align[%arg0, %568, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %570 = vector.broadcast %569 : f32 to vector<8xf32>
    %571 = vector.fma %570, %560, %539 : vector<8xf32>
    %572 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %573 = memref.load %assume_align[%arg0, %572, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %574 = vector.broadcast %573 : f32 to vector<8xf32>
    %575 = vector.fma %574, %560, %543 : vector<8xf32>
    %576 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %577 = memref.load %assume_align[%arg0, %576, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %578 = vector.broadcast %577 : f32 to vector<8xf32>
    %579 = vector.fma %578, %560, %547 : vector<8xf32>
    %580 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %581 = memref.load %assume_align[%arg0, %580, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %582 = vector.broadcast %581 : f32 to vector<8xf32>
    %583 = vector.fma %582, %560, %551 : vector<8xf32>
    %584 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %585 = memref.load %assume_align[%arg0, %584, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %586 = vector.broadcast %585 : f32 to vector<8xf32>
    %587 = vector.fma %586, %560, %555 : vector<8xf32>
    %588 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %589 = memref.load %assume_align[%arg0, %588, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %590 = vector.broadcast %589 : f32 to vector<8xf32>
    %591 = vector.fma %590, %560, %559 : vector<8xf32>
    %592 = vector.extract %7[18] : vector<8xf32> from vector<64x8xf32>
    %593 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %594 = vector.broadcast %593 : f32 to vector<8xf32>
    %595 = vector.fma %594, %592, %563 : vector<8xf32>
    %596 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %597 = memref.load %assume_align[%arg0, %596, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %598 = vector.broadcast %597 : f32 to vector<8xf32>
    %599 = vector.fma %598, %592, %567 : vector<8xf32>
    %600 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %601 = memref.load %assume_align[%arg0, %600, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %602 = vector.broadcast %601 : f32 to vector<8xf32>
    %603 = vector.fma %602, %592, %571 : vector<8xf32>
    %604 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %605 = memref.load %assume_align[%arg0, %604, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %606 = vector.broadcast %605 : f32 to vector<8xf32>
    %607 = vector.fma %606, %592, %575 : vector<8xf32>
    %608 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %609 = memref.load %assume_align[%arg0, %608, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %610 = vector.broadcast %609 : f32 to vector<8xf32>
    %611 = vector.fma %610, %592, %579 : vector<8xf32>
    %612 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %613 = memref.load %assume_align[%arg0, %612, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %614 = vector.broadcast %613 : f32 to vector<8xf32>
    %615 = vector.fma %614, %592, %583 : vector<8xf32>
    %616 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %617 = memref.load %assume_align[%arg0, %616, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %618 = vector.broadcast %617 : f32 to vector<8xf32>
    %619 = vector.fma %618, %592, %587 : vector<8xf32>
    %620 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %621 = memref.load %assume_align[%arg0, %620, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %622 = vector.broadcast %621 : f32 to vector<8xf32>
    %623 = vector.fma %622, %592, %591 : vector<8xf32>
    %624 = vector.extract %7[19] : vector<8xf32> from vector<64x8xf32>
    %625 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %626 = vector.broadcast %625 : f32 to vector<8xf32>
    %627 = vector.fma %626, %624, %595 : vector<8xf32>
    %628 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %629 = memref.load %assume_align[%arg0, %628, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %630 = vector.broadcast %629 : f32 to vector<8xf32>
    %631 = vector.fma %630, %624, %599 : vector<8xf32>
    %632 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %633 = memref.load %assume_align[%arg0, %632, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %634 = vector.broadcast %633 : f32 to vector<8xf32>
    %635 = vector.fma %634, %624, %603 : vector<8xf32>
    %636 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %637 = memref.load %assume_align[%arg0, %636, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %638 = vector.broadcast %637 : f32 to vector<8xf32>
    %639 = vector.fma %638, %624, %607 : vector<8xf32>
    %640 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %641 = memref.load %assume_align[%arg0, %640, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %642 = vector.broadcast %641 : f32 to vector<8xf32>
    %643 = vector.fma %642, %624, %611 : vector<8xf32>
    %644 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %645 = memref.load %assume_align[%arg0, %644, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %646 = vector.broadcast %645 : f32 to vector<8xf32>
    %647 = vector.fma %646, %624, %615 : vector<8xf32>
    %648 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %649 = memref.load %assume_align[%arg0, %648, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %650 = vector.broadcast %649 : f32 to vector<8xf32>
    %651 = vector.fma %650, %624, %619 : vector<8xf32>
    %652 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %653 = memref.load %assume_align[%arg0, %652, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %654 = vector.broadcast %653 : f32 to vector<8xf32>
    %655 = vector.fma %654, %624, %623 : vector<8xf32>
    %656 = vector.extract %7[20] : vector<8xf32> from vector<64x8xf32>
    %657 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %658 = vector.broadcast %657 : f32 to vector<8xf32>
    %659 = vector.fma %658, %656, %627 : vector<8xf32>
    %660 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %661 = memref.load %assume_align[%arg0, %660, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %662 = vector.broadcast %661 : f32 to vector<8xf32>
    %663 = vector.fma %662, %656, %631 : vector<8xf32>
    %664 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %665 = memref.load %assume_align[%arg0, %664, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %666 = vector.broadcast %665 : f32 to vector<8xf32>
    %667 = vector.fma %666, %656, %635 : vector<8xf32>
    %668 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %669 = memref.load %assume_align[%arg0, %668, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %670 = vector.broadcast %669 : f32 to vector<8xf32>
    %671 = vector.fma %670, %656, %639 : vector<8xf32>
    %672 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %673 = memref.load %assume_align[%arg0, %672, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %674 = vector.broadcast %673 : f32 to vector<8xf32>
    %675 = vector.fma %674, %656, %643 : vector<8xf32>
    %676 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %677 = memref.load %assume_align[%arg0, %676, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %678 = vector.broadcast %677 : f32 to vector<8xf32>
    %679 = vector.fma %678, %656, %647 : vector<8xf32>
    %680 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %681 = memref.load %assume_align[%arg0, %680, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %682 = vector.broadcast %681 : f32 to vector<8xf32>
    %683 = vector.fma %682, %656, %651 : vector<8xf32>
    %684 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %685 = memref.load %assume_align[%arg0, %684, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %686 = vector.broadcast %685 : f32 to vector<8xf32>
    %687 = vector.fma %686, %656, %655 : vector<8xf32>
    %688 = vector.extract %7[21] : vector<8xf32> from vector<64x8xf32>
    %689 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %690 = vector.broadcast %689 : f32 to vector<8xf32>
    %691 = vector.fma %690, %688, %659 : vector<8xf32>
    %692 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %693 = memref.load %assume_align[%arg0, %692, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %694 = vector.broadcast %693 : f32 to vector<8xf32>
    %695 = vector.fma %694, %688, %663 : vector<8xf32>
    %696 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %697 = memref.load %assume_align[%arg0, %696, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %698 = vector.broadcast %697 : f32 to vector<8xf32>
    %699 = vector.fma %698, %688, %667 : vector<8xf32>
    %700 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %701 = memref.load %assume_align[%arg0, %700, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %702 = vector.broadcast %701 : f32 to vector<8xf32>
    %703 = vector.fma %702, %688, %671 : vector<8xf32>
    %704 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %705 = memref.load %assume_align[%arg0, %704, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %706 = vector.broadcast %705 : f32 to vector<8xf32>
    %707 = vector.fma %706, %688, %675 : vector<8xf32>
    %708 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %709 = memref.load %assume_align[%arg0, %708, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %710 = vector.broadcast %709 : f32 to vector<8xf32>
    %711 = vector.fma %710, %688, %679 : vector<8xf32>
    %712 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %713 = memref.load %assume_align[%arg0, %712, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %714 = vector.broadcast %713 : f32 to vector<8xf32>
    %715 = vector.fma %714, %688, %683 : vector<8xf32>
    %716 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %717 = memref.load %assume_align[%arg0, %716, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %718 = vector.broadcast %717 : f32 to vector<8xf32>
    %719 = vector.fma %718, %688, %687 : vector<8xf32>
    %720 = vector.extract %7[22] : vector<8xf32> from vector<64x8xf32>
    %721 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %722 = vector.broadcast %721 : f32 to vector<8xf32>
    %723 = vector.fma %722, %720, %691 : vector<8xf32>
    %724 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %725 = memref.load %assume_align[%arg0, %724, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %726 = vector.broadcast %725 : f32 to vector<8xf32>
    %727 = vector.fma %726, %720, %695 : vector<8xf32>
    %728 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %729 = memref.load %assume_align[%arg0, %728, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %730 = vector.broadcast %729 : f32 to vector<8xf32>
    %731 = vector.fma %730, %720, %699 : vector<8xf32>
    %732 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %733 = memref.load %assume_align[%arg0, %732, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %734 = vector.broadcast %733 : f32 to vector<8xf32>
    %735 = vector.fma %734, %720, %703 : vector<8xf32>
    %736 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %737 = memref.load %assume_align[%arg0, %736, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %738 = vector.broadcast %737 : f32 to vector<8xf32>
    %739 = vector.fma %738, %720, %707 : vector<8xf32>
    %740 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %741 = memref.load %assume_align[%arg0, %740, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %742 = vector.broadcast %741 : f32 to vector<8xf32>
    %743 = vector.fma %742, %720, %711 : vector<8xf32>
    %744 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %745 = memref.load %assume_align[%arg0, %744, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %746 = vector.broadcast %745 : f32 to vector<8xf32>
    %747 = vector.fma %746, %720, %715 : vector<8xf32>
    %748 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %749 = memref.load %assume_align[%arg0, %748, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %750 = vector.broadcast %749 : f32 to vector<8xf32>
    %751 = vector.fma %750, %720, %719 : vector<8xf32>
    %752 = vector.extract %7[23] : vector<8xf32> from vector<64x8xf32>
    %753 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %754 = vector.broadcast %753 : f32 to vector<8xf32>
    %755 = vector.fma %754, %752, %723 : vector<8xf32>
    %756 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %757 = memref.load %assume_align[%arg0, %756, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %758 = vector.broadcast %757 : f32 to vector<8xf32>
    %759 = vector.fma %758, %752, %727 : vector<8xf32>
    %760 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %761 = memref.load %assume_align[%arg0, %760, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %762 = vector.broadcast %761 : f32 to vector<8xf32>
    %763 = vector.fma %762, %752, %731 : vector<8xf32>
    %764 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %765 = memref.load %assume_align[%arg0, %764, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %766 = vector.broadcast %765 : f32 to vector<8xf32>
    %767 = vector.fma %766, %752, %735 : vector<8xf32>
    %768 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %769 = memref.load %assume_align[%arg0, %768, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %770 = vector.broadcast %769 : f32 to vector<8xf32>
    %771 = vector.fma %770, %752, %739 : vector<8xf32>
    %772 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %773 = memref.load %assume_align[%arg0, %772, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %774 = vector.broadcast %773 : f32 to vector<8xf32>
    %775 = vector.fma %774, %752, %743 : vector<8xf32>
    %776 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %777 = memref.load %assume_align[%arg0, %776, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %778 = vector.broadcast %777 : f32 to vector<8xf32>
    %779 = vector.fma %778, %752, %747 : vector<8xf32>
    %780 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %781 = memref.load %assume_align[%arg0, %780, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %782 = vector.broadcast %781 : f32 to vector<8xf32>
    %783 = vector.fma %782, %752, %751 : vector<8xf32>
    %784 = vector.extract %7[24] : vector<8xf32> from vector<64x8xf32>
    %785 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %786 = vector.broadcast %785 : f32 to vector<8xf32>
    %787 = vector.fma %786, %784, %755 : vector<8xf32>
    %788 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %789 = memref.load %assume_align[%arg0, %788, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %790 = vector.broadcast %789 : f32 to vector<8xf32>
    %791 = vector.fma %790, %784, %759 : vector<8xf32>
    %792 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %793 = memref.load %assume_align[%arg0, %792, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %794 = vector.broadcast %793 : f32 to vector<8xf32>
    %795 = vector.fma %794, %784, %763 : vector<8xf32>
    %796 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %797 = memref.load %assume_align[%arg0, %796, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %798 = vector.broadcast %797 : f32 to vector<8xf32>
    %799 = vector.fma %798, %784, %767 : vector<8xf32>
    %800 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %801 = memref.load %assume_align[%arg0, %800, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %802 = vector.broadcast %801 : f32 to vector<8xf32>
    %803 = vector.fma %802, %784, %771 : vector<8xf32>
    %804 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %805 = memref.load %assume_align[%arg0, %804, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %806 = vector.broadcast %805 : f32 to vector<8xf32>
    %807 = vector.fma %806, %784, %775 : vector<8xf32>
    %808 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %809 = memref.load %assume_align[%arg0, %808, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %810 = vector.broadcast %809 : f32 to vector<8xf32>
    %811 = vector.fma %810, %784, %779 : vector<8xf32>
    %812 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %813 = memref.load %assume_align[%arg0, %812, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %814 = vector.broadcast %813 : f32 to vector<8xf32>
    %815 = vector.fma %814, %784, %783 : vector<8xf32>
    %816 = vector.extract %7[25] : vector<8xf32> from vector<64x8xf32>
    %817 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %818 = vector.broadcast %817 : f32 to vector<8xf32>
    %819 = vector.fma %818, %816, %787 : vector<8xf32>
    %820 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %821 = memref.load %assume_align[%arg0, %820, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %822 = vector.broadcast %821 : f32 to vector<8xf32>
    %823 = vector.fma %822, %816, %791 : vector<8xf32>
    %824 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %825 = memref.load %assume_align[%arg0, %824, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %826 = vector.broadcast %825 : f32 to vector<8xf32>
    %827 = vector.fma %826, %816, %795 : vector<8xf32>
    %828 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %829 = memref.load %assume_align[%arg0, %828, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %830 = vector.broadcast %829 : f32 to vector<8xf32>
    %831 = vector.fma %830, %816, %799 : vector<8xf32>
    %832 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %833 = memref.load %assume_align[%arg0, %832, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %834 = vector.broadcast %833 : f32 to vector<8xf32>
    %835 = vector.fma %834, %816, %803 : vector<8xf32>
    %836 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %837 = memref.load %assume_align[%arg0, %836, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %838 = vector.broadcast %837 : f32 to vector<8xf32>
    %839 = vector.fma %838, %816, %807 : vector<8xf32>
    %840 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %841 = memref.load %assume_align[%arg0, %840, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %842 = vector.broadcast %841 : f32 to vector<8xf32>
    %843 = vector.fma %842, %816, %811 : vector<8xf32>
    %844 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %845 = memref.load %assume_align[%arg0, %844, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %846 = vector.broadcast %845 : f32 to vector<8xf32>
    %847 = vector.fma %846, %816, %815 : vector<8xf32>
    %848 = vector.extract %7[26] : vector<8xf32> from vector<64x8xf32>
    %849 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %850 = vector.broadcast %849 : f32 to vector<8xf32>
    %851 = vector.fma %850, %848, %819 : vector<8xf32>
    %852 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %853 = memref.load %assume_align[%arg0, %852, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %854 = vector.broadcast %853 : f32 to vector<8xf32>
    %855 = vector.fma %854, %848, %823 : vector<8xf32>
    %856 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %857 = memref.load %assume_align[%arg0, %856, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %858 = vector.broadcast %857 : f32 to vector<8xf32>
    %859 = vector.fma %858, %848, %827 : vector<8xf32>
    %860 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %861 = memref.load %assume_align[%arg0, %860, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %862 = vector.broadcast %861 : f32 to vector<8xf32>
    %863 = vector.fma %862, %848, %831 : vector<8xf32>
    %864 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %865 = memref.load %assume_align[%arg0, %864, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %866 = vector.broadcast %865 : f32 to vector<8xf32>
    %867 = vector.fma %866, %848, %835 : vector<8xf32>
    %868 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %869 = memref.load %assume_align[%arg0, %868, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %870 = vector.broadcast %869 : f32 to vector<8xf32>
    %871 = vector.fma %870, %848, %839 : vector<8xf32>
    %872 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %873 = memref.load %assume_align[%arg0, %872, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %874 = vector.broadcast %873 : f32 to vector<8xf32>
    %875 = vector.fma %874, %848, %843 : vector<8xf32>
    %876 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %877 = memref.load %assume_align[%arg0, %876, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %878 = vector.broadcast %877 : f32 to vector<8xf32>
    %879 = vector.fma %878, %848, %847 : vector<8xf32>
    %880 = vector.extract %7[27] : vector<8xf32> from vector<64x8xf32>
    %881 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %882 = vector.broadcast %881 : f32 to vector<8xf32>
    %883 = vector.fma %882, %880, %851 : vector<8xf32>
    %884 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %885 = memref.load %assume_align[%arg0, %884, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %886 = vector.broadcast %885 : f32 to vector<8xf32>
    %887 = vector.fma %886, %880, %855 : vector<8xf32>
    %888 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %889 = memref.load %assume_align[%arg0, %888, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %890 = vector.broadcast %889 : f32 to vector<8xf32>
    %891 = vector.fma %890, %880, %859 : vector<8xf32>
    %892 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %893 = memref.load %assume_align[%arg0, %892, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %894 = vector.broadcast %893 : f32 to vector<8xf32>
    %895 = vector.fma %894, %880, %863 : vector<8xf32>
    %896 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %897 = memref.load %assume_align[%arg0, %896, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %898 = vector.broadcast %897 : f32 to vector<8xf32>
    %899 = vector.fma %898, %880, %867 : vector<8xf32>
    %900 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %901 = memref.load %assume_align[%arg0, %900, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %902 = vector.broadcast %901 : f32 to vector<8xf32>
    %903 = vector.fma %902, %880, %871 : vector<8xf32>
    %904 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %905 = memref.load %assume_align[%arg0, %904, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %906 = vector.broadcast %905 : f32 to vector<8xf32>
    %907 = vector.fma %906, %880, %875 : vector<8xf32>
    %908 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %909 = memref.load %assume_align[%arg0, %908, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %910 = vector.broadcast %909 : f32 to vector<8xf32>
    %911 = vector.fma %910, %880, %879 : vector<8xf32>
    %912 = vector.extract %7[28] : vector<8xf32> from vector<64x8xf32>
    %913 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %914 = vector.broadcast %913 : f32 to vector<8xf32>
    %915 = vector.fma %914, %912, %883 : vector<8xf32>
    %916 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %917 = memref.load %assume_align[%arg0, %916, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %918 = vector.broadcast %917 : f32 to vector<8xf32>
    %919 = vector.fma %918, %912, %887 : vector<8xf32>
    %920 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %921 = memref.load %assume_align[%arg0, %920, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %922 = vector.broadcast %921 : f32 to vector<8xf32>
    %923 = vector.fma %922, %912, %891 : vector<8xf32>
    %924 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %925 = memref.load %assume_align[%arg0, %924, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %926 = vector.broadcast %925 : f32 to vector<8xf32>
    %927 = vector.fma %926, %912, %895 : vector<8xf32>
    %928 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %929 = memref.load %assume_align[%arg0, %928, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %930 = vector.broadcast %929 : f32 to vector<8xf32>
    %931 = vector.fma %930, %912, %899 : vector<8xf32>
    %932 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %933 = memref.load %assume_align[%arg0, %932, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %934 = vector.broadcast %933 : f32 to vector<8xf32>
    %935 = vector.fma %934, %912, %903 : vector<8xf32>
    %936 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %937 = memref.load %assume_align[%arg0, %936, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %938 = vector.broadcast %937 : f32 to vector<8xf32>
    %939 = vector.fma %938, %912, %907 : vector<8xf32>
    %940 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %941 = memref.load %assume_align[%arg0, %940, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %942 = vector.broadcast %941 : f32 to vector<8xf32>
    %943 = vector.fma %942, %912, %911 : vector<8xf32>
    %944 = vector.extract %7[29] : vector<8xf32> from vector<64x8xf32>
    %945 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %946 = vector.broadcast %945 : f32 to vector<8xf32>
    %947 = vector.fma %946, %944, %915 : vector<8xf32>
    %948 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %949 = memref.load %assume_align[%arg0, %948, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %950 = vector.broadcast %949 : f32 to vector<8xf32>
    %951 = vector.fma %950, %944, %919 : vector<8xf32>
    %952 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %953 = memref.load %assume_align[%arg0, %952, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %954 = vector.broadcast %953 : f32 to vector<8xf32>
    %955 = vector.fma %954, %944, %923 : vector<8xf32>
    %956 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %957 = memref.load %assume_align[%arg0, %956, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %958 = vector.broadcast %957 : f32 to vector<8xf32>
    %959 = vector.fma %958, %944, %927 : vector<8xf32>
    %960 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %961 = memref.load %assume_align[%arg0, %960, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %962 = vector.broadcast %961 : f32 to vector<8xf32>
    %963 = vector.fma %962, %944, %931 : vector<8xf32>
    %964 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %965 = memref.load %assume_align[%arg0, %964, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %966 = vector.broadcast %965 : f32 to vector<8xf32>
    %967 = vector.fma %966, %944, %935 : vector<8xf32>
    %968 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %969 = memref.load %assume_align[%arg0, %968, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %970 = vector.broadcast %969 : f32 to vector<8xf32>
    %971 = vector.fma %970, %944, %939 : vector<8xf32>
    %972 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %973 = memref.load %assume_align[%arg0, %972, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %974 = vector.broadcast %973 : f32 to vector<8xf32>
    %975 = vector.fma %974, %944, %943 : vector<8xf32>
    %976 = vector.extract %7[30] : vector<8xf32> from vector<64x8xf32>
    %977 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %978 = vector.broadcast %977 : f32 to vector<8xf32>
    %979 = vector.fma %978, %976, %947 : vector<8xf32>
    %980 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %981 = memref.load %assume_align[%arg0, %980, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %982 = vector.broadcast %981 : f32 to vector<8xf32>
    %983 = vector.fma %982, %976, %951 : vector<8xf32>
    %984 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %985 = memref.load %assume_align[%arg0, %984, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %986 = vector.broadcast %985 : f32 to vector<8xf32>
    %987 = vector.fma %986, %976, %955 : vector<8xf32>
    %988 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %989 = memref.load %assume_align[%arg0, %988, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %990 = vector.broadcast %989 : f32 to vector<8xf32>
    %991 = vector.fma %990, %976, %959 : vector<8xf32>
    %992 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %993 = memref.load %assume_align[%arg0, %992, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %994 = vector.broadcast %993 : f32 to vector<8xf32>
    %995 = vector.fma %994, %976, %963 : vector<8xf32>
    %996 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %997 = memref.load %assume_align[%arg0, %996, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %998 = vector.broadcast %997 : f32 to vector<8xf32>
    %999 = vector.fma %998, %976, %967 : vector<8xf32>
    %1000 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1001 = memref.load %assume_align[%arg0, %1000, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1002 = vector.broadcast %1001 : f32 to vector<8xf32>
    %1003 = vector.fma %1002, %976, %971 : vector<8xf32>
    %1004 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1005 = memref.load %assume_align[%arg0, %1004, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1006 = vector.broadcast %1005 : f32 to vector<8xf32>
    %1007 = vector.fma %1006, %976, %975 : vector<8xf32>
    %1008 = vector.extract %7[31] : vector<8xf32> from vector<64x8xf32>
    %1009 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1010 = vector.broadcast %1009 : f32 to vector<8xf32>
    %1011 = vector.fma %1010, %1008, %979 : vector<8xf32>
    %1012 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1013 = memref.load %assume_align[%arg0, %1012, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1014 = vector.broadcast %1013 : f32 to vector<8xf32>
    %1015 = vector.fma %1014, %1008, %983 : vector<8xf32>
    %1016 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1017 = memref.load %assume_align[%arg0, %1016, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1018 = vector.broadcast %1017 : f32 to vector<8xf32>
    %1019 = vector.fma %1018, %1008, %987 : vector<8xf32>
    %1020 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1021 = memref.load %assume_align[%arg0, %1020, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1022 = vector.broadcast %1021 : f32 to vector<8xf32>
    %1023 = vector.fma %1022, %1008, %991 : vector<8xf32>
    %1024 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1025 = memref.load %assume_align[%arg0, %1024, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1026 = vector.broadcast %1025 : f32 to vector<8xf32>
    %1027 = vector.fma %1026, %1008, %995 : vector<8xf32>
    %1028 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1029 = memref.load %assume_align[%arg0, %1028, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1030 = vector.broadcast %1029 : f32 to vector<8xf32>
    %1031 = vector.fma %1030, %1008, %999 : vector<8xf32>
    %1032 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1033 = memref.load %assume_align[%arg0, %1032, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1034 = vector.broadcast %1033 : f32 to vector<8xf32>
    %1035 = vector.fma %1034, %1008, %1003 : vector<8xf32>
    %1036 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1037 = memref.load %assume_align[%arg0, %1036, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1038 = vector.broadcast %1037 : f32 to vector<8xf32>
    %1039 = vector.fma %1038, %1008, %1007 : vector<8xf32>
    %1040 = vector.extract %7[32] : vector<8xf32> from vector<64x8xf32>
    %1041 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1042 = vector.broadcast %1041 : f32 to vector<8xf32>
    %1043 = vector.fma %1042, %1040, %1011 : vector<8xf32>
    %1044 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1045 = memref.load %assume_align[%arg0, %1044, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1046 = vector.broadcast %1045 : f32 to vector<8xf32>
    %1047 = vector.fma %1046, %1040, %1015 : vector<8xf32>
    %1048 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1049 = memref.load %assume_align[%arg0, %1048, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1050 = vector.broadcast %1049 : f32 to vector<8xf32>
    %1051 = vector.fma %1050, %1040, %1019 : vector<8xf32>
    %1052 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1053 = memref.load %assume_align[%arg0, %1052, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1054 = vector.broadcast %1053 : f32 to vector<8xf32>
    %1055 = vector.fma %1054, %1040, %1023 : vector<8xf32>
    %1056 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1057 = memref.load %assume_align[%arg0, %1056, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1058 = vector.broadcast %1057 : f32 to vector<8xf32>
    %1059 = vector.fma %1058, %1040, %1027 : vector<8xf32>
    %1060 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1061 = memref.load %assume_align[%arg0, %1060, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1062 = vector.broadcast %1061 : f32 to vector<8xf32>
    %1063 = vector.fma %1062, %1040, %1031 : vector<8xf32>
    %1064 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1065 = memref.load %assume_align[%arg0, %1064, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1066 = vector.broadcast %1065 : f32 to vector<8xf32>
    %1067 = vector.fma %1066, %1040, %1035 : vector<8xf32>
    %1068 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1069 = memref.load %assume_align[%arg0, %1068, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1070 = vector.broadcast %1069 : f32 to vector<8xf32>
    %1071 = vector.fma %1070, %1040, %1039 : vector<8xf32>
    %1072 = vector.extract %7[33] : vector<8xf32> from vector<64x8xf32>
    %1073 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1074 = vector.broadcast %1073 : f32 to vector<8xf32>
    %1075 = vector.fma %1074, %1072, %1043 : vector<8xf32>
    %1076 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1077 = memref.load %assume_align[%arg0, %1076, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1078 = vector.broadcast %1077 : f32 to vector<8xf32>
    %1079 = vector.fma %1078, %1072, %1047 : vector<8xf32>
    %1080 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1081 = memref.load %assume_align[%arg0, %1080, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1082 = vector.broadcast %1081 : f32 to vector<8xf32>
    %1083 = vector.fma %1082, %1072, %1051 : vector<8xf32>
    %1084 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1085 = memref.load %assume_align[%arg0, %1084, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1086 = vector.broadcast %1085 : f32 to vector<8xf32>
    %1087 = vector.fma %1086, %1072, %1055 : vector<8xf32>
    %1088 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1089 = memref.load %assume_align[%arg0, %1088, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1090 = vector.broadcast %1089 : f32 to vector<8xf32>
    %1091 = vector.fma %1090, %1072, %1059 : vector<8xf32>
    %1092 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1093 = memref.load %assume_align[%arg0, %1092, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1094 = vector.broadcast %1093 : f32 to vector<8xf32>
    %1095 = vector.fma %1094, %1072, %1063 : vector<8xf32>
    %1096 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1097 = memref.load %assume_align[%arg0, %1096, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1098 = vector.broadcast %1097 : f32 to vector<8xf32>
    %1099 = vector.fma %1098, %1072, %1067 : vector<8xf32>
    %1100 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1101 = memref.load %assume_align[%arg0, %1100, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1102 = vector.broadcast %1101 : f32 to vector<8xf32>
    %1103 = vector.fma %1102, %1072, %1071 : vector<8xf32>
    %1104 = vector.extract %7[34] : vector<8xf32> from vector<64x8xf32>
    %1105 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1106 = vector.broadcast %1105 : f32 to vector<8xf32>
    %1107 = vector.fma %1106, %1104, %1075 : vector<8xf32>
    %1108 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1109 = memref.load %assume_align[%arg0, %1108, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1110 = vector.broadcast %1109 : f32 to vector<8xf32>
    %1111 = vector.fma %1110, %1104, %1079 : vector<8xf32>
    %1112 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1113 = memref.load %assume_align[%arg0, %1112, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1114 = vector.broadcast %1113 : f32 to vector<8xf32>
    %1115 = vector.fma %1114, %1104, %1083 : vector<8xf32>
    %1116 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1117 = memref.load %assume_align[%arg0, %1116, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1118 = vector.broadcast %1117 : f32 to vector<8xf32>
    %1119 = vector.fma %1118, %1104, %1087 : vector<8xf32>
    %1120 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1121 = memref.load %assume_align[%arg0, %1120, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1122 = vector.broadcast %1121 : f32 to vector<8xf32>
    %1123 = vector.fma %1122, %1104, %1091 : vector<8xf32>
    %1124 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1125 = memref.load %assume_align[%arg0, %1124, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1126 = vector.broadcast %1125 : f32 to vector<8xf32>
    %1127 = vector.fma %1126, %1104, %1095 : vector<8xf32>
    %1128 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1129 = memref.load %assume_align[%arg0, %1128, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1130 = vector.broadcast %1129 : f32 to vector<8xf32>
    %1131 = vector.fma %1130, %1104, %1099 : vector<8xf32>
    %1132 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1133 = memref.load %assume_align[%arg0, %1132, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1134 = vector.broadcast %1133 : f32 to vector<8xf32>
    %1135 = vector.fma %1134, %1104, %1103 : vector<8xf32>
    %1136 = vector.extract %7[35] : vector<8xf32> from vector<64x8xf32>
    %1137 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1138 = vector.broadcast %1137 : f32 to vector<8xf32>
    %1139 = vector.fma %1138, %1136, %1107 : vector<8xf32>
    %1140 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1141 = memref.load %assume_align[%arg0, %1140, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1142 = vector.broadcast %1141 : f32 to vector<8xf32>
    %1143 = vector.fma %1142, %1136, %1111 : vector<8xf32>
    %1144 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1145 = memref.load %assume_align[%arg0, %1144, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1146 = vector.broadcast %1145 : f32 to vector<8xf32>
    %1147 = vector.fma %1146, %1136, %1115 : vector<8xf32>
    %1148 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1149 = memref.load %assume_align[%arg0, %1148, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1150 = vector.broadcast %1149 : f32 to vector<8xf32>
    %1151 = vector.fma %1150, %1136, %1119 : vector<8xf32>
    %1152 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1153 = memref.load %assume_align[%arg0, %1152, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1154 = vector.broadcast %1153 : f32 to vector<8xf32>
    %1155 = vector.fma %1154, %1136, %1123 : vector<8xf32>
    %1156 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1157 = memref.load %assume_align[%arg0, %1156, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1158 = vector.broadcast %1157 : f32 to vector<8xf32>
    %1159 = vector.fma %1158, %1136, %1127 : vector<8xf32>
    %1160 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1161 = memref.load %assume_align[%arg0, %1160, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1162 = vector.broadcast %1161 : f32 to vector<8xf32>
    %1163 = vector.fma %1162, %1136, %1131 : vector<8xf32>
    %1164 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1165 = memref.load %assume_align[%arg0, %1164, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1166 = vector.broadcast %1165 : f32 to vector<8xf32>
    %1167 = vector.fma %1166, %1136, %1135 : vector<8xf32>
    %1168 = vector.extract %7[36] : vector<8xf32> from vector<64x8xf32>
    %1169 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1170 = vector.broadcast %1169 : f32 to vector<8xf32>
    %1171 = vector.fma %1170, %1168, %1139 : vector<8xf32>
    %1172 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1173 = memref.load %assume_align[%arg0, %1172, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1174 = vector.broadcast %1173 : f32 to vector<8xf32>
    %1175 = vector.fma %1174, %1168, %1143 : vector<8xf32>
    %1176 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1177 = memref.load %assume_align[%arg0, %1176, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1178 = vector.broadcast %1177 : f32 to vector<8xf32>
    %1179 = vector.fma %1178, %1168, %1147 : vector<8xf32>
    %1180 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1181 = memref.load %assume_align[%arg0, %1180, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1182 = vector.broadcast %1181 : f32 to vector<8xf32>
    %1183 = vector.fma %1182, %1168, %1151 : vector<8xf32>
    %1184 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1185 = memref.load %assume_align[%arg0, %1184, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1186 = vector.broadcast %1185 : f32 to vector<8xf32>
    %1187 = vector.fma %1186, %1168, %1155 : vector<8xf32>
    %1188 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1189 = memref.load %assume_align[%arg0, %1188, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1190 = vector.broadcast %1189 : f32 to vector<8xf32>
    %1191 = vector.fma %1190, %1168, %1159 : vector<8xf32>
    %1192 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1193 = memref.load %assume_align[%arg0, %1192, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1194 = vector.broadcast %1193 : f32 to vector<8xf32>
    %1195 = vector.fma %1194, %1168, %1163 : vector<8xf32>
    %1196 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1197 = memref.load %assume_align[%arg0, %1196, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1198 = vector.broadcast %1197 : f32 to vector<8xf32>
    %1199 = vector.fma %1198, %1168, %1167 : vector<8xf32>
    %1200 = vector.extract %7[37] : vector<8xf32> from vector<64x8xf32>
    %1201 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1202 = vector.broadcast %1201 : f32 to vector<8xf32>
    %1203 = vector.fma %1202, %1200, %1171 : vector<8xf32>
    %1204 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1205 = memref.load %assume_align[%arg0, %1204, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1206 = vector.broadcast %1205 : f32 to vector<8xf32>
    %1207 = vector.fma %1206, %1200, %1175 : vector<8xf32>
    %1208 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1209 = memref.load %assume_align[%arg0, %1208, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1210 = vector.broadcast %1209 : f32 to vector<8xf32>
    %1211 = vector.fma %1210, %1200, %1179 : vector<8xf32>
    %1212 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1213 = memref.load %assume_align[%arg0, %1212, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1214 = vector.broadcast %1213 : f32 to vector<8xf32>
    %1215 = vector.fma %1214, %1200, %1183 : vector<8xf32>
    %1216 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1217 = memref.load %assume_align[%arg0, %1216, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1218 = vector.broadcast %1217 : f32 to vector<8xf32>
    %1219 = vector.fma %1218, %1200, %1187 : vector<8xf32>
    %1220 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1221 = memref.load %assume_align[%arg0, %1220, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1222 = vector.broadcast %1221 : f32 to vector<8xf32>
    %1223 = vector.fma %1222, %1200, %1191 : vector<8xf32>
    %1224 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1225 = memref.load %assume_align[%arg0, %1224, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1226 = vector.broadcast %1225 : f32 to vector<8xf32>
    %1227 = vector.fma %1226, %1200, %1195 : vector<8xf32>
    %1228 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1229 = memref.load %assume_align[%arg0, %1228, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1230 = vector.broadcast %1229 : f32 to vector<8xf32>
    %1231 = vector.fma %1230, %1200, %1199 : vector<8xf32>
    %1232 = vector.extract %7[38] : vector<8xf32> from vector<64x8xf32>
    %1233 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1234 = vector.broadcast %1233 : f32 to vector<8xf32>
    %1235 = vector.fma %1234, %1232, %1203 : vector<8xf32>
    %1236 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1237 = memref.load %assume_align[%arg0, %1236, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1238 = vector.broadcast %1237 : f32 to vector<8xf32>
    %1239 = vector.fma %1238, %1232, %1207 : vector<8xf32>
    %1240 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1241 = memref.load %assume_align[%arg0, %1240, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1242 = vector.broadcast %1241 : f32 to vector<8xf32>
    %1243 = vector.fma %1242, %1232, %1211 : vector<8xf32>
    %1244 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1245 = memref.load %assume_align[%arg0, %1244, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1246 = vector.broadcast %1245 : f32 to vector<8xf32>
    %1247 = vector.fma %1246, %1232, %1215 : vector<8xf32>
    %1248 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1249 = memref.load %assume_align[%arg0, %1248, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1250 = vector.broadcast %1249 : f32 to vector<8xf32>
    %1251 = vector.fma %1250, %1232, %1219 : vector<8xf32>
    %1252 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1253 = memref.load %assume_align[%arg0, %1252, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1254 = vector.broadcast %1253 : f32 to vector<8xf32>
    %1255 = vector.fma %1254, %1232, %1223 : vector<8xf32>
    %1256 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1257 = memref.load %assume_align[%arg0, %1256, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1258 = vector.broadcast %1257 : f32 to vector<8xf32>
    %1259 = vector.fma %1258, %1232, %1227 : vector<8xf32>
    %1260 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1261 = memref.load %assume_align[%arg0, %1260, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1262 = vector.broadcast %1261 : f32 to vector<8xf32>
    %1263 = vector.fma %1262, %1232, %1231 : vector<8xf32>
    %1264 = vector.extract %7[39] : vector<8xf32> from vector<64x8xf32>
    %1265 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1266 = vector.broadcast %1265 : f32 to vector<8xf32>
    %1267 = vector.fma %1266, %1264, %1235 : vector<8xf32>
    %1268 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1269 = memref.load %assume_align[%arg0, %1268, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1270 = vector.broadcast %1269 : f32 to vector<8xf32>
    %1271 = vector.fma %1270, %1264, %1239 : vector<8xf32>
    %1272 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1273 = memref.load %assume_align[%arg0, %1272, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1274 = vector.broadcast %1273 : f32 to vector<8xf32>
    %1275 = vector.fma %1274, %1264, %1243 : vector<8xf32>
    %1276 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1277 = memref.load %assume_align[%arg0, %1276, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1278 = vector.broadcast %1277 : f32 to vector<8xf32>
    %1279 = vector.fma %1278, %1264, %1247 : vector<8xf32>
    %1280 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1281 = memref.load %assume_align[%arg0, %1280, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1282 = vector.broadcast %1281 : f32 to vector<8xf32>
    %1283 = vector.fma %1282, %1264, %1251 : vector<8xf32>
    %1284 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1285 = memref.load %assume_align[%arg0, %1284, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1286 = vector.broadcast %1285 : f32 to vector<8xf32>
    %1287 = vector.fma %1286, %1264, %1255 : vector<8xf32>
    %1288 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1289 = memref.load %assume_align[%arg0, %1288, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1290 = vector.broadcast %1289 : f32 to vector<8xf32>
    %1291 = vector.fma %1290, %1264, %1259 : vector<8xf32>
    %1292 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1293 = memref.load %assume_align[%arg0, %1292, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1294 = vector.broadcast %1293 : f32 to vector<8xf32>
    %1295 = vector.fma %1294, %1264, %1263 : vector<8xf32>
    %1296 = vector.extract %7[40] : vector<8xf32> from vector<64x8xf32>
    %1297 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1298 = vector.broadcast %1297 : f32 to vector<8xf32>
    %1299 = vector.fma %1298, %1296, %1267 : vector<8xf32>
    %1300 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1301 = memref.load %assume_align[%arg0, %1300, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1302 = vector.broadcast %1301 : f32 to vector<8xf32>
    %1303 = vector.fma %1302, %1296, %1271 : vector<8xf32>
    %1304 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1305 = memref.load %assume_align[%arg0, %1304, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1306 = vector.broadcast %1305 : f32 to vector<8xf32>
    %1307 = vector.fma %1306, %1296, %1275 : vector<8xf32>
    %1308 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1309 = memref.load %assume_align[%arg0, %1308, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1310 = vector.broadcast %1309 : f32 to vector<8xf32>
    %1311 = vector.fma %1310, %1296, %1279 : vector<8xf32>
    %1312 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1313 = memref.load %assume_align[%arg0, %1312, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1314 = vector.broadcast %1313 : f32 to vector<8xf32>
    %1315 = vector.fma %1314, %1296, %1283 : vector<8xf32>
    %1316 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1317 = memref.load %assume_align[%arg0, %1316, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1318 = vector.broadcast %1317 : f32 to vector<8xf32>
    %1319 = vector.fma %1318, %1296, %1287 : vector<8xf32>
    %1320 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1321 = memref.load %assume_align[%arg0, %1320, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1322 = vector.broadcast %1321 : f32 to vector<8xf32>
    %1323 = vector.fma %1322, %1296, %1291 : vector<8xf32>
    %1324 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1325 = memref.load %assume_align[%arg0, %1324, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1326 = vector.broadcast %1325 : f32 to vector<8xf32>
    %1327 = vector.fma %1326, %1296, %1295 : vector<8xf32>
    %1328 = vector.extract %7[41] : vector<8xf32> from vector<64x8xf32>
    %1329 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1330 = vector.broadcast %1329 : f32 to vector<8xf32>
    %1331 = vector.fma %1330, %1328, %1299 : vector<8xf32>
    %1332 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1333 = memref.load %assume_align[%arg0, %1332, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1334 = vector.broadcast %1333 : f32 to vector<8xf32>
    %1335 = vector.fma %1334, %1328, %1303 : vector<8xf32>
    %1336 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1337 = memref.load %assume_align[%arg0, %1336, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1338 = vector.broadcast %1337 : f32 to vector<8xf32>
    %1339 = vector.fma %1338, %1328, %1307 : vector<8xf32>
    %1340 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1341 = memref.load %assume_align[%arg0, %1340, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1342 = vector.broadcast %1341 : f32 to vector<8xf32>
    %1343 = vector.fma %1342, %1328, %1311 : vector<8xf32>
    %1344 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1345 = memref.load %assume_align[%arg0, %1344, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1346 = vector.broadcast %1345 : f32 to vector<8xf32>
    %1347 = vector.fma %1346, %1328, %1315 : vector<8xf32>
    %1348 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1349 = memref.load %assume_align[%arg0, %1348, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1350 = vector.broadcast %1349 : f32 to vector<8xf32>
    %1351 = vector.fma %1350, %1328, %1319 : vector<8xf32>
    %1352 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1353 = memref.load %assume_align[%arg0, %1352, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1354 = vector.broadcast %1353 : f32 to vector<8xf32>
    %1355 = vector.fma %1354, %1328, %1323 : vector<8xf32>
    %1356 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1357 = memref.load %assume_align[%arg0, %1356, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1358 = vector.broadcast %1357 : f32 to vector<8xf32>
    %1359 = vector.fma %1358, %1328, %1327 : vector<8xf32>
    %1360 = vector.extract %7[42] : vector<8xf32> from vector<64x8xf32>
    %1361 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1362 = vector.broadcast %1361 : f32 to vector<8xf32>
    %1363 = vector.fma %1362, %1360, %1331 : vector<8xf32>
    %1364 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1365 = memref.load %assume_align[%arg0, %1364, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1366 = vector.broadcast %1365 : f32 to vector<8xf32>
    %1367 = vector.fma %1366, %1360, %1335 : vector<8xf32>
    %1368 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1369 = memref.load %assume_align[%arg0, %1368, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1370 = vector.broadcast %1369 : f32 to vector<8xf32>
    %1371 = vector.fma %1370, %1360, %1339 : vector<8xf32>
    %1372 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1373 = memref.load %assume_align[%arg0, %1372, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1374 = vector.broadcast %1373 : f32 to vector<8xf32>
    %1375 = vector.fma %1374, %1360, %1343 : vector<8xf32>
    %1376 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1377 = memref.load %assume_align[%arg0, %1376, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1378 = vector.broadcast %1377 : f32 to vector<8xf32>
    %1379 = vector.fma %1378, %1360, %1347 : vector<8xf32>
    %1380 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1381 = memref.load %assume_align[%arg0, %1380, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1382 = vector.broadcast %1381 : f32 to vector<8xf32>
    %1383 = vector.fma %1382, %1360, %1351 : vector<8xf32>
    %1384 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1385 = memref.load %assume_align[%arg0, %1384, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1386 = vector.broadcast %1385 : f32 to vector<8xf32>
    %1387 = vector.fma %1386, %1360, %1355 : vector<8xf32>
    %1388 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1389 = memref.load %assume_align[%arg0, %1388, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1390 = vector.broadcast %1389 : f32 to vector<8xf32>
    %1391 = vector.fma %1390, %1360, %1359 : vector<8xf32>
    %1392 = vector.extract %7[43] : vector<8xf32> from vector<64x8xf32>
    %1393 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1394 = vector.broadcast %1393 : f32 to vector<8xf32>
    %1395 = vector.fma %1394, %1392, %1363 : vector<8xf32>
    %1396 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1397 = memref.load %assume_align[%arg0, %1396, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1398 = vector.broadcast %1397 : f32 to vector<8xf32>
    %1399 = vector.fma %1398, %1392, %1367 : vector<8xf32>
    %1400 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1401 = memref.load %assume_align[%arg0, %1400, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1402 = vector.broadcast %1401 : f32 to vector<8xf32>
    %1403 = vector.fma %1402, %1392, %1371 : vector<8xf32>
    %1404 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1405 = memref.load %assume_align[%arg0, %1404, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1406 = vector.broadcast %1405 : f32 to vector<8xf32>
    %1407 = vector.fma %1406, %1392, %1375 : vector<8xf32>
    %1408 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1409 = memref.load %assume_align[%arg0, %1408, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1410 = vector.broadcast %1409 : f32 to vector<8xf32>
    %1411 = vector.fma %1410, %1392, %1379 : vector<8xf32>
    %1412 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1413 = memref.load %assume_align[%arg0, %1412, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1414 = vector.broadcast %1413 : f32 to vector<8xf32>
    %1415 = vector.fma %1414, %1392, %1383 : vector<8xf32>
    %1416 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1417 = memref.load %assume_align[%arg0, %1416, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1418 = vector.broadcast %1417 : f32 to vector<8xf32>
    %1419 = vector.fma %1418, %1392, %1387 : vector<8xf32>
    %1420 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1421 = memref.load %assume_align[%arg0, %1420, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1422 = vector.broadcast %1421 : f32 to vector<8xf32>
    %1423 = vector.fma %1422, %1392, %1391 : vector<8xf32>
    %1424 = vector.extract %7[44] : vector<8xf32> from vector<64x8xf32>
    %1425 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1426 = vector.broadcast %1425 : f32 to vector<8xf32>
    %1427 = vector.fma %1426, %1424, %1395 : vector<8xf32>
    %1428 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1429 = memref.load %assume_align[%arg0, %1428, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1430 = vector.broadcast %1429 : f32 to vector<8xf32>
    %1431 = vector.fma %1430, %1424, %1399 : vector<8xf32>
    %1432 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1433 = memref.load %assume_align[%arg0, %1432, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1434 = vector.broadcast %1433 : f32 to vector<8xf32>
    %1435 = vector.fma %1434, %1424, %1403 : vector<8xf32>
    %1436 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1437 = memref.load %assume_align[%arg0, %1436, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1438 = vector.broadcast %1437 : f32 to vector<8xf32>
    %1439 = vector.fma %1438, %1424, %1407 : vector<8xf32>
    %1440 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1441 = memref.load %assume_align[%arg0, %1440, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1442 = vector.broadcast %1441 : f32 to vector<8xf32>
    %1443 = vector.fma %1442, %1424, %1411 : vector<8xf32>
    %1444 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1445 = memref.load %assume_align[%arg0, %1444, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1446 = vector.broadcast %1445 : f32 to vector<8xf32>
    %1447 = vector.fma %1446, %1424, %1415 : vector<8xf32>
    %1448 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1449 = memref.load %assume_align[%arg0, %1448, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1450 = vector.broadcast %1449 : f32 to vector<8xf32>
    %1451 = vector.fma %1450, %1424, %1419 : vector<8xf32>
    %1452 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1453 = memref.load %assume_align[%arg0, %1452, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1454 = vector.broadcast %1453 : f32 to vector<8xf32>
    %1455 = vector.fma %1454, %1424, %1423 : vector<8xf32>
    %1456 = vector.extract %7[45] : vector<8xf32> from vector<64x8xf32>
    %1457 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1458 = vector.broadcast %1457 : f32 to vector<8xf32>
    %1459 = vector.fma %1458, %1456, %1427 : vector<8xf32>
    %1460 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1461 = memref.load %assume_align[%arg0, %1460, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1462 = vector.broadcast %1461 : f32 to vector<8xf32>
    %1463 = vector.fma %1462, %1456, %1431 : vector<8xf32>
    %1464 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1465 = memref.load %assume_align[%arg0, %1464, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1466 = vector.broadcast %1465 : f32 to vector<8xf32>
    %1467 = vector.fma %1466, %1456, %1435 : vector<8xf32>
    %1468 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1469 = memref.load %assume_align[%arg0, %1468, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1470 = vector.broadcast %1469 : f32 to vector<8xf32>
    %1471 = vector.fma %1470, %1456, %1439 : vector<8xf32>
    %1472 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1473 = memref.load %assume_align[%arg0, %1472, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1474 = vector.broadcast %1473 : f32 to vector<8xf32>
    %1475 = vector.fma %1474, %1456, %1443 : vector<8xf32>
    %1476 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1477 = memref.load %assume_align[%arg0, %1476, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1478 = vector.broadcast %1477 : f32 to vector<8xf32>
    %1479 = vector.fma %1478, %1456, %1447 : vector<8xf32>
    %1480 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1481 = memref.load %assume_align[%arg0, %1480, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1482 = vector.broadcast %1481 : f32 to vector<8xf32>
    %1483 = vector.fma %1482, %1456, %1451 : vector<8xf32>
    %1484 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1485 = memref.load %assume_align[%arg0, %1484, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1486 = vector.broadcast %1485 : f32 to vector<8xf32>
    %1487 = vector.fma %1486, %1456, %1455 : vector<8xf32>
    %1488 = vector.extract %7[46] : vector<8xf32> from vector<64x8xf32>
    %1489 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1490 = vector.broadcast %1489 : f32 to vector<8xf32>
    %1491 = vector.fma %1490, %1488, %1459 : vector<8xf32>
    %1492 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1493 = memref.load %assume_align[%arg0, %1492, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1494 = vector.broadcast %1493 : f32 to vector<8xf32>
    %1495 = vector.fma %1494, %1488, %1463 : vector<8xf32>
    %1496 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1497 = memref.load %assume_align[%arg0, %1496, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1498 = vector.broadcast %1497 : f32 to vector<8xf32>
    %1499 = vector.fma %1498, %1488, %1467 : vector<8xf32>
    %1500 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1501 = memref.load %assume_align[%arg0, %1500, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1502 = vector.broadcast %1501 : f32 to vector<8xf32>
    %1503 = vector.fma %1502, %1488, %1471 : vector<8xf32>
    %1504 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1505 = memref.load %assume_align[%arg0, %1504, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1506 = vector.broadcast %1505 : f32 to vector<8xf32>
    %1507 = vector.fma %1506, %1488, %1475 : vector<8xf32>
    %1508 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1509 = memref.load %assume_align[%arg0, %1508, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1510 = vector.broadcast %1509 : f32 to vector<8xf32>
    %1511 = vector.fma %1510, %1488, %1479 : vector<8xf32>
    %1512 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1513 = memref.load %assume_align[%arg0, %1512, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1514 = vector.broadcast %1513 : f32 to vector<8xf32>
    %1515 = vector.fma %1514, %1488, %1483 : vector<8xf32>
    %1516 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1517 = memref.load %assume_align[%arg0, %1516, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1518 = vector.broadcast %1517 : f32 to vector<8xf32>
    %1519 = vector.fma %1518, %1488, %1487 : vector<8xf32>
    %1520 = vector.extract %7[47] : vector<8xf32> from vector<64x8xf32>
    %1521 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1522 = vector.broadcast %1521 : f32 to vector<8xf32>
    %1523 = vector.fma %1522, %1520, %1491 : vector<8xf32>
    %1524 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1525 = memref.load %assume_align[%arg0, %1524, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1526 = vector.broadcast %1525 : f32 to vector<8xf32>
    %1527 = vector.fma %1526, %1520, %1495 : vector<8xf32>
    %1528 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1529 = memref.load %assume_align[%arg0, %1528, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1530 = vector.broadcast %1529 : f32 to vector<8xf32>
    %1531 = vector.fma %1530, %1520, %1499 : vector<8xf32>
    %1532 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1533 = memref.load %assume_align[%arg0, %1532, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1534 = vector.broadcast %1533 : f32 to vector<8xf32>
    %1535 = vector.fma %1534, %1520, %1503 : vector<8xf32>
    %1536 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1537 = memref.load %assume_align[%arg0, %1536, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1538 = vector.broadcast %1537 : f32 to vector<8xf32>
    %1539 = vector.fma %1538, %1520, %1507 : vector<8xf32>
    %1540 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1541 = memref.load %assume_align[%arg0, %1540, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1542 = vector.broadcast %1541 : f32 to vector<8xf32>
    %1543 = vector.fma %1542, %1520, %1511 : vector<8xf32>
    %1544 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1545 = memref.load %assume_align[%arg0, %1544, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1546 = vector.broadcast %1545 : f32 to vector<8xf32>
    %1547 = vector.fma %1546, %1520, %1515 : vector<8xf32>
    %1548 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1549 = memref.load %assume_align[%arg0, %1548, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1550 = vector.broadcast %1549 : f32 to vector<8xf32>
    %1551 = vector.fma %1550, %1520, %1519 : vector<8xf32>
    %1552 = vector.extract %7[48] : vector<8xf32> from vector<64x8xf32>
    %1553 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1554 = vector.broadcast %1553 : f32 to vector<8xf32>
    %1555 = vector.fma %1554, %1552, %1523 : vector<8xf32>
    %1556 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1557 = memref.load %assume_align[%arg0, %1556, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1558 = vector.broadcast %1557 : f32 to vector<8xf32>
    %1559 = vector.fma %1558, %1552, %1527 : vector<8xf32>
    %1560 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1561 = memref.load %assume_align[%arg0, %1560, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1562 = vector.broadcast %1561 : f32 to vector<8xf32>
    %1563 = vector.fma %1562, %1552, %1531 : vector<8xf32>
    %1564 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1565 = memref.load %assume_align[%arg0, %1564, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1566 = vector.broadcast %1565 : f32 to vector<8xf32>
    %1567 = vector.fma %1566, %1552, %1535 : vector<8xf32>
    %1568 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1569 = memref.load %assume_align[%arg0, %1568, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1570 = vector.broadcast %1569 : f32 to vector<8xf32>
    %1571 = vector.fma %1570, %1552, %1539 : vector<8xf32>
    %1572 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1573 = memref.load %assume_align[%arg0, %1572, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1574 = vector.broadcast %1573 : f32 to vector<8xf32>
    %1575 = vector.fma %1574, %1552, %1543 : vector<8xf32>
    %1576 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1577 = memref.load %assume_align[%arg0, %1576, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1578 = vector.broadcast %1577 : f32 to vector<8xf32>
    %1579 = vector.fma %1578, %1552, %1547 : vector<8xf32>
    %1580 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1581 = memref.load %assume_align[%arg0, %1580, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1582 = vector.broadcast %1581 : f32 to vector<8xf32>
    %1583 = vector.fma %1582, %1552, %1551 : vector<8xf32>
    %1584 = vector.extract %7[49] : vector<8xf32> from vector<64x8xf32>
    %1585 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1586 = vector.broadcast %1585 : f32 to vector<8xf32>
    %1587 = vector.fma %1586, %1584, %1555 : vector<8xf32>
    %1588 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1589 = memref.load %assume_align[%arg0, %1588, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1590 = vector.broadcast %1589 : f32 to vector<8xf32>
    %1591 = vector.fma %1590, %1584, %1559 : vector<8xf32>
    %1592 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1593 = memref.load %assume_align[%arg0, %1592, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1594 = vector.broadcast %1593 : f32 to vector<8xf32>
    %1595 = vector.fma %1594, %1584, %1563 : vector<8xf32>
    %1596 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1597 = memref.load %assume_align[%arg0, %1596, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1598 = vector.broadcast %1597 : f32 to vector<8xf32>
    %1599 = vector.fma %1598, %1584, %1567 : vector<8xf32>
    %1600 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1601 = memref.load %assume_align[%arg0, %1600, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1602 = vector.broadcast %1601 : f32 to vector<8xf32>
    %1603 = vector.fma %1602, %1584, %1571 : vector<8xf32>
    %1604 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1605 = memref.load %assume_align[%arg0, %1604, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1606 = vector.broadcast %1605 : f32 to vector<8xf32>
    %1607 = vector.fma %1606, %1584, %1575 : vector<8xf32>
    %1608 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1609 = memref.load %assume_align[%arg0, %1608, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1610 = vector.broadcast %1609 : f32 to vector<8xf32>
    %1611 = vector.fma %1610, %1584, %1579 : vector<8xf32>
    %1612 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1613 = memref.load %assume_align[%arg0, %1612, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1614 = vector.broadcast %1613 : f32 to vector<8xf32>
    %1615 = vector.fma %1614, %1584, %1583 : vector<8xf32>
    %1616 = vector.extract %7[50] : vector<8xf32> from vector<64x8xf32>
    %1617 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1618 = vector.broadcast %1617 : f32 to vector<8xf32>
    %1619 = vector.fma %1618, %1616, %1587 : vector<8xf32>
    %1620 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1621 = memref.load %assume_align[%arg0, %1620, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1622 = vector.broadcast %1621 : f32 to vector<8xf32>
    %1623 = vector.fma %1622, %1616, %1591 : vector<8xf32>
    %1624 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1625 = memref.load %assume_align[%arg0, %1624, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1626 = vector.broadcast %1625 : f32 to vector<8xf32>
    %1627 = vector.fma %1626, %1616, %1595 : vector<8xf32>
    %1628 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1629 = memref.load %assume_align[%arg0, %1628, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1630 = vector.broadcast %1629 : f32 to vector<8xf32>
    %1631 = vector.fma %1630, %1616, %1599 : vector<8xf32>
    %1632 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1633 = memref.load %assume_align[%arg0, %1632, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1634 = vector.broadcast %1633 : f32 to vector<8xf32>
    %1635 = vector.fma %1634, %1616, %1603 : vector<8xf32>
    %1636 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1637 = memref.load %assume_align[%arg0, %1636, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1638 = vector.broadcast %1637 : f32 to vector<8xf32>
    %1639 = vector.fma %1638, %1616, %1607 : vector<8xf32>
    %1640 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1641 = memref.load %assume_align[%arg0, %1640, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1642 = vector.broadcast %1641 : f32 to vector<8xf32>
    %1643 = vector.fma %1642, %1616, %1611 : vector<8xf32>
    %1644 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1645 = memref.load %assume_align[%arg0, %1644, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1646 = vector.broadcast %1645 : f32 to vector<8xf32>
    %1647 = vector.fma %1646, %1616, %1615 : vector<8xf32>
    %1648 = vector.extract %7[51] : vector<8xf32> from vector<64x8xf32>
    %1649 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1650 = vector.broadcast %1649 : f32 to vector<8xf32>
    %1651 = vector.fma %1650, %1648, %1619 : vector<8xf32>
    %1652 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1653 = memref.load %assume_align[%arg0, %1652, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1654 = vector.broadcast %1653 : f32 to vector<8xf32>
    %1655 = vector.fma %1654, %1648, %1623 : vector<8xf32>
    %1656 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1657 = memref.load %assume_align[%arg0, %1656, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1658 = vector.broadcast %1657 : f32 to vector<8xf32>
    %1659 = vector.fma %1658, %1648, %1627 : vector<8xf32>
    %1660 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1661 = memref.load %assume_align[%arg0, %1660, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1662 = vector.broadcast %1661 : f32 to vector<8xf32>
    %1663 = vector.fma %1662, %1648, %1631 : vector<8xf32>
    %1664 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1665 = memref.load %assume_align[%arg0, %1664, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1666 = vector.broadcast %1665 : f32 to vector<8xf32>
    %1667 = vector.fma %1666, %1648, %1635 : vector<8xf32>
    %1668 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1669 = memref.load %assume_align[%arg0, %1668, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1670 = vector.broadcast %1669 : f32 to vector<8xf32>
    %1671 = vector.fma %1670, %1648, %1639 : vector<8xf32>
    %1672 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1673 = memref.load %assume_align[%arg0, %1672, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1674 = vector.broadcast %1673 : f32 to vector<8xf32>
    %1675 = vector.fma %1674, %1648, %1643 : vector<8xf32>
    %1676 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1677 = memref.load %assume_align[%arg0, %1676, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1678 = vector.broadcast %1677 : f32 to vector<8xf32>
    %1679 = vector.fma %1678, %1648, %1647 : vector<8xf32>
    %1680 = vector.extract %7[52] : vector<8xf32> from vector<64x8xf32>
    %1681 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1682 = vector.broadcast %1681 : f32 to vector<8xf32>
    %1683 = vector.fma %1682, %1680, %1651 : vector<8xf32>
    %1684 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1685 = memref.load %assume_align[%arg0, %1684, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1686 = vector.broadcast %1685 : f32 to vector<8xf32>
    %1687 = vector.fma %1686, %1680, %1655 : vector<8xf32>
    %1688 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1689 = memref.load %assume_align[%arg0, %1688, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1690 = vector.broadcast %1689 : f32 to vector<8xf32>
    %1691 = vector.fma %1690, %1680, %1659 : vector<8xf32>
    %1692 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1693 = memref.load %assume_align[%arg0, %1692, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1694 = vector.broadcast %1693 : f32 to vector<8xf32>
    %1695 = vector.fma %1694, %1680, %1663 : vector<8xf32>
    %1696 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1697 = memref.load %assume_align[%arg0, %1696, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1698 = vector.broadcast %1697 : f32 to vector<8xf32>
    %1699 = vector.fma %1698, %1680, %1667 : vector<8xf32>
    %1700 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1701 = memref.load %assume_align[%arg0, %1700, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1702 = vector.broadcast %1701 : f32 to vector<8xf32>
    %1703 = vector.fma %1702, %1680, %1671 : vector<8xf32>
    %1704 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1705 = memref.load %assume_align[%arg0, %1704, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1706 = vector.broadcast %1705 : f32 to vector<8xf32>
    %1707 = vector.fma %1706, %1680, %1675 : vector<8xf32>
    %1708 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1709 = memref.load %assume_align[%arg0, %1708, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1710 = vector.broadcast %1709 : f32 to vector<8xf32>
    %1711 = vector.fma %1710, %1680, %1679 : vector<8xf32>
    %1712 = vector.extract %7[53] : vector<8xf32> from vector<64x8xf32>
    %1713 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1714 = vector.broadcast %1713 : f32 to vector<8xf32>
    %1715 = vector.fma %1714, %1712, %1683 : vector<8xf32>
    %1716 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1717 = memref.load %assume_align[%arg0, %1716, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1718 = vector.broadcast %1717 : f32 to vector<8xf32>
    %1719 = vector.fma %1718, %1712, %1687 : vector<8xf32>
    %1720 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1721 = memref.load %assume_align[%arg0, %1720, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1722 = vector.broadcast %1721 : f32 to vector<8xf32>
    %1723 = vector.fma %1722, %1712, %1691 : vector<8xf32>
    %1724 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1725 = memref.load %assume_align[%arg0, %1724, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1726 = vector.broadcast %1725 : f32 to vector<8xf32>
    %1727 = vector.fma %1726, %1712, %1695 : vector<8xf32>
    %1728 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1729 = memref.load %assume_align[%arg0, %1728, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1730 = vector.broadcast %1729 : f32 to vector<8xf32>
    %1731 = vector.fma %1730, %1712, %1699 : vector<8xf32>
    %1732 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1733 = memref.load %assume_align[%arg0, %1732, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1734 = vector.broadcast %1733 : f32 to vector<8xf32>
    %1735 = vector.fma %1734, %1712, %1703 : vector<8xf32>
    %1736 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1737 = memref.load %assume_align[%arg0, %1736, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1738 = vector.broadcast %1737 : f32 to vector<8xf32>
    %1739 = vector.fma %1738, %1712, %1707 : vector<8xf32>
    %1740 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1741 = memref.load %assume_align[%arg0, %1740, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1742 = vector.broadcast %1741 : f32 to vector<8xf32>
    %1743 = vector.fma %1742, %1712, %1711 : vector<8xf32>
    %1744 = vector.extract %7[54] : vector<8xf32> from vector<64x8xf32>
    %1745 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1746 = vector.broadcast %1745 : f32 to vector<8xf32>
    %1747 = vector.fma %1746, %1744, %1715 : vector<8xf32>
    %1748 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1749 = memref.load %assume_align[%arg0, %1748, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1750 = vector.broadcast %1749 : f32 to vector<8xf32>
    %1751 = vector.fma %1750, %1744, %1719 : vector<8xf32>
    %1752 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1753 = memref.load %assume_align[%arg0, %1752, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1754 = vector.broadcast %1753 : f32 to vector<8xf32>
    %1755 = vector.fma %1754, %1744, %1723 : vector<8xf32>
    %1756 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1757 = memref.load %assume_align[%arg0, %1756, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1758 = vector.broadcast %1757 : f32 to vector<8xf32>
    %1759 = vector.fma %1758, %1744, %1727 : vector<8xf32>
    %1760 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1761 = memref.load %assume_align[%arg0, %1760, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1762 = vector.broadcast %1761 : f32 to vector<8xf32>
    %1763 = vector.fma %1762, %1744, %1731 : vector<8xf32>
    %1764 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1765 = memref.load %assume_align[%arg0, %1764, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1766 = vector.broadcast %1765 : f32 to vector<8xf32>
    %1767 = vector.fma %1766, %1744, %1735 : vector<8xf32>
    %1768 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1769 = memref.load %assume_align[%arg0, %1768, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1770 = vector.broadcast %1769 : f32 to vector<8xf32>
    %1771 = vector.fma %1770, %1744, %1739 : vector<8xf32>
    %1772 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1773 = memref.load %assume_align[%arg0, %1772, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1774 = vector.broadcast %1773 : f32 to vector<8xf32>
    %1775 = vector.fma %1774, %1744, %1743 : vector<8xf32>
    %1776 = vector.extract %7[55] : vector<8xf32> from vector<64x8xf32>
    %1777 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1778 = vector.broadcast %1777 : f32 to vector<8xf32>
    %1779 = vector.fma %1778, %1776, %1747 : vector<8xf32>
    %1780 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1781 = memref.load %assume_align[%arg0, %1780, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1782 = vector.broadcast %1781 : f32 to vector<8xf32>
    %1783 = vector.fma %1782, %1776, %1751 : vector<8xf32>
    %1784 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1785 = memref.load %assume_align[%arg0, %1784, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1786 = vector.broadcast %1785 : f32 to vector<8xf32>
    %1787 = vector.fma %1786, %1776, %1755 : vector<8xf32>
    %1788 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1789 = memref.load %assume_align[%arg0, %1788, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1790 = vector.broadcast %1789 : f32 to vector<8xf32>
    %1791 = vector.fma %1790, %1776, %1759 : vector<8xf32>
    %1792 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1793 = memref.load %assume_align[%arg0, %1792, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1794 = vector.broadcast %1793 : f32 to vector<8xf32>
    %1795 = vector.fma %1794, %1776, %1763 : vector<8xf32>
    %1796 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1797 = memref.load %assume_align[%arg0, %1796, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1798 = vector.broadcast %1797 : f32 to vector<8xf32>
    %1799 = vector.fma %1798, %1776, %1767 : vector<8xf32>
    %1800 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1801 = memref.load %assume_align[%arg0, %1800, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1802 = vector.broadcast %1801 : f32 to vector<8xf32>
    %1803 = vector.fma %1802, %1776, %1771 : vector<8xf32>
    %1804 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1805 = memref.load %assume_align[%arg0, %1804, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1806 = vector.broadcast %1805 : f32 to vector<8xf32>
    %1807 = vector.fma %1806, %1776, %1775 : vector<8xf32>
    %1808 = vector.extract %7[56] : vector<8xf32> from vector<64x8xf32>
    %1809 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1810 = vector.broadcast %1809 : f32 to vector<8xf32>
    %1811 = vector.fma %1810, %1808, %1779 : vector<8xf32>
    %1812 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1813 = memref.load %assume_align[%arg0, %1812, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1814 = vector.broadcast %1813 : f32 to vector<8xf32>
    %1815 = vector.fma %1814, %1808, %1783 : vector<8xf32>
    %1816 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1817 = memref.load %assume_align[%arg0, %1816, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1818 = vector.broadcast %1817 : f32 to vector<8xf32>
    %1819 = vector.fma %1818, %1808, %1787 : vector<8xf32>
    %1820 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1821 = memref.load %assume_align[%arg0, %1820, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1822 = vector.broadcast %1821 : f32 to vector<8xf32>
    %1823 = vector.fma %1822, %1808, %1791 : vector<8xf32>
    %1824 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1825 = memref.load %assume_align[%arg0, %1824, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1826 = vector.broadcast %1825 : f32 to vector<8xf32>
    %1827 = vector.fma %1826, %1808, %1795 : vector<8xf32>
    %1828 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1829 = memref.load %assume_align[%arg0, %1828, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1830 = vector.broadcast %1829 : f32 to vector<8xf32>
    %1831 = vector.fma %1830, %1808, %1799 : vector<8xf32>
    %1832 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1833 = memref.load %assume_align[%arg0, %1832, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1834 = vector.broadcast %1833 : f32 to vector<8xf32>
    %1835 = vector.fma %1834, %1808, %1803 : vector<8xf32>
    %1836 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1837 = memref.load %assume_align[%arg0, %1836, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1838 = vector.broadcast %1837 : f32 to vector<8xf32>
    %1839 = vector.fma %1838, %1808, %1807 : vector<8xf32>
    %1840 = vector.extract %7[57] : vector<8xf32> from vector<64x8xf32>
    %1841 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1842 = vector.broadcast %1841 : f32 to vector<8xf32>
    %1843 = vector.fma %1842, %1840, %1811 : vector<8xf32>
    %1844 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1845 = memref.load %assume_align[%arg0, %1844, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1846 = vector.broadcast %1845 : f32 to vector<8xf32>
    %1847 = vector.fma %1846, %1840, %1815 : vector<8xf32>
    %1848 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1849 = memref.load %assume_align[%arg0, %1848, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1850 = vector.broadcast %1849 : f32 to vector<8xf32>
    %1851 = vector.fma %1850, %1840, %1819 : vector<8xf32>
    %1852 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1853 = memref.load %assume_align[%arg0, %1852, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1854 = vector.broadcast %1853 : f32 to vector<8xf32>
    %1855 = vector.fma %1854, %1840, %1823 : vector<8xf32>
    %1856 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1857 = memref.load %assume_align[%arg0, %1856, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1858 = vector.broadcast %1857 : f32 to vector<8xf32>
    %1859 = vector.fma %1858, %1840, %1827 : vector<8xf32>
    %1860 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1861 = memref.load %assume_align[%arg0, %1860, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1862 = vector.broadcast %1861 : f32 to vector<8xf32>
    %1863 = vector.fma %1862, %1840, %1831 : vector<8xf32>
    %1864 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1865 = memref.load %assume_align[%arg0, %1864, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1866 = vector.broadcast %1865 : f32 to vector<8xf32>
    %1867 = vector.fma %1866, %1840, %1835 : vector<8xf32>
    %1868 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1869 = memref.load %assume_align[%arg0, %1868, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1870 = vector.broadcast %1869 : f32 to vector<8xf32>
    %1871 = vector.fma %1870, %1840, %1839 : vector<8xf32>
    %1872 = vector.extract %7[58] : vector<8xf32> from vector<64x8xf32>
    %1873 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1874 = vector.broadcast %1873 : f32 to vector<8xf32>
    %1875 = vector.fma %1874, %1872, %1843 : vector<8xf32>
    %1876 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1877 = memref.load %assume_align[%arg0, %1876, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1878 = vector.broadcast %1877 : f32 to vector<8xf32>
    %1879 = vector.fma %1878, %1872, %1847 : vector<8xf32>
    %1880 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1881 = memref.load %assume_align[%arg0, %1880, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1882 = vector.broadcast %1881 : f32 to vector<8xf32>
    %1883 = vector.fma %1882, %1872, %1851 : vector<8xf32>
    %1884 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1885 = memref.load %assume_align[%arg0, %1884, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1886 = vector.broadcast %1885 : f32 to vector<8xf32>
    %1887 = vector.fma %1886, %1872, %1855 : vector<8xf32>
    %1888 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1889 = memref.load %assume_align[%arg0, %1888, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1890 = vector.broadcast %1889 : f32 to vector<8xf32>
    %1891 = vector.fma %1890, %1872, %1859 : vector<8xf32>
    %1892 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1893 = memref.load %assume_align[%arg0, %1892, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1894 = vector.broadcast %1893 : f32 to vector<8xf32>
    %1895 = vector.fma %1894, %1872, %1863 : vector<8xf32>
    %1896 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1897 = memref.load %assume_align[%arg0, %1896, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1898 = vector.broadcast %1897 : f32 to vector<8xf32>
    %1899 = vector.fma %1898, %1872, %1867 : vector<8xf32>
    %1900 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1901 = memref.load %assume_align[%arg0, %1900, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1902 = vector.broadcast %1901 : f32 to vector<8xf32>
    %1903 = vector.fma %1902, %1872, %1871 : vector<8xf32>
    %1904 = vector.extract %7[59] : vector<8xf32> from vector<64x8xf32>
    %1905 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1906 = vector.broadcast %1905 : f32 to vector<8xf32>
    %1907 = vector.fma %1906, %1904, %1875 : vector<8xf32>
    %1908 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1909 = memref.load %assume_align[%arg0, %1908, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1910 = vector.broadcast %1909 : f32 to vector<8xf32>
    %1911 = vector.fma %1910, %1904, %1879 : vector<8xf32>
    %1912 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1913 = memref.load %assume_align[%arg0, %1912, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1914 = vector.broadcast %1913 : f32 to vector<8xf32>
    %1915 = vector.fma %1914, %1904, %1883 : vector<8xf32>
    %1916 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1917 = memref.load %assume_align[%arg0, %1916, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1918 = vector.broadcast %1917 : f32 to vector<8xf32>
    %1919 = vector.fma %1918, %1904, %1887 : vector<8xf32>
    %1920 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1921 = memref.load %assume_align[%arg0, %1920, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1922 = vector.broadcast %1921 : f32 to vector<8xf32>
    %1923 = vector.fma %1922, %1904, %1891 : vector<8xf32>
    %1924 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1925 = memref.load %assume_align[%arg0, %1924, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1926 = vector.broadcast %1925 : f32 to vector<8xf32>
    %1927 = vector.fma %1926, %1904, %1895 : vector<8xf32>
    %1928 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1929 = memref.load %assume_align[%arg0, %1928, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1930 = vector.broadcast %1929 : f32 to vector<8xf32>
    %1931 = vector.fma %1930, %1904, %1899 : vector<8xf32>
    %1932 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1933 = memref.load %assume_align[%arg0, %1932, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1934 = vector.broadcast %1933 : f32 to vector<8xf32>
    %1935 = vector.fma %1934, %1904, %1903 : vector<8xf32>
    %1936 = vector.extract %7[60] : vector<8xf32> from vector<64x8xf32>
    %1937 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1938 = vector.broadcast %1937 : f32 to vector<8xf32>
    %1939 = vector.fma %1938, %1936, %1907 : vector<8xf32>
    %1940 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1941 = memref.load %assume_align[%arg0, %1940, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1942 = vector.broadcast %1941 : f32 to vector<8xf32>
    %1943 = vector.fma %1942, %1936, %1911 : vector<8xf32>
    %1944 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1945 = memref.load %assume_align[%arg0, %1944, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1946 = vector.broadcast %1945 : f32 to vector<8xf32>
    %1947 = vector.fma %1946, %1936, %1915 : vector<8xf32>
    %1948 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1949 = memref.load %assume_align[%arg0, %1948, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1950 = vector.broadcast %1949 : f32 to vector<8xf32>
    %1951 = vector.fma %1950, %1936, %1919 : vector<8xf32>
    %1952 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1953 = memref.load %assume_align[%arg0, %1952, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1954 = vector.broadcast %1953 : f32 to vector<8xf32>
    %1955 = vector.fma %1954, %1936, %1923 : vector<8xf32>
    %1956 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1957 = memref.load %assume_align[%arg0, %1956, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1958 = vector.broadcast %1957 : f32 to vector<8xf32>
    %1959 = vector.fma %1958, %1936, %1927 : vector<8xf32>
    %1960 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1961 = memref.load %assume_align[%arg0, %1960, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1962 = vector.broadcast %1961 : f32 to vector<8xf32>
    %1963 = vector.fma %1962, %1936, %1931 : vector<8xf32>
    %1964 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1965 = memref.load %assume_align[%arg0, %1964, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1966 = vector.broadcast %1965 : f32 to vector<8xf32>
    %1967 = vector.fma %1966, %1936, %1935 : vector<8xf32>
    %1968 = vector.extract %7[61] : vector<8xf32> from vector<64x8xf32>
    %1969 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1970 = vector.broadcast %1969 : f32 to vector<8xf32>
    %1971 = vector.fma %1970, %1968, %1939 : vector<8xf32>
    %1972 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1973 = memref.load %assume_align[%arg0, %1972, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1974 = vector.broadcast %1973 : f32 to vector<8xf32>
    %1975 = vector.fma %1974, %1968, %1943 : vector<8xf32>
    %1976 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1977 = memref.load %assume_align[%arg0, %1976, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1978 = vector.broadcast %1977 : f32 to vector<8xf32>
    %1979 = vector.fma %1978, %1968, %1947 : vector<8xf32>
    %1980 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1981 = memref.load %assume_align[%arg0, %1980, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1982 = vector.broadcast %1981 : f32 to vector<8xf32>
    %1983 = vector.fma %1982, %1968, %1951 : vector<8xf32>
    %1984 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1985 = memref.load %assume_align[%arg0, %1984, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1986 = vector.broadcast %1985 : f32 to vector<8xf32>
    %1987 = vector.fma %1986, %1968, %1955 : vector<8xf32>
    %1988 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1989 = memref.load %assume_align[%arg0, %1988, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1990 = vector.broadcast %1989 : f32 to vector<8xf32>
    %1991 = vector.fma %1990, %1968, %1959 : vector<8xf32>
    %1992 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1993 = memref.load %assume_align[%arg0, %1992, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1994 = vector.broadcast %1993 : f32 to vector<8xf32>
    %1995 = vector.fma %1994, %1968, %1963 : vector<8xf32>
    %1996 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1997 = memref.load %assume_align[%arg0, %1996, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1998 = vector.broadcast %1997 : f32 to vector<8xf32>
    %1999 = vector.fma %1998, %1968, %1967 : vector<8xf32>
    %2000 = vector.extract %7[62] : vector<8xf32> from vector<64x8xf32>
    %2001 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2002 = vector.broadcast %2001 : f32 to vector<8xf32>
    %2003 = vector.fma %2002, %2000, %1971 : vector<8xf32>
    %2004 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2005 = memref.load %assume_align[%arg0, %2004, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2006 = vector.broadcast %2005 : f32 to vector<8xf32>
    %2007 = vector.fma %2006, %2000, %1975 : vector<8xf32>
    %2008 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2009 = memref.load %assume_align[%arg0, %2008, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2010 = vector.broadcast %2009 : f32 to vector<8xf32>
    %2011 = vector.fma %2010, %2000, %1979 : vector<8xf32>
    %2012 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2013 = memref.load %assume_align[%arg0, %2012, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2014 = vector.broadcast %2013 : f32 to vector<8xf32>
    %2015 = vector.fma %2014, %2000, %1983 : vector<8xf32>
    %2016 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2017 = memref.load %assume_align[%arg0, %2016, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2018 = vector.broadcast %2017 : f32 to vector<8xf32>
    %2019 = vector.fma %2018, %2000, %1987 : vector<8xf32>
    %2020 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2021 = memref.load %assume_align[%arg0, %2020, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2022 = vector.broadcast %2021 : f32 to vector<8xf32>
    %2023 = vector.fma %2022, %2000, %1991 : vector<8xf32>
    %2024 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2025 = memref.load %assume_align[%arg0, %2024, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2026 = vector.broadcast %2025 : f32 to vector<8xf32>
    %2027 = vector.fma %2026, %2000, %1995 : vector<8xf32>
    %2028 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2029 = memref.load %assume_align[%arg0, %2028, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2030 = vector.broadcast %2029 : f32 to vector<8xf32>
    %2031 = vector.fma %2030, %2000, %1999 : vector<8xf32>
    %2032 = vector.extract %7[63] : vector<8xf32> from vector<64x8xf32>
    %2033 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2034 = vector.broadcast %2033 : f32 to vector<8xf32>
    %2035 = vector.fma %2034, %2032, %2003 : vector<8xf32>
    %2036 = vector.insert %2035, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2037 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2038 = memref.load %assume_align[%arg0, %2037, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
    %2040 = vector.fma %2039, %2032, %2007 : vector<8xf32>
    %2041 = vector.insert %2040, %2036 [1] : vector<8xf32> into vector<8x8xf32>
    %2042 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2043 = memref.load %assume_align[%arg0, %2042, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2044 = vector.broadcast %2043 : f32 to vector<8xf32>
    %2045 = vector.fma %2044, %2032, %2011 : vector<8xf32>
    %2046 = vector.insert %2045, %2041 [2] : vector<8xf32> into vector<8x8xf32>
    %2047 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2048 = memref.load %assume_align[%arg0, %2047, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2049 = vector.broadcast %2048 : f32 to vector<8xf32>
    %2050 = vector.fma %2049, %2032, %2015 : vector<8xf32>
    %2051 = vector.insert %2050, %2046 [3] : vector<8xf32> into vector<8x8xf32>
    %2052 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2053 = memref.load %assume_align[%arg0, %2052, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2054 = vector.broadcast %2053 : f32 to vector<8xf32>
    %2055 = vector.fma %2054, %2032, %2019 : vector<8xf32>
    %2056 = vector.insert %2055, %2051 [4] : vector<8xf32> into vector<8x8xf32>
    %2057 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2058 = memref.load %assume_align[%arg0, %2057, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2059 = vector.broadcast %2058 : f32 to vector<8xf32>
    %2060 = vector.fma %2059, %2032, %2023 : vector<8xf32>
    %2061 = vector.insert %2060, %2056 [5] : vector<8xf32> into vector<8x8xf32>
    %2062 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2063 = memref.load %assume_align[%arg0, %2062, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2064 = vector.broadcast %2063 : f32 to vector<8xf32>
    %2065 = vector.fma %2064, %2032, %2027 : vector<8xf32>
    %2066 = vector.insert %2065, %2061 [6] : vector<8xf32> into vector<8x8xf32>
    %2067 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2068 = memref.load %assume_align[%arg0, %2067, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2069 = vector.broadcast %2068 : f32 to vector<8xf32>
    %2070 = vector.fma %2069, %2032, %2031 : vector<8xf32>
    %2071 = vector.insert %2070, %2066 [7] : vector<8xf32> into vector<8x8xf32>
    %2072 = vector.reduction <maximumf>, %2035, %cst : vector<8xf32> into f32
    %2073 = vector.insert %2072, %cst_0 [0] : f32 into vector<8xf32>
    %2074 = vector.reduction <maximumf>, %2040, %cst : vector<8xf32> into f32
    %2075 = vector.insert %2074, %2073 [1] : f32 into vector<8xf32>
    %2076 = vector.reduction <maximumf>, %2045, %cst : vector<8xf32> into f32
    %2077 = vector.insert %2076, %2075 [2] : f32 into vector<8xf32>
    %2078 = vector.reduction <maximumf>, %2050, %cst : vector<8xf32> into f32
    %2079 = vector.insert %2078, %2077 [3] : f32 into vector<8xf32>
    %2080 = vector.reduction <maximumf>, %2055, %cst : vector<8xf32> into f32
    %2081 = vector.insert %2080, %2079 [4] : f32 into vector<8xf32>
    %2082 = vector.reduction <maximumf>, %2060, %cst : vector<8xf32> into f32
    %2083 = vector.insert %2082, %2081 [5] : f32 into vector<8xf32>
    %2084 = vector.reduction <maximumf>, %2065, %cst : vector<8xf32> into f32
    %2085 = vector.insert %2084, %2083 [6] : f32 into vector<8xf32>
    %2086 = vector.reduction <maximumf>, %2070, %cst : vector<8xf32> into f32
    %2087 = vector.insert %2086, %2085 [7] : f32 into vector<8xf32>
    %2088 = vector.shape_cast %2087 : vector<8xf32> to vector<1x8xf32>
    %2089 = arith.subf %2087, %cst_2 : vector<8xf32>
    %2090 = math.exp2 %2089 : vector<8xf32>
    %2091 = vector.shape_cast %2090 : vector<8xf32> to vector<1x8xf32>
    %2092 = vector.broadcast %2091 : vector<1x8xf32> to vector<8x1x8xf32>
    %2093 = vector.shape_cast %2092 : vector<8x1x8xf32> to vector<8x8xf32>
    %2094 = arith.mulf %2093, %cst_1 : vector<8x8xf32>
    %2095 = vector.transpose %2094, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2096 = vector.broadcast %2088 : vector<1x8xf32> to vector<8x1x8xf32>
    %2097 = vector.shape_cast %2096 : vector<8x1x8xf32> to vector<8x8xf32>
    %2098 = vector.transpose %2097, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2099 = arith.subf %2071, %2098 : vector<8x8xf32>
    %2100 = math.exp2 %2099 : vector<8x8xf32>
    %2101 = vector.transfer_read %assume_align_4[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
    %2102 = vector.extract %2101[0] : vector<8xf32> from vector<8x8xf32>
    %2103 = vector.extract %2100[0, 0] : f32 from vector<8x8xf32>
    %2104 = vector.broadcast %2103 : f32 to vector<8xf32>
    %2105 = vector.extract %2095[0] : vector<8xf32> from vector<8x8xf32>
    %2106 = vector.fma %2104, %2102, %2105 : vector<8xf32>
    %2107 = vector.extract %2100[1, 0] : f32 from vector<8x8xf32>
    %2108 = vector.broadcast %2107 : f32 to vector<8xf32>
    %2109 = vector.extract %2095[1] : vector<8xf32> from vector<8x8xf32>
    %2110 = vector.fma %2108, %2102, %2109 : vector<8xf32>
    %2111 = vector.extract %2100[2, 0] : f32 from vector<8x8xf32>
    %2112 = vector.broadcast %2111 : f32 to vector<8xf32>
    %2113 = vector.extract %2095[2] : vector<8xf32> from vector<8x8xf32>
    %2114 = vector.fma %2112, %2102, %2113 : vector<8xf32>
    %2115 = vector.extract %2100[3, 0] : f32 from vector<8x8xf32>
    %2116 = vector.broadcast %2115 : f32 to vector<8xf32>
    %2117 = vector.extract %2095[3] : vector<8xf32> from vector<8x8xf32>
    %2118 = vector.fma %2116, %2102, %2117 : vector<8xf32>
    %2119 = vector.extract %2100[4, 0] : f32 from vector<8x8xf32>
    %2120 = vector.broadcast %2119 : f32 to vector<8xf32>
    %2121 = vector.extract %2095[4] : vector<8xf32> from vector<8x8xf32>
    %2122 = vector.fma %2120, %2102, %2121 : vector<8xf32>
    %2123 = vector.extract %2100[5, 0] : f32 from vector<8x8xf32>
    %2124 = vector.broadcast %2123 : f32 to vector<8xf32>
    %2125 = vector.extract %2095[5] : vector<8xf32> from vector<8x8xf32>
    %2126 = vector.fma %2124, %2102, %2125 : vector<8xf32>
    %2127 = vector.extract %2100[6, 0] : f32 from vector<8x8xf32>
    %2128 = vector.broadcast %2127 : f32 to vector<8xf32>
    %2129 = vector.extract %2095[6] : vector<8xf32> from vector<8x8xf32>
    %2130 = vector.fma %2128, %2102, %2129 : vector<8xf32>
    %2131 = vector.extract %2100[7, 0] : f32 from vector<8x8xf32>
    %2132 = vector.broadcast %2131 : f32 to vector<8xf32>
    %2133 = vector.extract %2095[7] : vector<8xf32> from vector<8x8xf32>
    %2134 = vector.fma %2132, %2102, %2133 : vector<8xf32>
    %2135 = vector.extract %2101[1] : vector<8xf32> from vector<8x8xf32>
    %2136 = vector.extract %2100[0, 1] : f32 from vector<8x8xf32>
    %2137 = vector.broadcast %2136 : f32 to vector<8xf32>
    %2138 = vector.fma %2137, %2135, %2106 : vector<8xf32>
    %2139 = vector.extract %2100[1, 1] : f32 from vector<8x8xf32>
    %2140 = vector.broadcast %2139 : f32 to vector<8xf32>
    %2141 = vector.fma %2140, %2135, %2110 : vector<8xf32>
    %2142 = vector.extract %2100[2, 1] : f32 from vector<8x8xf32>
    %2143 = vector.broadcast %2142 : f32 to vector<8xf32>
    %2144 = vector.fma %2143, %2135, %2114 : vector<8xf32>
    %2145 = vector.extract %2100[3, 1] : f32 from vector<8x8xf32>
    %2146 = vector.broadcast %2145 : f32 to vector<8xf32>
    %2147 = vector.fma %2146, %2135, %2118 : vector<8xf32>
    %2148 = vector.extract %2100[4, 1] : f32 from vector<8x8xf32>
    %2149 = vector.broadcast %2148 : f32 to vector<8xf32>
    %2150 = vector.fma %2149, %2135, %2122 : vector<8xf32>
    %2151 = vector.extract %2100[5, 1] : f32 from vector<8x8xf32>
    %2152 = vector.broadcast %2151 : f32 to vector<8xf32>
    %2153 = vector.fma %2152, %2135, %2126 : vector<8xf32>
    %2154 = vector.extract %2100[6, 1] : f32 from vector<8x8xf32>
    %2155 = vector.broadcast %2154 : f32 to vector<8xf32>
    %2156 = vector.fma %2155, %2135, %2130 : vector<8xf32>
    %2157 = vector.extract %2100[7, 1] : f32 from vector<8x8xf32>
    %2158 = vector.broadcast %2157 : f32 to vector<8xf32>
    %2159 = vector.fma %2158, %2135, %2134 : vector<8xf32>
    %2160 = vector.extract %2101[2] : vector<8xf32> from vector<8x8xf32>
    %2161 = vector.extract %2100[0, 2] : f32 from vector<8x8xf32>
    %2162 = vector.broadcast %2161 : f32 to vector<8xf32>
    %2163 = vector.fma %2162, %2160, %2138 : vector<8xf32>
    %2164 = vector.extract %2100[1, 2] : f32 from vector<8x8xf32>
    %2165 = vector.broadcast %2164 : f32 to vector<8xf32>
    %2166 = vector.fma %2165, %2160, %2141 : vector<8xf32>
    %2167 = vector.extract %2100[2, 2] : f32 from vector<8x8xf32>
    %2168 = vector.broadcast %2167 : f32 to vector<8xf32>
    %2169 = vector.fma %2168, %2160, %2144 : vector<8xf32>
    %2170 = vector.extract %2100[3, 2] : f32 from vector<8x8xf32>
    %2171 = vector.broadcast %2170 : f32 to vector<8xf32>
    %2172 = vector.fma %2171, %2160, %2147 : vector<8xf32>
    %2173 = vector.extract %2100[4, 2] : f32 from vector<8x8xf32>
    %2174 = vector.broadcast %2173 : f32 to vector<8xf32>
    %2175 = vector.fma %2174, %2160, %2150 : vector<8xf32>
    %2176 = vector.extract %2100[5, 2] : f32 from vector<8x8xf32>
    %2177 = vector.broadcast %2176 : f32 to vector<8xf32>
    %2178 = vector.fma %2177, %2160, %2153 : vector<8xf32>
    %2179 = vector.extract %2100[6, 2] : f32 from vector<8x8xf32>
    %2180 = vector.broadcast %2179 : f32 to vector<8xf32>
    %2181 = vector.fma %2180, %2160, %2156 : vector<8xf32>
    %2182 = vector.extract %2100[7, 2] : f32 from vector<8x8xf32>
    %2183 = vector.broadcast %2182 : f32 to vector<8xf32>
    %2184 = vector.fma %2183, %2160, %2159 : vector<8xf32>
    %2185 = vector.extract %2101[3] : vector<8xf32> from vector<8x8xf32>
    %2186 = vector.extract %2100[0, 3] : f32 from vector<8x8xf32>
    %2187 = vector.broadcast %2186 : f32 to vector<8xf32>
    %2188 = vector.fma %2187, %2185, %2163 : vector<8xf32>
    %2189 = vector.extract %2100[1, 3] : f32 from vector<8x8xf32>
    %2190 = vector.broadcast %2189 : f32 to vector<8xf32>
    %2191 = vector.fma %2190, %2185, %2166 : vector<8xf32>
    %2192 = vector.extract %2100[2, 3] : f32 from vector<8x8xf32>
    %2193 = vector.broadcast %2192 : f32 to vector<8xf32>
    %2194 = vector.fma %2193, %2185, %2169 : vector<8xf32>
    %2195 = vector.extract %2100[3, 3] : f32 from vector<8x8xf32>
    %2196 = vector.broadcast %2195 : f32 to vector<8xf32>
    %2197 = vector.fma %2196, %2185, %2172 : vector<8xf32>
    %2198 = vector.extract %2100[4, 3] : f32 from vector<8x8xf32>
    %2199 = vector.broadcast %2198 : f32 to vector<8xf32>
    %2200 = vector.fma %2199, %2185, %2175 : vector<8xf32>
    %2201 = vector.extract %2100[5, 3] : f32 from vector<8x8xf32>
    %2202 = vector.broadcast %2201 : f32 to vector<8xf32>
    %2203 = vector.fma %2202, %2185, %2178 : vector<8xf32>
    %2204 = vector.extract %2100[6, 3] : f32 from vector<8x8xf32>
    %2205 = vector.broadcast %2204 : f32 to vector<8xf32>
    %2206 = vector.fma %2205, %2185, %2181 : vector<8xf32>
    %2207 = vector.extract %2100[7, 3] : f32 from vector<8x8xf32>
    %2208 = vector.broadcast %2207 : f32 to vector<8xf32>
    %2209 = vector.fma %2208, %2185, %2184 : vector<8xf32>
    %2210 = vector.extract %2101[4] : vector<8xf32> from vector<8x8xf32>
    %2211 = vector.extract %2100[0, 4] : f32 from vector<8x8xf32>
    %2212 = vector.broadcast %2211 : f32 to vector<8xf32>
    %2213 = vector.fma %2212, %2210, %2188 : vector<8xf32>
    %2214 = vector.extract %2100[1, 4] : f32 from vector<8x8xf32>
    %2215 = vector.broadcast %2214 : f32 to vector<8xf32>
    %2216 = vector.fma %2215, %2210, %2191 : vector<8xf32>
    %2217 = vector.extract %2100[2, 4] : f32 from vector<8x8xf32>
    %2218 = vector.broadcast %2217 : f32 to vector<8xf32>
    %2219 = vector.fma %2218, %2210, %2194 : vector<8xf32>
    %2220 = vector.extract %2100[3, 4] : f32 from vector<8x8xf32>
    %2221 = vector.broadcast %2220 : f32 to vector<8xf32>
    %2222 = vector.fma %2221, %2210, %2197 : vector<8xf32>
    %2223 = vector.extract %2100[4, 4] : f32 from vector<8x8xf32>
    %2224 = vector.broadcast %2223 : f32 to vector<8xf32>
    %2225 = vector.fma %2224, %2210, %2200 : vector<8xf32>
    %2226 = vector.extract %2100[5, 4] : f32 from vector<8x8xf32>
    %2227 = vector.broadcast %2226 : f32 to vector<8xf32>
    %2228 = vector.fma %2227, %2210, %2203 : vector<8xf32>
    %2229 = vector.extract %2100[6, 4] : f32 from vector<8x8xf32>
    %2230 = vector.broadcast %2229 : f32 to vector<8xf32>
    %2231 = vector.fma %2230, %2210, %2206 : vector<8xf32>
    %2232 = vector.extract %2100[7, 4] : f32 from vector<8x8xf32>
    %2233 = vector.broadcast %2232 : f32 to vector<8xf32>
    %2234 = vector.fma %2233, %2210, %2209 : vector<8xf32>
    %2235 = vector.extract %2101[5] : vector<8xf32> from vector<8x8xf32>
    %2236 = vector.extract %2100[0, 5] : f32 from vector<8x8xf32>
    %2237 = vector.broadcast %2236 : f32 to vector<8xf32>
    %2238 = vector.fma %2237, %2235, %2213 : vector<8xf32>
    %2239 = vector.extract %2100[1, 5] : f32 from vector<8x8xf32>
    %2240 = vector.broadcast %2239 : f32 to vector<8xf32>
    %2241 = vector.fma %2240, %2235, %2216 : vector<8xf32>
    %2242 = vector.extract %2100[2, 5] : f32 from vector<8x8xf32>
    %2243 = vector.broadcast %2242 : f32 to vector<8xf32>
    %2244 = vector.fma %2243, %2235, %2219 : vector<8xf32>
    %2245 = vector.extract %2100[3, 5] : f32 from vector<8x8xf32>
    %2246 = vector.broadcast %2245 : f32 to vector<8xf32>
    %2247 = vector.fma %2246, %2235, %2222 : vector<8xf32>
    %2248 = vector.extract %2100[4, 5] : f32 from vector<8x8xf32>
    %2249 = vector.broadcast %2248 : f32 to vector<8xf32>
    %2250 = vector.fma %2249, %2235, %2225 : vector<8xf32>
    %2251 = vector.extract %2100[5, 5] : f32 from vector<8x8xf32>
    %2252 = vector.broadcast %2251 : f32 to vector<8xf32>
    %2253 = vector.fma %2252, %2235, %2228 : vector<8xf32>
    %2254 = vector.extract %2100[6, 5] : f32 from vector<8x8xf32>
    %2255 = vector.broadcast %2254 : f32 to vector<8xf32>
    %2256 = vector.fma %2255, %2235, %2231 : vector<8xf32>
    %2257 = vector.extract %2100[7, 5] : f32 from vector<8x8xf32>
    %2258 = vector.broadcast %2257 : f32 to vector<8xf32>
    %2259 = vector.fma %2258, %2235, %2234 : vector<8xf32>
    %2260 = vector.extract %2101[6] : vector<8xf32> from vector<8x8xf32>
    %2261 = vector.extract %2100[0, 6] : f32 from vector<8x8xf32>
    %2262 = vector.broadcast %2261 : f32 to vector<8xf32>
    %2263 = vector.fma %2262, %2260, %2238 : vector<8xf32>
    %2264 = vector.extract %2100[1, 6] : f32 from vector<8x8xf32>
    %2265 = vector.broadcast %2264 : f32 to vector<8xf32>
    %2266 = vector.fma %2265, %2260, %2241 : vector<8xf32>
    %2267 = vector.extract %2100[2, 6] : f32 from vector<8x8xf32>
    %2268 = vector.broadcast %2267 : f32 to vector<8xf32>
    %2269 = vector.fma %2268, %2260, %2244 : vector<8xf32>
    %2270 = vector.extract %2100[3, 6] : f32 from vector<8x8xf32>
    %2271 = vector.broadcast %2270 : f32 to vector<8xf32>
    %2272 = vector.fma %2271, %2260, %2247 : vector<8xf32>
    %2273 = vector.extract %2100[4, 6] : f32 from vector<8x8xf32>
    %2274 = vector.broadcast %2273 : f32 to vector<8xf32>
    %2275 = vector.fma %2274, %2260, %2250 : vector<8xf32>
    %2276 = vector.extract %2100[5, 6] : f32 from vector<8x8xf32>
    %2277 = vector.broadcast %2276 : f32 to vector<8xf32>
    %2278 = vector.fma %2277, %2260, %2253 : vector<8xf32>
    %2279 = vector.extract %2100[6, 6] : f32 from vector<8x8xf32>
    %2280 = vector.broadcast %2279 : f32 to vector<8xf32>
    %2281 = vector.fma %2280, %2260, %2256 : vector<8xf32>
    %2282 = vector.extract %2100[7, 6] : f32 from vector<8x8xf32>
    %2283 = vector.broadcast %2282 : f32 to vector<8xf32>
    %2284 = vector.fma %2283, %2260, %2259 : vector<8xf32>
    %2285 = vector.extract %2101[7] : vector<8xf32> from vector<8x8xf32>
    %2286 = vector.extract %2100[0, 7] : f32 from vector<8x8xf32>
    %2287 = vector.broadcast %2286 : f32 to vector<8xf32>
    %2288 = vector.fma %2287, %2285, %2263 : vector<8xf32>
    %2289 = vector.insert %2288, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2290 = vector.extract %2100[1, 7] : f32 from vector<8x8xf32>
    %2291 = vector.broadcast %2290 : f32 to vector<8xf32>
    %2292 = vector.fma %2291, %2285, %2266 : vector<8xf32>
    %2293 = vector.insert %2292, %2289 [1] : vector<8xf32> into vector<8x8xf32>
    %2294 = vector.extract %2100[2, 7] : f32 from vector<8x8xf32>
    %2295 = vector.broadcast %2294 : f32 to vector<8xf32>
    %2296 = vector.fma %2295, %2285, %2269 : vector<8xf32>
    %2297 = vector.insert %2296, %2293 [2] : vector<8xf32> into vector<8x8xf32>
    %2298 = vector.extract %2100[3, 7] : f32 from vector<8x8xf32>
    %2299 = vector.broadcast %2298 : f32 to vector<8xf32>
    %2300 = vector.fma %2299, %2285, %2272 : vector<8xf32>
    %2301 = vector.insert %2300, %2297 [3] : vector<8xf32> into vector<8x8xf32>
    %2302 = vector.extract %2100[4, 7] : f32 from vector<8x8xf32>
    %2303 = vector.broadcast %2302 : f32 to vector<8xf32>
    %2304 = vector.fma %2303, %2285, %2275 : vector<8xf32>
    %2305 = vector.insert %2304, %2301 [4] : vector<8xf32> into vector<8x8xf32>
    %2306 = vector.extract %2100[5, 7] : f32 from vector<8x8xf32>
    %2307 = vector.broadcast %2306 : f32 to vector<8xf32>
    %2308 = vector.fma %2307, %2285, %2278 : vector<8xf32>
    %2309 = vector.insert %2308, %2305 [5] : vector<8xf32> into vector<8x8xf32>
    %2310 = vector.extract %2100[6, 7] : f32 from vector<8x8xf32>
    %2311 = vector.broadcast %2310 : f32 to vector<8xf32>
    %2312 = vector.fma %2311, %2285, %2281 : vector<8xf32>
    %2313 = vector.insert %2312, %2309 [6] : vector<8xf32> into vector<8x8xf32>
    %2314 = vector.extract %2100[7, 7] : f32 from vector<8x8xf32>
    %2315 = vector.broadcast %2314 : f32 to vector<8xf32>
    %2316 = vector.fma %2315, %2285, %2284 : vector<8xf32>
    %2317 = vector.insert %2316, %2313 [7] : vector<8xf32> into vector<8x8xf32>
    %2318 = arith.mulf %2090, %cst_0 : vector<8xf32>
    %2319 = vector.extract %2100[0] : vector<8xf32> from vector<8x8xf32>
    %2320 = vector.extract %2318[0] : f32 from vector<8xf32>
    %2321 = vector.reduction <add>, %2319, %2320 : vector<8xf32> into f32
    %2322 = vector.insert %2321, %cst_0 [0] : f32 into vector<8xf32>
    %2323 = vector.extract %2100[1] : vector<8xf32> from vector<8x8xf32>
    %2324 = vector.extract %2318[1] : f32 from vector<8xf32>
    %2325 = vector.reduction <add>, %2323, %2324 : vector<8xf32> into f32
    %2326 = vector.insert %2325, %2322 [1] : f32 into vector<8xf32>
    %2327 = vector.extract %2100[2] : vector<8xf32> from vector<8x8xf32>
    %2328 = vector.extract %2318[2] : f32 from vector<8xf32>
    %2329 = vector.reduction <add>, %2327, %2328 : vector<8xf32> into f32
    %2330 = vector.insert %2329, %2326 [2] : f32 into vector<8xf32>
    %2331 = vector.extract %2100[3] : vector<8xf32> from vector<8x8xf32>
    %2332 = vector.extract %2318[3] : f32 from vector<8xf32>
    %2333 = vector.reduction <add>, %2331, %2332 : vector<8xf32> into f32
    %2334 = vector.insert %2333, %2330 [3] : f32 into vector<8xf32>
    %2335 = vector.extract %2100[4] : vector<8xf32> from vector<8x8xf32>
    %2336 = vector.extract %2318[4] : f32 from vector<8xf32>
    %2337 = vector.reduction <add>, %2335, %2336 : vector<8xf32> into f32
    %2338 = vector.insert %2337, %2334 [4] : f32 into vector<8xf32>
    %2339 = vector.extract %2100[5] : vector<8xf32> from vector<8x8xf32>
    %2340 = vector.extract %2318[5] : f32 from vector<8xf32>
    %2341 = vector.reduction <add>, %2339, %2340 : vector<8xf32> into f32
    %2342 = vector.insert %2341, %2338 [5] : f32 into vector<8xf32>
    %2343 = vector.extract %2100[6] : vector<8xf32> from vector<8x8xf32>
    %2344 = vector.extract %2318[6] : f32 from vector<8xf32>
    %2345 = vector.reduction <add>, %2343, %2344 : vector<8xf32> into f32
    %2346 = vector.insert %2345, %2342 [6] : f32 into vector<8xf32>
    %2347 = vector.extract %2100[7] : vector<8xf32> from vector<8x8xf32>
    %2348 = vector.extract %2318[7] : f32 from vector<8xf32>
    %2349 = vector.reduction <add>, %2347, %2348 : vector<8xf32> into f32
    %2350 = vector.insert %2349, %2346 [7] : f32 into vector<8xf32>
    %2351 = vector.shape_cast %2350 : vector<8xf32> to vector<1x8xf32>
    %2352 = vector.broadcast %2351 : vector<1x8xf32> to vector<8x1x8xf32>
    %2353 = vector.shape_cast %2352 : vector<8x1x8xf32> to vector<8x8xf32>
    %2354 = vector.transpose %2353, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2355 = arith.divf %2317, %2354 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    vector.transfer_write %2355, %subview_7[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.transfer_read %assume_align_3[%arg0, %arg3, %c0], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %6 = vector.transfer_read %subview_6[%c0, %c0], %0 {in_bounds = [true, true]} : memref<8x8xf32>, vector<8x8xf32>
    %7 = vector.transpose %5, [1, 0] : vector<8x64xf32> to vector<64x8xf32>
    %8 = vector.extract %7[0] : vector<8xf32> from vector<64x8xf32>
    %9 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %10 = vector.broadcast %9 : f32 to vector<8xf32>
    %11 = vector.extract %6[0] : vector<8xf32> from vector<8x8xf32>
    %12 = vector.fma %10, %8, %11 : vector<8xf32>
    %13 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %14 = memref.load %assume_align[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %15 = vector.broadcast %14 : f32 to vector<8xf32>
    %16 = vector.extract %6[1] : vector<8xf32> from vector<8x8xf32>
    %17 = vector.fma %15, %8, %16 : vector<8xf32>
    %18 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %19 = memref.load %assume_align[%arg0, %18, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %20 = vector.broadcast %19 : f32 to vector<8xf32>
    %21 = vector.extract %6[2] : vector<8xf32> from vector<8x8xf32>
    %22 = vector.fma %20, %8, %21 : vector<8xf32>
    %23 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %24 = memref.load %assume_align[%arg0, %23, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %25 = vector.broadcast %24 : f32 to vector<8xf32>
    %26 = vector.extract %6[3] : vector<8xf32> from vector<8x8xf32>
    %27 = vector.fma %25, %8, %26 : vector<8xf32>
    %28 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %29 = memref.load %assume_align[%arg0, %28, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %30 = vector.broadcast %29 : f32 to vector<8xf32>
    %31 = vector.extract %6[4] : vector<8xf32> from vector<8x8xf32>
    %32 = vector.fma %30, %8, %31 : vector<8xf32>
    %33 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %34 = memref.load %assume_align[%arg0, %33, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %35 = vector.broadcast %34 : f32 to vector<8xf32>
    %36 = vector.extract %6[5] : vector<8xf32> from vector<8x8xf32>
    %37 = vector.fma %35, %8, %36 : vector<8xf32>
    %38 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %39 = memref.load %assume_align[%arg0, %38, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %40 = vector.broadcast %39 : f32 to vector<8xf32>
    %41 = vector.extract %6[6] : vector<8xf32> from vector<8x8xf32>
    %42 = vector.fma %40, %8, %41 : vector<8xf32>
    %43 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %44 = memref.load %assume_align[%arg0, %43, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %45 = vector.broadcast %44 : f32 to vector<8xf32>
    %46 = vector.extract %6[7] : vector<8xf32> from vector<8x8xf32>
    %47 = vector.fma %45, %8, %46 : vector<8xf32>
    %48 = vector.extract %7[1] : vector<8xf32> from vector<64x8xf32>
    %49 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %50 = vector.broadcast %49 : f32 to vector<8xf32>
    %51 = vector.fma %50, %48, %12 : vector<8xf32>
    %52 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %53 = memref.load %assume_align[%arg0, %52, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %54 = vector.broadcast %53 : f32 to vector<8xf32>
    %55 = vector.fma %54, %48, %17 : vector<8xf32>
    %56 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %57 = memref.load %assume_align[%arg0, %56, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %58 = vector.broadcast %57 : f32 to vector<8xf32>
    %59 = vector.fma %58, %48, %22 : vector<8xf32>
    %60 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %61 = memref.load %assume_align[%arg0, %60, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %62 = vector.broadcast %61 : f32 to vector<8xf32>
    %63 = vector.fma %62, %48, %27 : vector<8xf32>
    %64 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %65 = memref.load %assume_align[%arg0, %64, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %66 = vector.broadcast %65 : f32 to vector<8xf32>
    %67 = vector.fma %66, %48, %32 : vector<8xf32>
    %68 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %69 = memref.load %assume_align[%arg0, %68, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %70 = vector.broadcast %69 : f32 to vector<8xf32>
    %71 = vector.fma %70, %48, %37 : vector<8xf32>
    %72 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %73 = memref.load %assume_align[%arg0, %72, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %74 = vector.broadcast %73 : f32 to vector<8xf32>
    %75 = vector.fma %74, %48, %42 : vector<8xf32>
    %76 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %77 = memref.load %assume_align[%arg0, %76, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %78 = vector.broadcast %77 : f32 to vector<8xf32>
    %79 = vector.fma %78, %48, %47 : vector<8xf32>
    %80 = vector.extract %7[2] : vector<8xf32> from vector<64x8xf32>
    %81 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %82 = vector.broadcast %81 : f32 to vector<8xf32>
    %83 = vector.fma %82, %80, %51 : vector<8xf32>
    %84 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %85 = memref.load %assume_align[%arg0, %84, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %86 = vector.broadcast %85 : f32 to vector<8xf32>
    %87 = vector.fma %86, %80, %55 : vector<8xf32>
    %88 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %89 = memref.load %assume_align[%arg0, %88, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %90 = vector.broadcast %89 : f32 to vector<8xf32>
    %91 = vector.fma %90, %80, %59 : vector<8xf32>
    %92 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %93 = memref.load %assume_align[%arg0, %92, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %94 = vector.broadcast %93 : f32 to vector<8xf32>
    %95 = vector.fma %94, %80, %63 : vector<8xf32>
    %96 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %97 = memref.load %assume_align[%arg0, %96, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %98 = vector.broadcast %97 : f32 to vector<8xf32>
    %99 = vector.fma %98, %80, %67 : vector<8xf32>
    %100 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %101 = memref.load %assume_align[%arg0, %100, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %102 = vector.broadcast %101 : f32 to vector<8xf32>
    %103 = vector.fma %102, %80, %71 : vector<8xf32>
    %104 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %105 = memref.load %assume_align[%arg0, %104, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %106 = vector.broadcast %105 : f32 to vector<8xf32>
    %107 = vector.fma %106, %80, %75 : vector<8xf32>
    %108 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %109 = memref.load %assume_align[%arg0, %108, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %110 = vector.broadcast %109 : f32 to vector<8xf32>
    %111 = vector.fma %110, %80, %79 : vector<8xf32>
    %112 = vector.extract %7[3] : vector<8xf32> from vector<64x8xf32>
    %113 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %114 = vector.broadcast %113 : f32 to vector<8xf32>
    %115 = vector.fma %114, %112, %83 : vector<8xf32>
    %116 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %117 = memref.load %assume_align[%arg0, %116, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %118 = vector.broadcast %117 : f32 to vector<8xf32>
    %119 = vector.fma %118, %112, %87 : vector<8xf32>
    %120 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %121 = memref.load %assume_align[%arg0, %120, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %122 = vector.broadcast %121 : f32 to vector<8xf32>
    %123 = vector.fma %122, %112, %91 : vector<8xf32>
    %124 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %125 = memref.load %assume_align[%arg0, %124, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %126 = vector.broadcast %125 : f32 to vector<8xf32>
    %127 = vector.fma %126, %112, %95 : vector<8xf32>
    %128 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %129 = memref.load %assume_align[%arg0, %128, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %130 = vector.broadcast %129 : f32 to vector<8xf32>
    %131 = vector.fma %130, %112, %99 : vector<8xf32>
    %132 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %133 = memref.load %assume_align[%arg0, %132, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %134 = vector.broadcast %133 : f32 to vector<8xf32>
    %135 = vector.fma %134, %112, %103 : vector<8xf32>
    %136 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %137 = memref.load %assume_align[%arg0, %136, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %138 = vector.broadcast %137 : f32 to vector<8xf32>
    %139 = vector.fma %138, %112, %107 : vector<8xf32>
    %140 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %141 = memref.load %assume_align[%arg0, %140, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %142 = vector.broadcast %141 : f32 to vector<8xf32>
    %143 = vector.fma %142, %112, %111 : vector<8xf32>
    %144 = vector.extract %7[4] : vector<8xf32> from vector<64x8xf32>
    %145 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %146 = vector.broadcast %145 : f32 to vector<8xf32>
    %147 = vector.fma %146, %144, %115 : vector<8xf32>
    %148 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %149 = memref.load %assume_align[%arg0, %148, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %150 = vector.broadcast %149 : f32 to vector<8xf32>
    %151 = vector.fma %150, %144, %119 : vector<8xf32>
    %152 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %153 = memref.load %assume_align[%arg0, %152, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %154 = vector.broadcast %153 : f32 to vector<8xf32>
    %155 = vector.fma %154, %144, %123 : vector<8xf32>
    %156 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %157 = memref.load %assume_align[%arg0, %156, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %158 = vector.broadcast %157 : f32 to vector<8xf32>
    %159 = vector.fma %158, %144, %127 : vector<8xf32>
    %160 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %161 = memref.load %assume_align[%arg0, %160, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %162 = vector.broadcast %161 : f32 to vector<8xf32>
    %163 = vector.fma %162, %144, %131 : vector<8xf32>
    %164 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %165 = memref.load %assume_align[%arg0, %164, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %166 = vector.broadcast %165 : f32 to vector<8xf32>
    %167 = vector.fma %166, %144, %135 : vector<8xf32>
    %168 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %169 = memref.load %assume_align[%arg0, %168, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %170 = vector.broadcast %169 : f32 to vector<8xf32>
    %171 = vector.fma %170, %144, %139 : vector<8xf32>
    %172 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %173 = memref.load %assume_align[%arg0, %172, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %174 = vector.broadcast %173 : f32 to vector<8xf32>
    %175 = vector.fma %174, %144, %143 : vector<8xf32>
    %176 = vector.extract %7[5] : vector<8xf32> from vector<64x8xf32>
    %177 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %178 = vector.broadcast %177 : f32 to vector<8xf32>
    %179 = vector.fma %178, %176, %147 : vector<8xf32>
    %180 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %181 = memref.load %assume_align[%arg0, %180, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %182 = vector.broadcast %181 : f32 to vector<8xf32>
    %183 = vector.fma %182, %176, %151 : vector<8xf32>
    %184 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %185 = memref.load %assume_align[%arg0, %184, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %186 = vector.broadcast %185 : f32 to vector<8xf32>
    %187 = vector.fma %186, %176, %155 : vector<8xf32>
    %188 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %189 = memref.load %assume_align[%arg0, %188, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %190 = vector.broadcast %189 : f32 to vector<8xf32>
    %191 = vector.fma %190, %176, %159 : vector<8xf32>
    %192 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %193 = memref.load %assume_align[%arg0, %192, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %194 = vector.broadcast %193 : f32 to vector<8xf32>
    %195 = vector.fma %194, %176, %163 : vector<8xf32>
    %196 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %197 = memref.load %assume_align[%arg0, %196, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %198 = vector.broadcast %197 : f32 to vector<8xf32>
    %199 = vector.fma %198, %176, %167 : vector<8xf32>
    %200 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %201 = memref.load %assume_align[%arg0, %200, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %202 = vector.broadcast %201 : f32 to vector<8xf32>
    %203 = vector.fma %202, %176, %171 : vector<8xf32>
    %204 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %205 = memref.load %assume_align[%arg0, %204, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %206 = vector.broadcast %205 : f32 to vector<8xf32>
    %207 = vector.fma %206, %176, %175 : vector<8xf32>
    %208 = vector.extract %7[6] : vector<8xf32> from vector<64x8xf32>
    %209 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %210 = vector.broadcast %209 : f32 to vector<8xf32>
    %211 = vector.fma %210, %208, %179 : vector<8xf32>
    %212 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %213 = memref.load %assume_align[%arg0, %212, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %214 = vector.broadcast %213 : f32 to vector<8xf32>
    %215 = vector.fma %214, %208, %183 : vector<8xf32>
    %216 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %217 = memref.load %assume_align[%arg0, %216, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %218 = vector.broadcast %217 : f32 to vector<8xf32>
    %219 = vector.fma %218, %208, %187 : vector<8xf32>
    %220 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %221 = memref.load %assume_align[%arg0, %220, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %222 = vector.broadcast %221 : f32 to vector<8xf32>
    %223 = vector.fma %222, %208, %191 : vector<8xf32>
    %224 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %225 = memref.load %assume_align[%arg0, %224, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %226 = vector.broadcast %225 : f32 to vector<8xf32>
    %227 = vector.fma %226, %208, %195 : vector<8xf32>
    %228 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %229 = memref.load %assume_align[%arg0, %228, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %230 = vector.broadcast %229 : f32 to vector<8xf32>
    %231 = vector.fma %230, %208, %199 : vector<8xf32>
    %232 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %233 = memref.load %assume_align[%arg0, %232, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %234 = vector.broadcast %233 : f32 to vector<8xf32>
    %235 = vector.fma %234, %208, %203 : vector<8xf32>
    %236 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %237 = memref.load %assume_align[%arg0, %236, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %238 = vector.broadcast %237 : f32 to vector<8xf32>
    %239 = vector.fma %238, %208, %207 : vector<8xf32>
    %240 = vector.extract %7[7] : vector<8xf32> from vector<64x8xf32>
    %241 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %242 = vector.broadcast %241 : f32 to vector<8xf32>
    %243 = vector.fma %242, %240, %211 : vector<8xf32>
    %244 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %245 = memref.load %assume_align[%arg0, %244, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %246 = vector.broadcast %245 : f32 to vector<8xf32>
    %247 = vector.fma %246, %240, %215 : vector<8xf32>
    %248 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %249 = memref.load %assume_align[%arg0, %248, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %250 = vector.broadcast %249 : f32 to vector<8xf32>
    %251 = vector.fma %250, %240, %219 : vector<8xf32>
    %252 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %253 = memref.load %assume_align[%arg0, %252, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %254 = vector.broadcast %253 : f32 to vector<8xf32>
    %255 = vector.fma %254, %240, %223 : vector<8xf32>
    %256 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %257 = memref.load %assume_align[%arg0, %256, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %258 = vector.broadcast %257 : f32 to vector<8xf32>
    %259 = vector.fma %258, %240, %227 : vector<8xf32>
    %260 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %261 = memref.load %assume_align[%arg0, %260, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %262 = vector.broadcast %261 : f32 to vector<8xf32>
    %263 = vector.fma %262, %240, %231 : vector<8xf32>
    %264 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %265 = memref.load %assume_align[%arg0, %264, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %266 = vector.broadcast %265 : f32 to vector<8xf32>
    %267 = vector.fma %266, %240, %235 : vector<8xf32>
    %268 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %269 = memref.load %assume_align[%arg0, %268, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %270 = vector.broadcast %269 : f32 to vector<8xf32>
    %271 = vector.fma %270, %240, %239 : vector<8xf32>
    %272 = vector.extract %7[8] : vector<8xf32> from vector<64x8xf32>
    %273 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %274 = vector.broadcast %273 : f32 to vector<8xf32>
    %275 = vector.fma %274, %272, %243 : vector<8xf32>
    %276 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %277 = memref.load %assume_align[%arg0, %276, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %278 = vector.broadcast %277 : f32 to vector<8xf32>
    %279 = vector.fma %278, %272, %247 : vector<8xf32>
    %280 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %281 = memref.load %assume_align[%arg0, %280, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %282 = vector.broadcast %281 : f32 to vector<8xf32>
    %283 = vector.fma %282, %272, %251 : vector<8xf32>
    %284 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %285 = memref.load %assume_align[%arg0, %284, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %286 = vector.broadcast %285 : f32 to vector<8xf32>
    %287 = vector.fma %286, %272, %255 : vector<8xf32>
    %288 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %289 = memref.load %assume_align[%arg0, %288, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %290 = vector.broadcast %289 : f32 to vector<8xf32>
    %291 = vector.fma %290, %272, %259 : vector<8xf32>
    %292 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %293 = memref.load %assume_align[%arg0, %292, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %294 = vector.broadcast %293 : f32 to vector<8xf32>
    %295 = vector.fma %294, %272, %263 : vector<8xf32>
    %296 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %297 = memref.load %assume_align[%arg0, %296, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %298 = vector.broadcast %297 : f32 to vector<8xf32>
    %299 = vector.fma %298, %272, %267 : vector<8xf32>
    %300 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %301 = memref.load %assume_align[%arg0, %300, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %302 = vector.broadcast %301 : f32 to vector<8xf32>
    %303 = vector.fma %302, %272, %271 : vector<8xf32>
    %304 = vector.extract %7[9] : vector<8xf32> from vector<64x8xf32>
    %305 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %306 = vector.broadcast %305 : f32 to vector<8xf32>
    %307 = vector.fma %306, %304, %275 : vector<8xf32>
    %308 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %309 = memref.load %assume_align[%arg0, %308, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %310 = vector.broadcast %309 : f32 to vector<8xf32>
    %311 = vector.fma %310, %304, %279 : vector<8xf32>
    %312 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %313 = memref.load %assume_align[%arg0, %312, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %314 = vector.broadcast %313 : f32 to vector<8xf32>
    %315 = vector.fma %314, %304, %283 : vector<8xf32>
    %316 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %317 = memref.load %assume_align[%arg0, %316, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %318 = vector.broadcast %317 : f32 to vector<8xf32>
    %319 = vector.fma %318, %304, %287 : vector<8xf32>
    %320 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %321 = memref.load %assume_align[%arg0, %320, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %322 = vector.broadcast %321 : f32 to vector<8xf32>
    %323 = vector.fma %322, %304, %291 : vector<8xf32>
    %324 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %325 = memref.load %assume_align[%arg0, %324, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %326 = vector.broadcast %325 : f32 to vector<8xf32>
    %327 = vector.fma %326, %304, %295 : vector<8xf32>
    %328 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %329 = memref.load %assume_align[%arg0, %328, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %330 = vector.broadcast %329 : f32 to vector<8xf32>
    %331 = vector.fma %330, %304, %299 : vector<8xf32>
    %332 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %333 = memref.load %assume_align[%arg0, %332, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %334 = vector.broadcast %333 : f32 to vector<8xf32>
    %335 = vector.fma %334, %304, %303 : vector<8xf32>
    %336 = vector.extract %7[10] : vector<8xf32> from vector<64x8xf32>
    %337 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %338 = vector.broadcast %337 : f32 to vector<8xf32>
    %339 = vector.fma %338, %336, %307 : vector<8xf32>
    %340 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %341 = memref.load %assume_align[%arg0, %340, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %342 = vector.broadcast %341 : f32 to vector<8xf32>
    %343 = vector.fma %342, %336, %311 : vector<8xf32>
    %344 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %345 = memref.load %assume_align[%arg0, %344, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %346 = vector.broadcast %345 : f32 to vector<8xf32>
    %347 = vector.fma %346, %336, %315 : vector<8xf32>
    %348 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %349 = memref.load %assume_align[%arg0, %348, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %350 = vector.broadcast %349 : f32 to vector<8xf32>
    %351 = vector.fma %350, %336, %319 : vector<8xf32>
    %352 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %353 = memref.load %assume_align[%arg0, %352, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %354 = vector.broadcast %353 : f32 to vector<8xf32>
    %355 = vector.fma %354, %336, %323 : vector<8xf32>
    %356 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %357 = memref.load %assume_align[%arg0, %356, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %358 = vector.broadcast %357 : f32 to vector<8xf32>
    %359 = vector.fma %358, %336, %327 : vector<8xf32>
    %360 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %361 = memref.load %assume_align[%arg0, %360, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %362 = vector.broadcast %361 : f32 to vector<8xf32>
    %363 = vector.fma %362, %336, %331 : vector<8xf32>
    %364 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %365 = memref.load %assume_align[%arg0, %364, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %366 = vector.broadcast %365 : f32 to vector<8xf32>
    %367 = vector.fma %366, %336, %335 : vector<8xf32>
    %368 = vector.extract %7[11] : vector<8xf32> from vector<64x8xf32>
    %369 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %370 = vector.broadcast %369 : f32 to vector<8xf32>
    %371 = vector.fma %370, %368, %339 : vector<8xf32>
    %372 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %373 = memref.load %assume_align[%arg0, %372, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %374 = vector.broadcast %373 : f32 to vector<8xf32>
    %375 = vector.fma %374, %368, %343 : vector<8xf32>
    %376 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %377 = memref.load %assume_align[%arg0, %376, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %378 = vector.broadcast %377 : f32 to vector<8xf32>
    %379 = vector.fma %378, %368, %347 : vector<8xf32>
    %380 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %381 = memref.load %assume_align[%arg0, %380, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %382 = vector.broadcast %381 : f32 to vector<8xf32>
    %383 = vector.fma %382, %368, %351 : vector<8xf32>
    %384 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %385 = memref.load %assume_align[%arg0, %384, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %386 = vector.broadcast %385 : f32 to vector<8xf32>
    %387 = vector.fma %386, %368, %355 : vector<8xf32>
    %388 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %389 = memref.load %assume_align[%arg0, %388, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %390 = vector.broadcast %389 : f32 to vector<8xf32>
    %391 = vector.fma %390, %368, %359 : vector<8xf32>
    %392 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %393 = memref.load %assume_align[%arg0, %392, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %394 = vector.broadcast %393 : f32 to vector<8xf32>
    %395 = vector.fma %394, %368, %363 : vector<8xf32>
    %396 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %397 = memref.load %assume_align[%arg0, %396, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %398 = vector.broadcast %397 : f32 to vector<8xf32>
    %399 = vector.fma %398, %368, %367 : vector<8xf32>
    %400 = vector.extract %7[12] : vector<8xf32> from vector<64x8xf32>
    %401 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %402 = vector.broadcast %401 : f32 to vector<8xf32>
    %403 = vector.fma %402, %400, %371 : vector<8xf32>
    %404 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %405 = memref.load %assume_align[%arg0, %404, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %406 = vector.broadcast %405 : f32 to vector<8xf32>
    %407 = vector.fma %406, %400, %375 : vector<8xf32>
    %408 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %409 = memref.load %assume_align[%arg0, %408, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %410 = vector.broadcast %409 : f32 to vector<8xf32>
    %411 = vector.fma %410, %400, %379 : vector<8xf32>
    %412 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %413 = memref.load %assume_align[%arg0, %412, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %414 = vector.broadcast %413 : f32 to vector<8xf32>
    %415 = vector.fma %414, %400, %383 : vector<8xf32>
    %416 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %417 = memref.load %assume_align[%arg0, %416, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %418 = vector.broadcast %417 : f32 to vector<8xf32>
    %419 = vector.fma %418, %400, %387 : vector<8xf32>
    %420 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %421 = memref.load %assume_align[%arg0, %420, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %422 = vector.broadcast %421 : f32 to vector<8xf32>
    %423 = vector.fma %422, %400, %391 : vector<8xf32>
    %424 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %425 = memref.load %assume_align[%arg0, %424, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %426 = vector.broadcast %425 : f32 to vector<8xf32>
    %427 = vector.fma %426, %400, %395 : vector<8xf32>
    %428 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %429 = memref.load %assume_align[%arg0, %428, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %430 = vector.broadcast %429 : f32 to vector<8xf32>
    %431 = vector.fma %430, %400, %399 : vector<8xf32>
    %432 = vector.extract %7[13] : vector<8xf32> from vector<64x8xf32>
    %433 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %434 = vector.broadcast %433 : f32 to vector<8xf32>
    %435 = vector.fma %434, %432, %403 : vector<8xf32>
    %436 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %437 = memref.load %assume_align[%arg0, %436, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %438 = vector.broadcast %437 : f32 to vector<8xf32>
    %439 = vector.fma %438, %432, %407 : vector<8xf32>
    %440 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %441 = memref.load %assume_align[%arg0, %440, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %442 = vector.broadcast %441 : f32 to vector<8xf32>
    %443 = vector.fma %442, %432, %411 : vector<8xf32>
    %444 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %445 = memref.load %assume_align[%arg0, %444, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %446 = vector.broadcast %445 : f32 to vector<8xf32>
    %447 = vector.fma %446, %432, %415 : vector<8xf32>
    %448 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %449 = memref.load %assume_align[%arg0, %448, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %450 = vector.broadcast %449 : f32 to vector<8xf32>
    %451 = vector.fma %450, %432, %419 : vector<8xf32>
    %452 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %453 = memref.load %assume_align[%arg0, %452, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %454 = vector.broadcast %453 : f32 to vector<8xf32>
    %455 = vector.fma %454, %432, %423 : vector<8xf32>
    %456 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %457 = memref.load %assume_align[%arg0, %456, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %458 = vector.broadcast %457 : f32 to vector<8xf32>
    %459 = vector.fma %458, %432, %427 : vector<8xf32>
    %460 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %461 = memref.load %assume_align[%arg0, %460, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %462 = vector.broadcast %461 : f32 to vector<8xf32>
    %463 = vector.fma %462, %432, %431 : vector<8xf32>
    %464 = vector.extract %7[14] : vector<8xf32> from vector<64x8xf32>
    %465 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %466 = vector.broadcast %465 : f32 to vector<8xf32>
    %467 = vector.fma %466, %464, %435 : vector<8xf32>
    %468 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %469 = memref.load %assume_align[%arg0, %468, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %470 = vector.broadcast %469 : f32 to vector<8xf32>
    %471 = vector.fma %470, %464, %439 : vector<8xf32>
    %472 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %473 = memref.load %assume_align[%arg0, %472, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %474 = vector.broadcast %473 : f32 to vector<8xf32>
    %475 = vector.fma %474, %464, %443 : vector<8xf32>
    %476 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %477 = memref.load %assume_align[%arg0, %476, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %478 = vector.broadcast %477 : f32 to vector<8xf32>
    %479 = vector.fma %478, %464, %447 : vector<8xf32>
    %480 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %481 = memref.load %assume_align[%arg0, %480, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %482 = vector.broadcast %481 : f32 to vector<8xf32>
    %483 = vector.fma %482, %464, %451 : vector<8xf32>
    %484 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %485 = memref.load %assume_align[%arg0, %484, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %486 = vector.broadcast %485 : f32 to vector<8xf32>
    %487 = vector.fma %486, %464, %455 : vector<8xf32>
    %488 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %489 = memref.load %assume_align[%arg0, %488, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %490 = vector.broadcast %489 : f32 to vector<8xf32>
    %491 = vector.fma %490, %464, %459 : vector<8xf32>
    %492 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %493 = memref.load %assume_align[%arg0, %492, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %494 = vector.broadcast %493 : f32 to vector<8xf32>
    %495 = vector.fma %494, %464, %463 : vector<8xf32>
    %496 = vector.extract %7[15] : vector<8xf32> from vector<64x8xf32>
    %497 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %498 = vector.broadcast %497 : f32 to vector<8xf32>
    %499 = vector.fma %498, %496, %467 : vector<8xf32>
    %500 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %501 = memref.load %assume_align[%arg0, %500, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %502 = vector.broadcast %501 : f32 to vector<8xf32>
    %503 = vector.fma %502, %496, %471 : vector<8xf32>
    %504 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %505 = memref.load %assume_align[%arg0, %504, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %506 = vector.broadcast %505 : f32 to vector<8xf32>
    %507 = vector.fma %506, %496, %475 : vector<8xf32>
    %508 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %509 = memref.load %assume_align[%arg0, %508, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %510 = vector.broadcast %509 : f32 to vector<8xf32>
    %511 = vector.fma %510, %496, %479 : vector<8xf32>
    %512 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %513 = memref.load %assume_align[%arg0, %512, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %514 = vector.broadcast %513 : f32 to vector<8xf32>
    %515 = vector.fma %514, %496, %483 : vector<8xf32>
    %516 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %517 = memref.load %assume_align[%arg0, %516, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %518 = vector.broadcast %517 : f32 to vector<8xf32>
    %519 = vector.fma %518, %496, %487 : vector<8xf32>
    %520 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %521 = memref.load %assume_align[%arg0, %520, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %522 = vector.broadcast %521 : f32 to vector<8xf32>
    %523 = vector.fma %522, %496, %491 : vector<8xf32>
    %524 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %525 = memref.load %assume_align[%arg0, %524, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %526 = vector.broadcast %525 : f32 to vector<8xf32>
    %527 = vector.fma %526, %496, %495 : vector<8xf32>
    %528 = vector.extract %7[16] : vector<8xf32> from vector<64x8xf32>
    %529 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %530 = vector.broadcast %529 : f32 to vector<8xf32>
    %531 = vector.fma %530, %528, %499 : vector<8xf32>
    %532 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %533 = memref.load %assume_align[%arg0, %532, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %534 = vector.broadcast %533 : f32 to vector<8xf32>
    %535 = vector.fma %534, %528, %503 : vector<8xf32>
    %536 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %537 = memref.load %assume_align[%arg0, %536, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %538 = vector.broadcast %537 : f32 to vector<8xf32>
    %539 = vector.fma %538, %528, %507 : vector<8xf32>
    %540 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %541 = memref.load %assume_align[%arg0, %540, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %542 = vector.broadcast %541 : f32 to vector<8xf32>
    %543 = vector.fma %542, %528, %511 : vector<8xf32>
    %544 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %545 = memref.load %assume_align[%arg0, %544, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %546 = vector.broadcast %545 : f32 to vector<8xf32>
    %547 = vector.fma %546, %528, %515 : vector<8xf32>
    %548 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %549 = memref.load %assume_align[%arg0, %548, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %550 = vector.broadcast %549 : f32 to vector<8xf32>
    %551 = vector.fma %550, %528, %519 : vector<8xf32>
    %552 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %553 = memref.load %assume_align[%arg0, %552, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %554 = vector.broadcast %553 : f32 to vector<8xf32>
    %555 = vector.fma %554, %528, %523 : vector<8xf32>
    %556 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %557 = memref.load %assume_align[%arg0, %556, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %558 = vector.broadcast %557 : f32 to vector<8xf32>
    %559 = vector.fma %558, %528, %527 : vector<8xf32>
    %560 = vector.extract %7[17] : vector<8xf32> from vector<64x8xf32>
    %561 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %562 = vector.broadcast %561 : f32 to vector<8xf32>
    %563 = vector.fma %562, %560, %531 : vector<8xf32>
    %564 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %565 = memref.load %assume_align[%arg0, %564, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %566 = vector.broadcast %565 : f32 to vector<8xf32>
    %567 = vector.fma %566, %560, %535 : vector<8xf32>
    %568 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %569 = memref.load %assume_align[%arg0, %568, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %570 = vector.broadcast %569 : f32 to vector<8xf32>
    %571 = vector.fma %570, %560, %539 : vector<8xf32>
    %572 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %573 = memref.load %assume_align[%arg0, %572, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %574 = vector.broadcast %573 : f32 to vector<8xf32>
    %575 = vector.fma %574, %560, %543 : vector<8xf32>
    %576 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %577 = memref.load %assume_align[%arg0, %576, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %578 = vector.broadcast %577 : f32 to vector<8xf32>
    %579 = vector.fma %578, %560, %547 : vector<8xf32>
    %580 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %581 = memref.load %assume_align[%arg0, %580, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %582 = vector.broadcast %581 : f32 to vector<8xf32>
    %583 = vector.fma %582, %560, %551 : vector<8xf32>
    %584 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %585 = memref.load %assume_align[%arg0, %584, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %586 = vector.broadcast %585 : f32 to vector<8xf32>
    %587 = vector.fma %586, %560, %555 : vector<8xf32>
    %588 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %589 = memref.load %assume_align[%arg0, %588, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %590 = vector.broadcast %589 : f32 to vector<8xf32>
    %591 = vector.fma %590, %560, %559 : vector<8xf32>
    %592 = vector.extract %7[18] : vector<8xf32> from vector<64x8xf32>
    %593 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %594 = vector.broadcast %593 : f32 to vector<8xf32>
    %595 = vector.fma %594, %592, %563 : vector<8xf32>
    %596 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %597 = memref.load %assume_align[%arg0, %596, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %598 = vector.broadcast %597 : f32 to vector<8xf32>
    %599 = vector.fma %598, %592, %567 : vector<8xf32>
    %600 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %601 = memref.load %assume_align[%arg0, %600, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %602 = vector.broadcast %601 : f32 to vector<8xf32>
    %603 = vector.fma %602, %592, %571 : vector<8xf32>
    %604 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %605 = memref.load %assume_align[%arg0, %604, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %606 = vector.broadcast %605 : f32 to vector<8xf32>
    %607 = vector.fma %606, %592, %575 : vector<8xf32>
    %608 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %609 = memref.load %assume_align[%arg0, %608, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %610 = vector.broadcast %609 : f32 to vector<8xf32>
    %611 = vector.fma %610, %592, %579 : vector<8xf32>
    %612 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %613 = memref.load %assume_align[%arg0, %612, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %614 = vector.broadcast %613 : f32 to vector<8xf32>
    %615 = vector.fma %614, %592, %583 : vector<8xf32>
    %616 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %617 = memref.load %assume_align[%arg0, %616, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %618 = vector.broadcast %617 : f32 to vector<8xf32>
    %619 = vector.fma %618, %592, %587 : vector<8xf32>
    %620 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %621 = memref.load %assume_align[%arg0, %620, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %622 = vector.broadcast %621 : f32 to vector<8xf32>
    %623 = vector.fma %622, %592, %591 : vector<8xf32>
    %624 = vector.extract %7[19] : vector<8xf32> from vector<64x8xf32>
    %625 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %626 = vector.broadcast %625 : f32 to vector<8xf32>
    %627 = vector.fma %626, %624, %595 : vector<8xf32>
    %628 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %629 = memref.load %assume_align[%arg0, %628, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %630 = vector.broadcast %629 : f32 to vector<8xf32>
    %631 = vector.fma %630, %624, %599 : vector<8xf32>
    %632 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %633 = memref.load %assume_align[%arg0, %632, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %634 = vector.broadcast %633 : f32 to vector<8xf32>
    %635 = vector.fma %634, %624, %603 : vector<8xf32>
    %636 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %637 = memref.load %assume_align[%arg0, %636, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %638 = vector.broadcast %637 : f32 to vector<8xf32>
    %639 = vector.fma %638, %624, %607 : vector<8xf32>
    %640 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %641 = memref.load %assume_align[%arg0, %640, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %642 = vector.broadcast %641 : f32 to vector<8xf32>
    %643 = vector.fma %642, %624, %611 : vector<8xf32>
    %644 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %645 = memref.load %assume_align[%arg0, %644, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %646 = vector.broadcast %645 : f32 to vector<8xf32>
    %647 = vector.fma %646, %624, %615 : vector<8xf32>
    %648 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %649 = memref.load %assume_align[%arg0, %648, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %650 = vector.broadcast %649 : f32 to vector<8xf32>
    %651 = vector.fma %650, %624, %619 : vector<8xf32>
    %652 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %653 = memref.load %assume_align[%arg0, %652, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %654 = vector.broadcast %653 : f32 to vector<8xf32>
    %655 = vector.fma %654, %624, %623 : vector<8xf32>
    %656 = vector.extract %7[20] : vector<8xf32> from vector<64x8xf32>
    %657 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %658 = vector.broadcast %657 : f32 to vector<8xf32>
    %659 = vector.fma %658, %656, %627 : vector<8xf32>
    %660 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %661 = memref.load %assume_align[%arg0, %660, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %662 = vector.broadcast %661 : f32 to vector<8xf32>
    %663 = vector.fma %662, %656, %631 : vector<8xf32>
    %664 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %665 = memref.load %assume_align[%arg0, %664, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %666 = vector.broadcast %665 : f32 to vector<8xf32>
    %667 = vector.fma %666, %656, %635 : vector<8xf32>
    %668 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %669 = memref.load %assume_align[%arg0, %668, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %670 = vector.broadcast %669 : f32 to vector<8xf32>
    %671 = vector.fma %670, %656, %639 : vector<8xf32>
    %672 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %673 = memref.load %assume_align[%arg0, %672, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %674 = vector.broadcast %673 : f32 to vector<8xf32>
    %675 = vector.fma %674, %656, %643 : vector<8xf32>
    %676 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %677 = memref.load %assume_align[%arg0, %676, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %678 = vector.broadcast %677 : f32 to vector<8xf32>
    %679 = vector.fma %678, %656, %647 : vector<8xf32>
    %680 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %681 = memref.load %assume_align[%arg0, %680, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %682 = vector.broadcast %681 : f32 to vector<8xf32>
    %683 = vector.fma %682, %656, %651 : vector<8xf32>
    %684 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %685 = memref.load %assume_align[%arg0, %684, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %686 = vector.broadcast %685 : f32 to vector<8xf32>
    %687 = vector.fma %686, %656, %655 : vector<8xf32>
    %688 = vector.extract %7[21] : vector<8xf32> from vector<64x8xf32>
    %689 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %690 = vector.broadcast %689 : f32 to vector<8xf32>
    %691 = vector.fma %690, %688, %659 : vector<8xf32>
    %692 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %693 = memref.load %assume_align[%arg0, %692, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %694 = vector.broadcast %693 : f32 to vector<8xf32>
    %695 = vector.fma %694, %688, %663 : vector<8xf32>
    %696 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %697 = memref.load %assume_align[%arg0, %696, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %698 = vector.broadcast %697 : f32 to vector<8xf32>
    %699 = vector.fma %698, %688, %667 : vector<8xf32>
    %700 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %701 = memref.load %assume_align[%arg0, %700, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %702 = vector.broadcast %701 : f32 to vector<8xf32>
    %703 = vector.fma %702, %688, %671 : vector<8xf32>
    %704 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %705 = memref.load %assume_align[%arg0, %704, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %706 = vector.broadcast %705 : f32 to vector<8xf32>
    %707 = vector.fma %706, %688, %675 : vector<8xf32>
    %708 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %709 = memref.load %assume_align[%arg0, %708, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %710 = vector.broadcast %709 : f32 to vector<8xf32>
    %711 = vector.fma %710, %688, %679 : vector<8xf32>
    %712 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %713 = memref.load %assume_align[%arg0, %712, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %714 = vector.broadcast %713 : f32 to vector<8xf32>
    %715 = vector.fma %714, %688, %683 : vector<8xf32>
    %716 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %717 = memref.load %assume_align[%arg0, %716, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %718 = vector.broadcast %717 : f32 to vector<8xf32>
    %719 = vector.fma %718, %688, %687 : vector<8xf32>
    %720 = vector.extract %7[22] : vector<8xf32> from vector<64x8xf32>
    %721 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %722 = vector.broadcast %721 : f32 to vector<8xf32>
    %723 = vector.fma %722, %720, %691 : vector<8xf32>
    %724 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %725 = memref.load %assume_align[%arg0, %724, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %726 = vector.broadcast %725 : f32 to vector<8xf32>
    %727 = vector.fma %726, %720, %695 : vector<8xf32>
    %728 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %729 = memref.load %assume_align[%arg0, %728, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %730 = vector.broadcast %729 : f32 to vector<8xf32>
    %731 = vector.fma %730, %720, %699 : vector<8xf32>
    %732 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %733 = memref.load %assume_align[%arg0, %732, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %734 = vector.broadcast %733 : f32 to vector<8xf32>
    %735 = vector.fma %734, %720, %703 : vector<8xf32>
    %736 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %737 = memref.load %assume_align[%arg0, %736, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %738 = vector.broadcast %737 : f32 to vector<8xf32>
    %739 = vector.fma %738, %720, %707 : vector<8xf32>
    %740 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %741 = memref.load %assume_align[%arg0, %740, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %742 = vector.broadcast %741 : f32 to vector<8xf32>
    %743 = vector.fma %742, %720, %711 : vector<8xf32>
    %744 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %745 = memref.load %assume_align[%arg0, %744, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %746 = vector.broadcast %745 : f32 to vector<8xf32>
    %747 = vector.fma %746, %720, %715 : vector<8xf32>
    %748 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %749 = memref.load %assume_align[%arg0, %748, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %750 = vector.broadcast %749 : f32 to vector<8xf32>
    %751 = vector.fma %750, %720, %719 : vector<8xf32>
    %752 = vector.extract %7[23] : vector<8xf32> from vector<64x8xf32>
    %753 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %754 = vector.broadcast %753 : f32 to vector<8xf32>
    %755 = vector.fma %754, %752, %723 : vector<8xf32>
    %756 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %757 = memref.load %assume_align[%arg0, %756, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %758 = vector.broadcast %757 : f32 to vector<8xf32>
    %759 = vector.fma %758, %752, %727 : vector<8xf32>
    %760 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %761 = memref.load %assume_align[%arg0, %760, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %762 = vector.broadcast %761 : f32 to vector<8xf32>
    %763 = vector.fma %762, %752, %731 : vector<8xf32>
    %764 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %765 = memref.load %assume_align[%arg0, %764, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %766 = vector.broadcast %765 : f32 to vector<8xf32>
    %767 = vector.fma %766, %752, %735 : vector<8xf32>
    %768 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %769 = memref.load %assume_align[%arg0, %768, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %770 = vector.broadcast %769 : f32 to vector<8xf32>
    %771 = vector.fma %770, %752, %739 : vector<8xf32>
    %772 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %773 = memref.load %assume_align[%arg0, %772, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %774 = vector.broadcast %773 : f32 to vector<8xf32>
    %775 = vector.fma %774, %752, %743 : vector<8xf32>
    %776 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %777 = memref.load %assume_align[%arg0, %776, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %778 = vector.broadcast %777 : f32 to vector<8xf32>
    %779 = vector.fma %778, %752, %747 : vector<8xf32>
    %780 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %781 = memref.load %assume_align[%arg0, %780, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %782 = vector.broadcast %781 : f32 to vector<8xf32>
    %783 = vector.fma %782, %752, %751 : vector<8xf32>
    %784 = vector.extract %7[24] : vector<8xf32> from vector<64x8xf32>
    %785 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %786 = vector.broadcast %785 : f32 to vector<8xf32>
    %787 = vector.fma %786, %784, %755 : vector<8xf32>
    %788 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %789 = memref.load %assume_align[%arg0, %788, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %790 = vector.broadcast %789 : f32 to vector<8xf32>
    %791 = vector.fma %790, %784, %759 : vector<8xf32>
    %792 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %793 = memref.load %assume_align[%arg0, %792, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %794 = vector.broadcast %793 : f32 to vector<8xf32>
    %795 = vector.fma %794, %784, %763 : vector<8xf32>
    %796 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %797 = memref.load %assume_align[%arg0, %796, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %798 = vector.broadcast %797 : f32 to vector<8xf32>
    %799 = vector.fma %798, %784, %767 : vector<8xf32>
    %800 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %801 = memref.load %assume_align[%arg0, %800, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %802 = vector.broadcast %801 : f32 to vector<8xf32>
    %803 = vector.fma %802, %784, %771 : vector<8xf32>
    %804 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %805 = memref.load %assume_align[%arg0, %804, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %806 = vector.broadcast %805 : f32 to vector<8xf32>
    %807 = vector.fma %806, %784, %775 : vector<8xf32>
    %808 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %809 = memref.load %assume_align[%arg0, %808, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %810 = vector.broadcast %809 : f32 to vector<8xf32>
    %811 = vector.fma %810, %784, %779 : vector<8xf32>
    %812 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %813 = memref.load %assume_align[%arg0, %812, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %814 = vector.broadcast %813 : f32 to vector<8xf32>
    %815 = vector.fma %814, %784, %783 : vector<8xf32>
    %816 = vector.extract %7[25] : vector<8xf32> from vector<64x8xf32>
    %817 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %818 = vector.broadcast %817 : f32 to vector<8xf32>
    %819 = vector.fma %818, %816, %787 : vector<8xf32>
    %820 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %821 = memref.load %assume_align[%arg0, %820, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %822 = vector.broadcast %821 : f32 to vector<8xf32>
    %823 = vector.fma %822, %816, %791 : vector<8xf32>
    %824 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %825 = memref.load %assume_align[%arg0, %824, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %826 = vector.broadcast %825 : f32 to vector<8xf32>
    %827 = vector.fma %826, %816, %795 : vector<8xf32>
    %828 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %829 = memref.load %assume_align[%arg0, %828, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %830 = vector.broadcast %829 : f32 to vector<8xf32>
    %831 = vector.fma %830, %816, %799 : vector<8xf32>
    %832 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %833 = memref.load %assume_align[%arg0, %832, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %834 = vector.broadcast %833 : f32 to vector<8xf32>
    %835 = vector.fma %834, %816, %803 : vector<8xf32>
    %836 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %837 = memref.load %assume_align[%arg0, %836, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %838 = vector.broadcast %837 : f32 to vector<8xf32>
    %839 = vector.fma %838, %816, %807 : vector<8xf32>
    %840 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %841 = memref.load %assume_align[%arg0, %840, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %842 = vector.broadcast %841 : f32 to vector<8xf32>
    %843 = vector.fma %842, %816, %811 : vector<8xf32>
    %844 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %845 = memref.load %assume_align[%arg0, %844, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %846 = vector.broadcast %845 : f32 to vector<8xf32>
    %847 = vector.fma %846, %816, %815 : vector<8xf32>
    %848 = vector.extract %7[26] : vector<8xf32> from vector<64x8xf32>
    %849 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %850 = vector.broadcast %849 : f32 to vector<8xf32>
    %851 = vector.fma %850, %848, %819 : vector<8xf32>
    %852 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %853 = memref.load %assume_align[%arg0, %852, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %854 = vector.broadcast %853 : f32 to vector<8xf32>
    %855 = vector.fma %854, %848, %823 : vector<8xf32>
    %856 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %857 = memref.load %assume_align[%arg0, %856, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %858 = vector.broadcast %857 : f32 to vector<8xf32>
    %859 = vector.fma %858, %848, %827 : vector<8xf32>
    %860 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %861 = memref.load %assume_align[%arg0, %860, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %862 = vector.broadcast %861 : f32 to vector<8xf32>
    %863 = vector.fma %862, %848, %831 : vector<8xf32>
    %864 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %865 = memref.load %assume_align[%arg0, %864, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %866 = vector.broadcast %865 : f32 to vector<8xf32>
    %867 = vector.fma %866, %848, %835 : vector<8xf32>
    %868 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %869 = memref.load %assume_align[%arg0, %868, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %870 = vector.broadcast %869 : f32 to vector<8xf32>
    %871 = vector.fma %870, %848, %839 : vector<8xf32>
    %872 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %873 = memref.load %assume_align[%arg0, %872, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %874 = vector.broadcast %873 : f32 to vector<8xf32>
    %875 = vector.fma %874, %848, %843 : vector<8xf32>
    %876 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %877 = memref.load %assume_align[%arg0, %876, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %878 = vector.broadcast %877 : f32 to vector<8xf32>
    %879 = vector.fma %878, %848, %847 : vector<8xf32>
    %880 = vector.extract %7[27] : vector<8xf32> from vector<64x8xf32>
    %881 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %882 = vector.broadcast %881 : f32 to vector<8xf32>
    %883 = vector.fma %882, %880, %851 : vector<8xf32>
    %884 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %885 = memref.load %assume_align[%arg0, %884, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %886 = vector.broadcast %885 : f32 to vector<8xf32>
    %887 = vector.fma %886, %880, %855 : vector<8xf32>
    %888 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %889 = memref.load %assume_align[%arg0, %888, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %890 = vector.broadcast %889 : f32 to vector<8xf32>
    %891 = vector.fma %890, %880, %859 : vector<8xf32>
    %892 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %893 = memref.load %assume_align[%arg0, %892, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %894 = vector.broadcast %893 : f32 to vector<8xf32>
    %895 = vector.fma %894, %880, %863 : vector<8xf32>
    %896 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %897 = memref.load %assume_align[%arg0, %896, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %898 = vector.broadcast %897 : f32 to vector<8xf32>
    %899 = vector.fma %898, %880, %867 : vector<8xf32>
    %900 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %901 = memref.load %assume_align[%arg0, %900, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %902 = vector.broadcast %901 : f32 to vector<8xf32>
    %903 = vector.fma %902, %880, %871 : vector<8xf32>
    %904 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %905 = memref.load %assume_align[%arg0, %904, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %906 = vector.broadcast %905 : f32 to vector<8xf32>
    %907 = vector.fma %906, %880, %875 : vector<8xf32>
    %908 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %909 = memref.load %assume_align[%arg0, %908, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %910 = vector.broadcast %909 : f32 to vector<8xf32>
    %911 = vector.fma %910, %880, %879 : vector<8xf32>
    %912 = vector.extract %7[28] : vector<8xf32> from vector<64x8xf32>
    %913 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %914 = vector.broadcast %913 : f32 to vector<8xf32>
    %915 = vector.fma %914, %912, %883 : vector<8xf32>
    %916 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %917 = memref.load %assume_align[%arg0, %916, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %918 = vector.broadcast %917 : f32 to vector<8xf32>
    %919 = vector.fma %918, %912, %887 : vector<8xf32>
    %920 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %921 = memref.load %assume_align[%arg0, %920, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %922 = vector.broadcast %921 : f32 to vector<8xf32>
    %923 = vector.fma %922, %912, %891 : vector<8xf32>
    %924 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %925 = memref.load %assume_align[%arg0, %924, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %926 = vector.broadcast %925 : f32 to vector<8xf32>
    %927 = vector.fma %926, %912, %895 : vector<8xf32>
    %928 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %929 = memref.load %assume_align[%arg0, %928, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %930 = vector.broadcast %929 : f32 to vector<8xf32>
    %931 = vector.fma %930, %912, %899 : vector<8xf32>
    %932 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %933 = memref.load %assume_align[%arg0, %932, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %934 = vector.broadcast %933 : f32 to vector<8xf32>
    %935 = vector.fma %934, %912, %903 : vector<8xf32>
    %936 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %937 = memref.load %assume_align[%arg0, %936, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %938 = vector.broadcast %937 : f32 to vector<8xf32>
    %939 = vector.fma %938, %912, %907 : vector<8xf32>
    %940 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %941 = memref.load %assume_align[%arg0, %940, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %942 = vector.broadcast %941 : f32 to vector<8xf32>
    %943 = vector.fma %942, %912, %911 : vector<8xf32>
    %944 = vector.extract %7[29] : vector<8xf32> from vector<64x8xf32>
    %945 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %946 = vector.broadcast %945 : f32 to vector<8xf32>
    %947 = vector.fma %946, %944, %915 : vector<8xf32>
    %948 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %949 = memref.load %assume_align[%arg0, %948, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %950 = vector.broadcast %949 : f32 to vector<8xf32>
    %951 = vector.fma %950, %944, %919 : vector<8xf32>
    %952 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %953 = memref.load %assume_align[%arg0, %952, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %954 = vector.broadcast %953 : f32 to vector<8xf32>
    %955 = vector.fma %954, %944, %923 : vector<8xf32>
    %956 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %957 = memref.load %assume_align[%arg0, %956, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %958 = vector.broadcast %957 : f32 to vector<8xf32>
    %959 = vector.fma %958, %944, %927 : vector<8xf32>
    %960 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %961 = memref.load %assume_align[%arg0, %960, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %962 = vector.broadcast %961 : f32 to vector<8xf32>
    %963 = vector.fma %962, %944, %931 : vector<8xf32>
    %964 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %965 = memref.load %assume_align[%arg0, %964, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %966 = vector.broadcast %965 : f32 to vector<8xf32>
    %967 = vector.fma %966, %944, %935 : vector<8xf32>
    %968 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %969 = memref.load %assume_align[%arg0, %968, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %970 = vector.broadcast %969 : f32 to vector<8xf32>
    %971 = vector.fma %970, %944, %939 : vector<8xf32>
    %972 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %973 = memref.load %assume_align[%arg0, %972, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %974 = vector.broadcast %973 : f32 to vector<8xf32>
    %975 = vector.fma %974, %944, %943 : vector<8xf32>
    %976 = vector.extract %7[30] : vector<8xf32> from vector<64x8xf32>
    %977 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %978 = vector.broadcast %977 : f32 to vector<8xf32>
    %979 = vector.fma %978, %976, %947 : vector<8xf32>
    %980 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %981 = memref.load %assume_align[%arg0, %980, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %982 = vector.broadcast %981 : f32 to vector<8xf32>
    %983 = vector.fma %982, %976, %951 : vector<8xf32>
    %984 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %985 = memref.load %assume_align[%arg0, %984, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %986 = vector.broadcast %985 : f32 to vector<8xf32>
    %987 = vector.fma %986, %976, %955 : vector<8xf32>
    %988 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %989 = memref.load %assume_align[%arg0, %988, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %990 = vector.broadcast %989 : f32 to vector<8xf32>
    %991 = vector.fma %990, %976, %959 : vector<8xf32>
    %992 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %993 = memref.load %assume_align[%arg0, %992, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %994 = vector.broadcast %993 : f32 to vector<8xf32>
    %995 = vector.fma %994, %976, %963 : vector<8xf32>
    %996 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %997 = memref.load %assume_align[%arg0, %996, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %998 = vector.broadcast %997 : f32 to vector<8xf32>
    %999 = vector.fma %998, %976, %967 : vector<8xf32>
    %1000 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1001 = memref.load %assume_align[%arg0, %1000, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1002 = vector.broadcast %1001 : f32 to vector<8xf32>
    %1003 = vector.fma %1002, %976, %971 : vector<8xf32>
    %1004 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1005 = memref.load %assume_align[%arg0, %1004, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1006 = vector.broadcast %1005 : f32 to vector<8xf32>
    %1007 = vector.fma %1006, %976, %975 : vector<8xf32>
    %1008 = vector.extract %7[31] : vector<8xf32> from vector<64x8xf32>
    %1009 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1010 = vector.broadcast %1009 : f32 to vector<8xf32>
    %1011 = vector.fma %1010, %1008, %979 : vector<8xf32>
    %1012 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1013 = memref.load %assume_align[%arg0, %1012, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1014 = vector.broadcast %1013 : f32 to vector<8xf32>
    %1015 = vector.fma %1014, %1008, %983 : vector<8xf32>
    %1016 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1017 = memref.load %assume_align[%arg0, %1016, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1018 = vector.broadcast %1017 : f32 to vector<8xf32>
    %1019 = vector.fma %1018, %1008, %987 : vector<8xf32>
    %1020 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1021 = memref.load %assume_align[%arg0, %1020, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1022 = vector.broadcast %1021 : f32 to vector<8xf32>
    %1023 = vector.fma %1022, %1008, %991 : vector<8xf32>
    %1024 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1025 = memref.load %assume_align[%arg0, %1024, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1026 = vector.broadcast %1025 : f32 to vector<8xf32>
    %1027 = vector.fma %1026, %1008, %995 : vector<8xf32>
    %1028 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1029 = memref.load %assume_align[%arg0, %1028, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1030 = vector.broadcast %1029 : f32 to vector<8xf32>
    %1031 = vector.fma %1030, %1008, %999 : vector<8xf32>
    %1032 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1033 = memref.load %assume_align[%arg0, %1032, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1034 = vector.broadcast %1033 : f32 to vector<8xf32>
    %1035 = vector.fma %1034, %1008, %1003 : vector<8xf32>
    %1036 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1037 = memref.load %assume_align[%arg0, %1036, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1038 = vector.broadcast %1037 : f32 to vector<8xf32>
    %1039 = vector.fma %1038, %1008, %1007 : vector<8xf32>
    %1040 = vector.extract %7[32] : vector<8xf32> from vector<64x8xf32>
    %1041 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1042 = vector.broadcast %1041 : f32 to vector<8xf32>
    %1043 = vector.fma %1042, %1040, %1011 : vector<8xf32>
    %1044 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1045 = memref.load %assume_align[%arg0, %1044, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1046 = vector.broadcast %1045 : f32 to vector<8xf32>
    %1047 = vector.fma %1046, %1040, %1015 : vector<8xf32>
    %1048 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1049 = memref.load %assume_align[%arg0, %1048, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1050 = vector.broadcast %1049 : f32 to vector<8xf32>
    %1051 = vector.fma %1050, %1040, %1019 : vector<8xf32>
    %1052 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1053 = memref.load %assume_align[%arg0, %1052, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1054 = vector.broadcast %1053 : f32 to vector<8xf32>
    %1055 = vector.fma %1054, %1040, %1023 : vector<8xf32>
    %1056 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1057 = memref.load %assume_align[%arg0, %1056, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1058 = vector.broadcast %1057 : f32 to vector<8xf32>
    %1059 = vector.fma %1058, %1040, %1027 : vector<8xf32>
    %1060 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1061 = memref.load %assume_align[%arg0, %1060, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1062 = vector.broadcast %1061 : f32 to vector<8xf32>
    %1063 = vector.fma %1062, %1040, %1031 : vector<8xf32>
    %1064 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1065 = memref.load %assume_align[%arg0, %1064, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1066 = vector.broadcast %1065 : f32 to vector<8xf32>
    %1067 = vector.fma %1066, %1040, %1035 : vector<8xf32>
    %1068 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1069 = memref.load %assume_align[%arg0, %1068, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1070 = vector.broadcast %1069 : f32 to vector<8xf32>
    %1071 = vector.fma %1070, %1040, %1039 : vector<8xf32>
    %1072 = vector.extract %7[33] : vector<8xf32> from vector<64x8xf32>
    %1073 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1074 = vector.broadcast %1073 : f32 to vector<8xf32>
    %1075 = vector.fma %1074, %1072, %1043 : vector<8xf32>
    %1076 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1077 = memref.load %assume_align[%arg0, %1076, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1078 = vector.broadcast %1077 : f32 to vector<8xf32>
    %1079 = vector.fma %1078, %1072, %1047 : vector<8xf32>
    %1080 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1081 = memref.load %assume_align[%arg0, %1080, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1082 = vector.broadcast %1081 : f32 to vector<8xf32>
    %1083 = vector.fma %1082, %1072, %1051 : vector<8xf32>
    %1084 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1085 = memref.load %assume_align[%arg0, %1084, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1086 = vector.broadcast %1085 : f32 to vector<8xf32>
    %1087 = vector.fma %1086, %1072, %1055 : vector<8xf32>
    %1088 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1089 = memref.load %assume_align[%arg0, %1088, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1090 = vector.broadcast %1089 : f32 to vector<8xf32>
    %1091 = vector.fma %1090, %1072, %1059 : vector<8xf32>
    %1092 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1093 = memref.load %assume_align[%arg0, %1092, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1094 = vector.broadcast %1093 : f32 to vector<8xf32>
    %1095 = vector.fma %1094, %1072, %1063 : vector<8xf32>
    %1096 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1097 = memref.load %assume_align[%arg0, %1096, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1098 = vector.broadcast %1097 : f32 to vector<8xf32>
    %1099 = vector.fma %1098, %1072, %1067 : vector<8xf32>
    %1100 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1101 = memref.load %assume_align[%arg0, %1100, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1102 = vector.broadcast %1101 : f32 to vector<8xf32>
    %1103 = vector.fma %1102, %1072, %1071 : vector<8xf32>
    %1104 = vector.extract %7[34] : vector<8xf32> from vector<64x8xf32>
    %1105 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1106 = vector.broadcast %1105 : f32 to vector<8xf32>
    %1107 = vector.fma %1106, %1104, %1075 : vector<8xf32>
    %1108 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1109 = memref.load %assume_align[%arg0, %1108, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1110 = vector.broadcast %1109 : f32 to vector<8xf32>
    %1111 = vector.fma %1110, %1104, %1079 : vector<8xf32>
    %1112 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1113 = memref.load %assume_align[%arg0, %1112, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1114 = vector.broadcast %1113 : f32 to vector<8xf32>
    %1115 = vector.fma %1114, %1104, %1083 : vector<8xf32>
    %1116 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1117 = memref.load %assume_align[%arg0, %1116, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1118 = vector.broadcast %1117 : f32 to vector<8xf32>
    %1119 = vector.fma %1118, %1104, %1087 : vector<8xf32>
    %1120 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1121 = memref.load %assume_align[%arg0, %1120, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1122 = vector.broadcast %1121 : f32 to vector<8xf32>
    %1123 = vector.fma %1122, %1104, %1091 : vector<8xf32>
    %1124 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1125 = memref.load %assume_align[%arg0, %1124, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1126 = vector.broadcast %1125 : f32 to vector<8xf32>
    %1127 = vector.fma %1126, %1104, %1095 : vector<8xf32>
    %1128 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1129 = memref.load %assume_align[%arg0, %1128, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1130 = vector.broadcast %1129 : f32 to vector<8xf32>
    %1131 = vector.fma %1130, %1104, %1099 : vector<8xf32>
    %1132 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1133 = memref.load %assume_align[%arg0, %1132, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1134 = vector.broadcast %1133 : f32 to vector<8xf32>
    %1135 = vector.fma %1134, %1104, %1103 : vector<8xf32>
    %1136 = vector.extract %7[35] : vector<8xf32> from vector<64x8xf32>
    %1137 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1138 = vector.broadcast %1137 : f32 to vector<8xf32>
    %1139 = vector.fma %1138, %1136, %1107 : vector<8xf32>
    %1140 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1141 = memref.load %assume_align[%arg0, %1140, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1142 = vector.broadcast %1141 : f32 to vector<8xf32>
    %1143 = vector.fma %1142, %1136, %1111 : vector<8xf32>
    %1144 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1145 = memref.load %assume_align[%arg0, %1144, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1146 = vector.broadcast %1145 : f32 to vector<8xf32>
    %1147 = vector.fma %1146, %1136, %1115 : vector<8xf32>
    %1148 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1149 = memref.load %assume_align[%arg0, %1148, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1150 = vector.broadcast %1149 : f32 to vector<8xf32>
    %1151 = vector.fma %1150, %1136, %1119 : vector<8xf32>
    %1152 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1153 = memref.load %assume_align[%arg0, %1152, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1154 = vector.broadcast %1153 : f32 to vector<8xf32>
    %1155 = vector.fma %1154, %1136, %1123 : vector<8xf32>
    %1156 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1157 = memref.load %assume_align[%arg0, %1156, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1158 = vector.broadcast %1157 : f32 to vector<8xf32>
    %1159 = vector.fma %1158, %1136, %1127 : vector<8xf32>
    %1160 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1161 = memref.load %assume_align[%arg0, %1160, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1162 = vector.broadcast %1161 : f32 to vector<8xf32>
    %1163 = vector.fma %1162, %1136, %1131 : vector<8xf32>
    %1164 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1165 = memref.load %assume_align[%arg0, %1164, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1166 = vector.broadcast %1165 : f32 to vector<8xf32>
    %1167 = vector.fma %1166, %1136, %1135 : vector<8xf32>
    %1168 = vector.extract %7[36] : vector<8xf32> from vector<64x8xf32>
    %1169 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1170 = vector.broadcast %1169 : f32 to vector<8xf32>
    %1171 = vector.fma %1170, %1168, %1139 : vector<8xf32>
    %1172 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1173 = memref.load %assume_align[%arg0, %1172, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1174 = vector.broadcast %1173 : f32 to vector<8xf32>
    %1175 = vector.fma %1174, %1168, %1143 : vector<8xf32>
    %1176 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1177 = memref.load %assume_align[%arg0, %1176, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1178 = vector.broadcast %1177 : f32 to vector<8xf32>
    %1179 = vector.fma %1178, %1168, %1147 : vector<8xf32>
    %1180 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1181 = memref.load %assume_align[%arg0, %1180, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1182 = vector.broadcast %1181 : f32 to vector<8xf32>
    %1183 = vector.fma %1182, %1168, %1151 : vector<8xf32>
    %1184 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1185 = memref.load %assume_align[%arg0, %1184, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1186 = vector.broadcast %1185 : f32 to vector<8xf32>
    %1187 = vector.fma %1186, %1168, %1155 : vector<8xf32>
    %1188 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1189 = memref.load %assume_align[%arg0, %1188, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1190 = vector.broadcast %1189 : f32 to vector<8xf32>
    %1191 = vector.fma %1190, %1168, %1159 : vector<8xf32>
    %1192 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1193 = memref.load %assume_align[%arg0, %1192, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1194 = vector.broadcast %1193 : f32 to vector<8xf32>
    %1195 = vector.fma %1194, %1168, %1163 : vector<8xf32>
    %1196 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1197 = memref.load %assume_align[%arg0, %1196, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1198 = vector.broadcast %1197 : f32 to vector<8xf32>
    %1199 = vector.fma %1198, %1168, %1167 : vector<8xf32>
    %1200 = vector.extract %7[37] : vector<8xf32> from vector<64x8xf32>
    %1201 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1202 = vector.broadcast %1201 : f32 to vector<8xf32>
    %1203 = vector.fma %1202, %1200, %1171 : vector<8xf32>
    %1204 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1205 = memref.load %assume_align[%arg0, %1204, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1206 = vector.broadcast %1205 : f32 to vector<8xf32>
    %1207 = vector.fma %1206, %1200, %1175 : vector<8xf32>
    %1208 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1209 = memref.load %assume_align[%arg0, %1208, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1210 = vector.broadcast %1209 : f32 to vector<8xf32>
    %1211 = vector.fma %1210, %1200, %1179 : vector<8xf32>
    %1212 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1213 = memref.load %assume_align[%arg0, %1212, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1214 = vector.broadcast %1213 : f32 to vector<8xf32>
    %1215 = vector.fma %1214, %1200, %1183 : vector<8xf32>
    %1216 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1217 = memref.load %assume_align[%arg0, %1216, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1218 = vector.broadcast %1217 : f32 to vector<8xf32>
    %1219 = vector.fma %1218, %1200, %1187 : vector<8xf32>
    %1220 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1221 = memref.load %assume_align[%arg0, %1220, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1222 = vector.broadcast %1221 : f32 to vector<8xf32>
    %1223 = vector.fma %1222, %1200, %1191 : vector<8xf32>
    %1224 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1225 = memref.load %assume_align[%arg0, %1224, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1226 = vector.broadcast %1225 : f32 to vector<8xf32>
    %1227 = vector.fma %1226, %1200, %1195 : vector<8xf32>
    %1228 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1229 = memref.load %assume_align[%arg0, %1228, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1230 = vector.broadcast %1229 : f32 to vector<8xf32>
    %1231 = vector.fma %1230, %1200, %1199 : vector<8xf32>
    %1232 = vector.extract %7[38] : vector<8xf32> from vector<64x8xf32>
    %1233 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1234 = vector.broadcast %1233 : f32 to vector<8xf32>
    %1235 = vector.fma %1234, %1232, %1203 : vector<8xf32>
    %1236 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1237 = memref.load %assume_align[%arg0, %1236, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1238 = vector.broadcast %1237 : f32 to vector<8xf32>
    %1239 = vector.fma %1238, %1232, %1207 : vector<8xf32>
    %1240 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1241 = memref.load %assume_align[%arg0, %1240, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1242 = vector.broadcast %1241 : f32 to vector<8xf32>
    %1243 = vector.fma %1242, %1232, %1211 : vector<8xf32>
    %1244 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1245 = memref.load %assume_align[%arg0, %1244, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1246 = vector.broadcast %1245 : f32 to vector<8xf32>
    %1247 = vector.fma %1246, %1232, %1215 : vector<8xf32>
    %1248 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1249 = memref.load %assume_align[%arg0, %1248, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1250 = vector.broadcast %1249 : f32 to vector<8xf32>
    %1251 = vector.fma %1250, %1232, %1219 : vector<8xf32>
    %1252 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1253 = memref.load %assume_align[%arg0, %1252, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1254 = vector.broadcast %1253 : f32 to vector<8xf32>
    %1255 = vector.fma %1254, %1232, %1223 : vector<8xf32>
    %1256 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1257 = memref.load %assume_align[%arg0, %1256, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1258 = vector.broadcast %1257 : f32 to vector<8xf32>
    %1259 = vector.fma %1258, %1232, %1227 : vector<8xf32>
    %1260 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1261 = memref.load %assume_align[%arg0, %1260, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1262 = vector.broadcast %1261 : f32 to vector<8xf32>
    %1263 = vector.fma %1262, %1232, %1231 : vector<8xf32>
    %1264 = vector.extract %7[39] : vector<8xf32> from vector<64x8xf32>
    %1265 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1266 = vector.broadcast %1265 : f32 to vector<8xf32>
    %1267 = vector.fma %1266, %1264, %1235 : vector<8xf32>
    %1268 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1269 = memref.load %assume_align[%arg0, %1268, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1270 = vector.broadcast %1269 : f32 to vector<8xf32>
    %1271 = vector.fma %1270, %1264, %1239 : vector<8xf32>
    %1272 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1273 = memref.load %assume_align[%arg0, %1272, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1274 = vector.broadcast %1273 : f32 to vector<8xf32>
    %1275 = vector.fma %1274, %1264, %1243 : vector<8xf32>
    %1276 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1277 = memref.load %assume_align[%arg0, %1276, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1278 = vector.broadcast %1277 : f32 to vector<8xf32>
    %1279 = vector.fma %1278, %1264, %1247 : vector<8xf32>
    %1280 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1281 = memref.load %assume_align[%arg0, %1280, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1282 = vector.broadcast %1281 : f32 to vector<8xf32>
    %1283 = vector.fma %1282, %1264, %1251 : vector<8xf32>
    %1284 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1285 = memref.load %assume_align[%arg0, %1284, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1286 = vector.broadcast %1285 : f32 to vector<8xf32>
    %1287 = vector.fma %1286, %1264, %1255 : vector<8xf32>
    %1288 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1289 = memref.load %assume_align[%arg0, %1288, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1290 = vector.broadcast %1289 : f32 to vector<8xf32>
    %1291 = vector.fma %1290, %1264, %1259 : vector<8xf32>
    %1292 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1293 = memref.load %assume_align[%arg0, %1292, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1294 = vector.broadcast %1293 : f32 to vector<8xf32>
    %1295 = vector.fma %1294, %1264, %1263 : vector<8xf32>
    %1296 = vector.extract %7[40] : vector<8xf32> from vector<64x8xf32>
    %1297 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1298 = vector.broadcast %1297 : f32 to vector<8xf32>
    %1299 = vector.fma %1298, %1296, %1267 : vector<8xf32>
    %1300 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1301 = memref.load %assume_align[%arg0, %1300, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1302 = vector.broadcast %1301 : f32 to vector<8xf32>
    %1303 = vector.fma %1302, %1296, %1271 : vector<8xf32>
    %1304 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1305 = memref.load %assume_align[%arg0, %1304, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1306 = vector.broadcast %1305 : f32 to vector<8xf32>
    %1307 = vector.fma %1306, %1296, %1275 : vector<8xf32>
    %1308 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1309 = memref.load %assume_align[%arg0, %1308, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1310 = vector.broadcast %1309 : f32 to vector<8xf32>
    %1311 = vector.fma %1310, %1296, %1279 : vector<8xf32>
    %1312 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1313 = memref.load %assume_align[%arg0, %1312, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1314 = vector.broadcast %1313 : f32 to vector<8xf32>
    %1315 = vector.fma %1314, %1296, %1283 : vector<8xf32>
    %1316 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1317 = memref.load %assume_align[%arg0, %1316, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1318 = vector.broadcast %1317 : f32 to vector<8xf32>
    %1319 = vector.fma %1318, %1296, %1287 : vector<8xf32>
    %1320 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1321 = memref.load %assume_align[%arg0, %1320, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1322 = vector.broadcast %1321 : f32 to vector<8xf32>
    %1323 = vector.fma %1322, %1296, %1291 : vector<8xf32>
    %1324 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1325 = memref.load %assume_align[%arg0, %1324, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1326 = vector.broadcast %1325 : f32 to vector<8xf32>
    %1327 = vector.fma %1326, %1296, %1295 : vector<8xf32>
    %1328 = vector.extract %7[41] : vector<8xf32> from vector<64x8xf32>
    %1329 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1330 = vector.broadcast %1329 : f32 to vector<8xf32>
    %1331 = vector.fma %1330, %1328, %1299 : vector<8xf32>
    %1332 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1333 = memref.load %assume_align[%arg0, %1332, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1334 = vector.broadcast %1333 : f32 to vector<8xf32>
    %1335 = vector.fma %1334, %1328, %1303 : vector<8xf32>
    %1336 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1337 = memref.load %assume_align[%arg0, %1336, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1338 = vector.broadcast %1337 : f32 to vector<8xf32>
    %1339 = vector.fma %1338, %1328, %1307 : vector<8xf32>
    %1340 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1341 = memref.load %assume_align[%arg0, %1340, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1342 = vector.broadcast %1341 : f32 to vector<8xf32>
    %1343 = vector.fma %1342, %1328, %1311 : vector<8xf32>
    %1344 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1345 = memref.load %assume_align[%arg0, %1344, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1346 = vector.broadcast %1345 : f32 to vector<8xf32>
    %1347 = vector.fma %1346, %1328, %1315 : vector<8xf32>
    %1348 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1349 = memref.load %assume_align[%arg0, %1348, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1350 = vector.broadcast %1349 : f32 to vector<8xf32>
    %1351 = vector.fma %1350, %1328, %1319 : vector<8xf32>
    %1352 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1353 = memref.load %assume_align[%arg0, %1352, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1354 = vector.broadcast %1353 : f32 to vector<8xf32>
    %1355 = vector.fma %1354, %1328, %1323 : vector<8xf32>
    %1356 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1357 = memref.load %assume_align[%arg0, %1356, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1358 = vector.broadcast %1357 : f32 to vector<8xf32>
    %1359 = vector.fma %1358, %1328, %1327 : vector<8xf32>
    %1360 = vector.extract %7[42] : vector<8xf32> from vector<64x8xf32>
    %1361 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1362 = vector.broadcast %1361 : f32 to vector<8xf32>
    %1363 = vector.fma %1362, %1360, %1331 : vector<8xf32>
    %1364 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1365 = memref.load %assume_align[%arg0, %1364, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1366 = vector.broadcast %1365 : f32 to vector<8xf32>
    %1367 = vector.fma %1366, %1360, %1335 : vector<8xf32>
    %1368 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1369 = memref.load %assume_align[%arg0, %1368, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1370 = vector.broadcast %1369 : f32 to vector<8xf32>
    %1371 = vector.fma %1370, %1360, %1339 : vector<8xf32>
    %1372 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1373 = memref.load %assume_align[%arg0, %1372, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1374 = vector.broadcast %1373 : f32 to vector<8xf32>
    %1375 = vector.fma %1374, %1360, %1343 : vector<8xf32>
    %1376 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1377 = memref.load %assume_align[%arg0, %1376, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1378 = vector.broadcast %1377 : f32 to vector<8xf32>
    %1379 = vector.fma %1378, %1360, %1347 : vector<8xf32>
    %1380 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1381 = memref.load %assume_align[%arg0, %1380, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1382 = vector.broadcast %1381 : f32 to vector<8xf32>
    %1383 = vector.fma %1382, %1360, %1351 : vector<8xf32>
    %1384 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1385 = memref.load %assume_align[%arg0, %1384, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1386 = vector.broadcast %1385 : f32 to vector<8xf32>
    %1387 = vector.fma %1386, %1360, %1355 : vector<8xf32>
    %1388 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1389 = memref.load %assume_align[%arg0, %1388, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1390 = vector.broadcast %1389 : f32 to vector<8xf32>
    %1391 = vector.fma %1390, %1360, %1359 : vector<8xf32>
    %1392 = vector.extract %7[43] : vector<8xf32> from vector<64x8xf32>
    %1393 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1394 = vector.broadcast %1393 : f32 to vector<8xf32>
    %1395 = vector.fma %1394, %1392, %1363 : vector<8xf32>
    %1396 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1397 = memref.load %assume_align[%arg0, %1396, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1398 = vector.broadcast %1397 : f32 to vector<8xf32>
    %1399 = vector.fma %1398, %1392, %1367 : vector<8xf32>
    %1400 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1401 = memref.load %assume_align[%arg0, %1400, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1402 = vector.broadcast %1401 : f32 to vector<8xf32>
    %1403 = vector.fma %1402, %1392, %1371 : vector<8xf32>
    %1404 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1405 = memref.load %assume_align[%arg0, %1404, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1406 = vector.broadcast %1405 : f32 to vector<8xf32>
    %1407 = vector.fma %1406, %1392, %1375 : vector<8xf32>
    %1408 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1409 = memref.load %assume_align[%arg0, %1408, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1410 = vector.broadcast %1409 : f32 to vector<8xf32>
    %1411 = vector.fma %1410, %1392, %1379 : vector<8xf32>
    %1412 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1413 = memref.load %assume_align[%arg0, %1412, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1414 = vector.broadcast %1413 : f32 to vector<8xf32>
    %1415 = vector.fma %1414, %1392, %1383 : vector<8xf32>
    %1416 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1417 = memref.load %assume_align[%arg0, %1416, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1418 = vector.broadcast %1417 : f32 to vector<8xf32>
    %1419 = vector.fma %1418, %1392, %1387 : vector<8xf32>
    %1420 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1421 = memref.load %assume_align[%arg0, %1420, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1422 = vector.broadcast %1421 : f32 to vector<8xf32>
    %1423 = vector.fma %1422, %1392, %1391 : vector<8xf32>
    %1424 = vector.extract %7[44] : vector<8xf32> from vector<64x8xf32>
    %1425 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1426 = vector.broadcast %1425 : f32 to vector<8xf32>
    %1427 = vector.fma %1426, %1424, %1395 : vector<8xf32>
    %1428 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1429 = memref.load %assume_align[%arg0, %1428, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1430 = vector.broadcast %1429 : f32 to vector<8xf32>
    %1431 = vector.fma %1430, %1424, %1399 : vector<8xf32>
    %1432 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1433 = memref.load %assume_align[%arg0, %1432, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1434 = vector.broadcast %1433 : f32 to vector<8xf32>
    %1435 = vector.fma %1434, %1424, %1403 : vector<8xf32>
    %1436 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1437 = memref.load %assume_align[%arg0, %1436, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1438 = vector.broadcast %1437 : f32 to vector<8xf32>
    %1439 = vector.fma %1438, %1424, %1407 : vector<8xf32>
    %1440 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1441 = memref.load %assume_align[%arg0, %1440, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1442 = vector.broadcast %1441 : f32 to vector<8xf32>
    %1443 = vector.fma %1442, %1424, %1411 : vector<8xf32>
    %1444 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1445 = memref.load %assume_align[%arg0, %1444, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1446 = vector.broadcast %1445 : f32 to vector<8xf32>
    %1447 = vector.fma %1446, %1424, %1415 : vector<8xf32>
    %1448 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1449 = memref.load %assume_align[%arg0, %1448, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1450 = vector.broadcast %1449 : f32 to vector<8xf32>
    %1451 = vector.fma %1450, %1424, %1419 : vector<8xf32>
    %1452 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1453 = memref.load %assume_align[%arg0, %1452, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1454 = vector.broadcast %1453 : f32 to vector<8xf32>
    %1455 = vector.fma %1454, %1424, %1423 : vector<8xf32>
    %1456 = vector.extract %7[45] : vector<8xf32> from vector<64x8xf32>
    %1457 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1458 = vector.broadcast %1457 : f32 to vector<8xf32>
    %1459 = vector.fma %1458, %1456, %1427 : vector<8xf32>
    %1460 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1461 = memref.load %assume_align[%arg0, %1460, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1462 = vector.broadcast %1461 : f32 to vector<8xf32>
    %1463 = vector.fma %1462, %1456, %1431 : vector<8xf32>
    %1464 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1465 = memref.load %assume_align[%arg0, %1464, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1466 = vector.broadcast %1465 : f32 to vector<8xf32>
    %1467 = vector.fma %1466, %1456, %1435 : vector<8xf32>
    %1468 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1469 = memref.load %assume_align[%arg0, %1468, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1470 = vector.broadcast %1469 : f32 to vector<8xf32>
    %1471 = vector.fma %1470, %1456, %1439 : vector<8xf32>
    %1472 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1473 = memref.load %assume_align[%arg0, %1472, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1474 = vector.broadcast %1473 : f32 to vector<8xf32>
    %1475 = vector.fma %1474, %1456, %1443 : vector<8xf32>
    %1476 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1477 = memref.load %assume_align[%arg0, %1476, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1478 = vector.broadcast %1477 : f32 to vector<8xf32>
    %1479 = vector.fma %1478, %1456, %1447 : vector<8xf32>
    %1480 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1481 = memref.load %assume_align[%arg0, %1480, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1482 = vector.broadcast %1481 : f32 to vector<8xf32>
    %1483 = vector.fma %1482, %1456, %1451 : vector<8xf32>
    %1484 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1485 = memref.load %assume_align[%arg0, %1484, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1486 = vector.broadcast %1485 : f32 to vector<8xf32>
    %1487 = vector.fma %1486, %1456, %1455 : vector<8xf32>
    %1488 = vector.extract %7[46] : vector<8xf32> from vector<64x8xf32>
    %1489 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1490 = vector.broadcast %1489 : f32 to vector<8xf32>
    %1491 = vector.fma %1490, %1488, %1459 : vector<8xf32>
    %1492 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1493 = memref.load %assume_align[%arg0, %1492, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1494 = vector.broadcast %1493 : f32 to vector<8xf32>
    %1495 = vector.fma %1494, %1488, %1463 : vector<8xf32>
    %1496 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1497 = memref.load %assume_align[%arg0, %1496, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1498 = vector.broadcast %1497 : f32 to vector<8xf32>
    %1499 = vector.fma %1498, %1488, %1467 : vector<8xf32>
    %1500 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1501 = memref.load %assume_align[%arg0, %1500, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1502 = vector.broadcast %1501 : f32 to vector<8xf32>
    %1503 = vector.fma %1502, %1488, %1471 : vector<8xf32>
    %1504 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1505 = memref.load %assume_align[%arg0, %1504, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1506 = vector.broadcast %1505 : f32 to vector<8xf32>
    %1507 = vector.fma %1506, %1488, %1475 : vector<8xf32>
    %1508 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1509 = memref.load %assume_align[%arg0, %1508, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1510 = vector.broadcast %1509 : f32 to vector<8xf32>
    %1511 = vector.fma %1510, %1488, %1479 : vector<8xf32>
    %1512 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1513 = memref.load %assume_align[%arg0, %1512, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1514 = vector.broadcast %1513 : f32 to vector<8xf32>
    %1515 = vector.fma %1514, %1488, %1483 : vector<8xf32>
    %1516 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1517 = memref.load %assume_align[%arg0, %1516, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1518 = vector.broadcast %1517 : f32 to vector<8xf32>
    %1519 = vector.fma %1518, %1488, %1487 : vector<8xf32>
    %1520 = vector.extract %7[47] : vector<8xf32> from vector<64x8xf32>
    %1521 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1522 = vector.broadcast %1521 : f32 to vector<8xf32>
    %1523 = vector.fma %1522, %1520, %1491 : vector<8xf32>
    %1524 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1525 = memref.load %assume_align[%arg0, %1524, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1526 = vector.broadcast %1525 : f32 to vector<8xf32>
    %1527 = vector.fma %1526, %1520, %1495 : vector<8xf32>
    %1528 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1529 = memref.load %assume_align[%arg0, %1528, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1530 = vector.broadcast %1529 : f32 to vector<8xf32>
    %1531 = vector.fma %1530, %1520, %1499 : vector<8xf32>
    %1532 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1533 = memref.load %assume_align[%arg0, %1532, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1534 = vector.broadcast %1533 : f32 to vector<8xf32>
    %1535 = vector.fma %1534, %1520, %1503 : vector<8xf32>
    %1536 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1537 = memref.load %assume_align[%arg0, %1536, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1538 = vector.broadcast %1537 : f32 to vector<8xf32>
    %1539 = vector.fma %1538, %1520, %1507 : vector<8xf32>
    %1540 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1541 = memref.load %assume_align[%arg0, %1540, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1542 = vector.broadcast %1541 : f32 to vector<8xf32>
    %1543 = vector.fma %1542, %1520, %1511 : vector<8xf32>
    %1544 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1545 = memref.load %assume_align[%arg0, %1544, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1546 = vector.broadcast %1545 : f32 to vector<8xf32>
    %1547 = vector.fma %1546, %1520, %1515 : vector<8xf32>
    %1548 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1549 = memref.load %assume_align[%arg0, %1548, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1550 = vector.broadcast %1549 : f32 to vector<8xf32>
    %1551 = vector.fma %1550, %1520, %1519 : vector<8xf32>
    %1552 = vector.extract %7[48] : vector<8xf32> from vector<64x8xf32>
    %1553 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1554 = vector.broadcast %1553 : f32 to vector<8xf32>
    %1555 = vector.fma %1554, %1552, %1523 : vector<8xf32>
    %1556 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1557 = memref.load %assume_align[%arg0, %1556, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1558 = vector.broadcast %1557 : f32 to vector<8xf32>
    %1559 = vector.fma %1558, %1552, %1527 : vector<8xf32>
    %1560 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1561 = memref.load %assume_align[%arg0, %1560, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1562 = vector.broadcast %1561 : f32 to vector<8xf32>
    %1563 = vector.fma %1562, %1552, %1531 : vector<8xf32>
    %1564 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1565 = memref.load %assume_align[%arg0, %1564, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1566 = vector.broadcast %1565 : f32 to vector<8xf32>
    %1567 = vector.fma %1566, %1552, %1535 : vector<8xf32>
    %1568 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1569 = memref.load %assume_align[%arg0, %1568, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1570 = vector.broadcast %1569 : f32 to vector<8xf32>
    %1571 = vector.fma %1570, %1552, %1539 : vector<8xf32>
    %1572 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1573 = memref.load %assume_align[%arg0, %1572, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1574 = vector.broadcast %1573 : f32 to vector<8xf32>
    %1575 = vector.fma %1574, %1552, %1543 : vector<8xf32>
    %1576 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1577 = memref.load %assume_align[%arg0, %1576, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1578 = vector.broadcast %1577 : f32 to vector<8xf32>
    %1579 = vector.fma %1578, %1552, %1547 : vector<8xf32>
    %1580 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1581 = memref.load %assume_align[%arg0, %1580, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1582 = vector.broadcast %1581 : f32 to vector<8xf32>
    %1583 = vector.fma %1582, %1552, %1551 : vector<8xf32>
    %1584 = vector.extract %7[49] : vector<8xf32> from vector<64x8xf32>
    %1585 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1586 = vector.broadcast %1585 : f32 to vector<8xf32>
    %1587 = vector.fma %1586, %1584, %1555 : vector<8xf32>
    %1588 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1589 = memref.load %assume_align[%arg0, %1588, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1590 = vector.broadcast %1589 : f32 to vector<8xf32>
    %1591 = vector.fma %1590, %1584, %1559 : vector<8xf32>
    %1592 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1593 = memref.load %assume_align[%arg0, %1592, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1594 = vector.broadcast %1593 : f32 to vector<8xf32>
    %1595 = vector.fma %1594, %1584, %1563 : vector<8xf32>
    %1596 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1597 = memref.load %assume_align[%arg0, %1596, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1598 = vector.broadcast %1597 : f32 to vector<8xf32>
    %1599 = vector.fma %1598, %1584, %1567 : vector<8xf32>
    %1600 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1601 = memref.load %assume_align[%arg0, %1600, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1602 = vector.broadcast %1601 : f32 to vector<8xf32>
    %1603 = vector.fma %1602, %1584, %1571 : vector<8xf32>
    %1604 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1605 = memref.load %assume_align[%arg0, %1604, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1606 = vector.broadcast %1605 : f32 to vector<8xf32>
    %1607 = vector.fma %1606, %1584, %1575 : vector<8xf32>
    %1608 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1609 = memref.load %assume_align[%arg0, %1608, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1610 = vector.broadcast %1609 : f32 to vector<8xf32>
    %1611 = vector.fma %1610, %1584, %1579 : vector<8xf32>
    %1612 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1613 = memref.load %assume_align[%arg0, %1612, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1614 = vector.broadcast %1613 : f32 to vector<8xf32>
    %1615 = vector.fma %1614, %1584, %1583 : vector<8xf32>
    %1616 = vector.extract %7[50] : vector<8xf32> from vector<64x8xf32>
    %1617 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1618 = vector.broadcast %1617 : f32 to vector<8xf32>
    %1619 = vector.fma %1618, %1616, %1587 : vector<8xf32>
    %1620 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1621 = memref.load %assume_align[%arg0, %1620, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1622 = vector.broadcast %1621 : f32 to vector<8xf32>
    %1623 = vector.fma %1622, %1616, %1591 : vector<8xf32>
    %1624 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1625 = memref.load %assume_align[%arg0, %1624, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1626 = vector.broadcast %1625 : f32 to vector<8xf32>
    %1627 = vector.fma %1626, %1616, %1595 : vector<8xf32>
    %1628 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1629 = memref.load %assume_align[%arg0, %1628, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1630 = vector.broadcast %1629 : f32 to vector<8xf32>
    %1631 = vector.fma %1630, %1616, %1599 : vector<8xf32>
    %1632 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1633 = memref.load %assume_align[%arg0, %1632, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1634 = vector.broadcast %1633 : f32 to vector<8xf32>
    %1635 = vector.fma %1634, %1616, %1603 : vector<8xf32>
    %1636 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1637 = memref.load %assume_align[%arg0, %1636, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1638 = vector.broadcast %1637 : f32 to vector<8xf32>
    %1639 = vector.fma %1638, %1616, %1607 : vector<8xf32>
    %1640 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1641 = memref.load %assume_align[%arg0, %1640, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1642 = vector.broadcast %1641 : f32 to vector<8xf32>
    %1643 = vector.fma %1642, %1616, %1611 : vector<8xf32>
    %1644 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1645 = memref.load %assume_align[%arg0, %1644, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1646 = vector.broadcast %1645 : f32 to vector<8xf32>
    %1647 = vector.fma %1646, %1616, %1615 : vector<8xf32>
    %1648 = vector.extract %7[51] : vector<8xf32> from vector<64x8xf32>
    %1649 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1650 = vector.broadcast %1649 : f32 to vector<8xf32>
    %1651 = vector.fma %1650, %1648, %1619 : vector<8xf32>
    %1652 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1653 = memref.load %assume_align[%arg0, %1652, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1654 = vector.broadcast %1653 : f32 to vector<8xf32>
    %1655 = vector.fma %1654, %1648, %1623 : vector<8xf32>
    %1656 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1657 = memref.load %assume_align[%arg0, %1656, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1658 = vector.broadcast %1657 : f32 to vector<8xf32>
    %1659 = vector.fma %1658, %1648, %1627 : vector<8xf32>
    %1660 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1661 = memref.load %assume_align[%arg0, %1660, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1662 = vector.broadcast %1661 : f32 to vector<8xf32>
    %1663 = vector.fma %1662, %1648, %1631 : vector<8xf32>
    %1664 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1665 = memref.load %assume_align[%arg0, %1664, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1666 = vector.broadcast %1665 : f32 to vector<8xf32>
    %1667 = vector.fma %1666, %1648, %1635 : vector<8xf32>
    %1668 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1669 = memref.load %assume_align[%arg0, %1668, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1670 = vector.broadcast %1669 : f32 to vector<8xf32>
    %1671 = vector.fma %1670, %1648, %1639 : vector<8xf32>
    %1672 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1673 = memref.load %assume_align[%arg0, %1672, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1674 = vector.broadcast %1673 : f32 to vector<8xf32>
    %1675 = vector.fma %1674, %1648, %1643 : vector<8xf32>
    %1676 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1677 = memref.load %assume_align[%arg0, %1676, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1678 = vector.broadcast %1677 : f32 to vector<8xf32>
    %1679 = vector.fma %1678, %1648, %1647 : vector<8xf32>
    %1680 = vector.extract %7[52] : vector<8xf32> from vector<64x8xf32>
    %1681 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1682 = vector.broadcast %1681 : f32 to vector<8xf32>
    %1683 = vector.fma %1682, %1680, %1651 : vector<8xf32>
    %1684 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1685 = memref.load %assume_align[%arg0, %1684, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1686 = vector.broadcast %1685 : f32 to vector<8xf32>
    %1687 = vector.fma %1686, %1680, %1655 : vector<8xf32>
    %1688 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1689 = memref.load %assume_align[%arg0, %1688, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1690 = vector.broadcast %1689 : f32 to vector<8xf32>
    %1691 = vector.fma %1690, %1680, %1659 : vector<8xf32>
    %1692 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1693 = memref.load %assume_align[%arg0, %1692, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1694 = vector.broadcast %1693 : f32 to vector<8xf32>
    %1695 = vector.fma %1694, %1680, %1663 : vector<8xf32>
    %1696 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1697 = memref.load %assume_align[%arg0, %1696, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1698 = vector.broadcast %1697 : f32 to vector<8xf32>
    %1699 = vector.fma %1698, %1680, %1667 : vector<8xf32>
    %1700 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1701 = memref.load %assume_align[%arg0, %1700, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1702 = vector.broadcast %1701 : f32 to vector<8xf32>
    %1703 = vector.fma %1702, %1680, %1671 : vector<8xf32>
    %1704 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1705 = memref.load %assume_align[%arg0, %1704, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1706 = vector.broadcast %1705 : f32 to vector<8xf32>
    %1707 = vector.fma %1706, %1680, %1675 : vector<8xf32>
    %1708 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1709 = memref.load %assume_align[%arg0, %1708, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1710 = vector.broadcast %1709 : f32 to vector<8xf32>
    %1711 = vector.fma %1710, %1680, %1679 : vector<8xf32>
    %1712 = vector.extract %7[53] : vector<8xf32> from vector<64x8xf32>
    %1713 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1714 = vector.broadcast %1713 : f32 to vector<8xf32>
    %1715 = vector.fma %1714, %1712, %1683 : vector<8xf32>
    %1716 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1717 = memref.load %assume_align[%arg0, %1716, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1718 = vector.broadcast %1717 : f32 to vector<8xf32>
    %1719 = vector.fma %1718, %1712, %1687 : vector<8xf32>
    %1720 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1721 = memref.load %assume_align[%arg0, %1720, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1722 = vector.broadcast %1721 : f32 to vector<8xf32>
    %1723 = vector.fma %1722, %1712, %1691 : vector<8xf32>
    %1724 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1725 = memref.load %assume_align[%arg0, %1724, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1726 = vector.broadcast %1725 : f32 to vector<8xf32>
    %1727 = vector.fma %1726, %1712, %1695 : vector<8xf32>
    %1728 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1729 = memref.load %assume_align[%arg0, %1728, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1730 = vector.broadcast %1729 : f32 to vector<8xf32>
    %1731 = vector.fma %1730, %1712, %1699 : vector<8xf32>
    %1732 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1733 = memref.load %assume_align[%arg0, %1732, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1734 = vector.broadcast %1733 : f32 to vector<8xf32>
    %1735 = vector.fma %1734, %1712, %1703 : vector<8xf32>
    %1736 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1737 = memref.load %assume_align[%arg0, %1736, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1738 = vector.broadcast %1737 : f32 to vector<8xf32>
    %1739 = vector.fma %1738, %1712, %1707 : vector<8xf32>
    %1740 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1741 = memref.load %assume_align[%arg0, %1740, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1742 = vector.broadcast %1741 : f32 to vector<8xf32>
    %1743 = vector.fma %1742, %1712, %1711 : vector<8xf32>
    %1744 = vector.extract %7[54] : vector<8xf32> from vector<64x8xf32>
    %1745 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1746 = vector.broadcast %1745 : f32 to vector<8xf32>
    %1747 = vector.fma %1746, %1744, %1715 : vector<8xf32>
    %1748 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1749 = memref.load %assume_align[%arg0, %1748, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1750 = vector.broadcast %1749 : f32 to vector<8xf32>
    %1751 = vector.fma %1750, %1744, %1719 : vector<8xf32>
    %1752 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1753 = memref.load %assume_align[%arg0, %1752, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1754 = vector.broadcast %1753 : f32 to vector<8xf32>
    %1755 = vector.fma %1754, %1744, %1723 : vector<8xf32>
    %1756 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1757 = memref.load %assume_align[%arg0, %1756, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1758 = vector.broadcast %1757 : f32 to vector<8xf32>
    %1759 = vector.fma %1758, %1744, %1727 : vector<8xf32>
    %1760 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1761 = memref.load %assume_align[%arg0, %1760, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1762 = vector.broadcast %1761 : f32 to vector<8xf32>
    %1763 = vector.fma %1762, %1744, %1731 : vector<8xf32>
    %1764 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1765 = memref.load %assume_align[%arg0, %1764, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1766 = vector.broadcast %1765 : f32 to vector<8xf32>
    %1767 = vector.fma %1766, %1744, %1735 : vector<8xf32>
    %1768 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1769 = memref.load %assume_align[%arg0, %1768, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1770 = vector.broadcast %1769 : f32 to vector<8xf32>
    %1771 = vector.fma %1770, %1744, %1739 : vector<8xf32>
    %1772 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1773 = memref.load %assume_align[%arg0, %1772, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1774 = vector.broadcast %1773 : f32 to vector<8xf32>
    %1775 = vector.fma %1774, %1744, %1743 : vector<8xf32>
    %1776 = vector.extract %7[55] : vector<8xf32> from vector<64x8xf32>
    %1777 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1778 = vector.broadcast %1777 : f32 to vector<8xf32>
    %1779 = vector.fma %1778, %1776, %1747 : vector<8xf32>
    %1780 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1781 = memref.load %assume_align[%arg0, %1780, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1782 = vector.broadcast %1781 : f32 to vector<8xf32>
    %1783 = vector.fma %1782, %1776, %1751 : vector<8xf32>
    %1784 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1785 = memref.load %assume_align[%arg0, %1784, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1786 = vector.broadcast %1785 : f32 to vector<8xf32>
    %1787 = vector.fma %1786, %1776, %1755 : vector<8xf32>
    %1788 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1789 = memref.load %assume_align[%arg0, %1788, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1790 = vector.broadcast %1789 : f32 to vector<8xf32>
    %1791 = vector.fma %1790, %1776, %1759 : vector<8xf32>
    %1792 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1793 = memref.load %assume_align[%arg0, %1792, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1794 = vector.broadcast %1793 : f32 to vector<8xf32>
    %1795 = vector.fma %1794, %1776, %1763 : vector<8xf32>
    %1796 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1797 = memref.load %assume_align[%arg0, %1796, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1798 = vector.broadcast %1797 : f32 to vector<8xf32>
    %1799 = vector.fma %1798, %1776, %1767 : vector<8xf32>
    %1800 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1801 = memref.load %assume_align[%arg0, %1800, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1802 = vector.broadcast %1801 : f32 to vector<8xf32>
    %1803 = vector.fma %1802, %1776, %1771 : vector<8xf32>
    %1804 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1805 = memref.load %assume_align[%arg0, %1804, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1806 = vector.broadcast %1805 : f32 to vector<8xf32>
    %1807 = vector.fma %1806, %1776, %1775 : vector<8xf32>
    %1808 = vector.extract %7[56] : vector<8xf32> from vector<64x8xf32>
    %1809 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1810 = vector.broadcast %1809 : f32 to vector<8xf32>
    %1811 = vector.fma %1810, %1808, %1779 : vector<8xf32>
    %1812 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1813 = memref.load %assume_align[%arg0, %1812, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1814 = vector.broadcast %1813 : f32 to vector<8xf32>
    %1815 = vector.fma %1814, %1808, %1783 : vector<8xf32>
    %1816 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1817 = memref.load %assume_align[%arg0, %1816, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1818 = vector.broadcast %1817 : f32 to vector<8xf32>
    %1819 = vector.fma %1818, %1808, %1787 : vector<8xf32>
    %1820 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1821 = memref.load %assume_align[%arg0, %1820, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1822 = vector.broadcast %1821 : f32 to vector<8xf32>
    %1823 = vector.fma %1822, %1808, %1791 : vector<8xf32>
    %1824 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1825 = memref.load %assume_align[%arg0, %1824, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1826 = vector.broadcast %1825 : f32 to vector<8xf32>
    %1827 = vector.fma %1826, %1808, %1795 : vector<8xf32>
    %1828 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1829 = memref.load %assume_align[%arg0, %1828, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1830 = vector.broadcast %1829 : f32 to vector<8xf32>
    %1831 = vector.fma %1830, %1808, %1799 : vector<8xf32>
    %1832 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1833 = memref.load %assume_align[%arg0, %1832, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1834 = vector.broadcast %1833 : f32 to vector<8xf32>
    %1835 = vector.fma %1834, %1808, %1803 : vector<8xf32>
    %1836 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1837 = memref.load %assume_align[%arg0, %1836, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1838 = vector.broadcast %1837 : f32 to vector<8xf32>
    %1839 = vector.fma %1838, %1808, %1807 : vector<8xf32>
    %1840 = vector.extract %7[57] : vector<8xf32> from vector<64x8xf32>
    %1841 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1842 = vector.broadcast %1841 : f32 to vector<8xf32>
    %1843 = vector.fma %1842, %1840, %1811 : vector<8xf32>
    %1844 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1845 = memref.load %assume_align[%arg0, %1844, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1846 = vector.broadcast %1845 : f32 to vector<8xf32>
    %1847 = vector.fma %1846, %1840, %1815 : vector<8xf32>
    %1848 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1849 = memref.load %assume_align[%arg0, %1848, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1850 = vector.broadcast %1849 : f32 to vector<8xf32>
    %1851 = vector.fma %1850, %1840, %1819 : vector<8xf32>
    %1852 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1853 = memref.load %assume_align[%arg0, %1852, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1854 = vector.broadcast %1853 : f32 to vector<8xf32>
    %1855 = vector.fma %1854, %1840, %1823 : vector<8xf32>
    %1856 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1857 = memref.load %assume_align[%arg0, %1856, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1858 = vector.broadcast %1857 : f32 to vector<8xf32>
    %1859 = vector.fma %1858, %1840, %1827 : vector<8xf32>
    %1860 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1861 = memref.load %assume_align[%arg0, %1860, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1862 = vector.broadcast %1861 : f32 to vector<8xf32>
    %1863 = vector.fma %1862, %1840, %1831 : vector<8xf32>
    %1864 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1865 = memref.load %assume_align[%arg0, %1864, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1866 = vector.broadcast %1865 : f32 to vector<8xf32>
    %1867 = vector.fma %1866, %1840, %1835 : vector<8xf32>
    %1868 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1869 = memref.load %assume_align[%arg0, %1868, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1870 = vector.broadcast %1869 : f32 to vector<8xf32>
    %1871 = vector.fma %1870, %1840, %1839 : vector<8xf32>
    %1872 = vector.extract %7[58] : vector<8xf32> from vector<64x8xf32>
    %1873 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1874 = vector.broadcast %1873 : f32 to vector<8xf32>
    %1875 = vector.fma %1874, %1872, %1843 : vector<8xf32>
    %1876 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1877 = memref.load %assume_align[%arg0, %1876, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1878 = vector.broadcast %1877 : f32 to vector<8xf32>
    %1879 = vector.fma %1878, %1872, %1847 : vector<8xf32>
    %1880 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1881 = memref.load %assume_align[%arg0, %1880, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1882 = vector.broadcast %1881 : f32 to vector<8xf32>
    %1883 = vector.fma %1882, %1872, %1851 : vector<8xf32>
    %1884 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1885 = memref.load %assume_align[%arg0, %1884, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1886 = vector.broadcast %1885 : f32 to vector<8xf32>
    %1887 = vector.fma %1886, %1872, %1855 : vector<8xf32>
    %1888 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1889 = memref.load %assume_align[%arg0, %1888, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1890 = vector.broadcast %1889 : f32 to vector<8xf32>
    %1891 = vector.fma %1890, %1872, %1859 : vector<8xf32>
    %1892 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1893 = memref.load %assume_align[%arg0, %1892, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1894 = vector.broadcast %1893 : f32 to vector<8xf32>
    %1895 = vector.fma %1894, %1872, %1863 : vector<8xf32>
    %1896 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1897 = memref.load %assume_align[%arg0, %1896, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1898 = vector.broadcast %1897 : f32 to vector<8xf32>
    %1899 = vector.fma %1898, %1872, %1867 : vector<8xf32>
    %1900 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1901 = memref.load %assume_align[%arg0, %1900, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1902 = vector.broadcast %1901 : f32 to vector<8xf32>
    %1903 = vector.fma %1902, %1872, %1871 : vector<8xf32>
    %1904 = vector.extract %7[59] : vector<8xf32> from vector<64x8xf32>
    %1905 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1906 = vector.broadcast %1905 : f32 to vector<8xf32>
    %1907 = vector.fma %1906, %1904, %1875 : vector<8xf32>
    %1908 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1909 = memref.load %assume_align[%arg0, %1908, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1910 = vector.broadcast %1909 : f32 to vector<8xf32>
    %1911 = vector.fma %1910, %1904, %1879 : vector<8xf32>
    %1912 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1913 = memref.load %assume_align[%arg0, %1912, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1914 = vector.broadcast %1913 : f32 to vector<8xf32>
    %1915 = vector.fma %1914, %1904, %1883 : vector<8xf32>
    %1916 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1917 = memref.load %assume_align[%arg0, %1916, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1918 = vector.broadcast %1917 : f32 to vector<8xf32>
    %1919 = vector.fma %1918, %1904, %1887 : vector<8xf32>
    %1920 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1921 = memref.load %assume_align[%arg0, %1920, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1922 = vector.broadcast %1921 : f32 to vector<8xf32>
    %1923 = vector.fma %1922, %1904, %1891 : vector<8xf32>
    %1924 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1925 = memref.load %assume_align[%arg0, %1924, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1926 = vector.broadcast %1925 : f32 to vector<8xf32>
    %1927 = vector.fma %1926, %1904, %1895 : vector<8xf32>
    %1928 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1929 = memref.load %assume_align[%arg0, %1928, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1930 = vector.broadcast %1929 : f32 to vector<8xf32>
    %1931 = vector.fma %1930, %1904, %1899 : vector<8xf32>
    %1932 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1933 = memref.load %assume_align[%arg0, %1932, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1934 = vector.broadcast %1933 : f32 to vector<8xf32>
    %1935 = vector.fma %1934, %1904, %1903 : vector<8xf32>
    %1936 = vector.extract %7[60] : vector<8xf32> from vector<64x8xf32>
    %1937 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1938 = vector.broadcast %1937 : f32 to vector<8xf32>
    %1939 = vector.fma %1938, %1936, %1907 : vector<8xf32>
    %1940 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1941 = memref.load %assume_align[%arg0, %1940, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1942 = vector.broadcast %1941 : f32 to vector<8xf32>
    %1943 = vector.fma %1942, %1936, %1911 : vector<8xf32>
    %1944 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1945 = memref.load %assume_align[%arg0, %1944, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1946 = vector.broadcast %1945 : f32 to vector<8xf32>
    %1947 = vector.fma %1946, %1936, %1915 : vector<8xf32>
    %1948 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1949 = memref.load %assume_align[%arg0, %1948, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1950 = vector.broadcast %1949 : f32 to vector<8xf32>
    %1951 = vector.fma %1950, %1936, %1919 : vector<8xf32>
    %1952 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1953 = memref.load %assume_align[%arg0, %1952, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1954 = vector.broadcast %1953 : f32 to vector<8xf32>
    %1955 = vector.fma %1954, %1936, %1923 : vector<8xf32>
    %1956 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1957 = memref.load %assume_align[%arg0, %1956, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1958 = vector.broadcast %1957 : f32 to vector<8xf32>
    %1959 = vector.fma %1958, %1936, %1927 : vector<8xf32>
    %1960 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1961 = memref.load %assume_align[%arg0, %1960, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1962 = vector.broadcast %1961 : f32 to vector<8xf32>
    %1963 = vector.fma %1962, %1936, %1931 : vector<8xf32>
    %1964 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1965 = memref.load %assume_align[%arg0, %1964, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1966 = vector.broadcast %1965 : f32 to vector<8xf32>
    %1967 = vector.fma %1966, %1936, %1935 : vector<8xf32>
    %1968 = vector.extract %7[61] : vector<8xf32> from vector<64x8xf32>
    %1969 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1970 = vector.broadcast %1969 : f32 to vector<8xf32>
    %1971 = vector.fma %1970, %1968, %1939 : vector<8xf32>
    %1972 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1973 = memref.load %assume_align[%arg0, %1972, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1974 = vector.broadcast %1973 : f32 to vector<8xf32>
    %1975 = vector.fma %1974, %1968, %1943 : vector<8xf32>
    %1976 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1977 = memref.load %assume_align[%arg0, %1976, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1978 = vector.broadcast %1977 : f32 to vector<8xf32>
    %1979 = vector.fma %1978, %1968, %1947 : vector<8xf32>
    %1980 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1981 = memref.load %assume_align[%arg0, %1980, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1982 = vector.broadcast %1981 : f32 to vector<8xf32>
    %1983 = vector.fma %1982, %1968, %1951 : vector<8xf32>
    %1984 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1985 = memref.load %assume_align[%arg0, %1984, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1986 = vector.broadcast %1985 : f32 to vector<8xf32>
    %1987 = vector.fma %1986, %1968, %1955 : vector<8xf32>
    %1988 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1989 = memref.load %assume_align[%arg0, %1988, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1990 = vector.broadcast %1989 : f32 to vector<8xf32>
    %1991 = vector.fma %1990, %1968, %1959 : vector<8xf32>
    %1992 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1993 = memref.load %assume_align[%arg0, %1992, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1994 = vector.broadcast %1993 : f32 to vector<8xf32>
    %1995 = vector.fma %1994, %1968, %1963 : vector<8xf32>
    %1996 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1997 = memref.load %assume_align[%arg0, %1996, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1998 = vector.broadcast %1997 : f32 to vector<8xf32>
    %1999 = vector.fma %1998, %1968, %1967 : vector<8xf32>
    %2000 = vector.extract %7[62] : vector<8xf32> from vector<64x8xf32>
    %2001 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2002 = vector.broadcast %2001 : f32 to vector<8xf32>
    %2003 = vector.fma %2002, %2000, %1971 : vector<8xf32>
    %2004 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2005 = memref.load %assume_align[%arg0, %2004, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2006 = vector.broadcast %2005 : f32 to vector<8xf32>
    %2007 = vector.fma %2006, %2000, %1975 : vector<8xf32>
    %2008 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2009 = memref.load %assume_align[%arg0, %2008, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2010 = vector.broadcast %2009 : f32 to vector<8xf32>
    %2011 = vector.fma %2010, %2000, %1979 : vector<8xf32>
    %2012 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2013 = memref.load %assume_align[%arg0, %2012, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2014 = vector.broadcast %2013 : f32 to vector<8xf32>
    %2015 = vector.fma %2014, %2000, %1983 : vector<8xf32>
    %2016 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2017 = memref.load %assume_align[%arg0, %2016, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2018 = vector.broadcast %2017 : f32 to vector<8xf32>
    %2019 = vector.fma %2018, %2000, %1987 : vector<8xf32>
    %2020 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2021 = memref.load %assume_align[%arg0, %2020, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2022 = vector.broadcast %2021 : f32 to vector<8xf32>
    %2023 = vector.fma %2022, %2000, %1991 : vector<8xf32>
    %2024 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2025 = memref.load %assume_align[%arg0, %2024, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2026 = vector.broadcast %2025 : f32 to vector<8xf32>
    %2027 = vector.fma %2026, %2000, %1995 : vector<8xf32>
    %2028 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2029 = memref.load %assume_align[%arg0, %2028, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2030 = vector.broadcast %2029 : f32 to vector<8xf32>
    %2031 = vector.fma %2030, %2000, %1999 : vector<8xf32>
    %2032 = vector.extract %7[63] : vector<8xf32> from vector<64x8xf32>
    %2033 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2034 = vector.broadcast %2033 : f32 to vector<8xf32>
    %2035 = vector.fma %2034, %2032, %2003 : vector<8xf32>
    %2036 = vector.insert %2035, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2037 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2038 = memref.load %assume_align[%arg0, %2037, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
    %2040 = vector.fma %2039, %2032, %2007 : vector<8xf32>
    %2041 = vector.insert %2040, %2036 [1] : vector<8xf32> into vector<8x8xf32>
    %2042 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2043 = memref.load %assume_align[%arg0, %2042, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2044 = vector.broadcast %2043 : f32 to vector<8xf32>
    %2045 = vector.fma %2044, %2032, %2011 : vector<8xf32>
    %2046 = vector.insert %2045, %2041 [2] : vector<8xf32> into vector<8x8xf32>
    %2047 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2048 = memref.load %assume_align[%arg0, %2047, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2049 = vector.broadcast %2048 : f32 to vector<8xf32>
    %2050 = vector.fma %2049, %2032, %2015 : vector<8xf32>
    %2051 = vector.insert %2050, %2046 [3] : vector<8xf32> into vector<8x8xf32>
    %2052 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2053 = memref.load %assume_align[%arg0, %2052, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2054 = vector.broadcast %2053 : f32 to vector<8xf32>
    %2055 = vector.fma %2054, %2032, %2019 : vector<8xf32>
    %2056 = vector.insert %2055, %2051 [4] : vector<8xf32> into vector<8x8xf32>
    %2057 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2058 = memref.load %assume_align[%arg0, %2057, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2059 = vector.broadcast %2058 : f32 to vector<8xf32>
    %2060 = vector.fma %2059, %2032, %2023 : vector<8xf32>
    %2061 = vector.insert %2060, %2056 [5] : vector<8xf32> into vector<8x8xf32>
    %2062 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2063 = memref.load %assume_align[%arg0, %2062, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2064 = vector.broadcast %2063 : f32 to vector<8xf32>
    %2065 = vector.fma %2064, %2032, %2027 : vector<8xf32>
    %2066 = vector.insert %2065, %2061 [6] : vector<8xf32> into vector<8x8xf32>
    %2067 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2068 = memref.load %assume_align[%arg0, %2067, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2069 = vector.broadcast %2068 : f32 to vector<8xf32>
    %2070 = vector.fma %2069, %2032, %2031 : vector<8xf32>
    %2071 = vector.insert %2070, %2066 [7] : vector<8xf32> into vector<8x8xf32>
    %2072 = vector.reduction <maximumf>, %2035, %cst : vector<8xf32> into f32
    %2073 = vector.insert %2072, %cst_0 [0] : f32 into vector<8xf32>
    %2074 = vector.reduction <maximumf>, %2040, %cst : vector<8xf32> into f32
    %2075 = vector.insert %2074, %2073 [1] : f32 into vector<8xf32>
    %2076 = vector.reduction <maximumf>, %2045, %cst : vector<8xf32> into f32
    %2077 = vector.insert %2076, %2075 [2] : f32 into vector<8xf32>
    %2078 = vector.reduction <maximumf>, %2050, %cst : vector<8xf32> into f32
    %2079 = vector.insert %2078, %2077 [3] : f32 into vector<8xf32>
    %2080 = vector.reduction <maximumf>, %2055, %cst : vector<8xf32> into f32
    %2081 = vector.insert %2080, %2079 [4] : f32 into vector<8xf32>
    %2082 = vector.reduction <maximumf>, %2060, %cst : vector<8xf32> into f32
    %2083 = vector.insert %2082, %2081 [5] : f32 into vector<8xf32>
    %2084 = vector.reduction <maximumf>, %2065, %cst : vector<8xf32> into f32
    %2085 = vector.insert %2084, %2083 [6] : f32 into vector<8xf32>
    %2086 = vector.reduction <maximumf>, %2070, %cst : vector<8xf32> into f32
    %2087 = vector.insert %2086, %2085 [7] : f32 into vector<8xf32>
    %2088 = vector.shape_cast %2087 : vector<8xf32> to vector<1x8xf32>
    %2089 = arith.subf %2087, %cst_2 : vector<8xf32>
    %2090 = math.exp2 %2089 : vector<8xf32>
    %2091 = vector.shape_cast %2090 : vector<8xf32> to vector<1x8xf32>
    %2092 = vector.broadcast %2091 : vector<1x8xf32> to vector<8x8xf32>
    %2093 = arith.mulf %2092, %cst_1 : vector<8x8xf32>
    %2094 = vector.transpose %2093, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2095 = vector.broadcast %2088 : vector<1x8xf32> to vector<8x8xf32>
    %2096 = vector.transpose %2095, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2097 = arith.subf %2071, %2096 : vector<8x8xf32>
    %2098 = math.exp2 %2097 : vector<8x8xf32>
    %2099 = vector.transfer_read %assume_align_4[%arg0, %arg3, %arg2], %0 {in_bounds = [true, true]} : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
    %2100 = vector.extract %2099[0] : vector<8xf32> from vector<8x8xf32>
    %2101 = vector.extract %2098[0, 0] : f32 from vector<8x8xf32>
    %2102 = vector.broadcast %2101 : f32 to vector<8xf32>
    %2103 = vector.extract %2094[0] : vector<8xf32> from vector<8x8xf32>
    %2104 = vector.fma %2102, %2100, %2103 : vector<8xf32>
    %2105 = vector.extract %2098[1, 0] : f32 from vector<8x8xf32>
    %2106 = vector.broadcast %2105 : f32 to vector<8xf32>
    %2107 = vector.extract %2094[1] : vector<8xf32> from vector<8x8xf32>
    %2108 = vector.fma %2106, %2100, %2107 : vector<8xf32>
    %2109 = vector.extract %2098[2, 0] : f32 from vector<8x8xf32>
    %2110 = vector.broadcast %2109 : f32 to vector<8xf32>
    %2111 = vector.extract %2094[2] : vector<8xf32> from vector<8x8xf32>
    %2112 = vector.fma %2110, %2100, %2111 : vector<8xf32>
    %2113 = vector.extract %2098[3, 0] : f32 from vector<8x8xf32>
    %2114 = vector.broadcast %2113 : f32 to vector<8xf32>
    %2115 = vector.extract %2094[3] : vector<8xf32> from vector<8x8xf32>
    %2116 = vector.fma %2114, %2100, %2115 : vector<8xf32>
    %2117 = vector.extract %2098[4, 0] : f32 from vector<8x8xf32>
    %2118 = vector.broadcast %2117 : f32 to vector<8xf32>
    %2119 = vector.extract %2094[4] : vector<8xf32> from vector<8x8xf32>
    %2120 = vector.fma %2118, %2100, %2119 : vector<8xf32>
    %2121 = vector.extract %2098[5, 0] : f32 from vector<8x8xf32>
    %2122 = vector.broadcast %2121 : f32 to vector<8xf32>
    %2123 = vector.extract %2094[5] : vector<8xf32> from vector<8x8xf32>
    %2124 = vector.fma %2122, %2100, %2123 : vector<8xf32>
    %2125 = vector.extract %2098[6, 0] : f32 from vector<8x8xf32>
    %2126 = vector.broadcast %2125 : f32 to vector<8xf32>
    %2127 = vector.extract %2094[6] : vector<8xf32> from vector<8x8xf32>
    %2128 = vector.fma %2126, %2100, %2127 : vector<8xf32>
    %2129 = vector.extract %2098[7, 0] : f32 from vector<8x8xf32>
    %2130 = vector.broadcast %2129 : f32 to vector<8xf32>
    %2131 = vector.extract %2094[7] : vector<8xf32> from vector<8x8xf32>
    %2132 = vector.fma %2130, %2100, %2131 : vector<8xf32>
    %2133 = vector.extract %2099[1] : vector<8xf32> from vector<8x8xf32>
    %2134 = vector.extract %2098[0, 1] : f32 from vector<8x8xf32>
    %2135 = vector.broadcast %2134 : f32 to vector<8xf32>
    %2136 = vector.fma %2135, %2133, %2104 : vector<8xf32>
    %2137 = vector.extract %2098[1, 1] : f32 from vector<8x8xf32>
    %2138 = vector.broadcast %2137 : f32 to vector<8xf32>
    %2139 = vector.fma %2138, %2133, %2108 : vector<8xf32>
    %2140 = vector.extract %2098[2, 1] : f32 from vector<8x8xf32>
    %2141 = vector.broadcast %2140 : f32 to vector<8xf32>
    %2142 = vector.fma %2141, %2133, %2112 : vector<8xf32>
    %2143 = vector.extract %2098[3, 1] : f32 from vector<8x8xf32>
    %2144 = vector.broadcast %2143 : f32 to vector<8xf32>
    %2145 = vector.fma %2144, %2133, %2116 : vector<8xf32>
    %2146 = vector.extract %2098[4, 1] : f32 from vector<8x8xf32>
    %2147 = vector.broadcast %2146 : f32 to vector<8xf32>
    %2148 = vector.fma %2147, %2133, %2120 : vector<8xf32>
    %2149 = vector.extract %2098[5, 1] : f32 from vector<8x8xf32>
    %2150 = vector.broadcast %2149 : f32 to vector<8xf32>
    %2151 = vector.fma %2150, %2133, %2124 : vector<8xf32>
    %2152 = vector.extract %2098[6, 1] : f32 from vector<8x8xf32>
    %2153 = vector.broadcast %2152 : f32 to vector<8xf32>
    %2154 = vector.fma %2153, %2133, %2128 : vector<8xf32>
    %2155 = vector.extract %2098[7, 1] : f32 from vector<8x8xf32>
    %2156 = vector.broadcast %2155 : f32 to vector<8xf32>
    %2157 = vector.fma %2156, %2133, %2132 : vector<8xf32>
    %2158 = vector.extract %2099[2] : vector<8xf32> from vector<8x8xf32>
    %2159 = vector.extract %2098[0, 2] : f32 from vector<8x8xf32>
    %2160 = vector.broadcast %2159 : f32 to vector<8xf32>
    %2161 = vector.fma %2160, %2158, %2136 : vector<8xf32>
    %2162 = vector.extract %2098[1, 2] : f32 from vector<8x8xf32>
    %2163 = vector.broadcast %2162 : f32 to vector<8xf32>
    %2164 = vector.fma %2163, %2158, %2139 : vector<8xf32>
    %2165 = vector.extract %2098[2, 2] : f32 from vector<8x8xf32>
    %2166 = vector.broadcast %2165 : f32 to vector<8xf32>
    %2167 = vector.fma %2166, %2158, %2142 : vector<8xf32>
    %2168 = vector.extract %2098[3, 2] : f32 from vector<8x8xf32>
    %2169 = vector.broadcast %2168 : f32 to vector<8xf32>
    %2170 = vector.fma %2169, %2158, %2145 : vector<8xf32>
    %2171 = vector.extract %2098[4, 2] : f32 from vector<8x8xf32>
    %2172 = vector.broadcast %2171 : f32 to vector<8xf32>
    %2173 = vector.fma %2172, %2158, %2148 : vector<8xf32>
    %2174 = vector.extract %2098[5, 2] : f32 from vector<8x8xf32>
    %2175 = vector.broadcast %2174 : f32 to vector<8xf32>
    %2176 = vector.fma %2175, %2158, %2151 : vector<8xf32>
    %2177 = vector.extract %2098[6, 2] : f32 from vector<8x8xf32>
    %2178 = vector.broadcast %2177 : f32 to vector<8xf32>
    %2179 = vector.fma %2178, %2158, %2154 : vector<8xf32>
    %2180 = vector.extract %2098[7, 2] : f32 from vector<8x8xf32>
    %2181 = vector.broadcast %2180 : f32 to vector<8xf32>
    %2182 = vector.fma %2181, %2158, %2157 : vector<8xf32>
    %2183 = vector.extract %2099[3] : vector<8xf32> from vector<8x8xf32>
    %2184 = vector.extract %2098[0, 3] : f32 from vector<8x8xf32>
    %2185 = vector.broadcast %2184 : f32 to vector<8xf32>
    %2186 = vector.fma %2185, %2183, %2161 : vector<8xf32>
    %2187 = vector.extract %2098[1, 3] : f32 from vector<8x8xf32>
    %2188 = vector.broadcast %2187 : f32 to vector<8xf32>
    %2189 = vector.fma %2188, %2183, %2164 : vector<8xf32>
    %2190 = vector.extract %2098[2, 3] : f32 from vector<8x8xf32>
    %2191 = vector.broadcast %2190 : f32 to vector<8xf32>
    %2192 = vector.fma %2191, %2183, %2167 : vector<8xf32>
    %2193 = vector.extract %2098[3, 3] : f32 from vector<8x8xf32>
    %2194 = vector.broadcast %2193 : f32 to vector<8xf32>
    %2195 = vector.fma %2194, %2183, %2170 : vector<8xf32>
    %2196 = vector.extract %2098[4, 3] : f32 from vector<8x8xf32>
    %2197 = vector.broadcast %2196 : f32 to vector<8xf32>
    %2198 = vector.fma %2197, %2183, %2173 : vector<8xf32>
    %2199 = vector.extract %2098[5, 3] : f32 from vector<8x8xf32>
    %2200 = vector.broadcast %2199 : f32 to vector<8xf32>
    %2201 = vector.fma %2200, %2183, %2176 : vector<8xf32>
    %2202 = vector.extract %2098[6, 3] : f32 from vector<8x8xf32>
    %2203 = vector.broadcast %2202 : f32 to vector<8xf32>
    %2204 = vector.fma %2203, %2183, %2179 : vector<8xf32>
    %2205 = vector.extract %2098[7, 3] : f32 from vector<8x8xf32>
    %2206 = vector.broadcast %2205 : f32 to vector<8xf32>
    %2207 = vector.fma %2206, %2183, %2182 : vector<8xf32>
    %2208 = vector.extract %2099[4] : vector<8xf32> from vector<8x8xf32>
    %2209 = vector.extract %2098[0, 4] : f32 from vector<8x8xf32>
    %2210 = vector.broadcast %2209 : f32 to vector<8xf32>
    %2211 = vector.fma %2210, %2208, %2186 : vector<8xf32>
    %2212 = vector.extract %2098[1, 4] : f32 from vector<8x8xf32>
    %2213 = vector.broadcast %2212 : f32 to vector<8xf32>
    %2214 = vector.fma %2213, %2208, %2189 : vector<8xf32>
    %2215 = vector.extract %2098[2, 4] : f32 from vector<8x8xf32>
    %2216 = vector.broadcast %2215 : f32 to vector<8xf32>
    %2217 = vector.fma %2216, %2208, %2192 : vector<8xf32>
    %2218 = vector.extract %2098[3, 4] : f32 from vector<8x8xf32>
    %2219 = vector.broadcast %2218 : f32 to vector<8xf32>
    %2220 = vector.fma %2219, %2208, %2195 : vector<8xf32>
    %2221 = vector.extract %2098[4, 4] : f32 from vector<8x8xf32>
    %2222 = vector.broadcast %2221 : f32 to vector<8xf32>
    %2223 = vector.fma %2222, %2208, %2198 : vector<8xf32>
    %2224 = vector.extract %2098[5, 4] : f32 from vector<8x8xf32>
    %2225 = vector.broadcast %2224 : f32 to vector<8xf32>
    %2226 = vector.fma %2225, %2208, %2201 : vector<8xf32>
    %2227 = vector.extract %2098[6, 4] : f32 from vector<8x8xf32>
    %2228 = vector.broadcast %2227 : f32 to vector<8xf32>
    %2229 = vector.fma %2228, %2208, %2204 : vector<8xf32>
    %2230 = vector.extract %2098[7, 4] : f32 from vector<8x8xf32>
    %2231 = vector.broadcast %2230 : f32 to vector<8xf32>
    %2232 = vector.fma %2231, %2208, %2207 : vector<8xf32>
    %2233 = vector.extract %2099[5] : vector<8xf32> from vector<8x8xf32>
    %2234 = vector.extract %2098[0, 5] : f32 from vector<8x8xf32>
    %2235 = vector.broadcast %2234 : f32 to vector<8xf32>
    %2236 = vector.fma %2235, %2233, %2211 : vector<8xf32>
    %2237 = vector.extract %2098[1, 5] : f32 from vector<8x8xf32>
    %2238 = vector.broadcast %2237 : f32 to vector<8xf32>
    %2239 = vector.fma %2238, %2233, %2214 : vector<8xf32>
    %2240 = vector.extract %2098[2, 5] : f32 from vector<8x8xf32>
    %2241 = vector.broadcast %2240 : f32 to vector<8xf32>
    %2242 = vector.fma %2241, %2233, %2217 : vector<8xf32>
    %2243 = vector.extract %2098[3, 5] : f32 from vector<8x8xf32>
    %2244 = vector.broadcast %2243 : f32 to vector<8xf32>
    %2245 = vector.fma %2244, %2233, %2220 : vector<8xf32>
    %2246 = vector.extract %2098[4, 5] : f32 from vector<8x8xf32>
    %2247 = vector.broadcast %2246 : f32 to vector<8xf32>
    %2248 = vector.fma %2247, %2233, %2223 : vector<8xf32>
    %2249 = vector.extract %2098[5, 5] : f32 from vector<8x8xf32>
    %2250 = vector.broadcast %2249 : f32 to vector<8xf32>
    %2251 = vector.fma %2250, %2233, %2226 : vector<8xf32>
    %2252 = vector.extract %2098[6, 5] : f32 from vector<8x8xf32>
    %2253 = vector.broadcast %2252 : f32 to vector<8xf32>
    %2254 = vector.fma %2253, %2233, %2229 : vector<8xf32>
    %2255 = vector.extract %2098[7, 5] : f32 from vector<8x8xf32>
    %2256 = vector.broadcast %2255 : f32 to vector<8xf32>
    %2257 = vector.fma %2256, %2233, %2232 : vector<8xf32>
    %2258 = vector.extract %2099[6] : vector<8xf32> from vector<8x8xf32>
    %2259 = vector.extract %2098[0, 6] : f32 from vector<8x8xf32>
    %2260 = vector.broadcast %2259 : f32 to vector<8xf32>
    %2261 = vector.fma %2260, %2258, %2236 : vector<8xf32>
    %2262 = vector.extract %2098[1, 6] : f32 from vector<8x8xf32>
    %2263 = vector.broadcast %2262 : f32 to vector<8xf32>
    %2264 = vector.fma %2263, %2258, %2239 : vector<8xf32>
    %2265 = vector.extract %2098[2, 6] : f32 from vector<8x8xf32>
    %2266 = vector.broadcast %2265 : f32 to vector<8xf32>
    %2267 = vector.fma %2266, %2258, %2242 : vector<8xf32>
    %2268 = vector.extract %2098[3, 6] : f32 from vector<8x8xf32>
    %2269 = vector.broadcast %2268 : f32 to vector<8xf32>
    %2270 = vector.fma %2269, %2258, %2245 : vector<8xf32>
    %2271 = vector.extract %2098[4, 6] : f32 from vector<8x8xf32>
    %2272 = vector.broadcast %2271 : f32 to vector<8xf32>
    %2273 = vector.fma %2272, %2258, %2248 : vector<8xf32>
    %2274 = vector.extract %2098[5, 6] : f32 from vector<8x8xf32>
    %2275 = vector.broadcast %2274 : f32 to vector<8xf32>
    %2276 = vector.fma %2275, %2258, %2251 : vector<8xf32>
    %2277 = vector.extract %2098[6, 6] : f32 from vector<8x8xf32>
    %2278 = vector.broadcast %2277 : f32 to vector<8xf32>
    %2279 = vector.fma %2278, %2258, %2254 : vector<8xf32>
    %2280 = vector.extract %2098[7, 6] : f32 from vector<8x8xf32>
    %2281 = vector.broadcast %2280 : f32 to vector<8xf32>
    %2282 = vector.fma %2281, %2258, %2257 : vector<8xf32>
    %2283 = vector.extract %2099[7] : vector<8xf32> from vector<8x8xf32>
    %2284 = vector.extract %2098[0, 7] : f32 from vector<8x8xf32>
    %2285 = vector.broadcast %2284 : f32 to vector<8xf32>
    %2286 = vector.fma %2285, %2283, %2261 : vector<8xf32>
    %2287 = vector.insert %2286, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2288 = vector.extract %2098[1, 7] : f32 from vector<8x8xf32>
    %2289 = vector.broadcast %2288 : f32 to vector<8xf32>
    %2290 = vector.fma %2289, %2283, %2264 : vector<8xf32>
    %2291 = vector.insert %2290, %2287 [1] : vector<8xf32> into vector<8x8xf32>
    %2292 = vector.extract %2098[2, 7] : f32 from vector<8x8xf32>
    %2293 = vector.broadcast %2292 : f32 to vector<8xf32>
    %2294 = vector.fma %2293, %2283, %2267 : vector<8xf32>
    %2295 = vector.insert %2294, %2291 [2] : vector<8xf32> into vector<8x8xf32>
    %2296 = vector.extract %2098[3, 7] : f32 from vector<8x8xf32>
    %2297 = vector.broadcast %2296 : f32 to vector<8xf32>
    %2298 = vector.fma %2297, %2283, %2270 : vector<8xf32>
    %2299 = vector.insert %2298, %2295 [3] : vector<8xf32> into vector<8x8xf32>
    %2300 = vector.extract %2098[4, 7] : f32 from vector<8x8xf32>
    %2301 = vector.broadcast %2300 : f32 to vector<8xf32>
    %2302 = vector.fma %2301, %2283, %2273 : vector<8xf32>
    %2303 = vector.insert %2302, %2299 [4] : vector<8xf32> into vector<8x8xf32>
    %2304 = vector.extract %2098[5, 7] : f32 from vector<8x8xf32>
    %2305 = vector.broadcast %2304 : f32 to vector<8xf32>
    %2306 = vector.fma %2305, %2283, %2276 : vector<8xf32>
    %2307 = vector.insert %2306, %2303 [5] : vector<8xf32> into vector<8x8xf32>
    %2308 = vector.extract %2098[6, 7] : f32 from vector<8x8xf32>
    %2309 = vector.broadcast %2308 : f32 to vector<8xf32>
    %2310 = vector.fma %2309, %2283, %2279 : vector<8xf32>
    %2311 = vector.insert %2310, %2307 [6] : vector<8xf32> into vector<8x8xf32>
    %2312 = vector.extract %2098[7, 7] : f32 from vector<8x8xf32>
    %2313 = vector.broadcast %2312 : f32 to vector<8xf32>
    %2314 = vector.fma %2313, %2283, %2282 : vector<8xf32>
    %2315 = vector.insert %2314, %2311 [7] : vector<8xf32> into vector<8x8xf32>
    %2316 = arith.mulf %2090, %cst_0 : vector<8xf32>
    %2317 = vector.extract %2098[0] : vector<8xf32> from vector<8x8xf32>
    %2318 = vector.extract %2316[0] : f32 from vector<8xf32>
    %2319 = vector.reduction <add>, %2317, %2318 : vector<8xf32> into f32
    %2320 = vector.insert %2319, %cst_0 [0] : f32 into vector<8xf32>
    %2321 = vector.extract %2098[1] : vector<8xf32> from vector<8x8xf32>
    %2322 = vector.extract %2316[1] : f32 from vector<8xf32>
    %2323 = vector.reduction <add>, %2321, %2322 : vector<8xf32> into f32
    %2324 = vector.insert %2323, %2320 [1] : f32 into vector<8xf32>
    %2325 = vector.extract %2098[2] : vector<8xf32> from vector<8x8xf32>
    %2326 = vector.extract %2316[2] : f32 from vector<8xf32>
    %2327 = vector.reduction <add>, %2325, %2326 : vector<8xf32> into f32
    %2328 = vector.insert %2327, %2324 [2] : f32 into vector<8xf32>
    %2329 = vector.extract %2098[3] : vector<8xf32> from vector<8x8xf32>
    %2330 = vector.extract %2316[3] : f32 from vector<8xf32>
    %2331 = vector.reduction <add>, %2329, %2330 : vector<8xf32> into f32
    %2332 = vector.insert %2331, %2328 [3] : f32 into vector<8xf32>
    %2333 = vector.extract %2098[4] : vector<8xf32> from vector<8x8xf32>
    %2334 = vector.extract %2316[4] : f32 from vector<8xf32>
    %2335 = vector.reduction <add>, %2333, %2334 : vector<8xf32> into f32
    %2336 = vector.insert %2335, %2332 [4] : f32 into vector<8xf32>
    %2337 = vector.extract %2098[5] : vector<8xf32> from vector<8x8xf32>
    %2338 = vector.extract %2316[5] : f32 from vector<8xf32>
    %2339 = vector.reduction <add>, %2337, %2338 : vector<8xf32> into f32
    %2340 = vector.insert %2339, %2336 [5] : f32 into vector<8xf32>
    %2341 = vector.extract %2098[6] : vector<8xf32> from vector<8x8xf32>
    %2342 = vector.extract %2316[6] : f32 from vector<8xf32>
    %2343 = vector.reduction <add>, %2341, %2342 : vector<8xf32> into f32
    %2344 = vector.insert %2343, %2340 [6] : f32 into vector<8xf32>
    %2345 = vector.extract %2098[7] : vector<8xf32> from vector<8x8xf32>
    %2346 = vector.extract %2316[7] : f32 from vector<8xf32>
    %2347 = vector.reduction <add>, %2345, %2346 : vector<8xf32> into f32
    %2348 = vector.insert %2347, %2344 [7] : f32 into vector<8xf32>
    %2349 = vector.shape_cast %2348 : vector<8xf32> to vector<1x8xf32>
    %2350 = vector.broadcast %2349 : vector<1x8xf32> to vector<8x8xf32>
    %2351 = vector.transpose %2350, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2352 = arith.divf %2315, %2351 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    vector.transfer_write %2352, %subview_7[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %0 = ub.poison : vector<8x64xf32>
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %6 = vector.insert %5, %0 [0] : vector<64xf32> into vector<8x64xf32>
    %7 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %8 = vector.load %assume_align_3[%arg0, %7, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %9 = vector.insert %8, %6 [1] : vector<64xf32> into vector<8x64xf32>
    %10 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %11 = vector.load %assume_align_3[%arg0, %10, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %12 = vector.insert %11, %9 [2] : vector<64xf32> into vector<8x64xf32>
    %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %15 = vector.insert %14, %12 [3] : vector<64xf32> into vector<8x64xf32>
    %16 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %17 = vector.load %assume_align_3[%arg0, %16, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %18 = vector.insert %17, %15 [4] : vector<64xf32> into vector<8x64xf32>
    %19 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %21 = vector.insert %20, %18 [5] : vector<64xf32> into vector<8x64xf32>
    %22 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %23 = vector.load %assume_align_3[%arg0, %22, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %24 = vector.insert %23, %21 [6] : vector<64xf32> into vector<8x64xf32>
    %25 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %26 = vector.load %assume_align_3[%arg0, %25, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %27 = vector.insert %26, %24 [7] : vector<64xf32> into vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %28 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
    %29 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
    %30 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
    %31 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
    %32 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
    %33 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
    %34 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
    %35 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
    %36 = vector.transpose %27, [1, 0] : vector<8x64xf32> to vector<64x8xf32>
    %37 = vector.extract %36[0] : vector<8xf32> from vector<64x8xf32>
    %38 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %39 = vector.broadcast %38 : f32 to vector<8xf32>
    %40 = vector.fma %39, %37, %28 : vector<8xf32>
    %41 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %42 = memref.load %assume_align[%arg0, %41, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %43 = vector.broadcast %42 : f32 to vector<8xf32>
    %44 = vector.fma %43, %37, %29 : vector<8xf32>
    %45 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %46 = memref.load %assume_align[%arg0, %45, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %47 = vector.broadcast %46 : f32 to vector<8xf32>
    %48 = vector.fma %47, %37, %30 : vector<8xf32>
    %49 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %50 = memref.load %assume_align[%arg0, %49, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %51 = vector.broadcast %50 : f32 to vector<8xf32>
    %52 = vector.fma %51, %37, %31 : vector<8xf32>
    %53 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %54 = memref.load %assume_align[%arg0, %53, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %55 = vector.broadcast %54 : f32 to vector<8xf32>
    %56 = vector.fma %55, %37, %32 : vector<8xf32>
    %57 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %58 = memref.load %assume_align[%arg0, %57, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %59 = vector.broadcast %58 : f32 to vector<8xf32>
    %60 = vector.fma %59, %37, %33 : vector<8xf32>
    %61 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %62 = memref.load %assume_align[%arg0, %61, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %63 = vector.broadcast %62 : f32 to vector<8xf32>
    %64 = vector.fma %63, %37, %34 : vector<8xf32>
    %65 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %66 = memref.load %assume_align[%arg0, %65, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %67 = vector.broadcast %66 : f32 to vector<8xf32>
    %68 = vector.fma %67, %37, %35 : vector<8xf32>
    %69 = vector.extract %36[1] : vector<8xf32> from vector<64x8xf32>
    %70 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %71 = vector.broadcast %70 : f32 to vector<8xf32>
    %72 = vector.fma %71, %69, %40 : vector<8xf32>
    %73 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %74 = memref.load %assume_align[%arg0, %73, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %75 = vector.broadcast %74 : f32 to vector<8xf32>
    %76 = vector.fma %75, %69, %44 : vector<8xf32>
    %77 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %78 = memref.load %assume_align[%arg0, %77, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %79 = vector.broadcast %78 : f32 to vector<8xf32>
    %80 = vector.fma %79, %69, %48 : vector<8xf32>
    %81 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %82 = memref.load %assume_align[%arg0, %81, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %83 = vector.broadcast %82 : f32 to vector<8xf32>
    %84 = vector.fma %83, %69, %52 : vector<8xf32>
    %85 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %86 = memref.load %assume_align[%arg0, %85, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %87 = vector.broadcast %86 : f32 to vector<8xf32>
    %88 = vector.fma %87, %69, %56 : vector<8xf32>
    %89 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %90 = memref.load %assume_align[%arg0, %89, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %91 = vector.broadcast %90 : f32 to vector<8xf32>
    %92 = vector.fma %91, %69, %60 : vector<8xf32>
    %93 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %94 = memref.load %assume_align[%arg0, %93, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %95 = vector.broadcast %94 : f32 to vector<8xf32>
    %96 = vector.fma %95, %69, %64 : vector<8xf32>
    %97 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %98 = memref.load %assume_align[%arg0, %97, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %99 = vector.broadcast %98 : f32 to vector<8xf32>
    %100 = vector.fma %99, %69, %68 : vector<8xf32>
    %101 = vector.extract %36[2] : vector<8xf32> from vector<64x8xf32>
    %102 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %103 = vector.broadcast %102 : f32 to vector<8xf32>
    %104 = vector.fma %103, %101, %72 : vector<8xf32>
    %105 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %106 = memref.load %assume_align[%arg0, %105, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %107 = vector.broadcast %106 : f32 to vector<8xf32>
    %108 = vector.fma %107, %101, %76 : vector<8xf32>
    %109 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %110 = memref.load %assume_align[%arg0, %109, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %111 = vector.broadcast %110 : f32 to vector<8xf32>
    %112 = vector.fma %111, %101, %80 : vector<8xf32>
    %113 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %114 = memref.load %assume_align[%arg0, %113, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %115 = vector.broadcast %114 : f32 to vector<8xf32>
    %116 = vector.fma %115, %101, %84 : vector<8xf32>
    %117 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %118 = memref.load %assume_align[%arg0, %117, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %119 = vector.broadcast %118 : f32 to vector<8xf32>
    %120 = vector.fma %119, %101, %88 : vector<8xf32>
    %121 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %122 = memref.load %assume_align[%arg0, %121, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %123 = vector.broadcast %122 : f32 to vector<8xf32>
    %124 = vector.fma %123, %101, %92 : vector<8xf32>
    %125 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %126 = memref.load %assume_align[%arg0, %125, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %127 = vector.broadcast %126 : f32 to vector<8xf32>
    %128 = vector.fma %127, %101, %96 : vector<8xf32>
    %129 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %130 = memref.load %assume_align[%arg0, %129, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %131 = vector.broadcast %130 : f32 to vector<8xf32>
    %132 = vector.fma %131, %101, %100 : vector<8xf32>
    %133 = vector.extract %36[3] : vector<8xf32> from vector<64x8xf32>
    %134 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %135 = vector.broadcast %134 : f32 to vector<8xf32>
    %136 = vector.fma %135, %133, %104 : vector<8xf32>
    %137 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %138 = memref.load %assume_align[%arg0, %137, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %139 = vector.broadcast %138 : f32 to vector<8xf32>
    %140 = vector.fma %139, %133, %108 : vector<8xf32>
    %141 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %142 = memref.load %assume_align[%arg0, %141, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %143 = vector.broadcast %142 : f32 to vector<8xf32>
    %144 = vector.fma %143, %133, %112 : vector<8xf32>
    %145 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %146 = memref.load %assume_align[%arg0, %145, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %147 = vector.broadcast %146 : f32 to vector<8xf32>
    %148 = vector.fma %147, %133, %116 : vector<8xf32>
    %149 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %150 = memref.load %assume_align[%arg0, %149, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %151 = vector.broadcast %150 : f32 to vector<8xf32>
    %152 = vector.fma %151, %133, %120 : vector<8xf32>
    %153 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %154 = memref.load %assume_align[%arg0, %153, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %155 = vector.broadcast %154 : f32 to vector<8xf32>
    %156 = vector.fma %155, %133, %124 : vector<8xf32>
    %157 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %158 = memref.load %assume_align[%arg0, %157, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %159 = vector.broadcast %158 : f32 to vector<8xf32>
    %160 = vector.fma %159, %133, %128 : vector<8xf32>
    %161 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %162 = memref.load %assume_align[%arg0, %161, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %163 = vector.broadcast %162 : f32 to vector<8xf32>
    %164 = vector.fma %163, %133, %132 : vector<8xf32>
    %165 = vector.extract %36[4] : vector<8xf32> from vector<64x8xf32>
    %166 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %167 = vector.broadcast %166 : f32 to vector<8xf32>
    %168 = vector.fma %167, %165, %136 : vector<8xf32>
    %169 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %170 = memref.load %assume_align[%arg0, %169, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %171 = vector.broadcast %170 : f32 to vector<8xf32>
    %172 = vector.fma %171, %165, %140 : vector<8xf32>
    %173 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %174 = memref.load %assume_align[%arg0, %173, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %175 = vector.broadcast %174 : f32 to vector<8xf32>
    %176 = vector.fma %175, %165, %144 : vector<8xf32>
    %177 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %178 = memref.load %assume_align[%arg0, %177, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %179 = vector.broadcast %178 : f32 to vector<8xf32>
    %180 = vector.fma %179, %165, %148 : vector<8xf32>
    %181 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %182 = memref.load %assume_align[%arg0, %181, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %183 = vector.broadcast %182 : f32 to vector<8xf32>
    %184 = vector.fma %183, %165, %152 : vector<8xf32>
    %185 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %186 = memref.load %assume_align[%arg0, %185, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %187 = vector.broadcast %186 : f32 to vector<8xf32>
    %188 = vector.fma %187, %165, %156 : vector<8xf32>
    %189 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %190 = memref.load %assume_align[%arg0, %189, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %191 = vector.broadcast %190 : f32 to vector<8xf32>
    %192 = vector.fma %191, %165, %160 : vector<8xf32>
    %193 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %194 = memref.load %assume_align[%arg0, %193, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %195 = vector.broadcast %194 : f32 to vector<8xf32>
    %196 = vector.fma %195, %165, %164 : vector<8xf32>
    %197 = vector.extract %36[5] : vector<8xf32> from vector<64x8xf32>
    %198 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %199 = vector.broadcast %198 : f32 to vector<8xf32>
    %200 = vector.fma %199, %197, %168 : vector<8xf32>
    %201 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %202 = memref.load %assume_align[%arg0, %201, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %203 = vector.broadcast %202 : f32 to vector<8xf32>
    %204 = vector.fma %203, %197, %172 : vector<8xf32>
    %205 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %206 = memref.load %assume_align[%arg0, %205, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %207 = vector.broadcast %206 : f32 to vector<8xf32>
    %208 = vector.fma %207, %197, %176 : vector<8xf32>
    %209 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %210 = memref.load %assume_align[%arg0, %209, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %211 = vector.broadcast %210 : f32 to vector<8xf32>
    %212 = vector.fma %211, %197, %180 : vector<8xf32>
    %213 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %214 = memref.load %assume_align[%arg0, %213, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %215 = vector.broadcast %214 : f32 to vector<8xf32>
    %216 = vector.fma %215, %197, %184 : vector<8xf32>
    %217 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %218 = memref.load %assume_align[%arg0, %217, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %219 = vector.broadcast %218 : f32 to vector<8xf32>
    %220 = vector.fma %219, %197, %188 : vector<8xf32>
    %221 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %222 = memref.load %assume_align[%arg0, %221, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %223 = vector.broadcast %222 : f32 to vector<8xf32>
    %224 = vector.fma %223, %197, %192 : vector<8xf32>
    %225 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %226 = memref.load %assume_align[%arg0, %225, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %227 = vector.broadcast %226 : f32 to vector<8xf32>
    %228 = vector.fma %227, %197, %196 : vector<8xf32>
    %229 = vector.extract %36[6] : vector<8xf32> from vector<64x8xf32>
    %230 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %231 = vector.broadcast %230 : f32 to vector<8xf32>
    %232 = vector.fma %231, %229, %200 : vector<8xf32>
    %233 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %234 = memref.load %assume_align[%arg0, %233, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %235 = vector.broadcast %234 : f32 to vector<8xf32>
    %236 = vector.fma %235, %229, %204 : vector<8xf32>
    %237 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %238 = memref.load %assume_align[%arg0, %237, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %239 = vector.broadcast %238 : f32 to vector<8xf32>
    %240 = vector.fma %239, %229, %208 : vector<8xf32>
    %241 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %242 = memref.load %assume_align[%arg0, %241, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %243 = vector.broadcast %242 : f32 to vector<8xf32>
    %244 = vector.fma %243, %229, %212 : vector<8xf32>
    %245 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %246 = memref.load %assume_align[%arg0, %245, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %247 = vector.broadcast %246 : f32 to vector<8xf32>
    %248 = vector.fma %247, %229, %216 : vector<8xf32>
    %249 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %250 = memref.load %assume_align[%arg0, %249, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %251 = vector.broadcast %250 : f32 to vector<8xf32>
    %252 = vector.fma %251, %229, %220 : vector<8xf32>
    %253 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %254 = memref.load %assume_align[%arg0, %253, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %255 = vector.broadcast %254 : f32 to vector<8xf32>
    %256 = vector.fma %255, %229, %224 : vector<8xf32>
    %257 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %258 = memref.load %assume_align[%arg0, %257, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %259 = vector.broadcast %258 : f32 to vector<8xf32>
    %260 = vector.fma %259, %229, %228 : vector<8xf32>
    %261 = vector.extract %36[7] : vector<8xf32> from vector<64x8xf32>
    %262 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %263 = vector.broadcast %262 : f32 to vector<8xf32>
    %264 = vector.fma %263, %261, %232 : vector<8xf32>
    %265 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %266 = memref.load %assume_align[%arg0, %265, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %267 = vector.broadcast %266 : f32 to vector<8xf32>
    %268 = vector.fma %267, %261, %236 : vector<8xf32>
    %269 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %270 = memref.load %assume_align[%arg0, %269, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %271 = vector.broadcast %270 : f32 to vector<8xf32>
    %272 = vector.fma %271, %261, %240 : vector<8xf32>
    %273 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %274 = memref.load %assume_align[%arg0, %273, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %275 = vector.broadcast %274 : f32 to vector<8xf32>
    %276 = vector.fma %275, %261, %244 : vector<8xf32>
    %277 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %278 = memref.load %assume_align[%arg0, %277, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %279 = vector.broadcast %278 : f32 to vector<8xf32>
    %280 = vector.fma %279, %261, %248 : vector<8xf32>
    %281 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %282 = memref.load %assume_align[%arg0, %281, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %283 = vector.broadcast %282 : f32 to vector<8xf32>
    %284 = vector.fma %283, %261, %252 : vector<8xf32>
    %285 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %286 = memref.load %assume_align[%arg0, %285, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %287 = vector.broadcast %286 : f32 to vector<8xf32>
    %288 = vector.fma %287, %261, %256 : vector<8xf32>
    %289 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %290 = memref.load %assume_align[%arg0, %289, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %291 = vector.broadcast %290 : f32 to vector<8xf32>
    %292 = vector.fma %291, %261, %260 : vector<8xf32>
    %293 = vector.extract %36[8] : vector<8xf32> from vector<64x8xf32>
    %294 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %295 = vector.broadcast %294 : f32 to vector<8xf32>
    %296 = vector.fma %295, %293, %264 : vector<8xf32>
    %297 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %298 = memref.load %assume_align[%arg0, %297, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %299 = vector.broadcast %298 : f32 to vector<8xf32>
    %300 = vector.fma %299, %293, %268 : vector<8xf32>
    %301 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %302 = memref.load %assume_align[%arg0, %301, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %303 = vector.broadcast %302 : f32 to vector<8xf32>
    %304 = vector.fma %303, %293, %272 : vector<8xf32>
    %305 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %306 = memref.load %assume_align[%arg0, %305, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %307 = vector.broadcast %306 : f32 to vector<8xf32>
    %308 = vector.fma %307, %293, %276 : vector<8xf32>
    %309 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %310 = memref.load %assume_align[%arg0, %309, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %311 = vector.broadcast %310 : f32 to vector<8xf32>
    %312 = vector.fma %311, %293, %280 : vector<8xf32>
    %313 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %314 = memref.load %assume_align[%arg0, %313, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %315 = vector.broadcast %314 : f32 to vector<8xf32>
    %316 = vector.fma %315, %293, %284 : vector<8xf32>
    %317 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %318 = memref.load %assume_align[%arg0, %317, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %319 = vector.broadcast %318 : f32 to vector<8xf32>
    %320 = vector.fma %319, %293, %288 : vector<8xf32>
    %321 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %322 = memref.load %assume_align[%arg0, %321, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %323 = vector.broadcast %322 : f32 to vector<8xf32>
    %324 = vector.fma %323, %293, %292 : vector<8xf32>
    %325 = vector.extract %36[9] : vector<8xf32> from vector<64x8xf32>
    %326 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %327 = vector.broadcast %326 : f32 to vector<8xf32>
    %328 = vector.fma %327, %325, %296 : vector<8xf32>
    %329 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %330 = memref.load %assume_align[%arg0, %329, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %331 = vector.broadcast %330 : f32 to vector<8xf32>
    %332 = vector.fma %331, %325, %300 : vector<8xf32>
    %333 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %334 = memref.load %assume_align[%arg0, %333, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %335 = vector.broadcast %334 : f32 to vector<8xf32>
    %336 = vector.fma %335, %325, %304 : vector<8xf32>
    %337 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %338 = memref.load %assume_align[%arg0, %337, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %339 = vector.broadcast %338 : f32 to vector<8xf32>
    %340 = vector.fma %339, %325, %308 : vector<8xf32>
    %341 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %342 = memref.load %assume_align[%arg0, %341, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %343 = vector.broadcast %342 : f32 to vector<8xf32>
    %344 = vector.fma %343, %325, %312 : vector<8xf32>
    %345 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %346 = memref.load %assume_align[%arg0, %345, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %347 = vector.broadcast %346 : f32 to vector<8xf32>
    %348 = vector.fma %347, %325, %316 : vector<8xf32>
    %349 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %350 = memref.load %assume_align[%arg0, %349, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %351 = vector.broadcast %350 : f32 to vector<8xf32>
    %352 = vector.fma %351, %325, %320 : vector<8xf32>
    %353 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %354 = memref.load %assume_align[%arg0, %353, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %355 = vector.broadcast %354 : f32 to vector<8xf32>
    %356 = vector.fma %355, %325, %324 : vector<8xf32>
    %357 = vector.extract %36[10] : vector<8xf32> from vector<64x8xf32>
    %358 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %359 = vector.broadcast %358 : f32 to vector<8xf32>
    %360 = vector.fma %359, %357, %328 : vector<8xf32>
    %361 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %362 = memref.load %assume_align[%arg0, %361, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %363 = vector.broadcast %362 : f32 to vector<8xf32>
    %364 = vector.fma %363, %357, %332 : vector<8xf32>
    %365 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %366 = memref.load %assume_align[%arg0, %365, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %367 = vector.broadcast %366 : f32 to vector<8xf32>
    %368 = vector.fma %367, %357, %336 : vector<8xf32>
    %369 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %370 = memref.load %assume_align[%arg0, %369, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %371 = vector.broadcast %370 : f32 to vector<8xf32>
    %372 = vector.fma %371, %357, %340 : vector<8xf32>
    %373 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %374 = memref.load %assume_align[%arg0, %373, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %375 = vector.broadcast %374 : f32 to vector<8xf32>
    %376 = vector.fma %375, %357, %344 : vector<8xf32>
    %377 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %378 = memref.load %assume_align[%arg0, %377, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %379 = vector.broadcast %378 : f32 to vector<8xf32>
    %380 = vector.fma %379, %357, %348 : vector<8xf32>
    %381 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %382 = memref.load %assume_align[%arg0, %381, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %383 = vector.broadcast %382 : f32 to vector<8xf32>
    %384 = vector.fma %383, %357, %352 : vector<8xf32>
    %385 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %386 = memref.load %assume_align[%arg0, %385, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %387 = vector.broadcast %386 : f32 to vector<8xf32>
    %388 = vector.fma %387, %357, %356 : vector<8xf32>
    %389 = vector.extract %36[11] : vector<8xf32> from vector<64x8xf32>
    %390 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %391 = vector.broadcast %390 : f32 to vector<8xf32>
    %392 = vector.fma %391, %389, %360 : vector<8xf32>
    %393 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %394 = memref.load %assume_align[%arg0, %393, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %395 = vector.broadcast %394 : f32 to vector<8xf32>
    %396 = vector.fma %395, %389, %364 : vector<8xf32>
    %397 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %398 = memref.load %assume_align[%arg0, %397, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %399 = vector.broadcast %398 : f32 to vector<8xf32>
    %400 = vector.fma %399, %389, %368 : vector<8xf32>
    %401 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %402 = memref.load %assume_align[%arg0, %401, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %403 = vector.broadcast %402 : f32 to vector<8xf32>
    %404 = vector.fma %403, %389, %372 : vector<8xf32>
    %405 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %406 = memref.load %assume_align[%arg0, %405, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %407 = vector.broadcast %406 : f32 to vector<8xf32>
    %408 = vector.fma %407, %389, %376 : vector<8xf32>
    %409 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %410 = memref.load %assume_align[%arg0, %409, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %411 = vector.broadcast %410 : f32 to vector<8xf32>
    %412 = vector.fma %411, %389, %380 : vector<8xf32>
    %413 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %414 = memref.load %assume_align[%arg0, %413, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %415 = vector.broadcast %414 : f32 to vector<8xf32>
    %416 = vector.fma %415, %389, %384 : vector<8xf32>
    %417 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %418 = memref.load %assume_align[%arg0, %417, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %419 = vector.broadcast %418 : f32 to vector<8xf32>
    %420 = vector.fma %419, %389, %388 : vector<8xf32>
    %421 = vector.extract %36[12] : vector<8xf32> from vector<64x8xf32>
    %422 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %423 = vector.broadcast %422 : f32 to vector<8xf32>
    %424 = vector.fma %423, %421, %392 : vector<8xf32>
    %425 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %426 = memref.load %assume_align[%arg0, %425, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %427 = vector.broadcast %426 : f32 to vector<8xf32>
    %428 = vector.fma %427, %421, %396 : vector<8xf32>
    %429 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %430 = memref.load %assume_align[%arg0, %429, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %431 = vector.broadcast %430 : f32 to vector<8xf32>
    %432 = vector.fma %431, %421, %400 : vector<8xf32>
    %433 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %434 = memref.load %assume_align[%arg0, %433, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %435 = vector.broadcast %434 : f32 to vector<8xf32>
    %436 = vector.fma %435, %421, %404 : vector<8xf32>
    %437 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %438 = memref.load %assume_align[%arg0, %437, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %439 = vector.broadcast %438 : f32 to vector<8xf32>
    %440 = vector.fma %439, %421, %408 : vector<8xf32>
    %441 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %442 = memref.load %assume_align[%arg0, %441, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %443 = vector.broadcast %442 : f32 to vector<8xf32>
    %444 = vector.fma %443, %421, %412 : vector<8xf32>
    %445 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %446 = memref.load %assume_align[%arg0, %445, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %447 = vector.broadcast %446 : f32 to vector<8xf32>
    %448 = vector.fma %447, %421, %416 : vector<8xf32>
    %449 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %450 = memref.load %assume_align[%arg0, %449, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %451 = vector.broadcast %450 : f32 to vector<8xf32>
    %452 = vector.fma %451, %421, %420 : vector<8xf32>
    %453 = vector.extract %36[13] : vector<8xf32> from vector<64x8xf32>
    %454 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %455 = vector.broadcast %454 : f32 to vector<8xf32>
    %456 = vector.fma %455, %453, %424 : vector<8xf32>
    %457 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %458 = memref.load %assume_align[%arg0, %457, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %459 = vector.broadcast %458 : f32 to vector<8xf32>
    %460 = vector.fma %459, %453, %428 : vector<8xf32>
    %461 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %462 = memref.load %assume_align[%arg0, %461, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %463 = vector.broadcast %462 : f32 to vector<8xf32>
    %464 = vector.fma %463, %453, %432 : vector<8xf32>
    %465 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %466 = memref.load %assume_align[%arg0, %465, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %467 = vector.broadcast %466 : f32 to vector<8xf32>
    %468 = vector.fma %467, %453, %436 : vector<8xf32>
    %469 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %470 = memref.load %assume_align[%arg0, %469, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %471 = vector.broadcast %470 : f32 to vector<8xf32>
    %472 = vector.fma %471, %453, %440 : vector<8xf32>
    %473 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %474 = memref.load %assume_align[%arg0, %473, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %475 = vector.broadcast %474 : f32 to vector<8xf32>
    %476 = vector.fma %475, %453, %444 : vector<8xf32>
    %477 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %478 = memref.load %assume_align[%arg0, %477, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %479 = vector.broadcast %478 : f32 to vector<8xf32>
    %480 = vector.fma %479, %453, %448 : vector<8xf32>
    %481 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %482 = memref.load %assume_align[%arg0, %481, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %483 = vector.broadcast %482 : f32 to vector<8xf32>
    %484 = vector.fma %483, %453, %452 : vector<8xf32>
    %485 = vector.extract %36[14] : vector<8xf32> from vector<64x8xf32>
    %486 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %487 = vector.broadcast %486 : f32 to vector<8xf32>
    %488 = vector.fma %487, %485, %456 : vector<8xf32>
    %489 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %490 = memref.load %assume_align[%arg0, %489, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %491 = vector.broadcast %490 : f32 to vector<8xf32>
    %492 = vector.fma %491, %485, %460 : vector<8xf32>
    %493 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %494 = memref.load %assume_align[%arg0, %493, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %495 = vector.broadcast %494 : f32 to vector<8xf32>
    %496 = vector.fma %495, %485, %464 : vector<8xf32>
    %497 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %498 = memref.load %assume_align[%arg0, %497, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %499 = vector.broadcast %498 : f32 to vector<8xf32>
    %500 = vector.fma %499, %485, %468 : vector<8xf32>
    %501 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %502 = memref.load %assume_align[%arg0, %501, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %503 = vector.broadcast %502 : f32 to vector<8xf32>
    %504 = vector.fma %503, %485, %472 : vector<8xf32>
    %505 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %506 = memref.load %assume_align[%arg0, %505, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %507 = vector.broadcast %506 : f32 to vector<8xf32>
    %508 = vector.fma %507, %485, %476 : vector<8xf32>
    %509 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %510 = memref.load %assume_align[%arg0, %509, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %511 = vector.broadcast %510 : f32 to vector<8xf32>
    %512 = vector.fma %511, %485, %480 : vector<8xf32>
    %513 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %514 = memref.load %assume_align[%arg0, %513, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %515 = vector.broadcast %514 : f32 to vector<8xf32>
    %516 = vector.fma %515, %485, %484 : vector<8xf32>
    %517 = vector.extract %36[15] : vector<8xf32> from vector<64x8xf32>
    %518 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %519 = vector.broadcast %518 : f32 to vector<8xf32>
    %520 = vector.fma %519, %517, %488 : vector<8xf32>
    %521 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %522 = memref.load %assume_align[%arg0, %521, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %523 = vector.broadcast %522 : f32 to vector<8xf32>
    %524 = vector.fma %523, %517, %492 : vector<8xf32>
    %525 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %526 = memref.load %assume_align[%arg0, %525, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %527 = vector.broadcast %526 : f32 to vector<8xf32>
    %528 = vector.fma %527, %517, %496 : vector<8xf32>
    %529 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %530 = memref.load %assume_align[%arg0, %529, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %531 = vector.broadcast %530 : f32 to vector<8xf32>
    %532 = vector.fma %531, %517, %500 : vector<8xf32>
    %533 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %534 = memref.load %assume_align[%arg0, %533, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %535 = vector.broadcast %534 : f32 to vector<8xf32>
    %536 = vector.fma %535, %517, %504 : vector<8xf32>
    %537 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %538 = memref.load %assume_align[%arg0, %537, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %539 = vector.broadcast %538 : f32 to vector<8xf32>
    %540 = vector.fma %539, %517, %508 : vector<8xf32>
    %541 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %542 = memref.load %assume_align[%arg0, %541, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %543 = vector.broadcast %542 : f32 to vector<8xf32>
    %544 = vector.fma %543, %517, %512 : vector<8xf32>
    %545 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %546 = memref.load %assume_align[%arg0, %545, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %547 = vector.broadcast %546 : f32 to vector<8xf32>
    %548 = vector.fma %547, %517, %516 : vector<8xf32>
    %549 = vector.extract %36[16] : vector<8xf32> from vector<64x8xf32>
    %550 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %551 = vector.broadcast %550 : f32 to vector<8xf32>
    %552 = vector.fma %551, %549, %520 : vector<8xf32>
    %553 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %554 = memref.load %assume_align[%arg0, %553, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %555 = vector.broadcast %554 : f32 to vector<8xf32>
    %556 = vector.fma %555, %549, %524 : vector<8xf32>
    %557 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %558 = memref.load %assume_align[%arg0, %557, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %559 = vector.broadcast %558 : f32 to vector<8xf32>
    %560 = vector.fma %559, %549, %528 : vector<8xf32>
    %561 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %562 = memref.load %assume_align[%arg0, %561, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %563 = vector.broadcast %562 : f32 to vector<8xf32>
    %564 = vector.fma %563, %549, %532 : vector<8xf32>
    %565 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %566 = memref.load %assume_align[%arg0, %565, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %567 = vector.broadcast %566 : f32 to vector<8xf32>
    %568 = vector.fma %567, %549, %536 : vector<8xf32>
    %569 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %570 = memref.load %assume_align[%arg0, %569, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %571 = vector.broadcast %570 : f32 to vector<8xf32>
    %572 = vector.fma %571, %549, %540 : vector<8xf32>
    %573 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %574 = memref.load %assume_align[%arg0, %573, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %575 = vector.broadcast %574 : f32 to vector<8xf32>
    %576 = vector.fma %575, %549, %544 : vector<8xf32>
    %577 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %578 = memref.load %assume_align[%arg0, %577, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %579 = vector.broadcast %578 : f32 to vector<8xf32>
    %580 = vector.fma %579, %549, %548 : vector<8xf32>
    %581 = vector.extract %36[17] : vector<8xf32> from vector<64x8xf32>
    %582 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %583 = vector.broadcast %582 : f32 to vector<8xf32>
    %584 = vector.fma %583, %581, %552 : vector<8xf32>
    %585 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %586 = memref.load %assume_align[%arg0, %585, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %587 = vector.broadcast %586 : f32 to vector<8xf32>
    %588 = vector.fma %587, %581, %556 : vector<8xf32>
    %589 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %590 = memref.load %assume_align[%arg0, %589, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %591 = vector.broadcast %590 : f32 to vector<8xf32>
    %592 = vector.fma %591, %581, %560 : vector<8xf32>
    %593 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %594 = memref.load %assume_align[%arg0, %593, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %595 = vector.broadcast %594 : f32 to vector<8xf32>
    %596 = vector.fma %595, %581, %564 : vector<8xf32>
    %597 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %598 = memref.load %assume_align[%arg0, %597, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %599 = vector.broadcast %598 : f32 to vector<8xf32>
    %600 = vector.fma %599, %581, %568 : vector<8xf32>
    %601 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %602 = memref.load %assume_align[%arg0, %601, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %603 = vector.broadcast %602 : f32 to vector<8xf32>
    %604 = vector.fma %603, %581, %572 : vector<8xf32>
    %605 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %606 = memref.load %assume_align[%arg0, %605, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %607 = vector.broadcast %606 : f32 to vector<8xf32>
    %608 = vector.fma %607, %581, %576 : vector<8xf32>
    %609 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %610 = memref.load %assume_align[%arg0, %609, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %611 = vector.broadcast %610 : f32 to vector<8xf32>
    %612 = vector.fma %611, %581, %580 : vector<8xf32>
    %613 = vector.extract %36[18] : vector<8xf32> from vector<64x8xf32>
    %614 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %615 = vector.broadcast %614 : f32 to vector<8xf32>
    %616 = vector.fma %615, %613, %584 : vector<8xf32>
    %617 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %618 = memref.load %assume_align[%arg0, %617, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %619 = vector.broadcast %618 : f32 to vector<8xf32>
    %620 = vector.fma %619, %613, %588 : vector<8xf32>
    %621 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %622 = memref.load %assume_align[%arg0, %621, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %623 = vector.broadcast %622 : f32 to vector<8xf32>
    %624 = vector.fma %623, %613, %592 : vector<8xf32>
    %625 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %626 = memref.load %assume_align[%arg0, %625, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %627 = vector.broadcast %626 : f32 to vector<8xf32>
    %628 = vector.fma %627, %613, %596 : vector<8xf32>
    %629 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %630 = memref.load %assume_align[%arg0, %629, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %631 = vector.broadcast %630 : f32 to vector<8xf32>
    %632 = vector.fma %631, %613, %600 : vector<8xf32>
    %633 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %634 = memref.load %assume_align[%arg0, %633, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %635 = vector.broadcast %634 : f32 to vector<8xf32>
    %636 = vector.fma %635, %613, %604 : vector<8xf32>
    %637 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %638 = memref.load %assume_align[%arg0, %637, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %639 = vector.broadcast %638 : f32 to vector<8xf32>
    %640 = vector.fma %639, %613, %608 : vector<8xf32>
    %641 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %642 = memref.load %assume_align[%arg0, %641, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %643 = vector.broadcast %642 : f32 to vector<8xf32>
    %644 = vector.fma %643, %613, %612 : vector<8xf32>
    %645 = vector.extract %36[19] : vector<8xf32> from vector<64x8xf32>
    %646 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %647 = vector.broadcast %646 : f32 to vector<8xf32>
    %648 = vector.fma %647, %645, %616 : vector<8xf32>
    %649 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %650 = memref.load %assume_align[%arg0, %649, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %651 = vector.broadcast %650 : f32 to vector<8xf32>
    %652 = vector.fma %651, %645, %620 : vector<8xf32>
    %653 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %654 = memref.load %assume_align[%arg0, %653, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %655 = vector.broadcast %654 : f32 to vector<8xf32>
    %656 = vector.fma %655, %645, %624 : vector<8xf32>
    %657 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %658 = memref.load %assume_align[%arg0, %657, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %659 = vector.broadcast %658 : f32 to vector<8xf32>
    %660 = vector.fma %659, %645, %628 : vector<8xf32>
    %661 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %662 = memref.load %assume_align[%arg0, %661, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %663 = vector.broadcast %662 : f32 to vector<8xf32>
    %664 = vector.fma %663, %645, %632 : vector<8xf32>
    %665 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %666 = memref.load %assume_align[%arg0, %665, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %667 = vector.broadcast %666 : f32 to vector<8xf32>
    %668 = vector.fma %667, %645, %636 : vector<8xf32>
    %669 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %670 = memref.load %assume_align[%arg0, %669, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %671 = vector.broadcast %670 : f32 to vector<8xf32>
    %672 = vector.fma %671, %645, %640 : vector<8xf32>
    %673 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %674 = memref.load %assume_align[%arg0, %673, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %675 = vector.broadcast %674 : f32 to vector<8xf32>
    %676 = vector.fma %675, %645, %644 : vector<8xf32>
    %677 = vector.extract %36[20] : vector<8xf32> from vector<64x8xf32>
    %678 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %679 = vector.broadcast %678 : f32 to vector<8xf32>
    %680 = vector.fma %679, %677, %648 : vector<8xf32>
    %681 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %682 = memref.load %assume_align[%arg0, %681, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %683 = vector.broadcast %682 : f32 to vector<8xf32>
    %684 = vector.fma %683, %677, %652 : vector<8xf32>
    %685 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %686 = memref.load %assume_align[%arg0, %685, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %687 = vector.broadcast %686 : f32 to vector<8xf32>
    %688 = vector.fma %687, %677, %656 : vector<8xf32>
    %689 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %690 = memref.load %assume_align[%arg0, %689, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %691 = vector.broadcast %690 : f32 to vector<8xf32>
    %692 = vector.fma %691, %677, %660 : vector<8xf32>
    %693 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %694 = memref.load %assume_align[%arg0, %693, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %695 = vector.broadcast %694 : f32 to vector<8xf32>
    %696 = vector.fma %695, %677, %664 : vector<8xf32>
    %697 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %698 = memref.load %assume_align[%arg0, %697, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %699 = vector.broadcast %698 : f32 to vector<8xf32>
    %700 = vector.fma %699, %677, %668 : vector<8xf32>
    %701 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %702 = memref.load %assume_align[%arg0, %701, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %703 = vector.broadcast %702 : f32 to vector<8xf32>
    %704 = vector.fma %703, %677, %672 : vector<8xf32>
    %705 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %706 = memref.load %assume_align[%arg0, %705, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %707 = vector.broadcast %706 : f32 to vector<8xf32>
    %708 = vector.fma %707, %677, %676 : vector<8xf32>
    %709 = vector.extract %36[21] : vector<8xf32> from vector<64x8xf32>
    %710 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %711 = vector.broadcast %710 : f32 to vector<8xf32>
    %712 = vector.fma %711, %709, %680 : vector<8xf32>
    %713 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %714 = memref.load %assume_align[%arg0, %713, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %715 = vector.broadcast %714 : f32 to vector<8xf32>
    %716 = vector.fma %715, %709, %684 : vector<8xf32>
    %717 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %718 = memref.load %assume_align[%arg0, %717, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %719 = vector.broadcast %718 : f32 to vector<8xf32>
    %720 = vector.fma %719, %709, %688 : vector<8xf32>
    %721 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %722 = memref.load %assume_align[%arg0, %721, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %723 = vector.broadcast %722 : f32 to vector<8xf32>
    %724 = vector.fma %723, %709, %692 : vector<8xf32>
    %725 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %726 = memref.load %assume_align[%arg0, %725, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %727 = vector.broadcast %726 : f32 to vector<8xf32>
    %728 = vector.fma %727, %709, %696 : vector<8xf32>
    %729 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %730 = memref.load %assume_align[%arg0, %729, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %731 = vector.broadcast %730 : f32 to vector<8xf32>
    %732 = vector.fma %731, %709, %700 : vector<8xf32>
    %733 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %734 = memref.load %assume_align[%arg0, %733, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %735 = vector.broadcast %734 : f32 to vector<8xf32>
    %736 = vector.fma %735, %709, %704 : vector<8xf32>
    %737 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %738 = memref.load %assume_align[%arg0, %737, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %739 = vector.broadcast %738 : f32 to vector<8xf32>
    %740 = vector.fma %739, %709, %708 : vector<8xf32>
    %741 = vector.extract %36[22] : vector<8xf32> from vector<64x8xf32>
    %742 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %743 = vector.broadcast %742 : f32 to vector<8xf32>
    %744 = vector.fma %743, %741, %712 : vector<8xf32>
    %745 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %746 = memref.load %assume_align[%arg0, %745, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %747 = vector.broadcast %746 : f32 to vector<8xf32>
    %748 = vector.fma %747, %741, %716 : vector<8xf32>
    %749 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %750 = memref.load %assume_align[%arg0, %749, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %751 = vector.broadcast %750 : f32 to vector<8xf32>
    %752 = vector.fma %751, %741, %720 : vector<8xf32>
    %753 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %754 = memref.load %assume_align[%arg0, %753, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %755 = vector.broadcast %754 : f32 to vector<8xf32>
    %756 = vector.fma %755, %741, %724 : vector<8xf32>
    %757 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %758 = memref.load %assume_align[%arg0, %757, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %759 = vector.broadcast %758 : f32 to vector<8xf32>
    %760 = vector.fma %759, %741, %728 : vector<8xf32>
    %761 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %762 = memref.load %assume_align[%arg0, %761, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %763 = vector.broadcast %762 : f32 to vector<8xf32>
    %764 = vector.fma %763, %741, %732 : vector<8xf32>
    %765 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %766 = memref.load %assume_align[%arg0, %765, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %767 = vector.broadcast %766 : f32 to vector<8xf32>
    %768 = vector.fma %767, %741, %736 : vector<8xf32>
    %769 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %770 = memref.load %assume_align[%arg0, %769, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %771 = vector.broadcast %770 : f32 to vector<8xf32>
    %772 = vector.fma %771, %741, %740 : vector<8xf32>
    %773 = vector.extract %36[23] : vector<8xf32> from vector<64x8xf32>
    %774 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %775 = vector.broadcast %774 : f32 to vector<8xf32>
    %776 = vector.fma %775, %773, %744 : vector<8xf32>
    %777 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %778 = memref.load %assume_align[%arg0, %777, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %779 = vector.broadcast %778 : f32 to vector<8xf32>
    %780 = vector.fma %779, %773, %748 : vector<8xf32>
    %781 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %782 = memref.load %assume_align[%arg0, %781, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %783 = vector.broadcast %782 : f32 to vector<8xf32>
    %784 = vector.fma %783, %773, %752 : vector<8xf32>
    %785 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %786 = memref.load %assume_align[%arg0, %785, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %787 = vector.broadcast %786 : f32 to vector<8xf32>
    %788 = vector.fma %787, %773, %756 : vector<8xf32>
    %789 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %790 = memref.load %assume_align[%arg0, %789, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %791 = vector.broadcast %790 : f32 to vector<8xf32>
    %792 = vector.fma %791, %773, %760 : vector<8xf32>
    %793 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %794 = memref.load %assume_align[%arg0, %793, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %795 = vector.broadcast %794 : f32 to vector<8xf32>
    %796 = vector.fma %795, %773, %764 : vector<8xf32>
    %797 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %798 = memref.load %assume_align[%arg0, %797, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %799 = vector.broadcast %798 : f32 to vector<8xf32>
    %800 = vector.fma %799, %773, %768 : vector<8xf32>
    %801 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %802 = memref.load %assume_align[%arg0, %801, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %803 = vector.broadcast %802 : f32 to vector<8xf32>
    %804 = vector.fma %803, %773, %772 : vector<8xf32>
    %805 = vector.extract %36[24] : vector<8xf32> from vector<64x8xf32>
    %806 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %807 = vector.broadcast %806 : f32 to vector<8xf32>
    %808 = vector.fma %807, %805, %776 : vector<8xf32>
    %809 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %810 = memref.load %assume_align[%arg0, %809, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %811 = vector.broadcast %810 : f32 to vector<8xf32>
    %812 = vector.fma %811, %805, %780 : vector<8xf32>
    %813 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %814 = memref.load %assume_align[%arg0, %813, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %815 = vector.broadcast %814 : f32 to vector<8xf32>
    %816 = vector.fma %815, %805, %784 : vector<8xf32>
    %817 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %818 = memref.load %assume_align[%arg0, %817, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %819 = vector.broadcast %818 : f32 to vector<8xf32>
    %820 = vector.fma %819, %805, %788 : vector<8xf32>
    %821 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %822 = memref.load %assume_align[%arg0, %821, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %823 = vector.broadcast %822 : f32 to vector<8xf32>
    %824 = vector.fma %823, %805, %792 : vector<8xf32>
    %825 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %826 = memref.load %assume_align[%arg0, %825, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %827 = vector.broadcast %826 : f32 to vector<8xf32>
    %828 = vector.fma %827, %805, %796 : vector<8xf32>
    %829 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %830 = memref.load %assume_align[%arg0, %829, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %831 = vector.broadcast %830 : f32 to vector<8xf32>
    %832 = vector.fma %831, %805, %800 : vector<8xf32>
    %833 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %834 = memref.load %assume_align[%arg0, %833, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %835 = vector.broadcast %834 : f32 to vector<8xf32>
    %836 = vector.fma %835, %805, %804 : vector<8xf32>
    %837 = vector.extract %36[25] : vector<8xf32> from vector<64x8xf32>
    %838 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %839 = vector.broadcast %838 : f32 to vector<8xf32>
    %840 = vector.fma %839, %837, %808 : vector<8xf32>
    %841 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %842 = memref.load %assume_align[%arg0, %841, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %843 = vector.broadcast %842 : f32 to vector<8xf32>
    %844 = vector.fma %843, %837, %812 : vector<8xf32>
    %845 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %846 = memref.load %assume_align[%arg0, %845, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %847 = vector.broadcast %846 : f32 to vector<8xf32>
    %848 = vector.fma %847, %837, %816 : vector<8xf32>
    %849 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %850 = memref.load %assume_align[%arg0, %849, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %851 = vector.broadcast %850 : f32 to vector<8xf32>
    %852 = vector.fma %851, %837, %820 : vector<8xf32>
    %853 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %854 = memref.load %assume_align[%arg0, %853, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %855 = vector.broadcast %854 : f32 to vector<8xf32>
    %856 = vector.fma %855, %837, %824 : vector<8xf32>
    %857 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %858 = memref.load %assume_align[%arg0, %857, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %859 = vector.broadcast %858 : f32 to vector<8xf32>
    %860 = vector.fma %859, %837, %828 : vector<8xf32>
    %861 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %862 = memref.load %assume_align[%arg0, %861, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %863 = vector.broadcast %862 : f32 to vector<8xf32>
    %864 = vector.fma %863, %837, %832 : vector<8xf32>
    %865 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %866 = memref.load %assume_align[%arg0, %865, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %867 = vector.broadcast %866 : f32 to vector<8xf32>
    %868 = vector.fma %867, %837, %836 : vector<8xf32>
    %869 = vector.extract %36[26] : vector<8xf32> from vector<64x8xf32>
    %870 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %871 = vector.broadcast %870 : f32 to vector<8xf32>
    %872 = vector.fma %871, %869, %840 : vector<8xf32>
    %873 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %874 = memref.load %assume_align[%arg0, %873, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %875 = vector.broadcast %874 : f32 to vector<8xf32>
    %876 = vector.fma %875, %869, %844 : vector<8xf32>
    %877 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %878 = memref.load %assume_align[%arg0, %877, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %879 = vector.broadcast %878 : f32 to vector<8xf32>
    %880 = vector.fma %879, %869, %848 : vector<8xf32>
    %881 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %882 = memref.load %assume_align[%arg0, %881, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %883 = vector.broadcast %882 : f32 to vector<8xf32>
    %884 = vector.fma %883, %869, %852 : vector<8xf32>
    %885 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %886 = memref.load %assume_align[%arg0, %885, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %887 = vector.broadcast %886 : f32 to vector<8xf32>
    %888 = vector.fma %887, %869, %856 : vector<8xf32>
    %889 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %890 = memref.load %assume_align[%arg0, %889, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %891 = vector.broadcast %890 : f32 to vector<8xf32>
    %892 = vector.fma %891, %869, %860 : vector<8xf32>
    %893 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %894 = memref.load %assume_align[%arg0, %893, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %895 = vector.broadcast %894 : f32 to vector<8xf32>
    %896 = vector.fma %895, %869, %864 : vector<8xf32>
    %897 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %898 = memref.load %assume_align[%arg0, %897, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %899 = vector.broadcast %898 : f32 to vector<8xf32>
    %900 = vector.fma %899, %869, %868 : vector<8xf32>
    %901 = vector.extract %36[27] : vector<8xf32> from vector<64x8xf32>
    %902 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %903 = vector.broadcast %902 : f32 to vector<8xf32>
    %904 = vector.fma %903, %901, %872 : vector<8xf32>
    %905 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %906 = memref.load %assume_align[%arg0, %905, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %907 = vector.broadcast %906 : f32 to vector<8xf32>
    %908 = vector.fma %907, %901, %876 : vector<8xf32>
    %909 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %910 = memref.load %assume_align[%arg0, %909, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %911 = vector.broadcast %910 : f32 to vector<8xf32>
    %912 = vector.fma %911, %901, %880 : vector<8xf32>
    %913 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %914 = memref.load %assume_align[%arg0, %913, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %915 = vector.broadcast %914 : f32 to vector<8xf32>
    %916 = vector.fma %915, %901, %884 : vector<8xf32>
    %917 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %918 = memref.load %assume_align[%arg0, %917, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %919 = vector.broadcast %918 : f32 to vector<8xf32>
    %920 = vector.fma %919, %901, %888 : vector<8xf32>
    %921 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %922 = memref.load %assume_align[%arg0, %921, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %923 = vector.broadcast %922 : f32 to vector<8xf32>
    %924 = vector.fma %923, %901, %892 : vector<8xf32>
    %925 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %926 = memref.load %assume_align[%arg0, %925, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %927 = vector.broadcast %926 : f32 to vector<8xf32>
    %928 = vector.fma %927, %901, %896 : vector<8xf32>
    %929 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %930 = memref.load %assume_align[%arg0, %929, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %931 = vector.broadcast %930 : f32 to vector<8xf32>
    %932 = vector.fma %931, %901, %900 : vector<8xf32>
    %933 = vector.extract %36[28] : vector<8xf32> from vector<64x8xf32>
    %934 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %935 = vector.broadcast %934 : f32 to vector<8xf32>
    %936 = vector.fma %935, %933, %904 : vector<8xf32>
    %937 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %938 = memref.load %assume_align[%arg0, %937, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %939 = vector.broadcast %938 : f32 to vector<8xf32>
    %940 = vector.fma %939, %933, %908 : vector<8xf32>
    %941 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %942 = memref.load %assume_align[%arg0, %941, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %943 = vector.broadcast %942 : f32 to vector<8xf32>
    %944 = vector.fma %943, %933, %912 : vector<8xf32>
    %945 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %946 = memref.load %assume_align[%arg0, %945, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %947 = vector.broadcast %946 : f32 to vector<8xf32>
    %948 = vector.fma %947, %933, %916 : vector<8xf32>
    %949 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %950 = memref.load %assume_align[%arg0, %949, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %951 = vector.broadcast %950 : f32 to vector<8xf32>
    %952 = vector.fma %951, %933, %920 : vector<8xf32>
    %953 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %954 = memref.load %assume_align[%arg0, %953, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %955 = vector.broadcast %954 : f32 to vector<8xf32>
    %956 = vector.fma %955, %933, %924 : vector<8xf32>
    %957 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %958 = memref.load %assume_align[%arg0, %957, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %959 = vector.broadcast %958 : f32 to vector<8xf32>
    %960 = vector.fma %959, %933, %928 : vector<8xf32>
    %961 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %962 = memref.load %assume_align[%arg0, %961, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %963 = vector.broadcast %962 : f32 to vector<8xf32>
    %964 = vector.fma %963, %933, %932 : vector<8xf32>
    %965 = vector.extract %36[29] : vector<8xf32> from vector<64x8xf32>
    %966 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %967 = vector.broadcast %966 : f32 to vector<8xf32>
    %968 = vector.fma %967, %965, %936 : vector<8xf32>
    %969 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %970 = memref.load %assume_align[%arg0, %969, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %971 = vector.broadcast %970 : f32 to vector<8xf32>
    %972 = vector.fma %971, %965, %940 : vector<8xf32>
    %973 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %974 = memref.load %assume_align[%arg0, %973, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %975 = vector.broadcast %974 : f32 to vector<8xf32>
    %976 = vector.fma %975, %965, %944 : vector<8xf32>
    %977 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %978 = memref.load %assume_align[%arg0, %977, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %979 = vector.broadcast %978 : f32 to vector<8xf32>
    %980 = vector.fma %979, %965, %948 : vector<8xf32>
    %981 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %982 = memref.load %assume_align[%arg0, %981, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %983 = vector.broadcast %982 : f32 to vector<8xf32>
    %984 = vector.fma %983, %965, %952 : vector<8xf32>
    %985 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %986 = memref.load %assume_align[%arg0, %985, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %987 = vector.broadcast %986 : f32 to vector<8xf32>
    %988 = vector.fma %987, %965, %956 : vector<8xf32>
    %989 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %990 = memref.load %assume_align[%arg0, %989, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %991 = vector.broadcast %990 : f32 to vector<8xf32>
    %992 = vector.fma %991, %965, %960 : vector<8xf32>
    %993 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %994 = memref.load %assume_align[%arg0, %993, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %995 = vector.broadcast %994 : f32 to vector<8xf32>
    %996 = vector.fma %995, %965, %964 : vector<8xf32>
    %997 = vector.extract %36[30] : vector<8xf32> from vector<64x8xf32>
    %998 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %999 = vector.broadcast %998 : f32 to vector<8xf32>
    %1000 = vector.fma %999, %997, %968 : vector<8xf32>
    %1001 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1002 = memref.load %assume_align[%arg0, %1001, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1003 = vector.broadcast %1002 : f32 to vector<8xf32>
    %1004 = vector.fma %1003, %997, %972 : vector<8xf32>
    %1005 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1006 = memref.load %assume_align[%arg0, %1005, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1007 = vector.broadcast %1006 : f32 to vector<8xf32>
    %1008 = vector.fma %1007, %997, %976 : vector<8xf32>
    %1009 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1010 = memref.load %assume_align[%arg0, %1009, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1011 = vector.broadcast %1010 : f32 to vector<8xf32>
    %1012 = vector.fma %1011, %997, %980 : vector<8xf32>
    %1013 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1014 = memref.load %assume_align[%arg0, %1013, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1015 = vector.broadcast %1014 : f32 to vector<8xf32>
    %1016 = vector.fma %1015, %997, %984 : vector<8xf32>
    %1017 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1018 = memref.load %assume_align[%arg0, %1017, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1019 = vector.broadcast %1018 : f32 to vector<8xf32>
    %1020 = vector.fma %1019, %997, %988 : vector<8xf32>
    %1021 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1022 = memref.load %assume_align[%arg0, %1021, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1023 = vector.broadcast %1022 : f32 to vector<8xf32>
    %1024 = vector.fma %1023, %997, %992 : vector<8xf32>
    %1025 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1026 = memref.load %assume_align[%arg0, %1025, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1027 = vector.broadcast %1026 : f32 to vector<8xf32>
    %1028 = vector.fma %1027, %997, %996 : vector<8xf32>
    %1029 = vector.extract %36[31] : vector<8xf32> from vector<64x8xf32>
    %1030 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1031 = vector.broadcast %1030 : f32 to vector<8xf32>
    %1032 = vector.fma %1031, %1029, %1000 : vector<8xf32>
    %1033 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1034 = memref.load %assume_align[%arg0, %1033, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1035 = vector.broadcast %1034 : f32 to vector<8xf32>
    %1036 = vector.fma %1035, %1029, %1004 : vector<8xf32>
    %1037 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1038 = memref.load %assume_align[%arg0, %1037, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1039 = vector.broadcast %1038 : f32 to vector<8xf32>
    %1040 = vector.fma %1039, %1029, %1008 : vector<8xf32>
    %1041 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1042 = memref.load %assume_align[%arg0, %1041, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1043 = vector.broadcast %1042 : f32 to vector<8xf32>
    %1044 = vector.fma %1043, %1029, %1012 : vector<8xf32>
    %1045 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1046 = memref.load %assume_align[%arg0, %1045, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1047 = vector.broadcast %1046 : f32 to vector<8xf32>
    %1048 = vector.fma %1047, %1029, %1016 : vector<8xf32>
    %1049 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1050 = memref.load %assume_align[%arg0, %1049, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1051 = vector.broadcast %1050 : f32 to vector<8xf32>
    %1052 = vector.fma %1051, %1029, %1020 : vector<8xf32>
    %1053 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1054 = memref.load %assume_align[%arg0, %1053, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1055 = vector.broadcast %1054 : f32 to vector<8xf32>
    %1056 = vector.fma %1055, %1029, %1024 : vector<8xf32>
    %1057 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1058 = memref.load %assume_align[%arg0, %1057, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1059 = vector.broadcast %1058 : f32 to vector<8xf32>
    %1060 = vector.fma %1059, %1029, %1028 : vector<8xf32>
    %1061 = vector.extract %36[32] : vector<8xf32> from vector<64x8xf32>
    %1062 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1063 = vector.broadcast %1062 : f32 to vector<8xf32>
    %1064 = vector.fma %1063, %1061, %1032 : vector<8xf32>
    %1065 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1066 = memref.load %assume_align[%arg0, %1065, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1067 = vector.broadcast %1066 : f32 to vector<8xf32>
    %1068 = vector.fma %1067, %1061, %1036 : vector<8xf32>
    %1069 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1070 = memref.load %assume_align[%arg0, %1069, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1071 = vector.broadcast %1070 : f32 to vector<8xf32>
    %1072 = vector.fma %1071, %1061, %1040 : vector<8xf32>
    %1073 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1074 = memref.load %assume_align[%arg0, %1073, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1075 = vector.broadcast %1074 : f32 to vector<8xf32>
    %1076 = vector.fma %1075, %1061, %1044 : vector<8xf32>
    %1077 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1078 = memref.load %assume_align[%arg0, %1077, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1079 = vector.broadcast %1078 : f32 to vector<8xf32>
    %1080 = vector.fma %1079, %1061, %1048 : vector<8xf32>
    %1081 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1082 = memref.load %assume_align[%arg0, %1081, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1083 = vector.broadcast %1082 : f32 to vector<8xf32>
    %1084 = vector.fma %1083, %1061, %1052 : vector<8xf32>
    %1085 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1086 = memref.load %assume_align[%arg0, %1085, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1087 = vector.broadcast %1086 : f32 to vector<8xf32>
    %1088 = vector.fma %1087, %1061, %1056 : vector<8xf32>
    %1089 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1090 = memref.load %assume_align[%arg0, %1089, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1091 = vector.broadcast %1090 : f32 to vector<8xf32>
    %1092 = vector.fma %1091, %1061, %1060 : vector<8xf32>
    %1093 = vector.extract %36[33] : vector<8xf32> from vector<64x8xf32>
    %1094 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1095 = vector.broadcast %1094 : f32 to vector<8xf32>
    %1096 = vector.fma %1095, %1093, %1064 : vector<8xf32>
    %1097 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1098 = memref.load %assume_align[%arg0, %1097, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1099 = vector.broadcast %1098 : f32 to vector<8xf32>
    %1100 = vector.fma %1099, %1093, %1068 : vector<8xf32>
    %1101 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1102 = memref.load %assume_align[%arg0, %1101, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1103 = vector.broadcast %1102 : f32 to vector<8xf32>
    %1104 = vector.fma %1103, %1093, %1072 : vector<8xf32>
    %1105 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1106 = memref.load %assume_align[%arg0, %1105, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1107 = vector.broadcast %1106 : f32 to vector<8xf32>
    %1108 = vector.fma %1107, %1093, %1076 : vector<8xf32>
    %1109 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1110 = memref.load %assume_align[%arg0, %1109, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1111 = vector.broadcast %1110 : f32 to vector<8xf32>
    %1112 = vector.fma %1111, %1093, %1080 : vector<8xf32>
    %1113 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1114 = memref.load %assume_align[%arg0, %1113, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1115 = vector.broadcast %1114 : f32 to vector<8xf32>
    %1116 = vector.fma %1115, %1093, %1084 : vector<8xf32>
    %1117 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1118 = memref.load %assume_align[%arg0, %1117, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1119 = vector.broadcast %1118 : f32 to vector<8xf32>
    %1120 = vector.fma %1119, %1093, %1088 : vector<8xf32>
    %1121 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1122 = memref.load %assume_align[%arg0, %1121, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1123 = vector.broadcast %1122 : f32 to vector<8xf32>
    %1124 = vector.fma %1123, %1093, %1092 : vector<8xf32>
    %1125 = vector.extract %36[34] : vector<8xf32> from vector<64x8xf32>
    %1126 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1127 = vector.broadcast %1126 : f32 to vector<8xf32>
    %1128 = vector.fma %1127, %1125, %1096 : vector<8xf32>
    %1129 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1130 = memref.load %assume_align[%arg0, %1129, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1131 = vector.broadcast %1130 : f32 to vector<8xf32>
    %1132 = vector.fma %1131, %1125, %1100 : vector<8xf32>
    %1133 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1134 = memref.load %assume_align[%arg0, %1133, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1135 = vector.broadcast %1134 : f32 to vector<8xf32>
    %1136 = vector.fma %1135, %1125, %1104 : vector<8xf32>
    %1137 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1138 = memref.load %assume_align[%arg0, %1137, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1139 = vector.broadcast %1138 : f32 to vector<8xf32>
    %1140 = vector.fma %1139, %1125, %1108 : vector<8xf32>
    %1141 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1142 = memref.load %assume_align[%arg0, %1141, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1143 = vector.broadcast %1142 : f32 to vector<8xf32>
    %1144 = vector.fma %1143, %1125, %1112 : vector<8xf32>
    %1145 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1146 = memref.load %assume_align[%arg0, %1145, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1147 = vector.broadcast %1146 : f32 to vector<8xf32>
    %1148 = vector.fma %1147, %1125, %1116 : vector<8xf32>
    %1149 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1150 = memref.load %assume_align[%arg0, %1149, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1151 = vector.broadcast %1150 : f32 to vector<8xf32>
    %1152 = vector.fma %1151, %1125, %1120 : vector<8xf32>
    %1153 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1154 = memref.load %assume_align[%arg0, %1153, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1155 = vector.broadcast %1154 : f32 to vector<8xf32>
    %1156 = vector.fma %1155, %1125, %1124 : vector<8xf32>
    %1157 = vector.extract %36[35] : vector<8xf32> from vector<64x8xf32>
    %1158 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1159 = vector.broadcast %1158 : f32 to vector<8xf32>
    %1160 = vector.fma %1159, %1157, %1128 : vector<8xf32>
    %1161 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1162 = memref.load %assume_align[%arg0, %1161, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1163 = vector.broadcast %1162 : f32 to vector<8xf32>
    %1164 = vector.fma %1163, %1157, %1132 : vector<8xf32>
    %1165 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1166 = memref.load %assume_align[%arg0, %1165, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1167 = vector.broadcast %1166 : f32 to vector<8xf32>
    %1168 = vector.fma %1167, %1157, %1136 : vector<8xf32>
    %1169 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1170 = memref.load %assume_align[%arg0, %1169, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1171 = vector.broadcast %1170 : f32 to vector<8xf32>
    %1172 = vector.fma %1171, %1157, %1140 : vector<8xf32>
    %1173 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1174 = memref.load %assume_align[%arg0, %1173, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1175 = vector.broadcast %1174 : f32 to vector<8xf32>
    %1176 = vector.fma %1175, %1157, %1144 : vector<8xf32>
    %1177 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1178 = memref.load %assume_align[%arg0, %1177, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1179 = vector.broadcast %1178 : f32 to vector<8xf32>
    %1180 = vector.fma %1179, %1157, %1148 : vector<8xf32>
    %1181 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1182 = memref.load %assume_align[%arg0, %1181, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1183 = vector.broadcast %1182 : f32 to vector<8xf32>
    %1184 = vector.fma %1183, %1157, %1152 : vector<8xf32>
    %1185 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1186 = memref.load %assume_align[%arg0, %1185, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1187 = vector.broadcast %1186 : f32 to vector<8xf32>
    %1188 = vector.fma %1187, %1157, %1156 : vector<8xf32>
    %1189 = vector.extract %36[36] : vector<8xf32> from vector<64x8xf32>
    %1190 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1191 = vector.broadcast %1190 : f32 to vector<8xf32>
    %1192 = vector.fma %1191, %1189, %1160 : vector<8xf32>
    %1193 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1194 = memref.load %assume_align[%arg0, %1193, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1195 = vector.broadcast %1194 : f32 to vector<8xf32>
    %1196 = vector.fma %1195, %1189, %1164 : vector<8xf32>
    %1197 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1198 = memref.load %assume_align[%arg0, %1197, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1199 = vector.broadcast %1198 : f32 to vector<8xf32>
    %1200 = vector.fma %1199, %1189, %1168 : vector<8xf32>
    %1201 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1202 = memref.load %assume_align[%arg0, %1201, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1203 = vector.broadcast %1202 : f32 to vector<8xf32>
    %1204 = vector.fma %1203, %1189, %1172 : vector<8xf32>
    %1205 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1206 = memref.load %assume_align[%arg0, %1205, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1207 = vector.broadcast %1206 : f32 to vector<8xf32>
    %1208 = vector.fma %1207, %1189, %1176 : vector<8xf32>
    %1209 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1210 = memref.load %assume_align[%arg0, %1209, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1211 = vector.broadcast %1210 : f32 to vector<8xf32>
    %1212 = vector.fma %1211, %1189, %1180 : vector<8xf32>
    %1213 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1214 = memref.load %assume_align[%arg0, %1213, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1215 = vector.broadcast %1214 : f32 to vector<8xf32>
    %1216 = vector.fma %1215, %1189, %1184 : vector<8xf32>
    %1217 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1218 = memref.load %assume_align[%arg0, %1217, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1219 = vector.broadcast %1218 : f32 to vector<8xf32>
    %1220 = vector.fma %1219, %1189, %1188 : vector<8xf32>
    %1221 = vector.extract %36[37] : vector<8xf32> from vector<64x8xf32>
    %1222 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1223 = vector.broadcast %1222 : f32 to vector<8xf32>
    %1224 = vector.fma %1223, %1221, %1192 : vector<8xf32>
    %1225 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1226 = memref.load %assume_align[%arg0, %1225, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1227 = vector.broadcast %1226 : f32 to vector<8xf32>
    %1228 = vector.fma %1227, %1221, %1196 : vector<8xf32>
    %1229 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1230 = memref.load %assume_align[%arg0, %1229, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1231 = vector.broadcast %1230 : f32 to vector<8xf32>
    %1232 = vector.fma %1231, %1221, %1200 : vector<8xf32>
    %1233 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1234 = memref.load %assume_align[%arg0, %1233, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1235 = vector.broadcast %1234 : f32 to vector<8xf32>
    %1236 = vector.fma %1235, %1221, %1204 : vector<8xf32>
    %1237 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1238 = memref.load %assume_align[%arg0, %1237, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1239 = vector.broadcast %1238 : f32 to vector<8xf32>
    %1240 = vector.fma %1239, %1221, %1208 : vector<8xf32>
    %1241 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1242 = memref.load %assume_align[%arg0, %1241, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1243 = vector.broadcast %1242 : f32 to vector<8xf32>
    %1244 = vector.fma %1243, %1221, %1212 : vector<8xf32>
    %1245 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1246 = memref.load %assume_align[%arg0, %1245, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1247 = vector.broadcast %1246 : f32 to vector<8xf32>
    %1248 = vector.fma %1247, %1221, %1216 : vector<8xf32>
    %1249 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1250 = memref.load %assume_align[%arg0, %1249, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1251 = vector.broadcast %1250 : f32 to vector<8xf32>
    %1252 = vector.fma %1251, %1221, %1220 : vector<8xf32>
    %1253 = vector.extract %36[38] : vector<8xf32> from vector<64x8xf32>
    %1254 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1255 = vector.broadcast %1254 : f32 to vector<8xf32>
    %1256 = vector.fma %1255, %1253, %1224 : vector<8xf32>
    %1257 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1258 = memref.load %assume_align[%arg0, %1257, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1259 = vector.broadcast %1258 : f32 to vector<8xf32>
    %1260 = vector.fma %1259, %1253, %1228 : vector<8xf32>
    %1261 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1262 = memref.load %assume_align[%arg0, %1261, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1263 = vector.broadcast %1262 : f32 to vector<8xf32>
    %1264 = vector.fma %1263, %1253, %1232 : vector<8xf32>
    %1265 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1266 = memref.load %assume_align[%arg0, %1265, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1267 = vector.broadcast %1266 : f32 to vector<8xf32>
    %1268 = vector.fma %1267, %1253, %1236 : vector<8xf32>
    %1269 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1270 = memref.load %assume_align[%arg0, %1269, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1271 = vector.broadcast %1270 : f32 to vector<8xf32>
    %1272 = vector.fma %1271, %1253, %1240 : vector<8xf32>
    %1273 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1274 = memref.load %assume_align[%arg0, %1273, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1275 = vector.broadcast %1274 : f32 to vector<8xf32>
    %1276 = vector.fma %1275, %1253, %1244 : vector<8xf32>
    %1277 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1278 = memref.load %assume_align[%arg0, %1277, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1279 = vector.broadcast %1278 : f32 to vector<8xf32>
    %1280 = vector.fma %1279, %1253, %1248 : vector<8xf32>
    %1281 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1282 = memref.load %assume_align[%arg0, %1281, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1283 = vector.broadcast %1282 : f32 to vector<8xf32>
    %1284 = vector.fma %1283, %1253, %1252 : vector<8xf32>
    %1285 = vector.extract %36[39] : vector<8xf32> from vector<64x8xf32>
    %1286 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1287 = vector.broadcast %1286 : f32 to vector<8xf32>
    %1288 = vector.fma %1287, %1285, %1256 : vector<8xf32>
    %1289 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1290 = memref.load %assume_align[%arg0, %1289, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1291 = vector.broadcast %1290 : f32 to vector<8xf32>
    %1292 = vector.fma %1291, %1285, %1260 : vector<8xf32>
    %1293 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1294 = memref.load %assume_align[%arg0, %1293, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1295 = vector.broadcast %1294 : f32 to vector<8xf32>
    %1296 = vector.fma %1295, %1285, %1264 : vector<8xf32>
    %1297 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1298 = memref.load %assume_align[%arg0, %1297, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1299 = vector.broadcast %1298 : f32 to vector<8xf32>
    %1300 = vector.fma %1299, %1285, %1268 : vector<8xf32>
    %1301 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1302 = memref.load %assume_align[%arg0, %1301, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1303 = vector.broadcast %1302 : f32 to vector<8xf32>
    %1304 = vector.fma %1303, %1285, %1272 : vector<8xf32>
    %1305 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1306 = memref.load %assume_align[%arg0, %1305, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1307 = vector.broadcast %1306 : f32 to vector<8xf32>
    %1308 = vector.fma %1307, %1285, %1276 : vector<8xf32>
    %1309 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1310 = memref.load %assume_align[%arg0, %1309, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1311 = vector.broadcast %1310 : f32 to vector<8xf32>
    %1312 = vector.fma %1311, %1285, %1280 : vector<8xf32>
    %1313 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1314 = memref.load %assume_align[%arg0, %1313, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1315 = vector.broadcast %1314 : f32 to vector<8xf32>
    %1316 = vector.fma %1315, %1285, %1284 : vector<8xf32>
    %1317 = vector.extract %36[40] : vector<8xf32> from vector<64x8xf32>
    %1318 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1319 = vector.broadcast %1318 : f32 to vector<8xf32>
    %1320 = vector.fma %1319, %1317, %1288 : vector<8xf32>
    %1321 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1322 = memref.load %assume_align[%arg0, %1321, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1323 = vector.broadcast %1322 : f32 to vector<8xf32>
    %1324 = vector.fma %1323, %1317, %1292 : vector<8xf32>
    %1325 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1326 = memref.load %assume_align[%arg0, %1325, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1327 = vector.broadcast %1326 : f32 to vector<8xf32>
    %1328 = vector.fma %1327, %1317, %1296 : vector<8xf32>
    %1329 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1330 = memref.load %assume_align[%arg0, %1329, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1331 = vector.broadcast %1330 : f32 to vector<8xf32>
    %1332 = vector.fma %1331, %1317, %1300 : vector<8xf32>
    %1333 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1334 = memref.load %assume_align[%arg0, %1333, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1335 = vector.broadcast %1334 : f32 to vector<8xf32>
    %1336 = vector.fma %1335, %1317, %1304 : vector<8xf32>
    %1337 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1338 = memref.load %assume_align[%arg0, %1337, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1339 = vector.broadcast %1338 : f32 to vector<8xf32>
    %1340 = vector.fma %1339, %1317, %1308 : vector<8xf32>
    %1341 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1342 = memref.load %assume_align[%arg0, %1341, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1343 = vector.broadcast %1342 : f32 to vector<8xf32>
    %1344 = vector.fma %1343, %1317, %1312 : vector<8xf32>
    %1345 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1346 = memref.load %assume_align[%arg0, %1345, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1347 = vector.broadcast %1346 : f32 to vector<8xf32>
    %1348 = vector.fma %1347, %1317, %1316 : vector<8xf32>
    %1349 = vector.extract %36[41] : vector<8xf32> from vector<64x8xf32>
    %1350 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1351 = vector.broadcast %1350 : f32 to vector<8xf32>
    %1352 = vector.fma %1351, %1349, %1320 : vector<8xf32>
    %1353 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1354 = memref.load %assume_align[%arg0, %1353, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1355 = vector.broadcast %1354 : f32 to vector<8xf32>
    %1356 = vector.fma %1355, %1349, %1324 : vector<8xf32>
    %1357 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1358 = memref.load %assume_align[%arg0, %1357, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1359 = vector.broadcast %1358 : f32 to vector<8xf32>
    %1360 = vector.fma %1359, %1349, %1328 : vector<8xf32>
    %1361 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1362 = memref.load %assume_align[%arg0, %1361, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1363 = vector.broadcast %1362 : f32 to vector<8xf32>
    %1364 = vector.fma %1363, %1349, %1332 : vector<8xf32>
    %1365 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1366 = memref.load %assume_align[%arg0, %1365, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1367 = vector.broadcast %1366 : f32 to vector<8xf32>
    %1368 = vector.fma %1367, %1349, %1336 : vector<8xf32>
    %1369 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1370 = memref.load %assume_align[%arg0, %1369, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1371 = vector.broadcast %1370 : f32 to vector<8xf32>
    %1372 = vector.fma %1371, %1349, %1340 : vector<8xf32>
    %1373 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1374 = memref.load %assume_align[%arg0, %1373, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1375 = vector.broadcast %1374 : f32 to vector<8xf32>
    %1376 = vector.fma %1375, %1349, %1344 : vector<8xf32>
    %1377 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1378 = memref.load %assume_align[%arg0, %1377, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1379 = vector.broadcast %1378 : f32 to vector<8xf32>
    %1380 = vector.fma %1379, %1349, %1348 : vector<8xf32>
    %1381 = vector.extract %36[42] : vector<8xf32> from vector<64x8xf32>
    %1382 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1383 = vector.broadcast %1382 : f32 to vector<8xf32>
    %1384 = vector.fma %1383, %1381, %1352 : vector<8xf32>
    %1385 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1386 = memref.load %assume_align[%arg0, %1385, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1387 = vector.broadcast %1386 : f32 to vector<8xf32>
    %1388 = vector.fma %1387, %1381, %1356 : vector<8xf32>
    %1389 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1390 = memref.load %assume_align[%arg0, %1389, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1391 = vector.broadcast %1390 : f32 to vector<8xf32>
    %1392 = vector.fma %1391, %1381, %1360 : vector<8xf32>
    %1393 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1394 = memref.load %assume_align[%arg0, %1393, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1395 = vector.broadcast %1394 : f32 to vector<8xf32>
    %1396 = vector.fma %1395, %1381, %1364 : vector<8xf32>
    %1397 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1398 = memref.load %assume_align[%arg0, %1397, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1399 = vector.broadcast %1398 : f32 to vector<8xf32>
    %1400 = vector.fma %1399, %1381, %1368 : vector<8xf32>
    %1401 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1402 = memref.load %assume_align[%arg0, %1401, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1403 = vector.broadcast %1402 : f32 to vector<8xf32>
    %1404 = vector.fma %1403, %1381, %1372 : vector<8xf32>
    %1405 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1406 = memref.load %assume_align[%arg0, %1405, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1407 = vector.broadcast %1406 : f32 to vector<8xf32>
    %1408 = vector.fma %1407, %1381, %1376 : vector<8xf32>
    %1409 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1410 = memref.load %assume_align[%arg0, %1409, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1411 = vector.broadcast %1410 : f32 to vector<8xf32>
    %1412 = vector.fma %1411, %1381, %1380 : vector<8xf32>
    %1413 = vector.extract %36[43] : vector<8xf32> from vector<64x8xf32>
    %1414 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1415 = vector.broadcast %1414 : f32 to vector<8xf32>
    %1416 = vector.fma %1415, %1413, %1384 : vector<8xf32>
    %1417 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1418 = memref.load %assume_align[%arg0, %1417, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1419 = vector.broadcast %1418 : f32 to vector<8xf32>
    %1420 = vector.fma %1419, %1413, %1388 : vector<8xf32>
    %1421 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1422 = memref.load %assume_align[%arg0, %1421, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1423 = vector.broadcast %1422 : f32 to vector<8xf32>
    %1424 = vector.fma %1423, %1413, %1392 : vector<8xf32>
    %1425 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1426 = memref.load %assume_align[%arg0, %1425, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1427 = vector.broadcast %1426 : f32 to vector<8xf32>
    %1428 = vector.fma %1427, %1413, %1396 : vector<8xf32>
    %1429 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1430 = memref.load %assume_align[%arg0, %1429, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1431 = vector.broadcast %1430 : f32 to vector<8xf32>
    %1432 = vector.fma %1431, %1413, %1400 : vector<8xf32>
    %1433 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1434 = memref.load %assume_align[%arg0, %1433, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1435 = vector.broadcast %1434 : f32 to vector<8xf32>
    %1436 = vector.fma %1435, %1413, %1404 : vector<8xf32>
    %1437 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1438 = memref.load %assume_align[%arg0, %1437, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1439 = vector.broadcast %1438 : f32 to vector<8xf32>
    %1440 = vector.fma %1439, %1413, %1408 : vector<8xf32>
    %1441 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1442 = memref.load %assume_align[%arg0, %1441, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1443 = vector.broadcast %1442 : f32 to vector<8xf32>
    %1444 = vector.fma %1443, %1413, %1412 : vector<8xf32>
    %1445 = vector.extract %36[44] : vector<8xf32> from vector<64x8xf32>
    %1446 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1447 = vector.broadcast %1446 : f32 to vector<8xf32>
    %1448 = vector.fma %1447, %1445, %1416 : vector<8xf32>
    %1449 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1450 = memref.load %assume_align[%arg0, %1449, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1451 = vector.broadcast %1450 : f32 to vector<8xf32>
    %1452 = vector.fma %1451, %1445, %1420 : vector<8xf32>
    %1453 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1454 = memref.load %assume_align[%arg0, %1453, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1455 = vector.broadcast %1454 : f32 to vector<8xf32>
    %1456 = vector.fma %1455, %1445, %1424 : vector<8xf32>
    %1457 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1458 = memref.load %assume_align[%arg0, %1457, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1459 = vector.broadcast %1458 : f32 to vector<8xf32>
    %1460 = vector.fma %1459, %1445, %1428 : vector<8xf32>
    %1461 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1462 = memref.load %assume_align[%arg0, %1461, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1463 = vector.broadcast %1462 : f32 to vector<8xf32>
    %1464 = vector.fma %1463, %1445, %1432 : vector<8xf32>
    %1465 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1466 = memref.load %assume_align[%arg0, %1465, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1467 = vector.broadcast %1466 : f32 to vector<8xf32>
    %1468 = vector.fma %1467, %1445, %1436 : vector<8xf32>
    %1469 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1470 = memref.load %assume_align[%arg0, %1469, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1471 = vector.broadcast %1470 : f32 to vector<8xf32>
    %1472 = vector.fma %1471, %1445, %1440 : vector<8xf32>
    %1473 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1474 = memref.load %assume_align[%arg0, %1473, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1475 = vector.broadcast %1474 : f32 to vector<8xf32>
    %1476 = vector.fma %1475, %1445, %1444 : vector<8xf32>
    %1477 = vector.extract %36[45] : vector<8xf32> from vector<64x8xf32>
    %1478 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1479 = vector.broadcast %1478 : f32 to vector<8xf32>
    %1480 = vector.fma %1479, %1477, %1448 : vector<8xf32>
    %1481 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1482 = memref.load %assume_align[%arg0, %1481, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1483 = vector.broadcast %1482 : f32 to vector<8xf32>
    %1484 = vector.fma %1483, %1477, %1452 : vector<8xf32>
    %1485 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1486 = memref.load %assume_align[%arg0, %1485, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1487 = vector.broadcast %1486 : f32 to vector<8xf32>
    %1488 = vector.fma %1487, %1477, %1456 : vector<8xf32>
    %1489 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1490 = memref.load %assume_align[%arg0, %1489, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1491 = vector.broadcast %1490 : f32 to vector<8xf32>
    %1492 = vector.fma %1491, %1477, %1460 : vector<8xf32>
    %1493 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1494 = memref.load %assume_align[%arg0, %1493, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1495 = vector.broadcast %1494 : f32 to vector<8xf32>
    %1496 = vector.fma %1495, %1477, %1464 : vector<8xf32>
    %1497 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1498 = memref.load %assume_align[%arg0, %1497, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1499 = vector.broadcast %1498 : f32 to vector<8xf32>
    %1500 = vector.fma %1499, %1477, %1468 : vector<8xf32>
    %1501 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1502 = memref.load %assume_align[%arg0, %1501, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1503 = vector.broadcast %1502 : f32 to vector<8xf32>
    %1504 = vector.fma %1503, %1477, %1472 : vector<8xf32>
    %1505 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1506 = memref.load %assume_align[%arg0, %1505, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1507 = vector.broadcast %1506 : f32 to vector<8xf32>
    %1508 = vector.fma %1507, %1477, %1476 : vector<8xf32>
    %1509 = vector.extract %36[46] : vector<8xf32> from vector<64x8xf32>
    %1510 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1511 = vector.broadcast %1510 : f32 to vector<8xf32>
    %1512 = vector.fma %1511, %1509, %1480 : vector<8xf32>
    %1513 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1514 = memref.load %assume_align[%arg0, %1513, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1515 = vector.broadcast %1514 : f32 to vector<8xf32>
    %1516 = vector.fma %1515, %1509, %1484 : vector<8xf32>
    %1517 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1518 = memref.load %assume_align[%arg0, %1517, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1519 = vector.broadcast %1518 : f32 to vector<8xf32>
    %1520 = vector.fma %1519, %1509, %1488 : vector<8xf32>
    %1521 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1522 = memref.load %assume_align[%arg0, %1521, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1523 = vector.broadcast %1522 : f32 to vector<8xf32>
    %1524 = vector.fma %1523, %1509, %1492 : vector<8xf32>
    %1525 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1526 = memref.load %assume_align[%arg0, %1525, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1527 = vector.broadcast %1526 : f32 to vector<8xf32>
    %1528 = vector.fma %1527, %1509, %1496 : vector<8xf32>
    %1529 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1530 = memref.load %assume_align[%arg0, %1529, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1531 = vector.broadcast %1530 : f32 to vector<8xf32>
    %1532 = vector.fma %1531, %1509, %1500 : vector<8xf32>
    %1533 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1534 = memref.load %assume_align[%arg0, %1533, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1535 = vector.broadcast %1534 : f32 to vector<8xf32>
    %1536 = vector.fma %1535, %1509, %1504 : vector<8xf32>
    %1537 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1538 = memref.load %assume_align[%arg0, %1537, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1539 = vector.broadcast %1538 : f32 to vector<8xf32>
    %1540 = vector.fma %1539, %1509, %1508 : vector<8xf32>
    %1541 = vector.extract %36[47] : vector<8xf32> from vector<64x8xf32>
    %1542 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1543 = vector.broadcast %1542 : f32 to vector<8xf32>
    %1544 = vector.fma %1543, %1541, %1512 : vector<8xf32>
    %1545 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1546 = memref.load %assume_align[%arg0, %1545, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1547 = vector.broadcast %1546 : f32 to vector<8xf32>
    %1548 = vector.fma %1547, %1541, %1516 : vector<8xf32>
    %1549 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1550 = memref.load %assume_align[%arg0, %1549, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1551 = vector.broadcast %1550 : f32 to vector<8xf32>
    %1552 = vector.fma %1551, %1541, %1520 : vector<8xf32>
    %1553 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1554 = memref.load %assume_align[%arg0, %1553, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1555 = vector.broadcast %1554 : f32 to vector<8xf32>
    %1556 = vector.fma %1555, %1541, %1524 : vector<8xf32>
    %1557 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1558 = memref.load %assume_align[%arg0, %1557, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1559 = vector.broadcast %1558 : f32 to vector<8xf32>
    %1560 = vector.fma %1559, %1541, %1528 : vector<8xf32>
    %1561 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1562 = memref.load %assume_align[%arg0, %1561, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1563 = vector.broadcast %1562 : f32 to vector<8xf32>
    %1564 = vector.fma %1563, %1541, %1532 : vector<8xf32>
    %1565 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1566 = memref.load %assume_align[%arg0, %1565, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1567 = vector.broadcast %1566 : f32 to vector<8xf32>
    %1568 = vector.fma %1567, %1541, %1536 : vector<8xf32>
    %1569 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1570 = memref.load %assume_align[%arg0, %1569, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1571 = vector.broadcast %1570 : f32 to vector<8xf32>
    %1572 = vector.fma %1571, %1541, %1540 : vector<8xf32>
    %1573 = vector.extract %36[48] : vector<8xf32> from vector<64x8xf32>
    %1574 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1575 = vector.broadcast %1574 : f32 to vector<8xf32>
    %1576 = vector.fma %1575, %1573, %1544 : vector<8xf32>
    %1577 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1578 = memref.load %assume_align[%arg0, %1577, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1579 = vector.broadcast %1578 : f32 to vector<8xf32>
    %1580 = vector.fma %1579, %1573, %1548 : vector<8xf32>
    %1581 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1582 = memref.load %assume_align[%arg0, %1581, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1583 = vector.broadcast %1582 : f32 to vector<8xf32>
    %1584 = vector.fma %1583, %1573, %1552 : vector<8xf32>
    %1585 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1586 = memref.load %assume_align[%arg0, %1585, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1587 = vector.broadcast %1586 : f32 to vector<8xf32>
    %1588 = vector.fma %1587, %1573, %1556 : vector<8xf32>
    %1589 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1590 = memref.load %assume_align[%arg0, %1589, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1591 = vector.broadcast %1590 : f32 to vector<8xf32>
    %1592 = vector.fma %1591, %1573, %1560 : vector<8xf32>
    %1593 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1594 = memref.load %assume_align[%arg0, %1593, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1595 = vector.broadcast %1594 : f32 to vector<8xf32>
    %1596 = vector.fma %1595, %1573, %1564 : vector<8xf32>
    %1597 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1598 = memref.load %assume_align[%arg0, %1597, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1599 = vector.broadcast %1598 : f32 to vector<8xf32>
    %1600 = vector.fma %1599, %1573, %1568 : vector<8xf32>
    %1601 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1602 = memref.load %assume_align[%arg0, %1601, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1603 = vector.broadcast %1602 : f32 to vector<8xf32>
    %1604 = vector.fma %1603, %1573, %1572 : vector<8xf32>
    %1605 = vector.extract %36[49] : vector<8xf32> from vector<64x8xf32>
    %1606 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1607 = vector.broadcast %1606 : f32 to vector<8xf32>
    %1608 = vector.fma %1607, %1605, %1576 : vector<8xf32>
    %1609 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1610 = memref.load %assume_align[%arg0, %1609, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1611 = vector.broadcast %1610 : f32 to vector<8xf32>
    %1612 = vector.fma %1611, %1605, %1580 : vector<8xf32>
    %1613 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1614 = memref.load %assume_align[%arg0, %1613, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1615 = vector.broadcast %1614 : f32 to vector<8xf32>
    %1616 = vector.fma %1615, %1605, %1584 : vector<8xf32>
    %1617 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1618 = memref.load %assume_align[%arg0, %1617, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1619 = vector.broadcast %1618 : f32 to vector<8xf32>
    %1620 = vector.fma %1619, %1605, %1588 : vector<8xf32>
    %1621 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1622 = memref.load %assume_align[%arg0, %1621, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1623 = vector.broadcast %1622 : f32 to vector<8xf32>
    %1624 = vector.fma %1623, %1605, %1592 : vector<8xf32>
    %1625 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1626 = memref.load %assume_align[%arg0, %1625, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1627 = vector.broadcast %1626 : f32 to vector<8xf32>
    %1628 = vector.fma %1627, %1605, %1596 : vector<8xf32>
    %1629 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1630 = memref.load %assume_align[%arg0, %1629, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1631 = vector.broadcast %1630 : f32 to vector<8xf32>
    %1632 = vector.fma %1631, %1605, %1600 : vector<8xf32>
    %1633 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1634 = memref.load %assume_align[%arg0, %1633, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1635 = vector.broadcast %1634 : f32 to vector<8xf32>
    %1636 = vector.fma %1635, %1605, %1604 : vector<8xf32>
    %1637 = vector.extract %36[50] : vector<8xf32> from vector<64x8xf32>
    %1638 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1639 = vector.broadcast %1638 : f32 to vector<8xf32>
    %1640 = vector.fma %1639, %1637, %1608 : vector<8xf32>
    %1641 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1642 = memref.load %assume_align[%arg0, %1641, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1643 = vector.broadcast %1642 : f32 to vector<8xf32>
    %1644 = vector.fma %1643, %1637, %1612 : vector<8xf32>
    %1645 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1646 = memref.load %assume_align[%arg0, %1645, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1647 = vector.broadcast %1646 : f32 to vector<8xf32>
    %1648 = vector.fma %1647, %1637, %1616 : vector<8xf32>
    %1649 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1650 = memref.load %assume_align[%arg0, %1649, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1651 = vector.broadcast %1650 : f32 to vector<8xf32>
    %1652 = vector.fma %1651, %1637, %1620 : vector<8xf32>
    %1653 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1654 = memref.load %assume_align[%arg0, %1653, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1655 = vector.broadcast %1654 : f32 to vector<8xf32>
    %1656 = vector.fma %1655, %1637, %1624 : vector<8xf32>
    %1657 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1658 = memref.load %assume_align[%arg0, %1657, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1659 = vector.broadcast %1658 : f32 to vector<8xf32>
    %1660 = vector.fma %1659, %1637, %1628 : vector<8xf32>
    %1661 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1662 = memref.load %assume_align[%arg0, %1661, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1663 = vector.broadcast %1662 : f32 to vector<8xf32>
    %1664 = vector.fma %1663, %1637, %1632 : vector<8xf32>
    %1665 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1666 = memref.load %assume_align[%arg0, %1665, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1667 = vector.broadcast %1666 : f32 to vector<8xf32>
    %1668 = vector.fma %1667, %1637, %1636 : vector<8xf32>
    %1669 = vector.extract %36[51] : vector<8xf32> from vector<64x8xf32>
    %1670 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1671 = vector.broadcast %1670 : f32 to vector<8xf32>
    %1672 = vector.fma %1671, %1669, %1640 : vector<8xf32>
    %1673 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1674 = memref.load %assume_align[%arg0, %1673, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1675 = vector.broadcast %1674 : f32 to vector<8xf32>
    %1676 = vector.fma %1675, %1669, %1644 : vector<8xf32>
    %1677 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1678 = memref.load %assume_align[%arg0, %1677, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1679 = vector.broadcast %1678 : f32 to vector<8xf32>
    %1680 = vector.fma %1679, %1669, %1648 : vector<8xf32>
    %1681 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1682 = memref.load %assume_align[%arg0, %1681, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1683 = vector.broadcast %1682 : f32 to vector<8xf32>
    %1684 = vector.fma %1683, %1669, %1652 : vector<8xf32>
    %1685 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1686 = memref.load %assume_align[%arg0, %1685, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1687 = vector.broadcast %1686 : f32 to vector<8xf32>
    %1688 = vector.fma %1687, %1669, %1656 : vector<8xf32>
    %1689 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1690 = memref.load %assume_align[%arg0, %1689, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1691 = vector.broadcast %1690 : f32 to vector<8xf32>
    %1692 = vector.fma %1691, %1669, %1660 : vector<8xf32>
    %1693 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1694 = memref.load %assume_align[%arg0, %1693, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1695 = vector.broadcast %1694 : f32 to vector<8xf32>
    %1696 = vector.fma %1695, %1669, %1664 : vector<8xf32>
    %1697 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1698 = memref.load %assume_align[%arg0, %1697, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1699 = vector.broadcast %1698 : f32 to vector<8xf32>
    %1700 = vector.fma %1699, %1669, %1668 : vector<8xf32>
    %1701 = vector.extract %36[52] : vector<8xf32> from vector<64x8xf32>
    %1702 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1703 = vector.broadcast %1702 : f32 to vector<8xf32>
    %1704 = vector.fma %1703, %1701, %1672 : vector<8xf32>
    %1705 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1706 = memref.load %assume_align[%arg0, %1705, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1707 = vector.broadcast %1706 : f32 to vector<8xf32>
    %1708 = vector.fma %1707, %1701, %1676 : vector<8xf32>
    %1709 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1710 = memref.load %assume_align[%arg0, %1709, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1711 = vector.broadcast %1710 : f32 to vector<8xf32>
    %1712 = vector.fma %1711, %1701, %1680 : vector<8xf32>
    %1713 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1714 = memref.load %assume_align[%arg0, %1713, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1715 = vector.broadcast %1714 : f32 to vector<8xf32>
    %1716 = vector.fma %1715, %1701, %1684 : vector<8xf32>
    %1717 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1718 = memref.load %assume_align[%arg0, %1717, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1719 = vector.broadcast %1718 : f32 to vector<8xf32>
    %1720 = vector.fma %1719, %1701, %1688 : vector<8xf32>
    %1721 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1722 = memref.load %assume_align[%arg0, %1721, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1723 = vector.broadcast %1722 : f32 to vector<8xf32>
    %1724 = vector.fma %1723, %1701, %1692 : vector<8xf32>
    %1725 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1726 = memref.load %assume_align[%arg0, %1725, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1727 = vector.broadcast %1726 : f32 to vector<8xf32>
    %1728 = vector.fma %1727, %1701, %1696 : vector<8xf32>
    %1729 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1730 = memref.load %assume_align[%arg0, %1729, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1731 = vector.broadcast %1730 : f32 to vector<8xf32>
    %1732 = vector.fma %1731, %1701, %1700 : vector<8xf32>
    %1733 = vector.extract %36[53] : vector<8xf32> from vector<64x8xf32>
    %1734 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1735 = vector.broadcast %1734 : f32 to vector<8xf32>
    %1736 = vector.fma %1735, %1733, %1704 : vector<8xf32>
    %1737 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1738 = memref.load %assume_align[%arg0, %1737, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1739 = vector.broadcast %1738 : f32 to vector<8xf32>
    %1740 = vector.fma %1739, %1733, %1708 : vector<8xf32>
    %1741 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1742 = memref.load %assume_align[%arg0, %1741, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1743 = vector.broadcast %1742 : f32 to vector<8xf32>
    %1744 = vector.fma %1743, %1733, %1712 : vector<8xf32>
    %1745 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1746 = memref.load %assume_align[%arg0, %1745, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1747 = vector.broadcast %1746 : f32 to vector<8xf32>
    %1748 = vector.fma %1747, %1733, %1716 : vector<8xf32>
    %1749 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1750 = memref.load %assume_align[%arg0, %1749, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1751 = vector.broadcast %1750 : f32 to vector<8xf32>
    %1752 = vector.fma %1751, %1733, %1720 : vector<8xf32>
    %1753 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1754 = memref.load %assume_align[%arg0, %1753, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1755 = vector.broadcast %1754 : f32 to vector<8xf32>
    %1756 = vector.fma %1755, %1733, %1724 : vector<8xf32>
    %1757 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1758 = memref.load %assume_align[%arg0, %1757, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1759 = vector.broadcast %1758 : f32 to vector<8xf32>
    %1760 = vector.fma %1759, %1733, %1728 : vector<8xf32>
    %1761 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1762 = memref.load %assume_align[%arg0, %1761, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1763 = vector.broadcast %1762 : f32 to vector<8xf32>
    %1764 = vector.fma %1763, %1733, %1732 : vector<8xf32>
    %1765 = vector.extract %36[54] : vector<8xf32> from vector<64x8xf32>
    %1766 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1767 = vector.broadcast %1766 : f32 to vector<8xf32>
    %1768 = vector.fma %1767, %1765, %1736 : vector<8xf32>
    %1769 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1770 = memref.load %assume_align[%arg0, %1769, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1771 = vector.broadcast %1770 : f32 to vector<8xf32>
    %1772 = vector.fma %1771, %1765, %1740 : vector<8xf32>
    %1773 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1774 = memref.load %assume_align[%arg0, %1773, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1775 = vector.broadcast %1774 : f32 to vector<8xf32>
    %1776 = vector.fma %1775, %1765, %1744 : vector<8xf32>
    %1777 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1778 = memref.load %assume_align[%arg0, %1777, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1779 = vector.broadcast %1778 : f32 to vector<8xf32>
    %1780 = vector.fma %1779, %1765, %1748 : vector<8xf32>
    %1781 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1782 = memref.load %assume_align[%arg0, %1781, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1783 = vector.broadcast %1782 : f32 to vector<8xf32>
    %1784 = vector.fma %1783, %1765, %1752 : vector<8xf32>
    %1785 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1786 = memref.load %assume_align[%arg0, %1785, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1787 = vector.broadcast %1786 : f32 to vector<8xf32>
    %1788 = vector.fma %1787, %1765, %1756 : vector<8xf32>
    %1789 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1790 = memref.load %assume_align[%arg0, %1789, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1791 = vector.broadcast %1790 : f32 to vector<8xf32>
    %1792 = vector.fma %1791, %1765, %1760 : vector<8xf32>
    %1793 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1794 = memref.load %assume_align[%arg0, %1793, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1795 = vector.broadcast %1794 : f32 to vector<8xf32>
    %1796 = vector.fma %1795, %1765, %1764 : vector<8xf32>
    %1797 = vector.extract %36[55] : vector<8xf32> from vector<64x8xf32>
    %1798 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1799 = vector.broadcast %1798 : f32 to vector<8xf32>
    %1800 = vector.fma %1799, %1797, %1768 : vector<8xf32>
    %1801 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1802 = memref.load %assume_align[%arg0, %1801, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1803 = vector.broadcast %1802 : f32 to vector<8xf32>
    %1804 = vector.fma %1803, %1797, %1772 : vector<8xf32>
    %1805 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1806 = memref.load %assume_align[%arg0, %1805, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1807 = vector.broadcast %1806 : f32 to vector<8xf32>
    %1808 = vector.fma %1807, %1797, %1776 : vector<8xf32>
    %1809 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1810 = memref.load %assume_align[%arg0, %1809, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1811 = vector.broadcast %1810 : f32 to vector<8xf32>
    %1812 = vector.fma %1811, %1797, %1780 : vector<8xf32>
    %1813 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1814 = memref.load %assume_align[%arg0, %1813, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1815 = vector.broadcast %1814 : f32 to vector<8xf32>
    %1816 = vector.fma %1815, %1797, %1784 : vector<8xf32>
    %1817 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1818 = memref.load %assume_align[%arg0, %1817, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1819 = vector.broadcast %1818 : f32 to vector<8xf32>
    %1820 = vector.fma %1819, %1797, %1788 : vector<8xf32>
    %1821 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1822 = memref.load %assume_align[%arg0, %1821, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1823 = vector.broadcast %1822 : f32 to vector<8xf32>
    %1824 = vector.fma %1823, %1797, %1792 : vector<8xf32>
    %1825 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1826 = memref.load %assume_align[%arg0, %1825, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1827 = vector.broadcast %1826 : f32 to vector<8xf32>
    %1828 = vector.fma %1827, %1797, %1796 : vector<8xf32>
    %1829 = vector.extract %36[56] : vector<8xf32> from vector<64x8xf32>
    %1830 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1831 = vector.broadcast %1830 : f32 to vector<8xf32>
    %1832 = vector.fma %1831, %1829, %1800 : vector<8xf32>
    %1833 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1834 = memref.load %assume_align[%arg0, %1833, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1835 = vector.broadcast %1834 : f32 to vector<8xf32>
    %1836 = vector.fma %1835, %1829, %1804 : vector<8xf32>
    %1837 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1838 = memref.load %assume_align[%arg0, %1837, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1839 = vector.broadcast %1838 : f32 to vector<8xf32>
    %1840 = vector.fma %1839, %1829, %1808 : vector<8xf32>
    %1841 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1842 = memref.load %assume_align[%arg0, %1841, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1843 = vector.broadcast %1842 : f32 to vector<8xf32>
    %1844 = vector.fma %1843, %1829, %1812 : vector<8xf32>
    %1845 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1846 = memref.load %assume_align[%arg0, %1845, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1847 = vector.broadcast %1846 : f32 to vector<8xf32>
    %1848 = vector.fma %1847, %1829, %1816 : vector<8xf32>
    %1849 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1850 = memref.load %assume_align[%arg0, %1849, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1851 = vector.broadcast %1850 : f32 to vector<8xf32>
    %1852 = vector.fma %1851, %1829, %1820 : vector<8xf32>
    %1853 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1854 = memref.load %assume_align[%arg0, %1853, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1855 = vector.broadcast %1854 : f32 to vector<8xf32>
    %1856 = vector.fma %1855, %1829, %1824 : vector<8xf32>
    %1857 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1858 = memref.load %assume_align[%arg0, %1857, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1859 = vector.broadcast %1858 : f32 to vector<8xf32>
    %1860 = vector.fma %1859, %1829, %1828 : vector<8xf32>
    %1861 = vector.extract %36[57] : vector<8xf32> from vector<64x8xf32>
    %1862 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1863 = vector.broadcast %1862 : f32 to vector<8xf32>
    %1864 = vector.fma %1863, %1861, %1832 : vector<8xf32>
    %1865 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1866 = memref.load %assume_align[%arg0, %1865, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1867 = vector.broadcast %1866 : f32 to vector<8xf32>
    %1868 = vector.fma %1867, %1861, %1836 : vector<8xf32>
    %1869 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1870 = memref.load %assume_align[%arg0, %1869, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1871 = vector.broadcast %1870 : f32 to vector<8xf32>
    %1872 = vector.fma %1871, %1861, %1840 : vector<8xf32>
    %1873 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1874 = memref.load %assume_align[%arg0, %1873, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1875 = vector.broadcast %1874 : f32 to vector<8xf32>
    %1876 = vector.fma %1875, %1861, %1844 : vector<8xf32>
    %1877 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1878 = memref.load %assume_align[%arg0, %1877, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1879 = vector.broadcast %1878 : f32 to vector<8xf32>
    %1880 = vector.fma %1879, %1861, %1848 : vector<8xf32>
    %1881 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1882 = memref.load %assume_align[%arg0, %1881, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1883 = vector.broadcast %1882 : f32 to vector<8xf32>
    %1884 = vector.fma %1883, %1861, %1852 : vector<8xf32>
    %1885 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1886 = memref.load %assume_align[%arg0, %1885, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1887 = vector.broadcast %1886 : f32 to vector<8xf32>
    %1888 = vector.fma %1887, %1861, %1856 : vector<8xf32>
    %1889 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1890 = memref.load %assume_align[%arg0, %1889, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1891 = vector.broadcast %1890 : f32 to vector<8xf32>
    %1892 = vector.fma %1891, %1861, %1860 : vector<8xf32>
    %1893 = vector.extract %36[58] : vector<8xf32> from vector<64x8xf32>
    %1894 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1895 = vector.broadcast %1894 : f32 to vector<8xf32>
    %1896 = vector.fma %1895, %1893, %1864 : vector<8xf32>
    %1897 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1898 = memref.load %assume_align[%arg0, %1897, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1899 = vector.broadcast %1898 : f32 to vector<8xf32>
    %1900 = vector.fma %1899, %1893, %1868 : vector<8xf32>
    %1901 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1902 = memref.load %assume_align[%arg0, %1901, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1903 = vector.broadcast %1902 : f32 to vector<8xf32>
    %1904 = vector.fma %1903, %1893, %1872 : vector<8xf32>
    %1905 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1906 = memref.load %assume_align[%arg0, %1905, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1907 = vector.broadcast %1906 : f32 to vector<8xf32>
    %1908 = vector.fma %1907, %1893, %1876 : vector<8xf32>
    %1909 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1910 = memref.load %assume_align[%arg0, %1909, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1911 = vector.broadcast %1910 : f32 to vector<8xf32>
    %1912 = vector.fma %1911, %1893, %1880 : vector<8xf32>
    %1913 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1914 = memref.load %assume_align[%arg0, %1913, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1915 = vector.broadcast %1914 : f32 to vector<8xf32>
    %1916 = vector.fma %1915, %1893, %1884 : vector<8xf32>
    %1917 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1918 = memref.load %assume_align[%arg0, %1917, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1919 = vector.broadcast %1918 : f32 to vector<8xf32>
    %1920 = vector.fma %1919, %1893, %1888 : vector<8xf32>
    %1921 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1922 = memref.load %assume_align[%arg0, %1921, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1923 = vector.broadcast %1922 : f32 to vector<8xf32>
    %1924 = vector.fma %1923, %1893, %1892 : vector<8xf32>
    %1925 = vector.extract %36[59] : vector<8xf32> from vector<64x8xf32>
    %1926 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1927 = vector.broadcast %1926 : f32 to vector<8xf32>
    %1928 = vector.fma %1927, %1925, %1896 : vector<8xf32>
    %1929 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1930 = memref.load %assume_align[%arg0, %1929, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1931 = vector.broadcast %1930 : f32 to vector<8xf32>
    %1932 = vector.fma %1931, %1925, %1900 : vector<8xf32>
    %1933 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1934 = memref.load %assume_align[%arg0, %1933, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1935 = vector.broadcast %1934 : f32 to vector<8xf32>
    %1936 = vector.fma %1935, %1925, %1904 : vector<8xf32>
    %1937 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1938 = memref.load %assume_align[%arg0, %1937, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1939 = vector.broadcast %1938 : f32 to vector<8xf32>
    %1940 = vector.fma %1939, %1925, %1908 : vector<8xf32>
    %1941 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1942 = memref.load %assume_align[%arg0, %1941, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1943 = vector.broadcast %1942 : f32 to vector<8xf32>
    %1944 = vector.fma %1943, %1925, %1912 : vector<8xf32>
    %1945 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1946 = memref.load %assume_align[%arg0, %1945, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1947 = vector.broadcast %1946 : f32 to vector<8xf32>
    %1948 = vector.fma %1947, %1925, %1916 : vector<8xf32>
    %1949 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1950 = memref.load %assume_align[%arg0, %1949, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1951 = vector.broadcast %1950 : f32 to vector<8xf32>
    %1952 = vector.fma %1951, %1925, %1920 : vector<8xf32>
    %1953 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1954 = memref.load %assume_align[%arg0, %1953, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1955 = vector.broadcast %1954 : f32 to vector<8xf32>
    %1956 = vector.fma %1955, %1925, %1924 : vector<8xf32>
    %1957 = vector.extract %36[60] : vector<8xf32> from vector<64x8xf32>
    %1958 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1959 = vector.broadcast %1958 : f32 to vector<8xf32>
    %1960 = vector.fma %1959, %1957, %1928 : vector<8xf32>
    %1961 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1962 = memref.load %assume_align[%arg0, %1961, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1963 = vector.broadcast %1962 : f32 to vector<8xf32>
    %1964 = vector.fma %1963, %1957, %1932 : vector<8xf32>
    %1965 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1966 = memref.load %assume_align[%arg0, %1965, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1967 = vector.broadcast %1966 : f32 to vector<8xf32>
    %1968 = vector.fma %1967, %1957, %1936 : vector<8xf32>
    %1969 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1970 = memref.load %assume_align[%arg0, %1969, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1971 = vector.broadcast %1970 : f32 to vector<8xf32>
    %1972 = vector.fma %1971, %1957, %1940 : vector<8xf32>
    %1973 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1974 = memref.load %assume_align[%arg0, %1973, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1975 = vector.broadcast %1974 : f32 to vector<8xf32>
    %1976 = vector.fma %1975, %1957, %1944 : vector<8xf32>
    %1977 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1978 = memref.load %assume_align[%arg0, %1977, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1979 = vector.broadcast %1978 : f32 to vector<8xf32>
    %1980 = vector.fma %1979, %1957, %1948 : vector<8xf32>
    %1981 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1982 = memref.load %assume_align[%arg0, %1981, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1983 = vector.broadcast %1982 : f32 to vector<8xf32>
    %1984 = vector.fma %1983, %1957, %1952 : vector<8xf32>
    %1985 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1986 = memref.load %assume_align[%arg0, %1985, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1987 = vector.broadcast %1986 : f32 to vector<8xf32>
    %1988 = vector.fma %1987, %1957, %1956 : vector<8xf32>
    %1989 = vector.extract %36[61] : vector<8xf32> from vector<64x8xf32>
    %1990 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1991 = vector.broadcast %1990 : f32 to vector<8xf32>
    %1992 = vector.fma %1991, %1989, %1960 : vector<8xf32>
    %1993 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1994 = memref.load %assume_align[%arg0, %1993, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1995 = vector.broadcast %1994 : f32 to vector<8xf32>
    %1996 = vector.fma %1995, %1989, %1964 : vector<8xf32>
    %1997 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1998 = memref.load %assume_align[%arg0, %1997, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1999 = vector.broadcast %1998 : f32 to vector<8xf32>
    %2000 = vector.fma %1999, %1989, %1968 : vector<8xf32>
    %2001 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2002 = memref.load %assume_align[%arg0, %2001, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2003 = vector.broadcast %2002 : f32 to vector<8xf32>
    %2004 = vector.fma %2003, %1989, %1972 : vector<8xf32>
    %2005 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2006 = memref.load %assume_align[%arg0, %2005, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2007 = vector.broadcast %2006 : f32 to vector<8xf32>
    %2008 = vector.fma %2007, %1989, %1976 : vector<8xf32>
    %2009 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2010 = memref.load %assume_align[%arg0, %2009, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2011 = vector.broadcast %2010 : f32 to vector<8xf32>
    %2012 = vector.fma %2011, %1989, %1980 : vector<8xf32>
    %2013 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2014 = memref.load %assume_align[%arg0, %2013, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2015 = vector.broadcast %2014 : f32 to vector<8xf32>
    %2016 = vector.fma %2015, %1989, %1984 : vector<8xf32>
    %2017 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2018 = memref.load %assume_align[%arg0, %2017, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2019 = vector.broadcast %2018 : f32 to vector<8xf32>
    %2020 = vector.fma %2019, %1989, %1988 : vector<8xf32>
    %2021 = vector.extract %36[62] : vector<8xf32> from vector<64x8xf32>
    %2022 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2023 = vector.broadcast %2022 : f32 to vector<8xf32>
    %2024 = vector.fma %2023, %2021, %1992 : vector<8xf32>
    %2025 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2026 = memref.load %assume_align[%arg0, %2025, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2027 = vector.broadcast %2026 : f32 to vector<8xf32>
    %2028 = vector.fma %2027, %2021, %1996 : vector<8xf32>
    %2029 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2030 = memref.load %assume_align[%arg0, %2029, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2031 = vector.broadcast %2030 : f32 to vector<8xf32>
    %2032 = vector.fma %2031, %2021, %2000 : vector<8xf32>
    %2033 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2034 = memref.load %assume_align[%arg0, %2033, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2035 = vector.broadcast %2034 : f32 to vector<8xf32>
    %2036 = vector.fma %2035, %2021, %2004 : vector<8xf32>
    %2037 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2038 = memref.load %assume_align[%arg0, %2037, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
    %2040 = vector.fma %2039, %2021, %2008 : vector<8xf32>
    %2041 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2042 = memref.load %assume_align[%arg0, %2041, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2043 = vector.broadcast %2042 : f32 to vector<8xf32>
    %2044 = vector.fma %2043, %2021, %2012 : vector<8xf32>
    %2045 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2046 = memref.load %assume_align[%arg0, %2045, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2047 = vector.broadcast %2046 : f32 to vector<8xf32>
    %2048 = vector.fma %2047, %2021, %2016 : vector<8xf32>
    %2049 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2050 = memref.load %assume_align[%arg0, %2049, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2051 = vector.broadcast %2050 : f32 to vector<8xf32>
    %2052 = vector.fma %2051, %2021, %2020 : vector<8xf32>
    %2053 = vector.extract %36[63] : vector<8xf32> from vector<64x8xf32>
    %2054 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2055 = vector.broadcast %2054 : f32 to vector<8xf32>
    %2056 = vector.fma %2055, %2053, %2024 : vector<8xf32>
    %2057 = vector.insert %2056, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2058 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2059 = memref.load %assume_align[%arg0, %2058, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2060 = vector.broadcast %2059 : f32 to vector<8xf32>
    %2061 = vector.fma %2060, %2053, %2028 : vector<8xf32>
    %2062 = vector.insert %2061, %2057 [1] : vector<8xf32> into vector<8x8xf32>
    %2063 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2064 = memref.load %assume_align[%arg0, %2063, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2065 = vector.broadcast %2064 : f32 to vector<8xf32>
    %2066 = vector.fma %2065, %2053, %2032 : vector<8xf32>
    %2067 = vector.insert %2066, %2062 [2] : vector<8xf32> into vector<8x8xf32>
    %2068 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2069 = memref.load %assume_align[%arg0, %2068, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2070 = vector.broadcast %2069 : f32 to vector<8xf32>
    %2071 = vector.fma %2070, %2053, %2036 : vector<8xf32>
    %2072 = vector.insert %2071, %2067 [3] : vector<8xf32> into vector<8x8xf32>
    %2073 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2074 = memref.load %assume_align[%arg0, %2073, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2075 = vector.broadcast %2074 : f32 to vector<8xf32>
    %2076 = vector.fma %2075, %2053, %2040 : vector<8xf32>
    %2077 = vector.insert %2076, %2072 [4] : vector<8xf32> into vector<8x8xf32>
    %2078 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2079 = memref.load %assume_align[%arg0, %2078, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2080 = vector.broadcast %2079 : f32 to vector<8xf32>
    %2081 = vector.fma %2080, %2053, %2044 : vector<8xf32>
    %2082 = vector.insert %2081, %2077 [5] : vector<8xf32> into vector<8x8xf32>
    %2083 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2084 = memref.load %assume_align[%arg0, %2083, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2085 = vector.broadcast %2084 : f32 to vector<8xf32>
    %2086 = vector.fma %2085, %2053, %2048 : vector<8xf32>
    %2087 = vector.insert %2086, %2082 [6] : vector<8xf32> into vector<8x8xf32>
    %2088 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2089 = memref.load %assume_align[%arg0, %2088, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2090 = vector.broadcast %2089 : f32 to vector<8xf32>
    %2091 = vector.fma %2090, %2053, %2052 : vector<8xf32>
    %2092 = vector.insert %2091, %2087 [7] : vector<8xf32> into vector<8x8xf32>
    %2093 = vector.reduction <maximumf>, %2056, %cst : vector<8xf32> into f32
    %2094 = vector.insert %2093, %cst_0 [0] : f32 into vector<8xf32>
    %2095 = vector.reduction <maximumf>, %2061, %cst : vector<8xf32> into f32
    %2096 = vector.insert %2095, %2094 [1] : f32 into vector<8xf32>
    %2097 = vector.reduction <maximumf>, %2066, %cst : vector<8xf32> into f32
    %2098 = vector.insert %2097, %2096 [2] : f32 into vector<8xf32>
    %2099 = vector.reduction <maximumf>, %2071, %cst : vector<8xf32> into f32
    %2100 = vector.insert %2099, %2098 [3] : f32 into vector<8xf32>
    %2101 = vector.reduction <maximumf>, %2076, %cst : vector<8xf32> into f32
    %2102 = vector.insert %2101, %2100 [4] : f32 into vector<8xf32>
    %2103 = vector.reduction <maximumf>, %2081, %cst : vector<8xf32> into f32
    %2104 = vector.insert %2103, %2102 [5] : f32 into vector<8xf32>
    %2105 = vector.reduction <maximumf>, %2086, %cst : vector<8xf32> into f32
    %2106 = vector.insert %2105, %2104 [6] : f32 into vector<8xf32>
    %2107 = vector.reduction <maximumf>, %2091, %cst : vector<8xf32> into f32
    %2108 = vector.insert %2107, %2106 [7] : f32 into vector<8xf32>
    %2109 = vector.shape_cast %2108 : vector<8xf32> to vector<1x8xf32>
    %2110 = arith.subf %2108, %cst_2 : vector<8xf32>
    %2111 = math.exp2 %2110 : vector<8xf32>
    %2112 = vector.shape_cast %2111 : vector<8xf32> to vector<1x8xf32>
    %2113 = vector.broadcast %2112 : vector<1x8xf32> to vector<8x8xf32>
    %2114 = arith.mulf %2113, %cst_1 : vector<8x8xf32>
    %2115 = vector.transpose %2114, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2116 = vector.broadcast %2109 : vector<1x8xf32> to vector<8x8xf32>
    %2117 = vector.transpose %2116, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2118 = arith.subf %2092, %2117 : vector<8x8xf32>
    %2119 = math.exp2 %2118 : vector<8x8xf32>
    %2120 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2121 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %2122 = vector.load %assume_align_4[%arg0, %2121, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2123 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %2124 = vector.load %assume_align_4[%arg0, %2123, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2125 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %2126 = vector.load %assume_align_4[%arg0, %2125, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2127 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %2128 = vector.load %assume_align_4[%arg0, %2127, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2129 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %2130 = vector.load %assume_align_4[%arg0, %2129, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2131 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %2132 = vector.load %assume_align_4[%arg0, %2131, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2133 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %2134 = vector.load %assume_align_4[%arg0, %2133, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2135 = vector.extract %2119[0, 0] : f32 from vector<8x8xf32>
    %2136 = vector.broadcast %2135 : f32 to vector<8xf32>
    %2137 = vector.extract %2115[0] : vector<8xf32> from vector<8x8xf32>
    %2138 = vector.fma %2136, %2120, %2137 : vector<8xf32>
    %2139 = vector.extract %2119[1, 0] : f32 from vector<8x8xf32>
    %2140 = vector.broadcast %2139 : f32 to vector<8xf32>
    %2141 = vector.extract %2115[1] : vector<8xf32> from vector<8x8xf32>
    %2142 = vector.fma %2140, %2120, %2141 : vector<8xf32>
    %2143 = vector.extract %2119[2, 0] : f32 from vector<8x8xf32>
    %2144 = vector.broadcast %2143 : f32 to vector<8xf32>
    %2145 = vector.extract %2115[2] : vector<8xf32> from vector<8x8xf32>
    %2146 = vector.fma %2144, %2120, %2145 : vector<8xf32>
    %2147 = vector.extract %2119[3, 0] : f32 from vector<8x8xf32>
    %2148 = vector.broadcast %2147 : f32 to vector<8xf32>
    %2149 = vector.extract %2115[3] : vector<8xf32> from vector<8x8xf32>
    %2150 = vector.fma %2148, %2120, %2149 : vector<8xf32>
    %2151 = vector.extract %2119[4, 0] : f32 from vector<8x8xf32>
    %2152 = vector.broadcast %2151 : f32 to vector<8xf32>
    %2153 = vector.extract %2115[4] : vector<8xf32> from vector<8x8xf32>
    %2154 = vector.fma %2152, %2120, %2153 : vector<8xf32>
    %2155 = vector.extract %2119[5, 0] : f32 from vector<8x8xf32>
    %2156 = vector.broadcast %2155 : f32 to vector<8xf32>
    %2157 = vector.extract %2115[5] : vector<8xf32> from vector<8x8xf32>
    %2158 = vector.fma %2156, %2120, %2157 : vector<8xf32>
    %2159 = vector.extract %2119[6, 0] : f32 from vector<8x8xf32>
    %2160 = vector.broadcast %2159 : f32 to vector<8xf32>
    %2161 = vector.extract %2115[6] : vector<8xf32> from vector<8x8xf32>
    %2162 = vector.fma %2160, %2120, %2161 : vector<8xf32>
    %2163 = vector.extract %2119[7, 0] : f32 from vector<8x8xf32>
    %2164 = vector.broadcast %2163 : f32 to vector<8xf32>
    %2165 = vector.extract %2115[7] : vector<8xf32> from vector<8x8xf32>
    %2166 = vector.fma %2164, %2120, %2165 : vector<8xf32>
    %2167 = vector.extract %2119[0, 1] : f32 from vector<8x8xf32>
    %2168 = vector.broadcast %2167 : f32 to vector<8xf32>
    %2169 = vector.fma %2168, %2122, %2138 : vector<8xf32>
    %2170 = vector.extract %2119[1, 1] : f32 from vector<8x8xf32>
    %2171 = vector.broadcast %2170 : f32 to vector<8xf32>
    %2172 = vector.fma %2171, %2122, %2142 : vector<8xf32>
    %2173 = vector.extract %2119[2, 1] : f32 from vector<8x8xf32>
    %2174 = vector.broadcast %2173 : f32 to vector<8xf32>
    %2175 = vector.fma %2174, %2122, %2146 : vector<8xf32>
    %2176 = vector.extract %2119[3, 1] : f32 from vector<8x8xf32>
    %2177 = vector.broadcast %2176 : f32 to vector<8xf32>
    %2178 = vector.fma %2177, %2122, %2150 : vector<8xf32>
    %2179 = vector.extract %2119[4, 1] : f32 from vector<8x8xf32>
    %2180 = vector.broadcast %2179 : f32 to vector<8xf32>
    %2181 = vector.fma %2180, %2122, %2154 : vector<8xf32>
    %2182 = vector.extract %2119[5, 1] : f32 from vector<8x8xf32>
    %2183 = vector.broadcast %2182 : f32 to vector<8xf32>
    %2184 = vector.fma %2183, %2122, %2158 : vector<8xf32>
    %2185 = vector.extract %2119[6, 1] : f32 from vector<8x8xf32>
    %2186 = vector.broadcast %2185 : f32 to vector<8xf32>
    %2187 = vector.fma %2186, %2122, %2162 : vector<8xf32>
    %2188 = vector.extract %2119[7, 1] : f32 from vector<8x8xf32>
    %2189 = vector.broadcast %2188 : f32 to vector<8xf32>
    %2190 = vector.fma %2189, %2122, %2166 : vector<8xf32>
    %2191 = vector.extract %2119[0, 2] : f32 from vector<8x8xf32>
    %2192 = vector.broadcast %2191 : f32 to vector<8xf32>
    %2193 = vector.fma %2192, %2124, %2169 : vector<8xf32>
    %2194 = vector.extract %2119[1, 2] : f32 from vector<8x8xf32>
    %2195 = vector.broadcast %2194 : f32 to vector<8xf32>
    %2196 = vector.fma %2195, %2124, %2172 : vector<8xf32>
    %2197 = vector.extract %2119[2, 2] : f32 from vector<8x8xf32>
    %2198 = vector.broadcast %2197 : f32 to vector<8xf32>
    %2199 = vector.fma %2198, %2124, %2175 : vector<8xf32>
    %2200 = vector.extract %2119[3, 2] : f32 from vector<8x8xf32>
    %2201 = vector.broadcast %2200 : f32 to vector<8xf32>
    %2202 = vector.fma %2201, %2124, %2178 : vector<8xf32>
    %2203 = vector.extract %2119[4, 2] : f32 from vector<8x8xf32>
    %2204 = vector.broadcast %2203 : f32 to vector<8xf32>
    %2205 = vector.fma %2204, %2124, %2181 : vector<8xf32>
    %2206 = vector.extract %2119[5, 2] : f32 from vector<8x8xf32>
    %2207 = vector.broadcast %2206 : f32 to vector<8xf32>
    %2208 = vector.fma %2207, %2124, %2184 : vector<8xf32>
    %2209 = vector.extract %2119[6, 2] : f32 from vector<8x8xf32>
    %2210 = vector.broadcast %2209 : f32 to vector<8xf32>
    %2211 = vector.fma %2210, %2124, %2187 : vector<8xf32>
    %2212 = vector.extract %2119[7, 2] : f32 from vector<8x8xf32>
    %2213 = vector.broadcast %2212 : f32 to vector<8xf32>
    %2214 = vector.fma %2213, %2124, %2190 : vector<8xf32>
    %2215 = vector.extract %2119[0, 3] : f32 from vector<8x8xf32>
    %2216 = vector.broadcast %2215 : f32 to vector<8xf32>
    %2217 = vector.fma %2216, %2126, %2193 : vector<8xf32>
    %2218 = vector.extract %2119[1, 3] : f32 from vector<8x8xf32>
    %2219 = vector.broadcast %2218 : f32 to vector<8xf32>
    %2220 = vector.fma %2219, %2126, %2196 : vector<8xf32>
    %2221 = vector.extract %2119[2, 3] : f32 from vector<8x8xf32>
    %2222 = vector.broadcast %2221 : f32 to vector<8xf32>
    %2223 = vector.fma %2222, %2126, %2199 : vector<8xf32>
    %2224 = vector.extract %2119[3, 3] : f32 from vector<8x8xf32>
    %2225 = vector.broadcast %2224 : f32 to vector<8xf32>
    %2226 = vector.fma %2225, %2126, %2202 : vector<8xf32>
    %2227 = vector.extract %2119[4, 3] : f32 from vector<8x8xf32>
    %2228 = vector.broadcast %2227 : f32 to vector<8xf32>
    %2229 = vector.fma %2228, %2126, %2205 : vector<8xf32>
    %2230 = vector.extract %2119[5, 3] : f32 from vector<8x8xf32>
    %2231 = vector.broadcast %2230 : f32 to vector<8xf32>
    %2232 = vector.fma %2231, %2126, %2208 : vector<8xf32>
    %2233 = vector.extract %2119[6, 3] : f32 from vector<8x8xf32>
    %2234 = vector.broadcast %2233 : f32 to vector<8xf32>
    %2235 = vector.fma %2234, %2126, %2211 : vector<8xf32>
    %2236 = vector.extract %2119[7, 3] : f32 from vector<8x8xf32>
    %2237 = vector.broadcast %2236 : f32 to vector<8xf32>
    %2238 = vector.fma %2237, %2126, %2214 : vector<8xf32>
    %2239 = vector.extract %2119[0, 4] : f32 from vector<8x8xf32>
    %2240 = vector.broadcast %2239 : f32 to vector<8xf32>
    %2241 = vector.fma %2240, %2128, %2217 : vector<8xf32>
    %2242 = vector.extract %2119[1, 4] : f32 from vector<8x8xf32>
    %2243 = vector.broadcast %2242 : f32 to vector<8xf32>
    %2244 = vector.fma %2243, %2128, %2220 : vector<8xf32>
    %2245 = vector.extract %2119[2, 4] : f32 from vector<8x8xf32>
    %2246 = vector.broadcast %2245 : f32 to vector<8xf32>
    %2247 = vector.fma %2246, %2128, %2223 : vector<8xf32>
    %2248 = vector.extract %2119[3, 4] : f32 from vector<8x8xf32>
    %2249 = vector.broadcast %2248 : f32 to vector<8xf32>
    %2250 = vector.fma %2249, %2128, %2226 : vector<8xf32>
    %2251 = vector.extract %2119[4, 4] : f32 from vector<8x8xf32>
    %2252 = vector.broadcast %2251 : f32 to vector<8xf32>
    %2253 = vector.fma %2252, %2128, %2229 : vector<8xf32>
    %2254 = vector.extract %2119[5, 4] : f32 from vector<8x8xf32>
    %2255 = vector.broadcast %2254 : f32 to vector<8xf32>
    %2256 = vector.fma %2255, %2128, %2232 : vector<8xf32>
    %2257 = vector.extract %2119[6, 4] : f32 from vector<8x8xf32>
    %2258 = vector.broadcast %2257 : f32 to vector<8xf32>
    %2259 = vector.fma %2258, %2128, %2235 : vector<8xf32>
    %2260 = vector.extract %2119[7, 4] : f32 from vector<8x8xf32>
    %2261 = vector.broadcast %2260 : f32 to vector<8xf32>
    %2262 = vector.fma %2261, %2128, %2238 : vector<8xf32>
    %2263 = vector.extract %2119[0, 5] : f32 from vector<8x8xf32>
    %2264 = vector.broadcast %2263 : f32 to vector<8xf32>
    %2265 = vector.fma %2264, %2130, %2241 : vector<8xf32>
    %2266 = vector.extract %2119[1, 5] : f32 from vector<8x8xf32>
    %2267 = vector.broadcast %2266 : f32 to vector<8xf32>
    %2268 = vector.fma %2267, %2130, %2244 : vector<8xf32>
    %2269 = vector.extract %2119[2, 5] : f32 from vector<8x8xf32>
    %2270 = vector.broadcast %2269 : f32 to vector<8xf32>
    %2271 = vector.fma %2270, %2130, %2247 : vector<8xf32>
    %2272 = vector.extract %2119[3, 5] : f32 from vector<8x8xf32>
    %2273 = vector.broadcast %2272 : f32 to vector<8xf32>
    %2274 = vector.fma %2273, %2130, %2250 : vector<8xf32>
    %2275 = vector.extract %2119[4, 5] : f32 from vector<8x8xf32>
    %2276 = vector.broadcast %2275 : f32 to vector<8xf32>
    %2277 = vector.fma %2276, %2130, %2253 : vector<8xf32>
    %2278 = vector.extract %2119[5, 5] : f32 from vector<8x8xf32>
    %2279 = vector.broadcast %2278 : f32 to vector<8xf32>
    %2280 = vector.fma %2279, %2130, %2256 : vector<8xf32>
    %2281 = vector.extract %2119[6, 5] : f32 from vector<8x8xf32>
    %2282 = vector.broadcast %2281 : f32 to vector<8xf32>
    %2283 = vector.fma %2282, %2130, %2259 : vector<8xf32>
    %2284 = vector.extract %2119[7, 5] : f32 from vector<8x8xf32>
    %2285 = vector.broadcast %2284 : f32 to vector<8xf32>
    %2286 = vector.fma %2285, %2130, %2262 : vector<8xf32>
    %2287 = vector.extract %2119[0, 6] : f32 from vector<8x8xf32>
    %2288 = vector.broadcast %2287 : f32 to vector<8xf32>
    %2289 = vector.fma %2288, %2132, %2265 : vector<8xf32>
    %2290 = vector.extract %2119[1, 6] : f32 from vector<8x8xf32>
    %2291 = vector.broadcast %2290 : f32 to vector<8xf32>
    %2292 = vector.fma %2291, %2132, %2268 : vector<8xf32>
    %2293 = vector.extract %2119[2, 6] : f32 from vector<8x8xf32>
    %2294 = vector.broadcast %2293 : f32 to vector<8xf32>
    %2295 = vector.fma %2294, %2132, %2271 : vector<8xf32>
    %2296 = vector.extract %2119[3, 6] : f32 from vector<8x8xf32>
    %2297 = vector.broadcast %2296 : f32 to vector<8xf32>
    %2298 = vector.fma %2297, %2132, %2274 : vector<8xf32>
    %2299 = vector.extract %2119[4, 6] : f32 from vector<8x8xf32>
    %2300 = vector.broadcast %2299 : f32 to vector<8xf32>
    %2301 = vector.fma %2300, %2132, %2277 : vector<8xf32>
    %2302 = vector.extract %2119[5, 6] : f32 from vector<8x8xf32>
    %2303 = vector.broadcast %2302 : f32 to vector<8xf32>
    %2304 = vector.fma %2303, %2132, %2280 : vector<8xf32>
    %2305 = vector.extract %2119[6, 6] : f32 from vector<8x8xf32>
    %2306 = vector.broadcast %2305 : f32 to vector<8xf32>
    %2307 = vector.fma %2306, %2132, %2283 : vector<8xf32>
    %2308 = vector.extract %2119[7, 6] : f32 from vector<8x8xf32>
    %2309 = vector.broadcast %2308 : f32 to vector<8xf32>
    %2310 = vector.fma %2309, %2132, %2286 : vector<8xf32>
    %2311 = vector.extract %2119[0, 7] : f32 from vector<8x8xf32>
    %2312 = vector.broadcast %2311 : f32 to vector<8xf32>
    %2313 = vector.fma %2312, %2134, %2289 : vector<8xf32>
    %2314 = vector.insert %2313, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2315 = vector.extract %2119[1, 7] : f32 from vector<8x8xf32>
    %2316 = vector.broadcast %2315 : f32 to vector<8xf32>
    %2317 = vector.fma %2316, %2134, %2292 : vector<8xf32>
    %2318 = vector.insert %2317, %2314 [1] : vector<8xf32> into vector<8x8xf32>
    %2319 = vector.extract %2119[2, 7] : f32 from vector<8x8xf32>
    %2320 = vector.broadcast %2319 : f32 to vector<8xf32>
    %2321 = vector.fma %2320, %2134, %2295 : vector<8xf32>
    %2322 = vector.insert %2321, %2318 [2] : vector<8xf32> into vector<8x8xf32>
    %2323 = vector.extract %2119[3, 7] : f32 from vector<8x8xf32>
    %2324 = vector.broadcast %2323 : f32 to vector<8xf32>
    %2325 = vector.fma %2324, %2134, %2298 : vector<8xf32>
    %2326 = vector.insert %2325, %2322 [3] : vector<8xf32> into vector<8x8xf32>
    %2327 = vector.extract %2119[4, 7] : f32 from vector<8x8xf32>
    %2328 = vector.broadcast %2327 : f32 to vector<8xf32>
    %2329 = vector.fma %2328, %2134, %2301 : vector<8xf32>
    %2330 = vector.insert %2329, %2326 [4] : vector<8xf32> into vector<8x8xf32>
    %2331 = vector.extract %2119[5, 7] : f32 from vector<8x8xf32>
    %2332 = vector.broadcast %2331 : f32 to vector<8xf32>
    %2333 = vector.fma %2332, %2134, %2304 : vector<8xf32>
    %2334 = vector.insert %2333, %2330 [5] : vector<8xf32> into vector<8x8xf32>
    %2335 = vector.extract %2119[6, 7] : f32 from vector<8x8xf32>
    %2336 = vector.broadcast %2335 : f32 to vector<8xf32>
    %2337 = vector.fma %2336, %2134, %2307 : vector<8xf32>
    %2338 = vector.insert %2337, %2334 [6] : vector<8xf32> into vector<8x8xf32>
    %2339 = vector.extract %2119[7, 7] : f32 from vector<8x8xf32>
    %2340 = vector.broadcast %2339 : f32 to vector<8xf32>
    %2341 = vector.fma %2340, %2134, %2310 : vector<8xf32>
    %2342 = vector.insert %2341, %2338 [7] : vector<8xf32> into vector<8x8xf32>
    %2343 = arith.mulf %2111, %cst_0 : vector<8xf32>
    %2344 = vector.extract %2119[0] : vector<8xf32> from vector<8x8xf32>
    %2345 = vector.extract %2343[0] : f32 from vector<8xf32>
    %2346 = vector.reduction <add>, %2344, %2345 : vector<8xf32> into f32
    %2347 = vector.insert %2346, %cst_0 [0] : f32 into vector<8xf32>
    %2348 = vector.extract %2119[1] : vector<8xf32> from vector<8x8xf32>
    %2349 = vector.extract %2343[1] : f32 from vector<8xf32>
    %2350 = vector.reduction <add>, %2348, %2349 : vector<8xf32> into f32
    %2351 = vector.insert %2350, %2347 [1] : f32 into vector<8xf32>
    %2352 = vector.extract %2119[2] : vector<8xf32> from vector<8x8xf32>
    %2353 = vector.extract %2343[2] : f32 from vector<8xf32>
    %2354 = vector.reduction <add>, %2352, %2353 : vector<8xf32> into f32
    %2355 = vector.insert %2354, %2351 [2] : f32 into vector<8xf32>
    %2356 = vector.extract %2119[3] : vector<8xf32> from vector<8x8xf32>
    %2357 = vector.extract %2343[3] : f32 from vector<8xf32>
    %2358 = vector.reduction <add>, %2356, %2357 : vector<8xf32> into f32
    %2359 = vector.insert %2358, %2355 [3] : f32 into vector<8xf32>
    %2360 = vector.extract %2119[4] : vector<8xf32> from vector<8x8xf32>
    %2361 = vector.extract %2343[4] : f32 from vector<8xf32>
    %2362 = vector.reduction <add>, %2360, %2361 : vector<8xf32> into f32
    %2363 = vector.insert %2362, %2359 [4] : f32 into vector<8xf32>
    %2364 = vector.extract %2119[5] : vector<8xf32> from vector<8x8xf32>
    %2365 = vector.extract %2343[5] : f32 from vector<8xf32>
    %2366 = vector.reduction <add>, %2364, %2365 : vector<8xf32> into f32
    %2367 = vector.insert %2366, %2363 [5] : f32 into vector<8xf32>
    %2368 = vector.extract %2119[6] : vector<8xf32> from vector<8x8xf32>
    %2369 = vector.extract %2343[6] : f32 from vector<8xf32>
    %2370 = vector.reduction <add>, %2368, %2369 : vector<8xf32> into f32
    %2371 = vector.insert %2370, %2367 [6] : f32 into vector<8xf32>
    %2372 = vector.extract %2119[7] : vector<8xf32> from vector<8x8xf32>
    %2373 = vector.extract %2343[7] : f32 from vector<8xf32>
    %2374 = vector.reduction <add>, %2372, %2373 : vector<8xf32> into f32
    %2375 = vector.insert %2374, %2371 [7] : f32 into vector<8xf32>
    %2376 = vector.shape_cast %2375 : vector<8xf32> to vector<1x8xf32>
    %2377 = vector.broadcast %2376 : vector<1x8xf32> to vector<8x8xf32>
    %2378 = vector.transpose %2377, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
    %2379 = arith.divf %2342, %2378 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    %2380 = vector.extract %2379[0] : vector<8xf32> from vector<8x8xf32>
    vector.store %2380, %subview_7[%c0, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2381 = vector.extract %2379[1] : vector<8xf32> from vector<8x8xf32>
    vector.store %2381, %subview_7[%c1, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2382 = vector.extract %2379[2] : vector<8xf32> from vector<8x8xf32>
    vector.store %2382, %subview_7[%c2, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2383 = vector.extract %2379[3] : vector<8xf32> from vector<8x8xf32>
    vector.store %2383, %subview_7[%c3, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2384 = vector.extract %2379[4] : vector<8xf32> from vector<8x8xf32>
    vector.store %2384, %subview_7[%c4, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2385 = vector.extract %2379[5] : vector<8xf32> from vector<8x8xf32>
    vector.store %2385, %subview_7[%c5, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2386 = vector.extract %2379[6] : vector<8xf32> from vector<8x8xf32>
    vector.store %2386, %subview_7[%c6, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2387 = vector.extract %2379[7] : vector<8xf32> from vector<8x8xf32>
    vector.store %2387, %subview_7[%c7, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVectorTransposeLoweringPass (iree-llvmcpu-vector-transpose-lowering) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %0 = ub.poison : vector<8x64xf32>
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %6 = vector.insert %5, %0 [0] : vector<64xf32> into vector<8x64xf32>
    %7 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %8 = vector.load %assume_align_3[%arg0, %7, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %9 = vector.insert %8, %6 [1] : vector<64xf32> into vector<8x64xf32>
    %10 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %11 = vector.load %assume_align_3[%arg0, %10, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %12 = vector.insert %11, %9 [2] : vector<64xf32> into vector<8x64xf32>
    %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %15 = vector.insert %14, %12 [3] : vector<64xf32> into vector<8x64xf32>
    %16 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %17 = vector.load %assume_align_3[%arg0, %16, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %18 = vector.insert %17, %15 [4] : vector<64xf32> into vector<8x64xf32>
    %19 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %21 = vector.insert %20, %18 [5] : vector<64xf32> into vector<8x64xf32>
    %22 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %23 = vector.load %assume_align_3[%arg0, %22, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %24 = vector.insert %23, %21 [6] : vector<64xf32> into vector<8x64xf32>
    %25 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %26 = vector.load %assume_align_3[%arg0, %25, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %27 = vector.insert %26, %24 [7] : vector<64xf32> into vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %28 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
    %29 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
    %30 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
    %31 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
    %32 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
    %33 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
    %34 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
    %35 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
    %36 = vector.shape_cast %27 : vector<8x64xf32> to vector<512xf32>
    %37 = vector.shuffle %36, %36 [0, 64, 128, 192, 256, 320, 384, 448, 1, 65, 129, 193, 257, 321, 385, 449, 2, 66, 130, 194, 258, 322, 386, 450, 3, 67, 131, 195, 259, 323, 387, 451, 4, 68, 132, 196, 260, 324, 388, 452, 5, 69, 133, 197, 261, 325, 389, 453, 6, 70, 134, 198, 262, 326, 390, 454, 7, 71, 135, 199, 263, 327, 391, 455, 8, 72, 136, 200, 264, 328, 392, 456, 9, 73, 137, 201, 265, 329, 393, 457, 10, 74, 138, 202, 266, 330, 394, 458, 11, 75, 139, 203, 267, 331, 395, 459, 12, 76, 140, 204, 268, 332, 396, 460, 13, 77, 141, 205, 269, 333, 397, 461, 14, 78, 142, 206, 270, 334, 398, 462, 15, 79, 143, 207, 271, 335, 399, 463, 16, 80, 144, 208, 272, 336, 400, 464, 17, 81, 145, 209, 273, 337, 401, 465, 18, 82, 146, 210, 274, 338, 402, 466, 19, 83, 147, 211, 275, 339, 403, 467, 20, 84, 148, 212, 276, 340, 404, 468, 21, 85, 149, 213, 277, 341, 405, 469, 22, 86, 150, 214, 278, 342, 406, 470, 23, 87, 151, 215, 279, 343, 407, 471, 24, 88, 152, 216, 280, 344, 408, 472, 25, 89, 153, 217, 281, 345, 409, 473, 26, 90, 154, 218, 282, 346, 410, 474, 27, 91, 155, 219, 283, 347, 411, 475, 28, 92, 156, 220, 284, 348, 412, 476, 29, 93, 157, 221, 285, 349, 413, 477, 30, 94, 158, 222, 286, 350, 414, 478, 31, 95, 159, 223, 287, 351, 415, 479, 32, 96, 160, 224, 288, 352, 416, 480, 33, 97, 161, 225, 289, 353, 417, 481, 34, 98, 162, 226, 290, 354, 418, 482, 35, 99, 163, 227, 291, 355, 419, 483, 36, 100, 164, 228, 292, 356, 420, 484, 37, 101, 165, 229, 293, 357, 421, 485, 38, 102, 166, 230, 294, 358, 422, 486, 39, 103, 167, 231, 295, 359, 423, 487, 40, 104, 168, 232, 296, 360, 424, 488, 41, 105, 169, 233, 297, 361, 425, 489, 42, 106, 170, 234, 298, 362, 426, 490, 43, 107, 171, 235, 299, 363, 427, 491, 44, 108, 172, 236, 300, 364, 428, 492, 45, 109, 173, 237, 301, 365, 429, 493, 46, 110, 174, 238, 302, 366, 430, 494, 47, 111, 175, 239, 303, 367, 431, 495, 48, 112, 176, 240, 304, 368, 432, 496, 49, 113, 177, 241, 305, 369, 433, 497, 50, 114, 178, 242, 306, 370, 434, 498, 51, 115, 179, 243, 307, 371, 435, 499, 52, 116, 180, 244, 308, 372, 436, 500, 53, 117, 181, 245, 309, 373, 437, 501, 54, 118, 182, 246, 310, 374, 438, 502, 55, 119, 183, 247, 311, 375, 439, 503, 56, 120, 184, 248, 312, 376, 440, 504, 57, 121, 185, 249, 313, 377, 441, 505, 58, 122, 186, 250, 314, 378, 442, 506, 59, 123, 187, 251, 315, 379, 443, 507, 60, 124, 188, 252, 316, 380, 444, 508, 61, 125, 189, 253, 317, 381, 445, 509, 62, 126, 190, 254, 318, 382, 446, 510, 63, 127, 191, 255, 319, 383, 447, 511] : vector<512xf32>, vector<512xf32>
    %38 = vector.shape_cast %37 : vector<512xf32> to vector<64x8xf32>
    %39 = vector.extract %38[0] : vector<8xf32> from vector<64x8xf32>
    %40 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %41 = vector.broadcast %40 : f32 to vector<8xf32>
    %42 = vector.fma %41, %39, %28 : vector<8xf32>
    %43 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %44 = memref.load %assume_align[%arg0, %43, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %45 = vector.broadcast %44 : f32 to vector<8xf32>
    %46 = vector.fma %45, %39, %29 : vector<8xf32>
    %47 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %48 = memref.load %assume_align[%arg0, %47, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %49 = vector.broadcast %48 : f32 to vector<8xf32>
    %50 = vector.fma %49, %39, %30 : vector<8xf32>
    %51 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %52 = memref.load %assume_align[%arg0, %51, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %53 = vector.broadcast %52 : f32 to vector<8xf32>
    %54 = vector.fma %53, %39, %31 : vector<8xf32>
    %55 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %56 = memref.load %assume_align[%arg0, %55, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %57 = vector.broadcast %56 : f32 to vector<8xf32>
    %58 = vector.fma %57, %39, %32 : vector<8xf32>
    %59 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %60 = memref.load %assume_align[%arg0, %59, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %61 = vector.broadcast %60 : f32 to vector<8xf32>
    %62 = vector.fma %61, %39, %33 : vector<8xf32>
    %63 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %64 = memref.load %assume_align[%arg0, %63, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %65 = vector.broadcast %64 : f32 to vector<8xf32>
    %66 = vector.fma %65, %39, %34 : vector<8xf32>
    %67 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %68 = memref.load %assume_align[%arg0, %67, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %69 = vector.broadcast %68 : f32 to vector<8xf32>
    %70 = vector.fma %69, %39, %35 : vector<8xf32>
    %71 = vector.extract %38[1] : vector<8xf32> from vector<64x8xf32>
    %72 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %73 = vector.broadcast %72 : f32 to vector<8xf32>
    %74 = vector.fma %73, %71, %42 : vector<8xf32>
    %75 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %76 = memref.load %assume_align[%arg0, %75, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %77 = vector.broadcast %76 : f32 to vector<8xf32>
    %78 = vector.fma %77, %71, %46 : vector<8xf32>
    %79 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %80 = memref.load %assume_align[%arg0, %79, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %81 = vector.broadcast %80 : f32 to vector<8xf32>
    %82 = vector.fma %81, %71, %50 : vector<8xf32>
    %83 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %84 = memref.load %assume_align[%arg0, %83, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %85 = vector.broadcast %84 : f32 to vector<8xf32>
    %86 = vector.fma %85, %71, %54 : vector<8xf32>
    %87 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %88 = memref.load %assume_align[%arg0, %87, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %89 = vector.broadcast %88 : f32 to vector<8xf32>
    %90 = vector.fma %89, %71, %58 : vector<8xf32>
    %91 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %92 = memref.load %assume_align[%arg0, %91, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %93 = vector.broadcast %92 : f32 to vector<8xf32>
    %94 = vector.fma %93, %71, %62 : vector<8xf32>
    %95 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %96 = memref.load %assume_align[%arg0, %95, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %97 = vector.broadcast %96 : f32 to vector<8xf32>
    %98 = vector.fma %97, %71, %66 : vector<8xf32>
    %99 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %100 = memref.load %assume_align[%arg0, %99, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %101 = vector.broadcast %100 : f32 to vector<8xf32>
    %102 = vector.fma %101, %71, %70 : vector<8xf32>
    %103 = vector.extract %38[2] : vector<8xf32> from vector<64x8xf32>
    %104 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %105 = vector.broadcast %104 : f32 to vector<8xf32>
    %106 = vector.fma %105, %103, %74 : vector<8xf32>
    %107 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %108 = memref.load %assume_align[%arg0, %107, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %109 = vector.broadcast %108 : f32 to vector<8xf32>
    %110 = vector.fma %109, %103, %78 : vector<8xf32>
    %111 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %112 = memref.load %assume_align[%arg0, %111, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %113 = vector.broadcast %112 : f32 to vector<8xf32>
    %114 = vector.fma %113, %103, %82 : vector<8xf32>
    %115 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %116 = memref.load %assume_align[%arg0, %115, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %117 = vector.broadcast %116 : f32 to vector<8xf32>
    %118 = vector.fma %117, %103, %86 : vector<8xf32>
    %119 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %120 = memref.load %assume_align[%arg0, %119, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %121 = vector.broadcast %120 : f32 to vector<8xf32>
    %122 = vector.fma %121, %103, %90 : vector<8xf32>
    %123 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %124 = memref.load %assume_align[%arg0, %123, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %125 = vector.broadcast %124 : f32 to vector<8xf32>
    %126 = vector.fma %125, %103, %94 : vector<8xf32>
    %127 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %128 = memref.load %assume_align[%arg0, %127, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %129 = vector.broadcast %128 : f32 to vector<8xf32>
    %130 = vector.fma %129, %103, %98 : vector<8xf32>
    %131 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %132 = memref.load %assume_align[%arg0, %131, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %133 = vector.broadcast %132 : f32 to vector<8xf32>
    %134 = vector.fma %133, %103, %102 : vector<8xf32>
    %135 = vector.extract %38[3] : vector<8xf32> from vector<64x8xf32>
    %136 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %137 = vector.broadcast %136 : f32 to vector<8xf32>
    %138 = vector.fma %137, %135, %106 : vector<8xf32>
    %139 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %140 = memref.load %assume_align[%arg0, %139, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %141 = vector.broadcast %140 : f32 to vector<8xf32>
    %142 = vector.fma %141, %135, %110 : vector<8xf32>
    %143 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %144 = memref.load %assume_align[%arg0, %143, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %145 = vector.broadcast %144 : f32 to vector<8xf32>
    %146 = vector.fma %145, %135, %114 : vector<8xf32>
    %147 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %148 = memref.load %assume_align[%arg0, %147, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %149 = vector.broadcast %148 : f32 to vector<8xf32>
    %150 = vector.fma %149, %135, %118 : vector<8xf32>
    %151 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %152 = memref.load %assume_align[%arg0, %151, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %153 = vector.broadcast %152 : f32 to vector<8xf32>
    %154 = vector.fma %153, %135, %122 : vector<8xf32>
    %155 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %156 = memref.load %assume_align[%arg0, %155, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %157 = vector.broadcast %156 : f32 to vector<8xf32>
    %158 = vector.fma %157, %135, %126 : vector<8xf32>
    %159 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %160 = memref.load %assume_align[%arg0, %159, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %161 = vector.broadcast %160 : f32 to vector<8xf32>
    %162 = vector.fma %161, %135, %130 : vector<8xf32>
    %163 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %164 = memref.load %assume_align[%arg0, %163, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %165 = vector.broadcast %164 : f32 to vector<8xf32>
    %166 = vector.fma %165, %135, %134 : vector<8xf32>
    %167 = vector.extract %38[4] : vector<8xf32> from vector<64x8xf32>
    %168 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %169 = vector.broadcast %168 : f32 to vector<8xf32>
    %170 = vector.fma %169, %167, %138 : vector<8xf32>
    %171 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %172 = memref.load %assume_align[%arg0, %171, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %173 = vector.broadcast %172 : f32 to vector<8xf32>
    %174 = vector.fma %173, %167, %142 : vector<8xf32>
    %175 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %176 = memref.load %assume_align[%arg0, %175, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %177 = vector.broadcast %176 : f32 to vector<8xf32>
    %178 = vector.fma %177, %167, %146 : vector<8xf32>
    %179 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %180 = memref.load %assume_align[%arg0, %179, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %181 = vector.broadcast %180 : f32 to vector<8xf32>
    %182 = vector.fma %181, %167, %150 : vector<8xf32>
    %183 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %184 = memref.load %assume_align[%arg0, %183, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %185 = vector.broadcast %184 : f32 to vector<8xf32>
    %186 = vector.fma %185, %167, %154 : vector<8xf32>
    %187 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %188 = memref.load %assume_align[%arg0, %187, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %189 = vector.broadcast %188 : f32 to vector<8xf32>
    %190 = vector.fma %189, %167, %158 : vector<8xf32>
    %191 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %192 = memref.load %assume_align[%arg0, %191, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %193 = vector.broadcast %192 : f32 to vector<8xf32>
    %194 = vector.fma %193, %167, %162 : vector<8xf32>
    %195 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %196 = memref.load %assume_align[%arg0, %195, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %197 = vector.broadcast %196 : f32 to vector<8xf32>
    %198 = vector.fma %197, %167, %166 : vector<8xf32>
    %199 = vector.extract %38[5] : vector<8xf32> from vector<64x8xf32>
    %200 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %201 = vector.broadcast %200 : f32 to vector<8xf32>
    %202 = vector.fma %201, %199, %170 : vector<8xf32>
    %203 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %204 = memref.load %assume_align[%arg0, %203, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %205 = vector.broadcast %204 : f32 to vector<8xf32>
    %206 = vector.fma %205, %199, %174 : vector<8xf32>
    %207 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %208 = memref.load %assume_align[%arg0, %207, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %209 = vector.broadcast %208 : f32 to vector<8xf32>
    %210 = vector.fma %209, %199, %178 : vector<8xf32>
    %211 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %212 = memref.load %assume_align[%arg0, %211, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %213 = vector.broadcast %212 : f32 to vector<8xf32>
    %214 = vector.fma %213, %199, %182 : vector<8xf32>
    %215 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %216 = memref.load %assume_align[%arg0, %215, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %217 = vector.broadcast %216 : f32 to vector<8xf32>
    %218 = vector.fma %217, %199, %186 : vector<8xf32>
    %219 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %220 = memref.load %assume_align[%arg0, %219, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %221 = vector.broadcast %220 : f32 to vector<8xf32>
    %222 = vector.fma %221, %199, %190 : vector<8xf32>
    %223 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %224 = memref.load %assume_align[%arg0, %223, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %225 = vector.broadcast %224 : f32 to vector<8xf32>
    %226 = vector.fma %225, %199, %194 : vector<8xf32>
    %227 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %228 = memref.load %assume_align[%arg0, %227, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %229 = vector.broadcast %228 : f32 to vector<8xf32>
    %230 = vector.fma %229, %199, %198 : vector<8xf32>
    %231 = vector.extract %38[6] : vector<8xf32> from vector<64x8xf32>
    %232 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %233 = vector.broadcast %232 : f32 to vector<8xf32>
    %234 = vector.fma %233, %231, %202 : vector<8xf32>
    %235 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %236 = memref.load %assume_align[%arg0, %235, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %237 = vector.broadcast %236 : f32 to vector<8xf32>
    %238 = vector.fma %237, %231, %206 : vector<8xf32>
    %239 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %240 = memref.load %assume_align[%arg0, %239, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %241 = vector.broadcast %240 : f32 to vector<8xf32>
    %242 = vector.fma %241, %231, %210 : vector<8xf32>
    %243 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %244 = memref.load %assume_align[%arg0, %243, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %245 = vector.broadcast %244 : f32 to vector<8xf32>
    %246 = vector.fma %245, %231, %214 : vector<8xf32>
    %247 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %248 = memref.load %assume_align[%arg0, %247, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %249 = vector.broadcast %248 : f32 to vector<8xf32>
    %250 = vector.fma %249, %231, %218 : vector<8xf32>
    %251 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %252 = memref.load %assume_align[%arg0, %251, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %253 = vector.broadcast %252 : f32 to vector<8xf32>
    %254 = vector.fma %253, %231, %222 : vector<8xf32>
    %255 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %256 = memref.load %assume_align[%arg0, %255, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %257 = vector.broadcast %256 : f32 to vector<8xf32>
    %258 = vector.fma %257, %231, %226 : vector<8xf32>
    %259 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %260 = memref.load %assume_align[%arg0, %259, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %261 = vector.broadcast %260 : f32 to vector<8xf32>
    %262 = vector.fma %261, %231, %230 : vector<8xf32>
    %263 = vector.extract %38[7] : vector<8xf32> from vector<64x8xf32>
    %264 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %265 = vector.broadcast %264 : f32 to vector<8xf32>
    %266 = vector.fma %265, %263, %234 : vector<8xf32>
    %267 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %268 = memref.load %assume_align[%arg0, %267, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %269 = vector.broadcast %268 : f32 to vector<8xf32>
    %270 = vector.fma %269, %263, %238 : vector<8xf32>
    %271 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %272 = memref.load %assume_align[%arg0, %271, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %273 = vector.broadcast %272 : f32 to vector<8xf32>
    %274 = vector.fma %273, %263, %242 : vector<8xf32>
    %275 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %276 = memref.load %assume_align[%arg0, %275, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %277 = vector.broadcast %276 : f32 to vector<8xf32>
    %278 = vector.fma %277, %263, %246 : vector<8xf32>
    %279 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %280 = memref.load %assume_align[%arg0, %279, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %281 = vector.broadcast %280 : f32 to vector<8xf32>
    %282 = vector.fma %281, %263, %250 : vector<8xf32>
    %283 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %284 = memref.load %assume_align[%arg0, %283, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %285 = vector.broadcast %284 : f32 to vector<8xf32>
    %286 = vector.fma %285, %263, %254 : vector<8xf32>
    %287 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %288 = memref.load %assume_align[%arg0, %287, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %289 = vector.broadcast %288 : f32 to vector<8xf32>
    %290 = vector.fma %289, %263, %258 : vector<8xf32>
    %291 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %292 = memref.load %assume_align[%arg0, %291, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %293 = vector.broadcast %292 : f32 to vector<8xf32>
    %294 = vector.fma %293, %263, %262 : vector<8xf32>
    %295 = vector.extract %38[8] : vector<8xf32> from vector<64x8xf32>
    %296 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %297 = vector.broadcast %296 : f32 to vector<8xf32>
    %298 = vector.fma %297, %295, %266 : vector<8xf32>
    %299 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %300 = memref.load %assume_align[%arg0, %299, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %301 = vector.broadcast %300 : f32 to vector<8xf32>
    %302 = vector.fma %301, %295, %270 : vector<8xf32>
    %303 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %304 = memref.load %assume_align[%arg0, %303, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %305 = vector.broadcast %304 : f32 to vector<8xf32>
    %306 = vector.fma %305, %295, %274 : vector<8xf32>
    %307 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %308 = memref.load %assume_align[%arg0, %307, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %309 = vector.broadcast %308 : f32 to vector<8xf32>
    %310 = vector.fma %309, %295, %278 : vector<8xf32>
    %311 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %312 = memref.load %assume_align[%arg0, %311, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %313 = vector.broadcast %312 : f32 to vector<8xf32>
    %314 = vector.fma %313, %295, %282 : vector<8xf32>
    %315 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %316 = memref.load %assume_align[%arg0, %315, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %317 = vector.broadcast %316 : f32 to vector<8xf32>
    %318 = vector.fma %317, %295, %286 : vector<8xf32>
    %319 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %320 = memref.load %assume_align[%arg0, %319, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %321 = vector.broadcast %320 : f32 to vector<8xf32>
    %322 = vector.fma %321, %295, %290 : vector<8xf32>
    %323 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %324 = memref.load %assume_align[%arg0, %323, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %325 = vector.broadcast %324 : f32 to vector<8xf32>
    %326 = vector.fma %325, %295, %294 : vector<8xf32>
    %327 = vector.extract %38[9] : vector<8xf32> from vector<64x8xf32>
    %328 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %329 = vector.broadcast %328 : f32 to vector<8xf32>
    %330 = vector.fma %329, %327, %298 : vector<8xf32>
    %331 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %332 = memref.load %assume_align[%arg0, %331, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %333 = vector.broadcast %332 : f32 to vector<8xf32>
    %334 = vector.fma %333, %327, %302 : vector<8xf32>
    %335 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %336 = memref.load %assume_align[%arg0, %335, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %337 = vector.broadcast %336 : f32 to vector<8xf32>
    %338 = vector.fma %337, %327, %306 : vector<8xf32>
    %339 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %340 = memref.load %assume_align[%arg0, %339, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %341 = vector.broadcast %340 : f32 to vector<8xf32>
    %342 = vector.fma %341, %327, %310 : vector<8xf32>
    %343 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %344 = memref.load %assume_align[%arg0, %343, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %345 = vector.broadcast %344 : f32 to vector<8xf32>
    %346 = vector.fma %345, %327, %314 : vector<8xf32>
    %347 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %348 = memref.load %assume_align[%arg0, %347, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %349 = vector.broadcast %348 : f32 to vector<8xf32>
    %350 = vector.fma %349, %327, %318 : vector<8xf32>
    %351 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %352 = memref.load %assume_align[%arg0, %351, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %353 = vector.broadcast %352 : f32 to vector<8xf32>
    %354 = vector.fma %353, %327, %322 : vector<8xf32>
    %355 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %356 = memref.load %assume_align[%arg0, %355, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %357 = vector.broadcast %356 : f32 to vector<8xf32>
    %358 = vector.fma %357, %327, %326 : vector<8xf32>
    %359 = vector.extract %38[10] : vector<8xf32> from vector<64x8xf32>
    %360 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %361 = vector.broadcast %360 : f32 to vector<8xf32>
    %362 = vector.fma %361, %359, %330 : vector<8xf32>
    %363 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %364 = memref.load %assume_align[%arg0, %363, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %365 = vector.broadcast %364 : f32 to vector<8xf32>
    %366 = vector.fma %365, %359, %334 : vector<8xf32>
    %367 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %368 = memref.load %assume_align[%arg0, %367, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %369 = vector.broadcast %368 : f32 to vector<8xf32>
    %370 = vector.fma %369, %359, %338 : vector<8xf32>
    %371 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %372 = memref.load %assume_align[%arg0, %371, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %373 = vector.broadcast %372 : f32 to vector<8xf32>
    %374 = vector.fma %373, %359, %342 : vector<8xf32>
    %375 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %376 = memref.load %assume_align[%arg0, %375, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %377 = vector.broadcast %376 : f32 to vector<8xf32>
    %378 = vector.fma %377, %359, %346 : vector<8xf32>
    %379 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %380 = memref.load %assume_align[%arg0, %379, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %381 = vector.broadcast %380 : f32 to vector<8xf32>
    %382 = vector.fma %381, %359, %350 : vector<8xf32>
    %383 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %384 = memref.load %assume_align[%arg0, %383, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %385 = vector.broadcast %384 : f32 to vector<8xf32>
    %386 = vector.fma %385, %359, %354 : vector<8xf32>
    %387 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %388 = memref.load %assume_align[%arg0, %387, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %389 = vector.broadcast %388 : f32 to vector<8xf32>
    %390 = vector.fma %389, %359, %358 : vector<8xf32>
    %391 = vector.extract %38[11] : vector<8xf32> from vector<64x8xf32>
    %392 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %393 = vector.broadcast %392 : f32 to vector<8xf32>
    %394 = vector.fma %393, %391, %362 : vector<8xf32>
    %395 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %396 = memref.load %assume_align[%arg0, %395, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %397 = vector.broadcast %396 : f32 to vector<8xf32>
    %398 = vector.fma %397, %391, %366 : vector<8xf32>
    %399 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %400 = memref.load %assume_align[%arg0, %399, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %401 = vector.broadcast %400 : f32 to vector<8xf32>
    %402 = vector.fma %401, %391, %370 : vector<8xf32>
    %403 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %404 = memref.load %assume_align[%arg0, %403, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %405 = vector.broadcast %404 : f32 to vector<8xf32>
    %406 = vector.fma %405, %391, %374 : vector<8xf32>
    %407 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %408 = memref.load %assume_align[%arg0, %407, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %409 = vector.broadcast %408 : f32 to vector<8xf32>
    %410 = vector.fma %409, %391, %378 : vector<8xf32>
    %411 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %412 = memref.load %assume_align[%arg0, %411, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %413 = vector.broadcast %412 : f32 to vector<8xf32>
    %414 = vector.fma %413, %391, %382 : vector<8xf32>
    %415 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %416 = memref.load %assume_align[%arg0, %415, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %417 = vector.broadcast %416 : f32 to vector<8xf32>
    %418 = vector.fma %417, %391, %386 : vector<8xf32>
    %419 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %420 = memref.load %assume_align[%arg0, %419, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %421 = vector.broadcast %420 : f32 to vector<8xf32>
    %422 = vector.fma %421, %391, %390 : vector<8xf32>
    %423 = vector.extract %38[12] : vector<8xf32> from vector<64x8xf32>
    %424 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %425 = vector.broadcast %424 : f32 to vector<8xf32>
    %426 = vector.fma %425, %423, %394 : vector<8xf32>
    %427 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %428 = memref.load %assume_align[%arg0, %427, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %429 = vector.broadcast %428 : f32 to vector<8xf32>
    %430 = vector.fma %429, %423, %398 : vector<8xf32>
    %431 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %432 = memref.load %assume_align[%arg0, %431, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %433 = vector.broadcast %432 : f32 to vector<8xf32>
    %434 = vector.fma %433, %423, %402 : vector<8xf32>
    %435 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %436 = memref.load %assume_align[%arg0, %435, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %437 = vector.broadcast %436 : f32 to vector<8xf32>
    %438 = vector.fma %437, %423, %406 : vector<8xf32>
    %439 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %440 = memref.load %assume_align[%arg0, %439, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %441 = vector.broadcast %440 : f32 to vector<8xf32>
    %442 = vector.fma %441, %423, %410 : vector<8xf32>
    %443 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %444 = memref.load %assume_align[%arg0, %443, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %445 = vector.broadcast %444 : f32 to vector<8xf32>
    %446 = vector.fma %445, %423, %414 : vector<8xf32>
    %447 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %448 = memref.load %assume_align[%arg0, %447, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %449 = vector.broadcast %448 : f32 to vector<8xf32>
    %450 = vector.fma %449, %423, %418 : vector<8xf32>
    %451 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %452 = memref.load %assume_align[%arg0, %451, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %453 = vector.broadcast %452 : f32 to vector<8xf32>
    %454 = vector.fma %453, %423, %422 : vector<8xf32>
    %455 = vector.extract %38[13] : vector<8xf32> from vector<64x8xf32>
    %456 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %457 = vector.broadcast %456 : f32 to vector<8xf32>
    %458 = vector.fma %457, %455, %426 : vector<8xf32>
    %459 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %460 = memref.load %assume_align[%arg0, %459, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %461 = vector.broadcast %460 : f32 to vector<8xf32>
    %462 = vector.fma %461, %455, %430 : vector<8xf32>
    %463 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %464 = memref.load %assume_align[%arg0, %463, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %465 = vector.broadcast %464 : f32 to vector<8xf32>
    %466 = vector.fma %465, %455, %434 : vector<8xf32>
    %467 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %468 = memref.load %assume_align[%arg0, %467, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %469 = vector.broadcast %468 : f32 to vector<8xf32>
    %470 = vector.fma %469, %455, %438 : vector<8xf32>
    %471 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %472 = memref.load %assume_align[%arg0, %471, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %473 = vector.broadcast %472 : f32 to vector<8xf32>
    %474 = vector.fma %473, %455, %442 : vector<8xf32>
    %475 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %476 = memref.load %assume_align[%arg0, %475, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %477 = vector.broadcast %476 : f32 to vector<8xf32>
    %478 = vector.fma %477, %455, %446 : vector<8xf32>
    %479 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %480 = memref.load %assume_align[%arg0, %479, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %481 = vector.broadcast %480 : f32 to vector<8xf32>
    %482 = vector.fma %481, %455, %450 : vector<8xf32>
    %483 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %484 = memref.load %assume_align[%arg0, %483, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %485 = vector.broadcast %484 : f32 to vector<8xf32>
    %486 = vector.fma %485, %455, %454 : vector<8xf32>
    %487 = vector.extract %38[14] : vector<8xf32> from vector<64x8xf32>
    %488 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %489 = vector.broadcast %488 : f32 to vector<8xf32>
    %490 = vector.fma %489, %487, %458 : vector<8xf32>
    %491 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %492 = memref.load %assume_align[%arg0, %491, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %493 = vector.broadcast %492 : f32 to vector<8xf32>
    %494 = vector.fma %493, %487, %462 : vector<8xf32>
    %495 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %496 = memref.load %assume_align[%arg0, %495, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %497 = vector.broadcast %496 : f32 to vector<8xf32>
    %498 = vector.fma %497, %487, %466 : vector<8xf32>
    %499 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %500 = memref.load %assume_align[%arg0, %499, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %501 = vector.broadcast %500 : f32 to vector<8xf32>
    %502 = vector.fma %501, %487, %470 : vector<8xf32>
    %503 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %504 = memref.load %assume_align[%arg0, %503, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %505 = vector.broadcast %504 : f32 to vector<8xf32>
    %506 = vector.fma %505, %487, %474 : vector<8xf32>
    %507 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %508 = memref.load %assume_align[%arg0, %507, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %509 = vector.broadcast %508 : f32 to vector<8xf32>
    %510 = vector.fma %509, %487, %478 : vector<8xf32>
    %511 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %512 = memref.load %assume_align[%arg0, %511, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %513 = vector.broadcast %512 : f32 to vector<8xf32>
    %514 = vector.fma %513, %487, %482 : vector<8xf32>
    %515 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %516 = memref.load %assume_align[%arg0, %515, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %517 = vector.broadcast %516 : f32 to vector<8xf32>
    %518 = vector.fma %517, %487, %486 : vector<8xf32>
    %519 = vector.extract %38[15] : vector<8xf32> from vector<64x8xf32>
    %520 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %521 = vector.broadcast %520 : f32 to vector<8xf32>
    %522 = vector.fma %521, %519, %490 : vector<8xf32>
    %523 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %524 = memref.load %assume_align[%arg0, %523, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %525 = vector.broadcast %524 : f32 to vector<8xf32>
    %526 = vector.fma %525, %519, %494 : vector<8xf32>
    %527 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %528 = memref.load %assume_align[%arg0, %527, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %529 = vector.broadcast %528 : f32 to vector<8xf32>
    %530 = vector.fma %529, %519, %498 : vector<8xf32>
    %531 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %532 = memref.load %assume_align[%arg0, %531, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %533 = vector.broadcast %532 : f32 to vector<8xf32>
    %534 = vector.fma %533, %519, %502 : vector<8xf32>
    %535 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %536 = memref.load %assume_align[%arg0, %535, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %537 = vector.broadcast %536 : f32 to vector<8xf32>
    %538 = vector.fma %537, %519, %506 : vector<8xf32>
    %539 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %540 = memref.load %assume_align[%arg0, %539, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %541 = vector.broadcast %540 : f32 to vector<8xf32>
    %542 = vector.fma %541, %519, %510 : vector<8xf32>
    %543 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %544 = memref.load %assume_align[%arg0, %543, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %545 = vector.broadcast %544 : f32 to vector<8xf32>
    %546 = vector.fma %545, %519, %514 : vector<8xf32>
    %547 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %548 = memref.load %assume_align[%arg0, %547, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %549 = vector.broadcast %548 : f32 to vector<8xf32>
    %550 = vector.fma %549, %519, %518 : vector<8xf32>
    %551 = vector.extract %38[16] : vector<8xf32> from vector<64x8xf32>
    %552 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %553 = vector.broadcast %552 : f32 to vector<8xf32>
    %554 = vector.fma %553, %551, %522 : vector<8xf32>
    %555 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %556 = memref.load %assume_align[%arg0, %555, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %557 = vector.broadcast %556 : f32 to vector<8xf32>
    %558 = vector.fma %557, %551, %526 : vector<8xf32>
    %559 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %560 = memref.load %assume_align[%arg0, %559, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %561 = vector.broadcast %560 : f32 to vector<8xf32>
    %562 = vector.fma %561, %551, %530 : vector<8xf32>
    %563 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %564 = memref.load %assume_align[%arg0, %563, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %565 = vector.broadcast %564 : f32 to vector<8xf32>
    %566 = vector.fma %565, %551, %534 : vector<8xf32>
    %567 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %568 = memref.load %assume_align[%arg0, %567, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %569 = vector.broadcast %568 : f32 to vector<8xf32>
    %570 = vector.fma %569, %551, %538 : vector<8xf32>
    %571 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %572 = memref.load %assume_align[%arg0, %571, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %573 = vector.broadcast %572 : f32 to vector<8xf32>
    %574 = vector.fma %573, %551, %542 : vector<8xf32>
    %575 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %576 = memref.load %assume_align[%arg0, %575, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %577 = vector.broadcast %576 : f32 to vector<8xf32>
    %578 = vector.fma %577, %551, %546 : vector<8xf32>
    %579 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %580 = memref.load %assume_align[%arg0, %579, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %581 = vector.broadcast %580 : f32 to vector<8xf32>
    %582 = vector.fma %581, %551, %550 : vector<8xf32>
    %583 = vector.extract %38[17] : vector<8xf32> from vector<64x8xf32>
    %584 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %585 = vector.broadcast %584 : f32 to vector<8xf32>
    %586 = vector.fma %585, %583, %554 : vector<8xf32>
    %587 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %588 = memref.load %assume_align[%arg0, %587, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %589 = vector.broadcast %588 : f32 to vector<8xf32>
    %590 = vector.fma %589, %583, %558 : vector<8xf32>
    %591 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %592 = memref.load %assume_align[%arg0, %591, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %593 = vector.broadcast %592 : f32 to vector<8xf32>
    %594 = vector.fma %593, %583, %562 : vector<8xf32>
    %595 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %596 = memref.load %assume_align[%arg0, %595, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %597 = vector.broadcast %596 : f32 to vector<8xf32>
    %598 = vector.fma %597, %583, %566 : vector<8xf32>
    %599 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %600 = memref.load %assume_align[%arg0, %599, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %601 = vector.broadcast %600 : f32 to vector<8xf32>
    %602 = vector.fma %601, %583, %570 : vector<8xf32>
    %603 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %604 = memref.load %assume_align[%arg0, %603, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %605 = vector.broadcast %604 : f32 to vector<8xf32>
    %606 = vector.fma %605, %583, %574 : vector<8xf32>
    %607 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %608 = memref.load %assume_align[%arg0, %607, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %609 = vector.broadcast %608 : f32 to vector<8xf32>
    %610 = vector.fma %609, %583, %578 : vector<8xf32>
    %611 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %612 = memref.load %assume_align[%arg0, %611, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %613 = vector.broadcast %612 : f32 to vector<8xf32>
    %614 = vector.fma %613, %583, %582 : vector<8xf32>
    %615 = vector.extract %38[18] : vector<8xf32> from vector<64x8xf32>
    %616 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %617 = vector.broadcast %616 : f32 to vector<8xf32>
    %618 = vector.fma %617, %615, %586 : vector<8xf32>
    %619 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %620 = memref.load %assume_align[%arg0, %619, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %621 = vector.broadcast %620 : f32 to vector<8xf32>
    %622 = vector.fma %621, %615, %590 : vector<8xf32>
    %623 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %624 = memref.load %assume_align[%arg0, %623, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %625 = vector.broadcast %624 : f32 to vector<8xf32>
    %626 = vector.fma %625, %615, %594 : vector<8xf32>
    %627 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %628 = memref.load %assume_align[%arg0, %627, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %629 = vector.broadcast %628 : f32 to vector<8xf32>
    %630 = vector.fma %629, %615, %598 : vector<8xf32>
    %631 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %632 = memref.load %assume_align[%arg0, %631, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %633 = vector.broadcast %632 : f32 to vector<8xf32>
    %634 = vector.fma %633, %615, %602 : vector<8xf32>
    %635 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %636 = memref.load %assume_align[%arg0, %635, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %637 = vector.broadcast %636 : f32 to vector<8xf32>
    %638 = vector.fma %637, %615, %606 : vector<8xf32>
    %639 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %640 = memref.load %assume_align[%arg0, %639, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %641 = vector.broadcast %640 : f32 to vector<8xf32>
    %642 = vector.fma %641, %615, %610 : vector<8xf32>
    %643 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %644 = memref.load %assume_align[%arg0, %643, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %645 = vector.broadcast %644 : f32 to vector<8xf32>
    %646 = vector.fma %645, %615, %614 : vector<8xf32>
    %647 = vector.extract %38[19] : vector<8xf32> from vector<64x8xf32>
    %648 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %649 = vector.broadcast %648 : f32 to vector<8xf32>
    %650 = vector.fma %649, %647, %618 : vector<8xf32>
    %651 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %652 = memref.load %assume_align[%arg0, %651, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %653 = vector.broadcast %652 : f32 to vector<8xf32>
    %654 = vector.fma %653, %647, %622 : vector<8xf32>
    %655 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %656 = memref.load %assume_align[%arg0, %655, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %657 = vector.broadcast %656 : f32 to vector<8xf32>
    %658 = vector.fma %657, %647, %626 : vector<8xf32>
    %659 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %660 = memref.load %assume_align[%arg0, %659, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %661 = vector.broadcast %660 : f32 to vector<8xf32>
    %662 = vector.fma %661, %647, %630 : vector<8xf32>
    %663 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %664 = memref.load %assume_align[%arg0, %663, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %665 = vector.broadcast %664 : f32 to vector<8xf32>
    %666 = vector.fma %665, %647, %634 : vector<8xf32>
    %667 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %668 = memref.load %assume_align[%arg0, %667, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %669 = vector.broadcast %668 : f32 to vector<8xf32>
    %670 = vector.fma %669, %647, %638 : vector<8xf32>
    %671 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %672 = memref.load %assume_align[%arg0, %671, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %673 = vector.broadcast %672 : f32 to vector<8xf32>
    %674 = vector.fma %673, %647, %642 : vector<8xf32>
    %675 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %676 = memref.load %assume_align[%arg0, %675, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %677 = vector.broadcast %676 : f32 to vector<8xf32>
    %678 = vector.fma %677, %647, %646 : vector<8xf32>
    %679 = vector.extract %38[20] : vector<8xf32> from vector<64x8xf32>
    %680 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %681 = vector.broadcast %680 : f32 to vector<8xf32>
    %682 = vector.fma %681, %679, %650 : vector<8xf32>
    %683 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %684 = memref.load %assume_align[%arg0, %683, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %685 = vector.broadcast %684 : f32 to vector<8xf32>
    %686 = vector.fma %685, %679, %654 : vector<8xf32>
    %687 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %688 = memref.load %assume_align[%arg0, %687, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %689 = vector.broadcast %688 : f32 to vector<8xf32>
    %690 = vector.fma %689, %679, %658 : vector<8xf32>
    %691 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %692 = memref.load %assume_align[%arg0, %691, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %693 = vector.broadcast %692 : f32 to vector<8xf32>
    %694 = vector.fma %693, %679, %662 : vector<8xf32>
    %695 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %696 = memref.load %assume_align[%arg0, %695, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %697 = vector.broadcast %696 : f32 to vector<8xf32>
    %698 = vector.fma %697, %679, %666 : vector<8xf32>
    %699 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %700 = memref.load %assume_align[%arg0, %699, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %701 = vector.broadcast %700 : f32 to vector<8xf32>
    %702 = vector.fma %701, %679, %670 : vector<8xf32>
    %703 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %704 = memref.load %assume_align[%arg0, %703, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %705 = vector.broadcast %704 : f32 to vector<8xf32>
    %706 = vector.fma %705, %679, %674 : vector<8xf32>
    %707 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %708 = memref.load %assume_align[%arg0, %707, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %709 = vector.broadcast %708 : f32 to vector<8xf32>
    %710 = vector.fma %709, %679, %678 : vector<8xf32>
    %711 = vector.extract %38[21] : vector<8xf32> from vector<64x8xf32>
    %712 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %713 = vector.broadcast %712 : f32 to vector<8xf32>
    %714 = vector.fma %713, %711, %682 : vector<8xf32>
    %715 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %716 = memref.load %assume_align[%arg0, %715, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %717 = vector.broadcast %716 : f32 to vector<8xf32>
    %718 = vector.fma %717, %711, %686 : vector<8xf32>
    %719 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %720 = memref.load %assume_align[%arg0, %719, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %721 = vector.broadcast %720 : f32 to vector<8xf32>
    %722 = vector.fma %721, %711, %690 : vector<8xf32>
    %723 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %724 = memref.load %assume_align[%arg0, %723, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %725 = vector.broadcast %724 : f32 to vector<8xf32>
    %726 = vector.fma %725, %711, %694 : vector<8xf32>
    %727 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %728 = memref.load %assume_align[%arg0, %727, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %729 = vector.broadcast %728 : f32 to vector<8xf32>
    %730 = vector.fma %729, %711, %698 : vector<8xf32>
    %731 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %732 = memref.load %assume_align[%arg0, %731, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %733 = vector.broadcast %732 : f32 to vector<8xf32>
    %734 = vector.fma %733, %711, %702 : vector<8xf32>
    %735 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %736 = memref.load %assume_align[%arg0, %735, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %737 = vector.broadcast %736 : f32 to vector<8xf32>
    %738 = vector.fma %737, %711, %706 : vector<8xf32>
    %739 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %740 = memref.load %assume_align[%arg0, %739, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %741 = vector.broadcast %740 : f32 to vector<8xf32>
    %742 = vector.fma %741, %711, %710 : vector<8xf32>
    %743 = vector.extract %38[22] : vector<8xf32> from vector<64x8xf32>
    %744 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %745 = vector.broadcast %744 : f32 to vector<8xf32>
    %746 = vector.fma %745, %743, %714 : vector<8xf32>
    %747 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %748 = memref.load %assume_align[%arg0, %747, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %749 = vector.broadcast %748 : f32 to vector<8xf32>
    %750 = vector.fma %749, %743, %718 : vector<8xf32>
    %751 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %752 = memref.load %assume_align[%arg0, %751, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %753 = vector.broadcast %752 : f32 to vector<8xf32>
    %754 = vector.fma %753, %743, %722 : vector<8xf32>
    %755 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %756 = memref.load %assume_align[%arg0, %755, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %757 = vector.broadcast %756 : f32 to vector<8xf32>
    %758 = vector.fma %757, %743, %726 : vector<8xf32>
    %759 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %760 = memref.load %assume_align[%arg0, %759, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %761 = vector.broadcast %760 : f32 to vector<8xf32>
    %762 = vector.fma %761, %743, %730 : vector<8xf32>
    %763 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %764 = memref.load %assume_align[%arg0, %763, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %765 = vector.broadcast %764 : f32 to vector<8xf32>
    %766 = vector.fma %765, %743, %734 : vector<8xf32>
    %767 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %768 = memref.load %assume_align[%arg0, %767, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %769 = vector.broadcast %768 : f32 to vector<8xf32>
    %770 = vector.fma %769, %743, %738 : vector<8xf32>
    %771 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %772 = memref.load %assume_align[%arg0, %771, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %773 = vector.broadcast %772 : f32 to vector<8xf32>
    %774 = vector.fma %773, %743, %742 : vector<8xf32>
    %775 = vector.extract %38[23] : vector<8xf32> from vector<64x8xf32>
    %776 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %777 = vector.broadcast %776 : f32 to vector<8xf32>
    %778 = vector.fma %777, %775, %746 : vector<8xf32>
    %779 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %780 = memref.load %assume_align[%arg0, %779, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %781 = vector.broadcast %780 : f32 to vector<8xf32>
    %782 = vector.fma %781, %775, %750 : vector<8xf32>
    %783 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %784 = memref.load %assume_align[%arg0, %783, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %785 = vector.broadcast %784 : f32 to vector<8xf32>
    %786 = vector.fma %785, %775, %754 : vector<8xf32>
    %787 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %788 = memref.load %assume_align[%arg0, %787, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %789 = vector.broadcast %788 : f32 to vector<8xf32>
    %790 = vector.fma %789, %775, %758 : vector<8xf32>
    %791 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %792 = memref.load %assume_align[%arg0, %791, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %793 = vector.broadcast %792 : f32 to vector<8xf32>
    %794 = vector.fma %793, %775, %762 : vector<8xf32>
    %795 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %796 = memref.load %assume_align[%arg0, %795, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %797 = vector.broadcast %796 : f32 to vector<8xf32>
    %798 = vector.fma %797, %775, %766 : vector<8xf32>
    %799 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %800 = memref.load %assume_align[%arg0, %799, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %801 = vector.broadcast %800 : f32 to vector<8xf32>
    %802 = vector.fma %801, %775, %770 : vector<8xf32>
    %803 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %804 = memref.load %assume_align[%arg0, %803, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %805 = vector.broadcast %804 : f32 to vector<8xf32>
    %806 = vector.fma %805, %775, %774 : vector<8xf32>
    %807 = vector.extract %38[24] : vector<8xf32> from vector<64x8xf32>
    %808 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %809 = vector.broadcast %808 : f32 to vector<8xf32>
    %810 = vector.fma %809, %807, %778 : vector<8xf32>
    %811 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %812 = memref.load %assume_align[%arg0, %811, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %813 = vector.broadcast %812 : f32 to vector<8xf32>
    %814 = vector.fma %813, %807, %782 : vector<8xf32>
    %815 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %816 = memref.load %assume_align[%arg0, %815, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %817 = vector.broadcast %816 : f32 to vector<8xf32>
    %818 = vector.fma %817, %807, %786 : vector<8xf32>
    %819 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %820 = memref.load %assume_align[%arg0, %819, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %821 = vector.broadcast %820 : f32 to vector<8xf32>
    %822 = vector.fma %821, %807, %790 : vector<8xf32>
    %823 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %824 = memref.load %assume_align[%arg0, %823, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %825 = vector.broadcast %824 : f32 to vector<8xf32>
    %826 = vector.fma %825, %807, %794 : vector<8xf32>
    %827 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %828 = memref.load %assume_align[%arg0, %827, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %829 = vector.broadcast %828 : f32 to vector<8xf32>
    %830 = vector.fma %829, %807, %798 : vector<8xf32>
    %831 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %832 = memref.load %assume_align[%arg0, %831, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %833 = vector.broadcast %832 : f32 to vector<8xf32>
    %834 = vector.fma %833, %807, %802 : vector<8xf32>
    %835 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %836 = memref.load %assume_align[%arg0, %835, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %837 = vector.broadcast %836 : f32 to vector<8xf32>
    %838 = vector.fma %837, %807, %806 : vector<8xf32>
    %839 = vector.extract %38[25] : vector<8xf32> from vector<64x8xf32>
    %840 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %841 = vector.broadcast %840 : f32 to vector<8xf32>
    %842 = vector.fma %841, %839, %810 : vector<8xf32>
    %843 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %844 = memref.load %assume_align[%arg0, %843, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %845 = vector.broadcast %844 : f32 to vector<8xf32>
    %846 = vector.fma %845, %839, %814 : vector<8xf32>
    %847 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %848 = memref.load %assume_align[%arg0, %847, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %849 = vector.broadcast %848 : f32 to vector<8xf32>
    %850 = vector.fma %849, %839, %818 : vector<8xf32>
    %851 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %852 = memref.load %assume_align[%arg0, %851, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %853 = vector.broadcast %852 : f32 to vector<8xf32>
    %854 = vector.fma %853, %839, %822 : vector<8xf32>
    %855 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %856 = memref.load %assume_align[%arg0, %855, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %857 = vector.broadcast %856 : f32 to vector<8xf32>
    %858 = vector.fma %857, %839, %826 : vector<8xf32>
    %859 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %860 = memref.load %assume_align[%arg0, %859, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %861 = vector.broadcast %860 : f32 to vector<8xf32>
    %862 = vector.fma %861, %839, %830 : vector<8xf32>
    %863 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %864 = memref.load %assume_align[%arg0, %863, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %865 = vector.broadcast %864 : f32 to vector<8xf32>
    %866 = vector.fma %865, %839, %834 : vector<8xf32>
    %867 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %868 = memref.load %assume_align[%arg0, %867, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %869 = vector.broadcast %868 : f32 to vector<8xf32>
    %870 = vector.fma %869, %839, %838 : vector<8xf32>
    %871 = vector.extract %38[26] : vector<8xf32> from vector<64x8xf32>
    %872 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %873 = vector.broadcast %872 : f32 to vector<8xf32>
    %874 = vector.fma %873, %871, %842 : vector<8xf32>
    %875 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %876 = memref.load %assume_align[%arg0, %875, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %877 = vector.broadcast %876 : f32 to vector<8xf32>
    %878 = vector.fma %877, %871, %846 : vector<8xf32>
    %879 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %880 = memref.load %assume_align[%arg0, %879, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %881 = vector.broadcast %880 : f32 to vector<8xf32>
    %882 = vector.fma %881, %871, %850 : vector<8xf32>
    %883 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %884 = memref.load %assume_align[%arg0, %883, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %885 = vector.broadcast %884 : f32 to vector<8xf32>
    %886 = vector.fma %885, %871, %854 : vector<8xf32>
    %887 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %888 = memref.load %assume_align[%arg0, %887, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %889 = vector.broadcast %888 : f32 to vector<8xf32>
    %890 = vector.fma %889, %871, %858 : vector<8xf32>
    %891 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %892 = memref.load %assume_align[%arg0, %891, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %893 = vector.broadcast %892 : f32 to vector<8xf32>
    %894 = vector.fma %893, %871, %862 : vector<8xf32>
    %895 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %896 = memref.load %assume_align[%arg0, %895, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %897 = vector.broadcast %896 : f32 to vector<8xf32>
    %898 = vector.fma %897, %871, %866 : vector<8xf32>
    %899 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %900 = memref.load %assume_align[%arg0, %899, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %901 = vector.broadcast %900 : f32 to vector<8xf32>
    %902 = vector.fma %901, %871, %870 : vector<8xf32>
    %903 = vector.extract %38[27] : vector<8xf32> from vector<64x8xf32>
    %904 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %905 = vector.broadcast %904 : f32 to vector<8xf32>
    %906 = vector.fma %905, %903, %874 : vector<8xf32>
    %907 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %908 = memref.load %assume_align[%arg0, %907, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %909 = vector.broadcast %908 : f32 to vector<8xf32>
    %910 = vector.fma %909, %903, %878 : vector<8xf32>
    %911 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %912 = memref.load %assume_align[%arg0, %911, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %913 = vector.broadcast %912 : f32 to vector<8xf32>
    %914 = vector.fma %913, %903, %882 : vector<8xf32>
    %915 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %916 = memref.load %assume_align[%arg0, %915, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %917 = vector.broadcast %916 : f32 to vector<8xf32>
    %918 = vector.fma %917, %903, %886 : vector<8xf32>
    %919 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %920 = memref.load %assume_align[%arg0, %919, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %921 = vector.broadcast %920 : f32 to vector<8xf32>
    %922 = vector.fma %921, %903, %890 : vector<8xf32>
    %923 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %924 = memref.load %assume_align[%arg0, %923, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %925 = vector.broadcast %924 : f32 to vector<8xf32>
    %926 = vector.fma %925, %903, %894 : vector<8xf32>
    %927 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %928 = memref.load %assume_align[%arg0, %927, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %929 = vector.broadcast %928 : f32 to vector<8xf32>
    %930 = vector.fma %929, %903, %898 : vector<8xf32>
    %931 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %932 = memref.load %assume_align[%arg0, %931, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %933 = vector.broadcast %932 : f32 to vector<8xf32>
    %934 = vector.fma %933, %903, %902 : vector<8xf32>
    %935 = vector.extract %38[28] : vector<8xf32> from vector<64x8xf32>
    %936 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %937 = vector.broadcast %936 : f32 to vector<8xf32>
    %938 = vector.fma %937, %935, %906 : vector<8xf32>
    %939 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %940 = memref.load %assume_align[%arg0, %939, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %941 = vector.broadcast %940 : f32 to vector<8xf32>
    %942 = vector.fma %941, %935, %910 : vector<8xf32>
    %943 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %944 = memref.load %assume_align[%arg0, %943, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %945 = vector.broadcast %944 : f32 to vector<8xf32>
    %946 = vector.fma %945, %935, %914 : vector<8xf32>
    %947 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %948 = memref.load %assume_align[%arg0, %947, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %949 = vector.broadcast %948 : f32 to vector<8xf32>
    %950 = vector.fma %949, %935, %918 : vector<8xf32>
    %951 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %952 = memref.load %assume_align[%arg0, %951, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %953 = vector.broadcast %952 : f32 to vector<8xf32>
    %954 = vector.fma %953, %935, %922 : vector<8xf32>
    %955 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %956 = memref.load %assume_align[%arg0, %955, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %957 = vector.broadcast %956 : f32 to vector<8xf32>
    %958 = vector.fma %957, %935, %926 : vector<8xf32>
    %959 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %960 = memref.load %assume_align[%arg0, %959, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %961 = vector.broadcast %960 : f32 to vector<8xf32>
    %962 = vector.fma %961, %935, %930 : vector<8xf32>
    %963 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %964 = memref.load %assume_align[%arg0, %963, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %965 = vector.broadcast %964 : f32 to vector<8xf32>
    %966 = vector.fma %965, %935, %934 : vector<8xf32>
    %967 = vector.extract %38[29] : vector<8xf32> from vector<64x8xf32>
    %968 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %969 = vector.broadcast %968 : f32 to vector<8xf32>
    %970 = vector.fma %969, %967, %938 : vector<8xf32>
    %971 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %972 = memref.load %assume_align[%arg0, %971, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %973 = vector.broadcast %972 : f32 to vector<8xf32>
    %974 = vector.fma %973, %967, %942 : vector<8xf32>
    %975 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %976 = memref.load %assume_align[%arg0, %975, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %977 = vector.broadcast %976 : f32 to vector<8xf32>
    %978 = vector.fma %977, %967, %946 : vector<8xf32>
    %979 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %980 = memref.load %assume_align[%arg0, %979, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %981 = vector.broadcast %980 : f32 to vector<8xf32>
    %982 = vector.fma %981, %967, %950 : vector<8xf32>
    %983 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %984 = memref.load %assume_align[%arg0, %983, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %985 = vector.broadcast %984 : f32 to vector<8xf32>
    %986 = vector.fma %985, %967, %954 : vector<8xf32>
    %987 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %988 = memref.load %assume_align[%arg0, %987, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %989 = vector.broadcast %988 : f32 to vector<8xf32>
    %990 = vector.fma %989, %967, %958 : vector<8xf32>
    %991 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %992 = memref.load %assume_align[%arg0, %991, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %993 = vector.broadcast %992 : f32 to vector<8xf32>
    %994 = vector.fma %993, %967, %962 : vector<8xf32>
    %995 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %996 = memref.load %assume_align[%arg0, %995, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %997 = vector.broadcast %996 : f32 to vector<8xf32>
    %998 = vector.fma %997, %967, %966 : vector<8xf32>
    %999 = vector.extract %38[30] : vector<8xf32> from vector<64x8xf32>
    %1000 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1001 = vector.broadcast %1000 : f32 to vector<8xf32>
    %1002 = vector.fma %1001, %999, %970 : vector<8xf32>
    %1003 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1004 = memref.load %assume_align[%arg0, %1003, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1005 = vector.broadcast %1004 : f32 to vector<8xf32>
    %1006 = vector.fma %1005, %999, %974 : vector<8xf32>
    %1007 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1008 = memref.load %assume_align[%arg0, %1007, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1009 = vector.broadcast %1008 : f32 to vector<8xf32>
    %1010 = vector.fma %1009, %999, %978 : vector<8xf32>
    %1011 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1012 = memref.load %assume_align[%arg0, %1011, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1013 = vector.broadcast %1012 : f32 to vector<8xf32>
    %1014 = vector.fma %1013, %999, %982 : vector<8xf32>
    %1015 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1016 = memref.load %assume_align[%arg0, %1015, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1017 = vector.broadcast %1016 : f32 to vector<8xf32>
    %1018 = vector.fma %1017, %999, %986 : vector<8xf32>
    %1019 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1020 = memref.load %assume_align[%arg0, %1019, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1021 = vector.broadcast %1020 : f32 to vector<8xf32>
    %1022 = vector.fma %1021, %999, %990 : vector<8xf32>
    %1023 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1024 = memref.load %assume_align[%arg0, %1023, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1025 = vector.broadcast %1024 : f32 to vector<8xf32>
    %1026 = vector.fma %1025, %999, %994 : vector<8xf32>
    %1027 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1028 = memref.load %assume_align[%arg0, %1027, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1029 = vector.broadcast %1028 : f32 to vector<8xf32>
    %1030 = vector.fma %1029, %999, %998 : vector<8xf32>
    %1031 = vector.extract %38[31] : vector<8xf32> from vector<64x8xf32>
    %1032 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1033 = vector.broadcast %1032 : f32 to vector<8xf32>
    %1034 = vector.fma %1033, %1031, %1002 : vector<8xf32>
    %1035 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1036 = memref.load %assume_align[%arg0, %1035, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1037 = vector.broadcast %1036 : f32 to vector<8xf32>
    %1038 = vector.fma %1037, %1031, %1006 : vector<8xf32>
    %1039 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1040 = memref.load %assume_align[%arg0, %1039, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1041 = vector.broadcast %1040 : f32 to vector<8xf32>
    %1042 = vector.fma %1041, %1031, %1010 : vector<8xf32>
    %1043 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1044 = memref.load %assume_align[%arg0, %1043, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1045 = vector.broadcast %1044 : f32 to vector<8xf32>
    %1046 = vector.fma %1045, %1031, %1014 : vector<8xf32>
    %1047 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1048 = memref.load %assume_align[%arg0, %1047, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1049 = vector.broadcast %1048 : f32 to vector<8xf32>
    %1050 = vector.fma %1049, %1031, %1018 : vector<8xf32>
    %1051 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1052 = memref.load %assume_align[%arg0, %1051, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1053 = vector.broadcast %1052 : f32 to vector<8xf32>
    %1054 = vector.fma %1053, %1031, %1022 : vector<8xf32>
    %1055 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1056 = memref.load %assume_align[%arg0, %1055, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1057 = vector.broadcast %1056 : f32 to vector<8xf32>
    %1058 = vector.fma %1057, %1031, %1026 : vector<8xf32>
    %1059 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1060 = memref.load %assume_align[%arg0, %1059, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1061 = vector.broadcast %1060 : f32 to vector<8xf32>
    %1062 = vector.fma %1061, %1031, %1030 : vector<8xf32>
    %1063 = vector.extract %38[32] : vector<8xf32> from vector<64x8xf32>
    %1064 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1065 = vector.broadcast %1064 : f32 to vector<8xf32>
    %1066 = vector.fma %1065, %1063, %1034 : vector<8xf32>
    %1067 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1068 = memref.load %assume_align[%arg0, %1067, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1069 = vector.broadcast %1068 : f32 to vector<8xf32>
    %1070 = vector.fma %1069, %1063, %1038 : vector<8xf32>
    %1071 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1072 = memref.load %assume_align[%arg0, %1071, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1073 = vector.broadcast %1072 : f32 to vector<8xf32>
    %1074 = vector.fma %1073, %1063, %1042 : vector<8xf32>
    %1075 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1076 = memref.load %assume_align[%arg0, %1075, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1077 = vector.broadcast %1076 : f32 to vector<8xf32>
    %1078 = vector.fma %1077, %1063, %1046 : vector<8xf32>
    %1079 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1080 = memref.load %assume_align[%arg0, %1079, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1081 = vector.broadcast %1080 : f32 to vector<8xf32>
    %1082 = vector.fma %1081, %1063, %1050 : vector<8xf32>
    %1083 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1084 = memref.load %assume_align[%arg0, %1083, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1085 = vector.broadcast %1084 : f32 to vector<8xf32>
    %1086 = vector.fma %1085, %1063, %1054 : vector<8xf32>
    %1087 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1088 = memref.load %assume_align[%arg0, %1087, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1089 = vector.broadcast %1088 : f32 to vector<8xf32>
    %1090 = vector.fma %1089, %1063, %1058 : vector<8xf32>
    %1091 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1092 = memref.load %assume_align[%arg0, %1091, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1093 = vector.broadcast %1092 : f32 to vector<8xf32>
    %1094 = vector.fma %1093, %1063, %1062 : vector<8xf32>
    %1095 = vector.extract %38[33] : vector<8xf32> from vector<64x8xf32>
    %1096 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1097 = vector.broadcast %1096 : f32 to vector<8xf32>
    %1098 = vector.fma %1097, %1095, %1066 : vector<8xf32>
    %1099 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1100 = memref.load %assume_align[%arg0, %1099, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1101 = vector.broadcast %1100 : f32 to vector<8xf32>
    %1102 = vector.fma %1101, %1095, %1070 : vector<8xf32>
    %1103 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1104 = memref.load %assume_align[%arg0, %1103, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1105 = vector.broadcast %1104 : f32 to vector<8xf32>
    %1106 = vector.fma %1105, %1095, %1074 : vector<8xf32>
    %1107 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1108 = memref.load %assume_align[%arg0, %1107, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1109 = vector.broadcast %1108 : f32 to vector<8xf32>
    %1110 = vector.fma %1109, %1095, %1078 : vector<8xf32>
    %1111 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1112 = memref.load %assume_align[%arg0, %1111, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1113 = vector.broadcast %1112 : f32 to vector<8xf32>
    %1114 = vector.fma %1113, %1095, %1082 : vector<8xf32>
    %1115 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1116 = memref.load %assume_align[%arg0, %1115, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1117 = vector.broadcast %1116 : f32 to vector<8xf32>
    %1118 = vector.fma %1117, %1095, %1086 : vector<8xf32>
    %1119 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1120 = memref.load %assume_align[%arg0, %1119, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1121 = vector.broadcast %1120 : f32 to vector<8xf32>
    %1122 = vector.fma %1121, %1095, %1090 : vector<8xf32>
    %1123 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1124 = memref.load %assume_align[%arg0, %1123, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1125 = vector.broadcast %1124 : f32 to vector<8xf32>
    %1126 = vector.fma %1125, %1095, %1094 : vector<8xf32>
    %1127 = vector.extract %38[34] : vector<8xf32> from vector<64x8xf32>
    %1128 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1129 = vector.broadcast %1128 : f32 to vector<8xf32>
    %1130 = vector.fma %1129, %1127, %1098 : vector<8xf32>
    %1131 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1132 = memref.load %assume_align[%arg0, %1131, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1133 = vector.broadcast %1132 : f32 to vector<8xf32>
    %1134 = vector.fma %1133, %1127, %1102 : vector<8xf32>
    %1135 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1136 = memref.load %assume_align[%arg0, %1135, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1137 = vector.broadcast %1136 : f32 to vector<8xf32>
    %1138 = vector.fma %1137, %1127, %1106 : vector<8xf32>
    %1139 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1140 = memref.load %assume_align[%arg0, %1139, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1141 = vector.broadcast %1140 : f32 to vector<8xf32>
    %1142 = vector.fma %1141, %1127, %1110 : vector<8xf32>
    %1143 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1144 = memref.load %assume_align[%arg0, %1143, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1145 = vector.broadcast %1144 : f32 to vector<8xf32>
    %1146 = vector.fma %1145, %1127, %1114 : vector<8xf32>
    %1147 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1148 = memref.load %assume_align[%arg0, %1147, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1149 = vector.broadcast %1148 : f32 to vector<8xf32>
    %1150 = vector.fma %1149, %1127, %1118 : vector<8xf32>
    %1151 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1152 = memref.load %assume_align[%arg0, %1151, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1153 = vector.broadcast %1152 : f32 to vector<8xf32>
    %1154 = vector.fma %1153, %1127, %1122 : vector<8xf32>
    %1155 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1156 = memref.load %assume_align[%arg0, %1155, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1157 = vector.broadcast %1156 : f32 to vector<8xf32>
    %1158 = vector.fma %1157, %1127, %1126 : vector<8xf32>
    %1159 = vector.extract %38[35] : vector<8xf32> from vector<64x8xf32>
    %1160 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1161 = vector.broadcast %1160 : f32 to vector<8xf32>
    %1162 = vector.fma %1161, %1159, %1130 : vector<8xf32>
    %1163 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1164 = memref.load %assume_align[%arg0, %1163, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1165 = vector.broadcast %1164 : f32 to vector<8xf32>
    %1166 = vector.fma %1165, %1159, %1134 : vector<8xf32>
    %1167 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1168 = memref.load %assume_align[%arg0, %1167, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1169 = vector.broadcast %1168 : f32 to vector<8xf32>
    %1170 = vector.fma %1169, %1159, %1138 : vector<8xf32>
    %1171 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1172 = memref.load %assume_align[%arg0, %1171, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1173 = vector.broadcast %1172 : f32 to vector<8xf32>
    %1174 = vector.fma %1173, %1159, %1142 : vector<8xf32>
    %1175 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1176 = memref.load %assume_align[%arg0, %1175, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1177 = vector.broadcast %1176 : f32 to vector<8xf32>
    %1178 = vector.fma %1177, %1159, %1146 : vector<8xf32>
    %1179 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1180 = memref.load %assume_align[%arg0, %1179, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1181 = vector.broadcast %1180 : f32 to vector<8xf32>
    %1182 = vector.fma %1181, %1159, %1150 : vector<8xf32>
    %1183 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1184 = memref.load %assume_align[%arg0, %1183, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1185 = vector.broadcast %1184 : f32 to vector<8xf32>
    %1186 = vector.fma %1185, %1159, %1154 : vector<8xf32>
    %1187 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1188 = memref.load %assume_align[%arg0, %1187, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1189 = vector.broadcast %1188 : f32 to vector<8xf32>
    %1190 = vector.fma %1189, %1159, %1158 : vector<8xf32>
    %1191 = vector.extract %38[36] : vector<8xf32> from vector<64x8xf32>
    %1192 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1193 = vector.broadcast %1192 : f32 to vector<8xf32>
    %1194 = vector.fma %1193, %1191, %1162 : vector<8xf32>
    %1195 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1196 = memref.load %assume_align[%arg0, %1195, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1197 = vector.broadcast %1196 : f32 to vector<8xf32>
    %1198 = vector.fma %1197, %1191, %1166 : vector<8xf32>
    %1199 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1200 = memref.load %assume_align[%arg0, %1199, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1201 = vector.broadcast %1200 : f32 to vector<8xf32>
    %1202 = vector.fma %1201, %1191, %1170 : vector<8xf32>
    %1203 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1204 = memref.load %assume_align[%arg0, %1203, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1205 = vector.broadcast %1204 : f32 to vector<8xf32>
    %1206 = vector.fma %1205, %1191, %1174 : vector<8xf32>
    %1207 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1208 = memref.load %assume_align[%arg0, %1207, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1209 = vector.broadcast %1208 : f32 to vector<8xf32>
    %1210 = vector.fma %1209, %1191, %1178 : vector<8xf32>
    %1211 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1212 = memref.load %assume_align[%arg0, %1211, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1213 = vector.broadcast %1212 : f32 to vector<8xf32>
    %1214 = vector.fma %1213, %1191, %1182 : vector<8xf32>
    %1215 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1216 = memref.load %assume_align[%arg0, %1215, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1217 = vector.broadcast %1216 : f32 to vector<8xf32>
    %1218 = vector.fma %1217, %1191, %1186 : vector<8xf32>
    %1219 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1220 = memref.load %assume_align[%arg0, %1219, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1221 = vector.broadcast %1220 : f32 to vector<8xf32>
    %1222 = vector.fma %1221, %1191, %1190 : vector<8xf32>
    %1223 = vector.extract %38[37] : vector<8xf32> from vector<64x8xf32>
    %1224 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1225 = vector.broadcast %1224 : f32 to vector<8xf32>
    %1226 = vector.fma %1225, %1223, %1194 : vector<8xf32>
    %1227 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1228 = memref.load %assume_align[%arg0, %1227, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1229 = vector.broadcast %1228 : f32 to vector<8xf32>
    %1230 = vector.fma %1229, %1223, %1198 : vector<8xf32>
    %1231 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1232 = memref.load %assume_align[%arg0, %1231, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1233 = vector.broadcast %1232 : f32 to vector<8xf32>
    %1234 = vector.fma %1233, %1223, %1202 : vector<8xf32>
    %1235 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1236 = memref.load %assume_align[%arg0, %1235, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1237 = vector.broadcast %1236 : f32 to vector<8xf32>
    %1238 = vector.fma %1237, %1223, %1206 : vector<8xf32>
    %1239 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1240 = memref.load %assume_align[%arg0, %1239, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1241 = vector.broadcast %1240 : f32 to vector<8xf32>
    %1242 = vector.fma %1241, %1223, %1210 : vector<8xf32>
    %1243 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1244 = memref.load %assume_align[%arg0, %1243, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1245 = vector.broadcast %1244 : f32 to vector<8xf32>
    %1246 = vector.fma %1245, %1223, %1214 : vector<8xf32>
    %1247 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1248 = memref.load %assume_align[%arg0, %1247, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1249 = vector.broadcast %1248 : f32 to vector<8xf32>
    %1250 = vector.fma %1249, %1223, %1218 : vector<8xf32>
    %1251 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1252 = memref.load %assume_align[%arg0, %1251, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1253 = vector.broadcast %1252 : f32 to vector<8xf32>
    %1254 = vector.fma %1253, %1223, %1222 : vector<8xf32>
    %1255 = vector.extract %38[38] : vector<8xf32> from vector<64x8xf32>
    %1256 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1257 = vector.broadcast %1256 : f32 to vector<8xf32>
    %1258 = vector.fma %1257, %1255, %1226 : vector<8xf32>
    %1259 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1260 = memref.load %assume_align[%arg0, %1259, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1261 = vector.broadcast %1260 : f32 to vector<8xf32>
    %1262 = vector.fma %1261, %1255, %1230 : vector<8xf32>
    %1263 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1264 = memref.load %assume_align[%arg0, %1263, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1265 = vector.broadcast %1264 : f32 to vector<8xf32>
    %1266 = vector.fma %1265, %1255, %1234 : vector<8xf32>
    %1267 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1268 = memref.load %assume_align[%arg0, %1267, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1269 = vector.broadcast %1268 : f32 to vector<8xf32>
    %1270 = vector.fma %1269, %1255, %1238 : vector<8xf32>
    %1271 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1272 = memref.load %assume_align[%arg0, %1271, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1273 = vector.broadcast %1272 : f32 to vector<8xf32>
    %1274 = vector.fma %1273, %1255, %1242 : vector<8xf32>
    %1275 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1276 = memref.load %assume_align[%arg0, %1275, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1277 = vector.broadcast %1276 : f32 to vector<8xf32>
    %1278 = vector.fma %1277, %1255, %1246 : vector<8xf32>
    %1279 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1280 = memref.load %assume_align[%arg0, %1279, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1281 = vector.broadcast %1280 : f32 to vector<8xf32>
    %1282 = vector.fma %1281, %1255, %1250 : vector<8xf32>
    %1283 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1284 = memref.load %assume_align[%arg0, %1283, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1285 = vector.broadcast %1284 : f32 to vector<8xf32>
    %1286 = vector.fma %1285, %1255, %1254 : vector<8xf32>
    %1287 = vector.extract %38[39] : vector<8xf32> from vector<64x8xf32>
    %1288 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1289 = vector.broadcast %1288 : f32 to vector<8xf32>
    %1290 = vector.fma %1289, %1287, %1258 : vector<8xf32>
    %1291 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1292 = memref.load %assume_align[%arg0, %1291, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1293 = vector.broadcast %1292 : f32 to vector<8xf32>
    %1294 = vector.fma %1293, %1287, %1262 : vector<8xf32>
    %1295 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1296 = memref.load %assume_align[%arg0, %1295, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1297 = vector.broadcast %1296 : f32 to vector<8xf32>
    %1298 = vector.fma %1297, %1287, %1266 : vector<8xf32>
    %1299 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1300 = memref.load %assume_align[%arg0, %1299, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1301 = vector.broadcast %1300 : f32 to vector<8xf32>
    %1302 = vector.fma %1301, %1287, %1270 : vector<8xf32>
    %1303 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1304 = memref.load %assume_align[%arg0, %1303, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1305 = vector.broadcast %1304 : f32 to vector<8xf32>
    %1306 = vector.fma %1305, %1287, %1274 : vector<8xf32>
    %1307 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1308 = memref.load %assume_align[%arg0, %1307, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1309 = vector.broadcast %1308 : f32 to vector<8xf32>
    %1310 = vector.fma %1309, %1287, %1278 : vector<8xf32>
    %1311 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1312 = memref.load %assume_align[%arg0, %1311, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1313 = vector.broadcast %1312 : f32 to vector<8xf32>
    %1314 = vector.fma %1313, %1287, %1282 : vector<8xf32>
    %1315 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1316 = memref.load %assume_align[%arg0, %1315, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1317 = vector.broadcast %1316 : f32 to vector<8xf32>
    %1318 = vector.fma %1317, %1287, %1286 : vector<8xf32>
    %1319 = vector.extract %38[40] : vector<8xf32> from vector<64x8xf32>
    %1320 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1321 = vector.broadcast %1320 : f32 to vector<8xf32>
    %1322 = vector.fma %1321, %1319, %1290 : vector<8xf32>
    %1323 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1324 = memref.load %assume_align[%arg0, %1323, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1325 = vector.broadcast %1324 : f32 to vector<8xf32>
    %1326 = vector.fma %1325, %1319, %1294 : vector<8xf32>
    %1327 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1328 = memref.load %assume_align[%arg0, %1327, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1329 = vector.broadcast %1328 : f32 to vector<8xf32>
    %1330 = vector.fma %1329, %1319, %1298 : vector<8xf32>
    %1331 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1332 = memref.load %assume_align[%arg0, %1331, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1333 = vector.broadcast %1332 : f32 to vector<8xf32>
    %1334 = vector.fma %1333, %1319, %1302 : vector<8xf32>
    %1335 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1336 = memref.load %assume_align[%arg0, %1335, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1337 = vector.broadcast %1336 : f32 to vector<8xf32>
    %1338 = vector.fma %1337, %1319, %1306 : vector<8xf32>
    %1339 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1340 = memref.load %assume_align[%arg0, %1339, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1341 = vector.broadcast %1340 : f32 to vector<8xf32>
    %1342 = vector.fma %1341, %1319, %1310 : vector<8xf32>
    %1343 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1344 = memref.load %assume_align[%arg0, %1343, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1345 = vector.broadcast %1344 : f32 to vector<8xf32>
    %1346 = vector.fma %1345, %1319, %1314 : vector<8xf32>
    %1347 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1348 = memref.load %assume_align[%arg0, %1347, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1349 = vector.broadcast %1348 : f32 to vector<8xf32>
    %1350 = vector.fma %1349, %1319, %1318 : vector<8xf32>
    %1351 = vector.extract %38[41] : vector<8xf32> from vector<64x8xf32>
    %1352 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1353 = vector.broadcast %1352 : f32 to vector<8xf32>
    %1354 = vector.fma %1353, %1351, %1322 : vector<8xf32>
    %1355 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1356 = memref.load %assume_align[%arg0, %1355, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1357 = vector.broadcast %1356 : f32 to vector<8xf32>
    %1358 = vector.fma %1357, %1351, %1326 : vector<8xf32>
    %1359 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1360 = memref.load %assume_align[%arg0, %1359, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1361 = vector.broadcast %1360 : f32 to vector<8xf32>
    %1362 = vector.fma %1361, %1351, %1330 : vector<8xf32>
    %1363 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1364 = memref.load %assume_align[%arg0, %1363, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1365 = vector.broadcast %1364 : f32 to vector<8xf32>
    %1366 = vector.fma %1365, %1351, %1334 : vector<8xf32>
    %1367 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1368 = memref.load %assume_align[%arg0, %1367, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1369 = vector.broadcast %1368 : f32 to vector<8xf32>
    %1370 = vector.fma %1369, %1351, %1338 : vector<8xf32>
    %1371 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1372 = memref.load %assume_align[%arg0, %1371, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1373 = vector.broadcast %1372 : f32 to vector<8xf32>
    %1374 = vector.fma %1373, %1351, %1342 : vector<8xf32>
    %1375 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1376 = memref.load %assume_align[%arg0, %1375, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1377 = vector.broadcast %1376 : f32 to vector<8xf32>
    %1378 = vector.fma %1377, %1351, %1346 : vector<8xf32>
    %1379 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1380 = memref.load %assume_align[%arg0, %1379, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1381 = vector.broadcast %1380 : f32 to vector<8xf32>
    %1382 = vector.fma %1381, %1351, %1350 : vector<8xf32>
    %1383 = vector.extract %38[42] : vector<8xf32> from vector<64x8xf32>
    %1384 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1385 = vector.broadcast %1384 : f32 to vector<8xf32>
    %1386 = vector.fma %1385, %1383, %1354 : vector<8xf32>
    %1387 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1388 = memref.load %assume_align[%arg0, %1387, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1389 = vector.broadcast %1388 : f32 to vector<8xf32>
    %1390 = vector.fma %1389, %1383, %1358 : vector<8xf32>
    %1391 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1392 = memref.load %assume_align[%arg0, %1391, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1393 = vector.broadcast %1392 : f32 to vector<8xf32>
    %1394 = vector.fma %1393, %1383, %1362 : vector<8xf32>
    %1395 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1396 = memref.load %assume_align[%arg0, %1395, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1397 = vector.broadcast %1396 : f32 to vector<8xf32>
    %1398 = vector.fma %1397, %1383, %1366 : vector<8xf32>
    %1399 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1400 = memref.load %assume_align[%arg0, %1399, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1401 = vector.broadcast %1400 : f32 to vector<8xf32>
    %1402 = vector.fma %1401, %1383, %1370 : vector<8xf32>
    %1403 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1404 = memref.load %assume_align[%arg0, %1403, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1405 = vector.broadcast %1404 : f32 to vector<8xf32>
    %1406 = vector.fma %1405, %1383, %1374 : vector<8xf32>
    %1407 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1408 = memref.load %assume_align[%arg0, %1407, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1409 = vector.broadcast %1408 : f32 to vector<8xf32>
    %1410 = vector.fma %1409, %1383, %1378 : vector<8xf32>
    %1411 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1412 = memref.load %assume_align[%arg0, %1411, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1413 = vector.broadcast %1412 : f32 to vector<8xf32>
    %1414 = vector.fma %1413, %1383, %1382 : vector<8xf32>
    %1415 = vector.extract %38[43] : vector<8xf32> from vector<64x8xf32>
    %1416 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1417 = vector.broadcast %1416 : f32 to vector<8xf32>
    %1418 = vector.fma %1417, %1415, %1386 : vector<8xf32>
    %1419 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1420 = memref.load %assume_align[%arg0, %1419, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1421 = vector.broadcast %1420 : f32 to vector<8xf32>
    %1422 = vector.fma %1421, %1415, %1390 : vector<8xf32>
    %1423 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1424 = memref.load %assume_align[%arg0, %1423, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1425 = vector.broadcast %1424 : f32 to vector<8xf32>
    %1426 = vector.fma %1425, %1415, %1394 : vector<8xf32>
    %1427 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1428 = memref.load %assume_align[%arg0, %1427, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1429 = vector.broadcast %1428 : f32 to vector<8xf32>
    %1430 = vector.fma %1429, %1415, %1398 : vector<8xf32>
    %1431 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1432 = memref.load %assume_align[%arg0, %1431, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1433 = vector.broadcast %1432 : f32 to vector<8xf32>
    %1434 = vector.fma %1433, %1415, %1402 : vector<8xf32>
    %1435 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1436 = memref.load %assume_align[%arg0, %1435, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1437 = vector.broadcast %1436 : f32 to vector<8xf32>
    %1438 = vector.fma %1437, %1415, %1406 : vector<8xf32>
    %1439 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1440 = memref.load %assume_align[%arg0, %1439, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1441 = vector.broadcast %1440 : f32 to vector<8xf32>
    %1442 = vector.fma %1441, %1415, %1410 : vector<8xf32>
    %1443 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1444 = memref.load %assume_align[%arg0, %1443, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1445 = vector.broadcast %1444 : f32 to vector<8xf32>
    %1446 = vector.fma %1445, %1415, %1414 : vector<8xf32>
    %1447 = vector.extract %38[44] : vector<8xf32> from vector<64x8xf32>
    %1448 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1449 = vector.broadcast %1448 : f32 to vector<8xf32>
    %1450 = vector.fma %1449, %1447, %1418 : vector<8xf32>
    %1451 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1452 = memref.load %assume_align[%arg0, %1451, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1453 = vector.broadcast %1452 : f32 to vector<8xf32>
    %1454 = vector.fma %1453, %1447, %1422 : vector<8xf32>
    %1455 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1456 = memref.load %assume_align[%arg0, %1455, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1457 = vector.broadcast %1456 : f32 to vector<8xf32>
    %1458 = vector.fma %1457, %1447, %1426 : vector<8xf32>
    %1459 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1460 = memref.load %assume_align[%arg0, %1459, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1461 = vector.broadcast %1460 : f32 to vector<8xf32>
    %1462 = vector.fma %1461, %1447, %1430 : vector<8xf32>
    %1463 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1464 = memref.load %assume_align[%arg0, %1463, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1465 = vector.broadcast %1464 : f32 to vector<8xf32>
    %1466 = vector.fma %1465, %1447, %1434 : vector<8xf32>
    %1467 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1468 = memref.load %assume_align[%arg0, %1467, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1469 = vector.broadcast %1468 : f32 to vector<8xf32>
    %1470 = vector.fma %1469, %1447, %1438 : vector<8xf32>
    %1471 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1472 = memref.load %assume_align[%arg0, %1471, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1473 = vector.broadcast %1472 : f32 to vector<8xf32>
    %1474 = vector.fma %1473, %1447, %1442 : vector<8xf32>
    %1475 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1476 = memref.load %assume_align[%arg0, %1475, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1477 = vector.broadcast %1476 : f32 to vector<8xf32>
    %1478 = vector.fma %1477, %1447, %1446 : vector<8xf32>
    %1479 = vector.extract %38[45] : vector<8xf32> from vector<64x8xf32>
    %1480 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1481 = vector.broadcast %1480 : f32 to vector<8xf32>
    %1482 = vector.fma %1481, %1479, %1450 : vector<8xf32>
    %1483 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1484 = memref.load %assume_align[%arg0, %1483, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1485 = vector.broadcast %1484 : f32 to vector<8xf32>
    %1486 = vector.fma %1485, %1479, %1454 : vector<8xf32>
    %1487 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1488 = memref.load %assume_align[%arg0, %1487, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1489 = vector.broadcast %1488 : f32 to vector<8xf32>
    %1490 = vector.fma %1489, %1479, %1458 : vector<8xf32>
    %1491 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1492 = memref.load %assume_align[%arg0, %1491, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1493 = vector.broadcast %1492 : f32 to vector<8xf32>
    %1494 = vector.fma %1493, %1479, %1462 : vector<8xf32>
    %1495 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1496 = memref.load %assume_align[%arg0, %1495, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1497 = vector.broadcast %1496 : f32 to vector<8xf32>
    %1498 = vector.fma %1497, %1479, %1466 : vector<8xf32>
    %1499 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1500 = memref.load %assume_align[%arg0, %1499, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1501 = vector.broadcast %1500 : f32 to vector<8xf32>
    %1502 = vector.fma %1501, %1479, %1470 : vector<8xf32>
    %1503 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1504 = memref.load %assume_align[%arg0, %1503, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1505 = vector.broadcast %1504 : f32 to vector<8xf32>
    %1506 = vector.fma %1505, %1479, %1474 : vector<8xf32>
    %1507 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1508 = memref.load %assume_align[%arg0, %1507, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1509 = vector.broadcast %1508 : f32 to vector<8xf32>
    %1510 = vector.fma %1509, %1479, %1478 : vector<8xf32>
    %1511 = vector.extract %38[46] : vector<8xf32> from vector<64x8xf32>
    %1512 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1513 = vector.broadcast %1512 : f32 to vector<8xf32>
    %1514 = vector.fma %1513, %1511, %1482 : vector<8xf32>
    %1515 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1516 = memref.load %assume_align[%arg0, %1515, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1517 = vector.broadcast %1516 : f32 to vector<8xf32>
    %1518 = vector.fma %1517, %1511, %1486 : vector<8xf32>
    %1519 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1520 = memref.load %assume_align[%arg0, %1519, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1521 = vector.broadcast %1520 : f32 to vector<8xf32>
    %1522 = vector.fma %1521, %1511, %1490 : vector<8xf32>
    %1523 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1524 = memref.load %assume_align[%arg0, %1523, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1525 = vector.broadcast %1524 : f32 to vector<8xf32>
    %1526 = vector.fma %1525, %1511, %1494 : vector<8xf32>
    %1527 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1528 = memref.load %assume_align[%arg0, %1527, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1529 = vector.broadcast %1528 : f32 to vector<8xf32>
    %1530 = vector.fma %1529, %1511, %1498 : vector<8xf32>
    %1531 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1532 = memref.load %assume_align[%arg0, %1531, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1533 = vector.broadcast %1532 : f32 to vector<8xf32>
    %1534 = vector.fma %1533, %1511, %1502 : vector<8xf32>
    %1535 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1536 = memref.load %assume_align[%arg0, %1535, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1537 = vector.broadcast %1536 : f32 to vector<8xf32>
    %1538 = vector.fma %1537, %1511, %1506 : vector<8xf32>
    %1539 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1540 = memref.load %assume_align[%arg0, %1539, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1541 = vector.broadcast %1540 : f32 to vector<8xf32>
    %1542 = vector.fma %1541, %1511, %1510 : vector<8xf32>
    %1543 = vector.extract %38[47] : vector<8xf32> from vector<64x8xf32>
    %1544 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1545 = vector.broadcast %1544 : f32 to vector<8xf32>
    %1546 = vector.fma %1545, %1543, %1514 : vector<8xf32>
    %1547 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1548 = memref.load %assume_align[%arg0, %1547, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1549 = vector.broadcast %1548 : f32 to vector<8xf32>
    %1550 = vector.fma %1549, %1543, %1518 : vector<8xf32>
    %1551 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1552 = memref.load %assume_align[%arg0, %1551, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1553 = vector.broadcast %1552 : f32 to vector<8xf32>
    %1554 = vector.fma %1553, %1543, %1522 : vector<8xf32>
    %1555 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1556 = memref.load %assume_align[%arg0, %1555, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1557 = vector.broadcast %1556 : f32 to vector<8xf32>
    %1558 = vector.fma %1557, %1543, %1526 : vector<8xf32>
    %1559 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1560 = memref.load %assume_align[%arg0, %1559, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1561 = vector.broadcast %1560 : f32 to vector<8xf32>
    %1562 = vector.fma %1561, %1543, %1530 : vector<8xf32>
    %1563 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1564 = memref.load %assume_align[%arg0, %1563, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1565 = vector.broadcast %1564 : f32 to vector<8xf32>
    %1566 = vector.fma %1565, %1543, %1534 : vector<8xf32>
    %1567 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1568 = memref.load %assume_align[%arg0, %1567, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1569 = vector.broadcast %1568 : f32 to vector<8xf32>
    %1570 = vector.fma %1569, %1543, %1538 : vector<8xf32>
    %1571 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1572 = memref.load %assume_align[%arg0, %1571, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1573 = vector.broadcast %1572 : f32 to vector<8xf32>
    %1574 = vector.fma %1573, %1543, %1542 : vector<8xf32>
    %1575 = vector.extract %38[48] : vector<8xf32> from vector<64x8xf32>
    %1576 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1577 = vector.broadcast %1576 : f32 to vector<8xf32>
    %1578 = vector.fma %1577, %1575, %1546 : vector<8xf32>
    %1579 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1580 = memref.load %assume_align[%arg0, %1579, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1581 = vector.broadcast %1580 : f32 to vector<8xf32>
    %1582 = vector.fma %1581, %1575, %1550 : vector<8xf32>
    %1583 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1584 = memref.load %assume_align[%arg0, %1583, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1585 = vector.broadcast %1584 : f32 to vector<8xf32>
    %1586 = vector.fma %1585, %1575, %1554 : vector<8xf32>
    %1587 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1588 = memref.load %assume_align[%arg0, %1587, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1589 = vector.broadcast %1588 : f32 to vector<8xf32>
    %1590 = vector.fma %1589, %1575, %1558 : vector<8xf32>
    %1591 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1592 = memref.load %assume_align[%arg0, %1591, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1593 = vector.broadcast %1592 : f32 to vector<8xf32>
    %1594 = vector.fma %1593, %1575, %1562 : vector<8xf32>
    %1595 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1596 = memref.load %assume_align[%arg0, %1595, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1597 = vector.broadcast %1596 : f32 to vector<8xf32>
    %1598 = vector.fma %1597, %1575, %1566 : vector<8xf32>
    %1599 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1600 = memref.load %assume_align[%arg0, %1599, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1601 = vector.broadcast %1600 : f32 to vector<8xf32>
    %1602 = vector.fma %1601, %1575, %1570 : vector<8xf32>
    %1603 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1604 = memref.load %assume_align[%arg0, %1603, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1605 = vector.broadcast %1604 : f32 to vector<8xf32>
    %1606 = vector.fma %1605, %1575, %1574 : vector<8xf32>
    %1607 = vector.extract %38[49] : vector<8xf32> from vector<64x8xf32>
    %1608 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1609 = vector.broadcast %1608 : f32 to vector<8xf32>
    %1610 = vector.fma %1609, %1607, %1578 : vector<8xf32>
    %1611 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1612 = memref.load %assume_align[%arg0, %1611, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1613 = vector.broadcast %1612 : f32 to vector<8xf32>
    %1614 = vector.fma %1613, %1607, %1582 : vector<8xf32>
    %1615 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1616 = memref.load %assume_align[%arg0, %1615, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1617 = vector.broadcast %1616 : f32 to vector<8xf32>
    %1618 = vector.fma %1617, %1607, %1586 : vector<8xf32>
    %1619 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1620 = memref.load %assume_align[%arg0, %1619, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1621 = vector.broadcast %1620 : f32 to vector<8xf32>
    %1622 = vector.fma %1621, %1607, %1590 : vector<8xf32>
    %1623 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1624 = memref.load %assume_align[%arg0, %1623, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1625 = vector.broadcast %1624 : f32 to vector<8xf32>
    %1626 = vector.fma %1625, %1607, %1594 : vector<8xf32>
    %1627 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1628 = memref.load %assume_align[%arg0, %1627, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1629 = vector.broadcast %1628 : f32 to vector<8xf32>
    %1630 = vector.fma %1629, %1607, %1598 : vector<8xf32>
    %1631 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1632 = memref.load %assume_align[%arg0, %1631, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1633 = vector.broadcast %1632 : f32 to vector<8xf32>
    %1634 = vector.fma %1633, %1607, %1602 : vector<8xf32>
    %1635 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1636 = memref.load %assume_align[%arg0, %1635, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1637 = vector.broadcast %1636 : f32 to vector<8xf32>
    %1638 = vector.fma %1637, %1607, %1606 : vector<8xf32>
    %1639 = vector.extract %38[50] : vector<8xf32> from vector<64x8xf32>
    %1640 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1641 = vector.broadcast %1640 : f32 to vector<8xf32>
    %1642 = vector.fma %1641, %1639, %1610 : vector<8xf32>
    %1643 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1644 = memref.load %assume_align[%arg0, %1643, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1645 = vector.broadcast %1644 : f32 to vector<8xf32>
    %1646 = vector.fma %1645, %1639, %1614 : vector<8xf32>
    %1647 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1648 = memref.load %assume_align[%arg0, %1647, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1649 = vector.broadcast %1648 : f32 to vector<8xf32>
    %1650 = vector.fma %1649, %1639, %1618 : vector<8xf32>
    %1651 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1652 = memref.load %assume_align[%arg0, %1651, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1653 = vector.broadcast %1652 : f32 to vector<8xf32>
    %1654 = vector.fma %1653, %1639, %1622 : vector<8xf32>
    %1655 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1656 = memref.load %assume_align[%arg0, %1655, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1657 = vector.broadcast %1656 : f32 to vector<8xf32>
    %1658 = vector.fma %1657, %1639, %1626 : vector<8xf32>
    %1659 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1660 = memref.load %assume_align[%arg0, %1659, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1661 = vector.broadcast %1660 : f32 to vector<8xf32>
    %1662 = vector.fma %1661, %1639, %1630 : vector<8xf32>
    %1663 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1664 = memref.load %assume_align[%arg0, %1663, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1665 = vector.broadcast %1664 : f32 to vector<8xf32>
    %1666 = vector.fma %1665, %1639, %1634 : vector<8xf32>
    %1667 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1668 = memref.load %assume_align[%arg0, %1667, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1669 = vector.broadcast %1668 : f32 to vector<8xf32>
    %1670 = vector.fma %1669, %1639, %1638 : vector<8xf32>
    %1671 = vector.extract %38[51] : vector<8xf32> from vector<64x8xf32>
    %1672 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1673 = vector.broadcast %1672 : f32 to vector<8xf32>
    %1674 = vector.fma %1673, %1671, %1642 : vector<8xf32>
    %1675 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1676 = memref.load %assume_align[%arg0, %1675, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1677 = vector.broadcast %1676 : f32 to vector<8xf32>
    %1678 = vector.fma %1677, %1671, %1646 : vector<8xf32>
    %1679 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1680 = memref.load %assume_align[%arg0, %1679, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1681 = vector.broadcast %1680 : f32 to vector<8xf32>
    %1682 = vector.fma %1681, %1671, %1650 : vector<8xf32>
    %1683 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1684 = memref.load %assume_align[%arg0, %1683, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1685 = vector.broadcast %1684 : f32 to vector<8xf32>
    %1686 = vector.fma %1685, %1671, %1654 : vector<8xf32>
    %1687 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1688 = memref.load %assume_align[%arg0, %1687, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1689 = vector.broadcast %1688 : f32 to vector<8xf32>
    %1690 = vector.fma %1689, %1671, %1658 : vector<8xf32>
    %1691 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1692 = memref.load %assume_align[%arg0, %1691, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1693 = vector.broadcast %1692 : f32 to vector<8xf32>
    %1694 = vector.fma %1693, %1671, %1662 : vector<8xf32>
    %1695 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1696 = memref.load %assume_align[%arg0, %1695, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1697 = vector.broadcast %1696 : f32 to vector<8xf32>
    %1698 = vector.fma %1697, %1671, %1666 : vector<8xf32>
    %1699 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1700 = memref.load %assume_align[%arg0, %1699, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1701 = vector.broadcast %1700 : f32 to vector<8xf32>
    %1702 = vector.fma %1701, %1671, %1670 : vector<8xf32>
    %1703 = vector.extract %38[52] : vector<8xf32> from vector<64x8xf32>
    %1704 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1705 = vector.broadcast %1704 : f32 to vector<8xf32>
    %1706 = vector.fma %1705, %1703, %1674 : vector<8xf32>
    %1707 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1708 = memref.load %assume_align[%arg0, %1707, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1709 = vector.broadcast %1708 : f32 to vector<8xf32>
    %1710 = vector.fma %1709, %1703, %1678 : vector<8xf32>
    %1711 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1712 = memref.load %assume_align[%arg0, %1711, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1713 = vector.broadcast %1712 : f32 to vector<8xf32>
    %1714 = vector.fma %1713, %1703, %1682 : vector<8xf32>
    %1715 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1716 = memref.load %assume_align[%arg0, %1715, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1717 = vector.broadcast %1716 : f32 to vector<8xf32>
    %1718 = vector.fma %1717, %1703, %1686 : vector<8xf32>
    %1719 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1720 = memref.load %assume_align[%arg0, %1719, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1721 = vector.broadcast %1720 : f32 to vector<8xf32>
    %1722 = vector.fma %1721, %1703, %1690 : vector<8xf32>
    %1723 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1724 = memref.load %assume_align[%arg0, %1723, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1725 = vector.broadcast %1724 : f32 to vector<8xf32>
    %1726 = vector.fma %1725, %1703, %1694 : vector<8xf32>
    %1727 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1728 = memref.load %assume_align[%arg0, %1727, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1729 = vector.broadcast %1728 : f32 to vector<8xf32>
    %1730 = vector.fma %1729, %1703, %1698 : vector<8xf32>
    %1731 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1732 = memref.load %assume_align[%arg0, %1731, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1733 = vector.broadcast %1732 : f32 to vector<8xf32>
    %1734 = vector.fma %1733, %1703, %1702 : vector<8xf32>
    %1735 = vector.extract %38[53] : vector<8xf32> from vector<64x8xf32>
    %1736 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1737 = vector.broadcast %1736 : f32 to vector<8xf32>
    %1738 = vector.fma %1737, %1735, %1706 : vector<8xf32>
    %1739 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1740 = memref.load %assume_align[%arg0, %1739, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1741 = vector.broadcast %1740 : f32 to vector<8xf32>
    %1742 = vector.fma %1741, %1735, %1710 : vector<8xf32>
    %1743 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1744 = memref.load %assume_align[%arg0, %1743, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1745 = vector.broadcast %1744 : f32 to vector<8xf32>
    %1746 = vector.fma %1745, %1735, %1714 : vector<8xf32>
    %1747 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1748 = memref.load %assume_align[%arg0, %1747, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1749 = vector.broadcast %1748 : f32 to vector<8xf32>
    %1750 = vector.fma %1749, %1735, %1718 : vector<8xf32>
    %1751 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1752 = memref.load %assume_align[%arg0, %1751, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1753 = vector.broadcast %1752 : f32 to vector<8xf32>
    %1754 = vector.fma %1753, %1735, %1722 : vector<8xf32>
    %1755 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1756 = memref.load %assume_align[%arg0, %1755, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1757 = vector.broadcast %1756 : f32 to vector<8xf32>
    %1758 = vector.fma %1757, %1735, %1726 : vector<8xf32>
    %1759 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1760 = memref.load %assume_align[%arg0, %1759, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1761 = vector.broadcast %1760 : f32 to vector<8xf32>
    %1762 = vector.fma %1761, %1735, %1730 : vector<8xf32>
    %1763 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1764 = memref.load %assume_align[%arg0, %1763, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1765 = vector.broadcast %1764 : f32 to vector<8xf32>
    %1766 = vector.fma %1765, %1735, %1734 : vector<8xf32>
    %1767 = vector.extract %38[54] : vector<8xf32> from vector<64x8xf32>
    %1768 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1769 = vector.broadcast %1768 : f32 to vector<8xf32>
    %1770 = vector.fma %1769, %1767, %1738 : vector<8xf32>
    %1771 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1772 = memref.load %assume_align[%arg0, %1771, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1773 = vector.broadcast %1772 : f32 to vector<8xf32>
    %1774 = vector.fma %1773, %1767, %1742 : vector<8xf32>
    %1775 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1776 = memref.load %assume_align[%arg0, %1775, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1777 = vector.broadcast %1776 : f32 to vector<8xf32>
    %1778 = vector.fma %1777, %1767, %1746 : vector<8xf32>
    %1779 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1780 = memref.load %assume_align[%arg0, %1779, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1781 = vector.broadcast %1780 : f32 to vector<8xf32>
    %1782 = vector.fma %1781, %1767, %1750 : vector<8xf32>
    %1783 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1784 = memref.load %assume_align[%arg0, %1783, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1785 = vector.broadcast %1784 : f32 to vector<8xf32>
    %1786 = vector.fma %1785, %1767, %1754 : vector<8xf32>
    %1787 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1788 = memref.load %assume_align[%arg0, %1787, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1789 = vector.broadcast %1788 : f32 to vector<8xf32>
    %1790 = vector.fma %1789, %1767, %1758 : vector<8xf32>
    %1791 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1792 = memref.load %assume_align[%arg0, %1791, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1793 = vector.broadcast %1792 : f32 to vector<8xf32>
    %1794 = vector.fma %1793, %1767, %1762 : vector<8xf32>
    %1795 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1796 = memref.load %assume_align[%arg0, %1795, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1797 = vector.broadcast %1796 : f32 to vector<8xf32>
    %1798 = vector.fma %1797, %1767, %1766 : vector<8xf32>
    %1799 = vector.extract %38[55] : vector<8xf32> from vector<64x8xf32>
    %1800 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1801 = vector.broadcast %1800 : f32 to vector<8xf32>
    %1802 = vector.fma %1801, %1799, %1770 : vector<8xf32>
    %1803 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1804 = memref.load %assume_align[%arg0, %1803, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1805 = vector.broadcast %1804 : f32 to vector<8xf32>
    %1806 = vector.fma %1805, %1799, %1774 : vector<8xf32>
    %1807 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1808 = memref.load %assume_align[%arg0, %1807, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1809 = vector.broadcast %1808 : f32 to vector<8xf32>
    %1810 = vector.fma %1809, %1799, %1778 : vector<8xf32>
    %1811 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1812 = memref.load %assume_align[%arg0, %1811, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1813 = vector.broadcast %1812 : f32 to vector<8xf32>
    %1814 = vector.fma %1813, %1799, %1782 : vector<8xf32>
    %1815 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1816 = memref.load %assume_align[%arg0, %1815, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1817 = vector.broadcast %1816 : f32 to vector<8xf32>
    %1818 = vector.fma %1817, %1799, %1786 : vector<8xf32>
    %1819 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1820 = memref.load %assume_align[%arg0, %1819, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1821 = vector.broadcast %1820 : f32 to vector<8xf32>
    %1822 = vector.fma %1821, %1799, %1790 : vector<8xf32>
    %1823 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1824 = memref.load %assume_align[%arg0, %1823, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1825 = vector.broadcast %1824 : f32 to vector<8xf32>
    %1826 = vector.fma %1825, %1799, %1794 : vector<8xf32>
    %1827 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1828 = memref.load %assume_align[%arg0, %1827, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1829 = vector.broadcast %1828 : f32 to vector<8xf32>
    %1830 = vector.fma %1829, %1799, %1798 : vector<8xf32>
    %1831 = vector.extract %38[56] : vector<8xf32> from vector<64x8xf32>
    %1832 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1833 = vector.broadcast %1832 : f32 to vector<8xf32>
    %1834 = vector.fma %1833, %1831, %1802 : vector<8xf32>
    %1835 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1836 = memref.load %assume_align[%arg0, %1835, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1837 = vector.broadcast %1836 : f32 to vector<8xf32>
    %1838 = vector.fma %1837, %1831, %1806 : vector<8xf32>
    %1839 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1840 = memref.load %assume_align[%arg0, %1839, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1841 = vector.broadcast %1840 : f32 to vector<8xf32>
    %1842 = vector.fma %1841, %1831, %1810 : vector<8xf32>
    %1843 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1844 = memref.load %assume_align[%arg0, %1843, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1845 = vector.broadcast %1844 : f32 to vector<8xf32>
    %1846 = vector.fma %1845, %1831, %1814 : vector<8xf32>
    %1847 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1848 = memref.load %assume_align[%arg0, %1847, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1849 = vector.broadcast %1848 : f32 to vector<8xf32>
    %1850 = vector.fma %1849, %1831, %1818 : vector<8xf32>
    %1851 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1852 = memref.load %assume_align[%arg0, %1851, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1853 = vector.broadcast %1852 : f32 to vector<8xf32>
    %1854 = vector.fma %1853, %1831, %1822 : vector<8xf32>
    %1855 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1856 = memref.load %assume_align[%arg0, %1855, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1857 = vector.broadcast %1856 : f32 to vector<8xf32>
    %1858 = vector.fma %1857, %1831, %1826 : vector<8xf32>
    %1859 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1860 = memref.load %assume_align[%arg0, %1859, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1861 = vector.broadcast %1860 : f32 to vector<8xf32>
    %1862 = vector.fma %1861, %1831, %1830 : vector<8xf32>
    %1863 = vector.extract %38[57] : vector<8xf32> from vector<64x8xf32>
    %1864 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1865 = vector.broadcast %1864 : f32 to vector<8xf32>
    %1866 = vector.fma %1865, %1863, %1834 : vector<8xf32>
    %1867 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1868 = memref.load %assume_align[%arg0, %1867, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1869 = vector.broadcast %1868 : f32 to vector<8xf32>
    %1870 = vector.fma %1869, %1863, %1838 : vector<8xf32>
    %1871 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1872 = memref.load %assume_align[%arg0, %1871, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1873 = vector.broadcast %1872 : f32 to vector<8xf32>
    %1874 = vector.fma %1873, %1863, %1842 : vector<8xf32>
    %1875 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1876 = memref.load %assume_align[%arg0, %1875, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1877 = vector.broadcast %1876 : f32 to vector<8xf32>
    %1878 = vector.fma %1877, %1863, %1846 : vector<8xf32>
    %1879 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1880 = memref.load %assume_align[%arg0, %1879, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1881 = vector.broadcast %1880 : f32 to vector<8xf32>
    %1882 = vector.fma %1881, %1863, %1850 : vector<8xf32>
    %1883 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1884 = memref.load %assume_align[%arg0, %1883, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1885 = vector.broadcast %1884 : f32 to vector<8xf32>
    %1886 = vector.fma %1885, %1863, %1854 : vector<8xf32>
    %1887 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1888 = memref.load %assume_align[%arg0, %1887, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1889 = vector.broadcast %1888 : f32 to vector<8xf32>
    %1890 = vector.fma %1889, %1863, %1858 : vector<8xf32>
    %1891 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1892 = memref.load %assume_align[%arg0, %1891, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1893 = vector.broadcast %1892 : f32 to vector<8xf32>
    %1894 = vector.fma %1893, %1863, %1862 : vector<8xf32>
    %1895 = vector.extract %38[58] : vector<8xf32> from vector<64x8xf32>
    %1896 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1897 = vector.broadcast %1896 : f32 to vector<8xf32>
    %1898 = vector.fma %1897, %1895, %1866 : vector<8xf32>
    %1899 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1900 = memref.load %assume_align[%arg0, %1899, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1901 = vector.broadcast %1900 : f32 to vector<8xf32>
    %1902 = vector.fma %1901, %1895, %1870 : vector<8xf32>
    %1903 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1904 = memref.load %assume_align[%arg0, %1903, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1905 = vector.broadcast %1904 : f32 to vector<8xf32>
    %1906 = vector.fma %1905, %1895, %1874 : vector<8xf32>
    %1907 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1908 = memref.load %assume_align[%arg0, %1907, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1909 = vector.broadcast %1908 : f32 to vector<8xf32>
    %1910 = vector.fma %1909, %1895, %1878 : vector<8xf32>
    %1911 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1912 = memref.load %assume_align[%arg0, %1911, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1913 = vector.broadcast %1912 : f32 to vector<8xf32>
    %1914 = vector.fma %1913, %1895, %1882 : vector<8xf32>
    %1915 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1916 = memref.load %assume_align[%arg0, %1915, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1917 = vector.broadcast %1916 : f32 to vector<8xf32>
    %1918 = vector.fma %1917, %1895, %1886 : vector<8xf32>
    %1919 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1920 = memref.load %assume_align[%arg0, %1919, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1921 = vector.broadcast %1920 : f32 to vector<8xf32>
    %1922 = vector.fma %1921, %1895, %1890 : vector<8xf32>
    %1923 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1924 = memref.load %assume_align[%arg0, %1923, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1925 = vector.broadcast %1924 : f32 to vector<8xf32>
    %1926 = vector.fma %1925, %1895, %1894 : vector<8xf32>
    %1927 = vector.extract %38[59] : vector<8xf32> from vector<64x8xf32>
    %1928 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1929 = vector.broadcast %1928 : f32 to vector<8xf32>
    %1930 = vector.fma %1929, %1927, %1898 : vector<8xf32>
    %1931 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1932 = memref.load %assume_align[%arg0, %1931, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1933 = vector.broadcast %1932 : f32 to vector<8xf32>
    %1934 = vector.fma %1933, %1927, %1902 : vector<8xf32>
    %1935 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1936 = memref.load %assume_align[%arg0, %1935, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1937 = vector.broadcast %1936 : f32 to vector<8xf32>
    %1938 = vector.fma %1937, %1927, %1906 : vector<8xf32>
    %1939 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1940 = memref.load %assume_align[%arg0, %1939, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1941 = vector.broadcast %1940 : f32 to vector<8xf32>
    %1942 = vector.fma %1941, %1927, %1910 : vector<8xf32>
    %1943 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1944 = memref.load %assume_align[%arg0, %1943, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1945 = vector.broadcast %1944 : f32 to vector<8xf32>
    %1946 = vector.fma %1945, %1927, %1914 : vector<8xf32>
    %1947 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1948 = memref.load %assume_align[%arg0, %1947, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1949 = vector.broadcast %1948 : f32 to vector<8xf32>
    %1950 = vector.fma %1949, %1927, %1918 : vector<8xf32>
    %1951 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1952 = memref.load %assume_align[%arg0, %1951, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1953 = vector.broadcast %1952 : f32 to vector<8xf32>
    %1954 = vector.fma %1953, %1927, %1922 : vector<8xf32>
    %1955 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1956 = memref.load %assume_align[%arg0, %1955, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1957 = vector.broadcast %1956 : f32 to vector<8xf32>
    %1958 = vector.fma %1957, %1927, %1926 : vector<8xf32>
    %1959 = vector.extract %38[60] : vector<8xf32> from vector<64x8xf32>
    %1960 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1961 = vector.broadcast %1960 : f32 to vector<8xf32>
    %1962 = vector.fma %1961, %1959, %1930 : vector<8xf32>
    %1963 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1964 = memref.load %assume_align[%arg0, %1963, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1965 = vector.broadcast %1964 : f32 to vector<8xf32>
    %1966 = vector.fma %1965, %1959, %1934 : vector<8xf32>
    %1967 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1968 = memref.load %assume_align[%arg0, %1967, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1969 = vector.broadcast %1968 : f32 to vector<8xf32>
    %1970 = vector.fma %1969, %1959, %1938 : vector<8xf32>
    %1971 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1972 = memref.load %assume_align[%arg0, %1971, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1973 = vector.broadcast %1972 : f32 to vector<8xf32>
    %1974 = vector.fma %1973, %1959, %1942 : vector<8xf32>
    %1975 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1976 = memref.load %assume_align[%arg0, %1975, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1977 = vector.broadcast %1976 : f32 to vector<8xf32>
    %1978 = vector.fma %1977, %1959, %1946 : vector<8xf32>
    %1979 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1980 = memref.load %assume_align[%arg0, %1979, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1981 = vector.broadcast %1980 : f32 to vector<8xf32>
    %1982 = vector.fma %1981, %1959, %1950 : vector<8xf32>
    %1983 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1984 = memref.load %assume_align[%arg0, %1983, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1985 = vector.broadcast %1984 : f32 to vector<8xf32>
    %1986 = vector.fma %1985, %1959, %1954 : vector<8xf32>
    %1987 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1988 = memref.load %assume_align[%arg0, %1987, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1989 = vector.broadcast %1988 : f32 to vector<8xf32>
    %1990 = vector.fma %1989, %1959, %1958 : vector<8xf32>
    %1991 = vector.extract %38[61] : vector<8xf32> from vector<64x8xf32>
    %1992 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1993 = vector.broadcast %1992 : f32 to vector<8xf32>
    %1994 = vector.fma %1993, %1991, %1962 : vector<8xf32>
    %1995 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1996 = memref.load %assume_align[%arg0, %1995, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1997 = vector.broadcast %1996 : f32 to vector<8xf32>
    %1998 = vector.fma %1997, %1991, %1966 : vector<8xf32>
    %1999 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2000 = memref.load %assume_align[%arg0, %1999, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2001 = vector.broadcast %2000 : f32 to vector<8xf32>
    %2002 = vector.fma %2001, %1991, %1970 : vector<8xf32>
    %2003 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2004 = memref.load %assume_align[%arg0, %2003, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2005 = vector.broadcast %2004 : f32 to vector<8xf32>
    %2006 = vector.fma %2005, %1991, %1974 : vector<8xf32>
    %2007 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2008 = memref.load %assume_align[%arg0, %2007, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2009 = vector.broadcast %2008 : f32 to vector<8xf32>
    %2010 = vector.fma %2009, %1991, %1978 : vector<8xf32>
    %2011 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2012 = memref.load %assume_align[%arg0, %2011, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2013 = vector.broadcast %2012 : f32 to vector<8xf32>
    %2014 = vector.fma %2013, %1991, %1982 : vector<8xf32>
    %2015 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2016 = memref.load %assume_align[%arg0, %2015, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2017 = vector.broadcast %2016 : f32 to vector<8xf32>
    %2018 = vector.fma %2017, %1991, %1986 : vector<8xf32>
    %2019 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2020 = memref.load %assume_align[%arg0, %2019, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2021 = vector.broadcast %2020 : f32 to vector<8xf32>
    %2022 = vector.fma %2021, %1991, %1990 : vector<8xf32>
    %2023 = vector.extract %38[62] : vector<8xf32> from vector<64x8xf32>
    %2024 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2025 = vector.broadcast %2024 : f32 to vector<8xf32>
    %2026 = vector.fma %2025, %2023, %1994 : vector<8xf32>
    %2027 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2028 = memref.load %assume_align[%arg0, %2027, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2029 = vector.broadcast %2028 : f32 to vector<8xf32>
    %2030 = vector.fma %2029, %2023, %1998 : vector<8xf32>
    %2031 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2032 = memref.load %assume_align[%arg0, %2031, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2033 = vector.broadcast %2032 : f32 to vector<8xf32>
    %2034 = vector.fma %2033, %2023, %2002 : vector<8xf32>
    %2035 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2036 = memref.load %assume_align[%arg0, %2035, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2037 = vector.broadcast %2036 : f32 to vector<8xf32>
    %2038 = vector.fma %2037, %2023, %2006 : vector<8xf32>
    %2039 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2040 = memref.load %assume_align[%arg0, %2039, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2041 = vector.broadcast %2040 : f32 to vector<8xf32>
    %2042 = vector.fma %2041, %2023, %2010 : vector<8xf32>
    %2043 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2044 = memref.load %assume_align[%arg0, %2043, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2045 = vector.broadcast %2044 : f32 to vector<8xf32>
    %2046 = vector.fma %2045, %2023, %2014 : vector<8xf32>
    %2047 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2048 = memref.load %assume_align[%arg0, %2047, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2049 = vector.broadcast %2048 : f32 to vector<8xf32>
    %2050 = vector.fma %2049, %2023, %2018 : vector<8xf32>
    %2051 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2052 = memref.load %assume_align[%arg0, %2051, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2053 = vector.broadcast %2052 : f32 to vector<8xf32>
    %2054 = vector.fma %2053, %2023, %2022 : vector<8xf32>
    %2055 = vector.extract %38[63] : vector<8xf32> from vector<64x8xf32>
    %2056 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2057 = vector.broadcast %2056 : f32 to vector<8xf32>
    %2058 = vector.fma %2057, %2055, %2026 : vector<8xf32>
    %2059 = vector.insert %2058, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2060 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2061 = memref.load %assume_align[%arg0, %2060, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2062 = vector.broadcast %2061 : f32 to vector<8xf32>
    %2063 = vector.fma %2062, %2055, %2030 : vector<8xf32>
    %2064 = vector.insert %2063, %2059 [1] : vector<8xf32> into vector<8x8xf32>
    %2065 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2066 = memref.load %assume_align[%arg0, %2065, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2067 = vector.broadcast %2066 : f32 to vector<8xf32>
    %2068 = vector.fma %2067, %2055, %2034 : vector<8xf32>
    %2069 = vector.insert %2068, %2064 [2] : vector<8xf32> into vector<8x8xf32>
    %2070 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2071 = memref.load %assume_align[%arg0, %2070, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2072 = vector.broadcast %2071 : f32 to vector<8xf32>
    %2073 = vector.fma %2072, %2055, %2038 : vector<8xf32>
    %2074 = vector.insert %2073, %2069 [3] : vector<8xf32> into vector<8x8xf32>
    %2075 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2076 = memref.load %assume_align[%arg0, %2075, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2077 = vector.broadcast %2076 : f32 to vector<8xf32>
    %2078 = vector.fma %2077, %2055, %2042 : vector<8xf32>
    %2079 = vector.insert %2078, %2074 [4] : vector<8xf32> into vector<8x8xf32>
    %2080 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2081 = memref.load %assume_align[%arg0, %2080, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2082 = vector.broadcast %2081 : f32 to vector<8xf32>
    %2083 = vector.fma %2082, %2055, %2046 : vector<8xf32>
    %2084 = vector.insert %2083, %2079 [5] : vector<8xf32> into vector<8x8xf32>
    %2085 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2086 = memref.load %assume_align[%arg0, %2085, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2087 = vector.broadcast %2086 : f32 to vector<8xf32>
    %2088 = vector.fma %2087, %2055, %2050 : vector<8xf32>
    %2089 = vector.insert %2088, %2084 [6] : vector<8xf32> into vector<8x8xf32>
    %2090 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2091 = memref.load %assume_align[%arg0, %2090, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2092 = vector.broadcast %2091 : f32 to vector<8xf32>
    %2093 = vector.fma %2092, %2055, %2054 : vector<8xf32>
    %2094 = vector.insert %2093, %2089 [7] : vector<8xf32> into vector<8x8xf32>
    %2095 = vector.reduction <maximumf>, %2058, %cst : vector<8xf32> into f32
    %2096 = vector.insert %2095, %cst_0 [0] : f32 into vector<8xf32>
    %2097 = vector.reduction <maximumf>, %2063, %cst : vector<8xf32> into f32
    %2098 = vector.insert %2097, %2096 [1] : f32 into vector<8xf32>
    %2099 = vector.reduction <maximumf>, %2068, %cst : vector<8xf32> into f32
    %2100 = vector.insert %2099, %2098 [2] : f32 into vector<8xf32>
    %2101 = vector.reduction <maximumf>, %2073, %cst : vector<8xf32> into f32
    %2102 = vector.insert %2101, %2100 [3] : f32 into vector<8xf32>
    %2103 = vector.reduction <maximumf>, %2078, %cst : vector<8xf32> into f32
    %2104 = vector.insert %2103, %2102 [4] : f32 into vector<8xf32>
    %2105 = vector.reduction <maximumf>, %2083, %cst : vector<8xf32> into f32
    %2106 = vector.insert %2105, %2104 [5] : f32 into vector<8xf32>
    %2107 = vector.reduction <maximumf>, %2088, %cst : vector<8xf32> into f32
    %2108 = vector.insert %2107, %2106 [6] : f32 into vector<8xf32>
    %2109 = vector.reduction <maximumf>, %2093, %cst : vector<8xf32> into f32
    %2110 = vector.insert %2109, %2108 [7] : f32 into vector<8xf32>
    %2111 = vector.shape_cast %2110 : vector<8xf32> to vector<1x8xf32>
    %2112 = arith.subf %2110, %cst_2 : vector<8xf32>
    %2113 = math.exp2 %2112 : vector<8xf32>
    %2114 = vector.shape_cast %2113 : vector<8xf32> to vector<1x8xf32>
    %2115 = vector.broadcast %2114 : vector<1x8xf32> to vector<8x8xf32>
    %2116 = arith.mulf %2115, %cst_1 : vector<8x8xf32>
    %2117 = vector.shape_cast %2116 : vector<8x8xf32> to vector<64xf32>
    %2118 = vector.shuffle %2117, %2117 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2119 = vector.shape_cast %2118 : vector<64xf32> to vector<8x8xf32>
    %2120 = vector.broadcast %2111 : vector<1x8xf32> to vector<8x8xf32>
    %2121 = vector.shape_cast %2120 : vector<8x8xf32> to vector<64xf32>
    %2122 = vector.shuffle %2121, %2121 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2123 = vector.shape_cast %2122 : vector<64xf32> to vector<8x8xf32>
    %2124 = arith.subf %2094, %2123 : vector<8x8xf32>
    %2125 = math.exp2 %2124 : vector<8x8xf32>
    %2126 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2127 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %2128 = vector.load %assume_align_4[%arg0, %2127, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2129 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %2130 = vector.load %assume_align_4[%arg0, %2129, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2131 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %2132 = vector.load %assume_align_4[%arg0, %2131, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2133 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %2134 = vector.load %assume_align_4[%arg0, %2133, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2135 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %2136 = vector.load %assume_align_4[%arg0, %2135, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2137 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %2138 = vector.load %assume_align_4[%arg0, %2137, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2139 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %2140 = vector.load %assume_align_4[%arg0, %2139, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2141 = vector.extract %2125[0, 0] : f32 from vector<8x8xf32>
    %2142 = vector.broadcast %2141 : f32 to vector<8xf32>
    %2143 = vector.extract %2119[0] : vector<8xf32> from vector<8x8xf32>
    %2144 = vector.fma %2142, %2126, %2143 : vector<8xf32>
    %2145 = vector.extract %2125[1, 0] : f32 from vector<8x8xf32>
    %2146 = vector.broadcast %2145 : f32 to vector<8xf32>
    %2147 = vector.extract %2119[1] : vector<8xf32> from vector<8x8xf32>
    %2148 = vector.fma %2146, %2126, %2147 : vector<8xf32>
    %2149 = vector.extract %2125[2, 0] : f32 from vector<8x8xf32>
    %2150 = vector.broadcast %2149 : f32 to vector<8xf32>
    %2151 = vector.extract %2119[2] : vector<8xf32> from vector<8x8xf32>
    %2152 = vector.fma %2150, %2126, %2151 : vector<8xf32>
    %2153 = vector.extract %2125[3, 0] : f32 from vector<8x8xf32>
    %2154 = vector.broadcast %2153 : f32 to vector<8xf32>
    %2155 = vector.extract %2119[3] : vector<8xf32> from vector<8x8xf32>
    %2156 = vector.fma %2154, %2126, %2155 : vector<8xf32>
    %2157 = vector.extract %2125[4, 0] : f32 from vector<8x8xf32>
    %2158 = vector.broadcast %2157 : f32 to vector<8xf32>
    %2159 = vector.extract %2119[4] : vector<8xf32> from vector<8x8xf32>
    %2160 = vector.fma %2158, %2126, %2159 : vector<8xf32>
    %2161 = vector.extract %2125[5, 0] : f32 from vector<8x8xf32>
    %2162 = vector.broadcast %2161 : f32 to vector<8xf32>
    %2163 = vector.extract %2119[5] : vector<8xf32> from vector<8x8xf32>
    %2164 = vector.fma %2162, %2126, %2163 : vector<8xf32>
    %2165 = vector.extract %2125[6, 0] : f32 from vector<8x8xf32>
    %2166 = vector.broadcast %2165 : f32 to vector<8xf32>
    %2167 = vector.extract %2119[6] : vector<8xf32> from vector<8x8xf32>
    %2168 = vector.fma %2166, %2126, %2167 : vector<8xf32>
    %2169 = vector.extract %2125[7, 0] : f32 from vector<8x8xf32>
    %2170 = vector.broadcast %2169 : f32 to vector<8xf32>
    %2171 = vector.extract %2119[7] : vector<8xf32> from vector<8x8xf32>
    %2172 = vector.fma %2170, %2126, %2171 : vector<8xf32>
    %2173 = vector.extract %2125[0, 1] : f32 from vector<8x8xf32>
    %2174 = vector.broadcast %2173 : f32 to vector<8xf32>
    %2175 = vector.fma %2174, %2128, %2144 : vector<8xf32>
    %2176 = vector.extract %2125[1, 1] : f32 from vector<8x8xf32>
    %2177 = vector.broadcast %2176 : f32 to vector<8xf32>
    %2178 = vector.fma %2177, %2128, %2148 : vector<8xf32>
    %2179 = vector.extract %2125[2, 1] : f32 from vector<8x8xf32>
    %2180 = vector.broadcast %2179 : f32 to vector<8xf32>
    %2181 = vector.fma %2180, %2128, %2152 : vector<8xf32>
    %2182 = vector.extract %2125[3, 1] : f32 from vector<8x8xf32>
    %2183 = vector.broadcast %2182 : f32 to vector<8xf32>
    %2184 = vector.fma %2183, %2128, %2156 : vector<8xf32>
    %2185 = vector.extract %2125[4, 1] : f32 from vector<8x8xf32>
    %2186 = vector.broadcast %2185 : f32 to vector<8xf32>
    %2187 = vector.fma %2186, %2128, %2160 : vector<8xf32>
    %2188 = vector.extract %2125[5, 1] : f32 from vector<8x8xf32>
    %2189 = vector.broadcast %2188 : f32 to vector<8xf32>
    %2190 = vector.fma %2189, %2128, %2164 : vector<8xf32>
    %2191 = vector.extract %2125[6, 1] : f32 from vector<8x8xf32>
    %2192 = vector.broadcast %2191 : f32 to vector<8xf32>
    %2193 = vector.fma %2192, %2128, %2168 : vector<8xf32>
    %2194 = vector.extract %2125[7, 1] : f32 from vector<8x8xf32>
    %2195 = vector.broadcast %2194 : f32 to vector<8xf32>
    %2196 = vector.fma %2195, %2128, %2172 : vector<8xf32>
    %2197 = vector.extract %2125[0, 2] : f32 from vector<8x8xf32>
    %2198 = vector.broadcast %2197 : f32 to vector<8xf32>
    %2199 = vector.fma %2198, %2130, %2175 : vector<8xf32>
    %2200 = vector.extract %2125[1, 2] : f32 from vector<8x8xf32>
    %2201 = vector.broadcast %2200 : f32 to vector<8xf32>
    %2202 = vector.fma %2201, %2130, %2178 : vector<8xf32>
    %2203 = vector.extract %2125[2, 2] : f32 from vector<8x8xf32>
    %2204 = vector.broadcast %2203 : f32 to vector<8xf32>
    %2205 = vector.fma %2204, %2130, %2181 : vector<8xf32>
    %2206 = vector.extract %2125[3, 2] : f32 from vector<8x8xf32>
    %2207 = vector.broadcast %2206 : f32 to vector<8xf32>
    %2208 = vector.fma %2207, %2130, %2184 : vector<8xf32>
    %2209 = vector.extract %2125[4, 2] : f32 from vector<8x8xf32>
    %2210 = vector.broadcast %2209 : f32 to vector<8xf32>
    %2211 = vector.fma %2210, %2130, %2187 : vector<8xf32>
    %2212 = vector.extract %2125[5, 2] : f32 from vector<8x8xf32>
    %2213 = vector.broadcast %2212 : f32 to vector<8xf32>
    %2214 = vector.fma %2213, %2130, %2190 : vector<8xf32>
    %2215 = vector.extract %2125[6, 2] : f32 from vector<8x8xf32>
    %2216 = vector.broadcast %2215 : f32 to vector<8xf32>
    %2217 = vector.fma %2216, %2130, %2193 : vector<8xf32>
    %2218 = vector.extract %2125[7, 2] : f32 from vector<8x8xf32>
    %2219 = vector.broadcast %2218 : f32 to vector<8xf32>
    %2220 = vector.fma %2219, %2130, %2196 : vector<8xf32>
    %2221 = vector.extract %2125[0, 3] : f32 from vector<8x8xf32>
    %2222 = vector.broadcast %2221 : f32 to vector<8xf32>
    %2223 = vector.fma %2222, %2132, %2199 : vector<8xf32>
    %2224 = vector.extract %2125[1, 3] : f32 from vector<8x8xf32>
    %2225 = vector.broadcast %2224 : f32 to vector<8xf32>
    %2226 = vector.fma %2225, %2132, %2202 : vector<8xf32>
    %2227 = vector.extract %2125[2, 3] : f32 from vector<8x8xf32>
    %2228 = vector.broadcast %2227 : f32 to vector<8xf32>
    %2229 = vector.fma %2228, %2132, %2205 : vector<8xf32>
    %2230 = vector.extract %2125[3, 3] : f32 from vector<8x8xf32>
    %2231 = vector.broadcast %2230 : f32 to vector<8xf32>
    %2232 = vector.fma %2231, %2132, %2208 : vector<8xf32>
    %2233 = vector.extract %2125[4, 3] : f32 from vector<8x8xf32>
    %2234 = vector.broadcast %2233 : f32 to vector<8xf32>
    %2235 = vector.fma %2234, %2132, %2211 : vector<8xf32>
    %2236 = vector.extract %2125[5, 3] : f32 from vector<8x8xf32>
    %2237 = vector.broadcast %2236 : f32 to vector<8xf32>
    %2238 = vector.fma %2237, %2132, %2214 : vector<8xf32>
    %2239 = vector.extract %2125[6, 3] : f32 from vector<8x8xf32>
    %2240 = vector.broadcast %2239 : f32 to vector<8xf32>
    %2241 = vector.fma %2240, %2132, %2217 : vector<8xf32>
    %2242 = vector.extract %2125[7, 3] : f32 from vector<8x8xf32>
    %2243 = vector.broadcast %2242 : f32 to vector<8xf32>
    %2244 = vector.fma %2243, %2132, %2220 : vector<8xf32>
    %2245 = vector.extract %2125[0, 4] : f32 from vector<8x8xf32>
    %2246 = vector.broadcast %2245 : f32 to vector<8xf32>
    %2247 = vector.fma %2246, %2134, %2223 : vector<8xf32>
    %2248 = vector.extract %2125[1, 4] : f32 from vector<8x8xf32>
    %2249 = vector.broadcast %2248 : f32 to vector<8xf32>
    %2250 = vector.fma %2249, %2134, %2226 : vector<8xf32>
    %2251 = vector.extract %2125[2, 4] : f32 from vector<8x8xf32>
    %2252 = vector.broadcast %2251 : f32 to vector<8xf32>
    %2253 = vector.fma %2252, %2134, %2229 : vector<8xf32>
    %2254 = vector.extract %2125[3, 4] : f32 from vector<8x8xf32>
    %2255 = vector.broadcast %2254 : f32 to vector<8xf32>
    %2256 = vector.fma %2255, %2134, %2232 : vector<8xf32>
    %2257 = vector.extract %2125[4, 4] : f32 from vector<8x8xf32>
    %2258 = vector.broadcast %2257 : f32 to vector<8xf32>
    %2259 = vector.fma %2258, %2134, %2235 : vector<8xf32>
    %2260 = vector.extract %2125[5, 4] : f32 from vector<8x8xf32>
    %2261 = vector.broadcast %2260 : f32 to vector<8xf32>
    %2262 = vector.fma %2261, %2134, %2238 : vector<8xf32>
    %2263 = vector.extract %2125[6, 4] : f32 from vector<8x8xf32>
    %2264 = vector.broadcast %2263 : f32 to vector<8xf32>
    %2265 = vector.fma %2264, %2134, %2241 : vector<8xf32>
    %2266 = vector.extract %2125[7, 4] : f32 from vector<8x8xf32>
    %2267 = vector.broadcast %2266 : f32 to vector<8xf32>
    %2268 = vector.fma %2267, %2134, %2244 : vector<8xf32>
    %2269 = vector.extract %2125[0, 5] : f32 from vector<8x8xf32>
    %2270 = vector.broadcast %2269 : f32 to vector<8xf32>
    %2271 = vector.fma %2270, %2136, %2247 : vector<8xf32>
    %2272 = vector.extract %2125[1, 5] : f32 from vector<8x8xf32>
    %2273 = vector.broadcast %2272 : f32 to vector<8xf32>
    %2274 = vector.fma %2273, %2136, %2250 : vector<8xf32>
    %2275 = vector.extract %2125[2, 5] : f32 from vector<8x8xf32>
    %2276 = vector.broadcast %2275 : f32 to vector<8xf32>
    %2277 = vector.fma %2276, %2136, %2253 : vector<8xf32>
    %2278 = vector.extract %2125[3, 5] : f32 from vector<8x8xf32>
    %2279 = vector.broadcast %2278 : f32 to vector<8xf32>
    %2280 = vector.fma %2279, %2136, %2256 : vector<8xf32>
    %2281 = vector.extract %2125[4, 5] : f32 from vector<8x8xf32>
    %2282 = vector.broadcast %2281 : f32 to vector<8xf32>
    %2283 = vector.fma %2282, %2136, %2259 : vector<8xf32>
    %2284 = vector.extract %2125[5, 5] : f32 from vector<8x8xf32>
    %2285 = vector.broadcast %2284 : f32 to vector<8xf32>
    %2286 = vector.fma %2285, %2136, %2262 : vector<8xf32>
    %2287 = vector.extract %2125[6, 5] : f32 from vector<8x8xf32>
    %2288 = vector.broadcast %2287 : f32 to vector<8xf32>
    %2289 = vector.fma %2288, %2136, %2265 : vector<8xf32>
    %2290 = vector.extract %2125[7, 5] : f32 from vector<8x8xf32>
    %2291 = vector.broadcast %2290 : f32 to vector<8xf32>
    %2292 = vector.fma %2291, %2136, %2268 : vector<8xf32>
    %2293 = vector.extract %2125[0, 6] : f32 from vector<8x8xf32>
    %2294 = vector.broadcast %2293 : f32 to vector<8xf32>
    %2295 = vector.fma %2294, %2138, %2271 : vector<8xf32>
    %2296 = vector.extract %2125[1, 6] : f32 from vector<8x8xf32>
    %2297 = vector.broadcast %2296 : f32 to vector<8xf32>
    %2298 = vector.fma %2297, %2138, %2274 : vector<8xf32>
    %2299 = vector.extract %2125[2, 6] : f32 from vector<8x8xf32>
    %2300 = vector.broadcast %2299 : f32 to vector<8xf32>
    %2301 = vector.fma %2300, %2138, %2277 : vector<8xf32>
    %2302 = vector.extract %2125[3, 6] : f32 from vector<8x8xf32>
    %2303 = vector.broadcast %2302 : f32 to vector<8xf32>
    %2304 = vector.fma %2303, %2138, %2280 : vector<8xf32>
    %2305 = vector.extract %2125[4, 6] : f32 from vector<8x8xf32>
    %2306 = vector.broadcast %2305 : f32 to vector<8xf32>
    %2307 = vector.fma %2306, %2138, %2283 : vector<8xf32>
    %2308 = vector.extract %2125[5, 6] : f32 from vector<8x8xf32>
    %2309 = vector.broadcast %2308 : f32 to vector<8xf32>
    %2310 = vector.fma %2309, %2138, %2286 : vector<8xf32>
    %2311 = vector.extract %2125[6, 6] : f32 from vector<8x8xf32>
    %2312 = vector.broadcast %2311 : f32 to vector<8xf32>
    %2313 = vector.fma %2312, %2138, %2289 : vector<8xf32>
    %2314 = vector.extract %2125[7, 6] : f32 from vector<8x8xf32>
    %2315 = vector.broadcast %2314 : f32 to vector<8xf32>
    %2316 = vector.fma %2315, %2138, %2292 : vector<8xf32>
    %2317 = vector.extract %2125[0, 7] : f32 from vector<8x8xf32>
    %2318 = vector.broadcast %2317 : f32 to vector<8xf32>
    %2319 = vector.fma %2318, %2140, %2295 : vector<8xf32>
    %2320 = vector.insert %2319, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2321 = vector.extract %2125[1, 7] : f32 from vector<8x8xf32>
    %2322 = vector.broadcast %2321 : f32 to vector<8xf32>
    %2323 = vector.fma %2322, %2140, %2298 : vector<8xf32>
    %2324 = vector.insert %2323, %2320 [1] : vector<8xf32> into vector<8x8xf32>
    %2325 = vector.extract %2125[2, 7] : f32 from vector<8x8xf32>
    %2326 = vector.broadcast %2325 : f32 to vector<8xf32>
    %2327 = vector.fma %2326, %2140, %2301 : vector<8xf32>
    %2328 = vector.insert %2327, %2324 [2] : vector<8xf32> into vector<8x8xf32>
    %2329 = vector.extract %2125[3, 7] : f32 from vector<8x8xf32>
    %2330 = vector.broadcast %2329 : f32 to vector<8xf32>
    %2331 = vector.fma %2330, %2140, %2304 : vector<8xf32>
    %2332 = vector.insert %2331, %2328 [3] : vector<8xf32> into vector<8x8xf32>
    %2333 = vector.extract %2125[4, 7] : f32 from vector<8x8xf32>
    %2334 = vector.broadcast %2333 : f32 to vector<8xf32>
    %2335 = vector.fma %2334, %2140, %2307 : vector<8xf32>
    %2336 = vector.insert %2335, %2332 [4] : vector<8xf32> into vector<8x8xf32>
    %2337 = vector.extract %2125[5, 7] : f32 from vector<8x8xf32>
    %2338 = vector.broadcast %2337 : f32 to vector<8xf32>
    %2339 = vector.fma %2338, %2140, %2310 : vector<8xf32>
    %2340 = vector.insert %2339, %2336 [5] : vector<8xf32> into vector<8x8xf32>
    %2341 = vector.extract %2125[6, 7] : f32 from vector<8x8xf32>
    %2342 = vector.broadcast %2341 : f32 to vector<8xf32>
    %2343 = vector.fma %2342, %2140, %2313 : vector<8xf32>
    %2344 = vector.insert %2343, %2340 [6] : vector<8xf32> into vector<8x8xf32>
    %2345 = vector.extract %2125[7, 7] : f32 from vector<8x8xf32>
    %2346 = vector.broadcast %2345 : f32 to vector<8xf32>
    %2347 = vector.fma %2346, %2140, %2316 : vector<8xf32>
    %2348 = vector.insert %2347, %2344 [7] : vector<8xf32> into vector<8x8xf32>
    %2349 = arith.mulf %2113, %cst_0 : vector<8xf32>
    %2350 = vector.extract %2125[0] : vector<8xf32> from vector<8x8xf32>
    %2351 = vector.extract %2349[0] : f32 from vector<8xf32>
    %2352 = vector.reduction <add>, %2350, %2351 : vector<8xf32> into f32
    %2353 = vector.insert %2352, %cst_0 [0] : f32 into vector<8xf32>
    %2354 = vector.extract %2125[1] : vector<8xf32> from vector<8x8xf32>
    %2355 = vector.extract %2349[1] : f32 from vector<8xf32>
    %2356 = vector.reduction <add>, %2354, %2355 : vector<8xf32> into f32
    %2357 = vector.insert %2356, %2353 [1] : f32 into vector<8xf32>
    %2358 = vector.extract %2125[2] : vector<8xf32> from vector<8x8xf32>
    %2359 = vector.extract %2349[2] : f32 from vector<8xf32>
    %2360 = vector.reduction <add>, %2358, %2359 : vector<8xf32> into f32
    %2361 = vector.insert %2360, %2357 [2] : f32 into vector<8xf32>
    %2362 = vector.extract %2125[3] : vector<8xf32> from vector<8x8xf32>
    %2363 = vector.extract %2349[3] : f32 from vector<8xf32>
    %2364 = vector.reduction <add>, %2362, %2363 : vector<8xf32> into f32
    %2365 = vector.insert %2364, %2361 [3] : f32 into vector<8xf32>
    %2366 = vector.extract %2125[4] : vector<8xf32> from vector<8x8xf32>
    %2367 = vector.extract %2349[4] : f32 from vector<8xf32>
    %2368 = vector.reduction <add>, %2366, %2367 : vector<8xf32> into f32
    %2369 = vector.insert %2368, %2365 [4] : f32 into vector<8xf32>
    %2370 = vector.extract %2125[5] : vector<8xf32> from vector<8x8xf32>
    %2371 = vector.extract %2349[5] : f32 from vector<8xf32>
    %2372 = vector.reduction <add>, %2370, %2371 : vector<8xf32> into f32
    %2373 = vector.insert %2372, %2369 [5] : f32 into vector<8xf32>
    %2374 = vector.extract %2125[6] : vector<8xf32> from vector<8x8xf32>
    %2375 = vector.extract %2349[6] : f32 from vector<8xf32>
    %2376 = vector.reduction <add>, %2374, %2375 : vector<8xf32> into f32
    %2377 = vector.insert %2376, %2373 [6] : f32 into vector<8xf32>
    %2378 = vector.extract %2125[7] : vector<8xf32> from vector<8x8xf32>
    %2379 = vector.extract %2349[7] : f32 from vector<8xf32>
    %2380 = vector.reduction <add>, %2378, %2379 : vector<8xf32> into f32
    %2381 = vector.insert %2380, %2377 [7] : f32 into vector<8xf32>
    %2382 = vector.shape_cast %2381 : vector<8xf32> to vector<1x8xf32>
    %2383 = vector.broadcast %2382 : vector<1x8xf32> to vector<8x8xf32>
    %2384 = vector.shape_cast %2383 : vector<8x8xf32> to vector<64xf32>
    %2385 = vector.shuffle %2384, %2384 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2386 = vector.shape_cast %2385 : vector<64xf32> to vector<8x8xf32>
    %2387 = arith.divf %2348, %2386 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    %2388 = vector.extract %2387[0] : vector<8xf32> from vector<8x8xf32>
    vector.store %2388, %subview_7[%c0, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2389 = vector.extract %2387[1] : vector<8xf32> from vector<8x8xf32>
    vector.store %2389, %subview_7[%c1, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2390 = vector.extract %2387[2] : vector<8xf32> from vector<8x8xf32>
    vector.store %2390, %subview_7[%c2, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2391 = vector.extract %2387[3] : vector<8xf32> from vector<8x8xf32>
    vector.store %2391, %subview_7[%c3, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2392 = vector.extract %2387[4] : vector<8xf32> from vector<8x8xf32>
    vector.store %2392, %subview_7[%c4, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2393 = vector.extract %2387[5] : vector<8xf32> from vector<8x8xf32>
    vector.store %2393, %subview_7[%c5, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2394 = vector.extract %2387[6] : vector<8xf32> from vector<8x8xf32>
    vector.store %2394, %subview_7[%c6, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2395 = vector.extract %2387[7] : vector<8xf32> from vector<8x8xf32>
    vector.store %2395, %subview_7[%c7, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %0 = ub.poison : vector<8x64xf32>
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %2, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %3, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %5 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %6 = vector.insert %5, %0 [0] : vector<64xf32> into vector<8x64xf32>
    %7 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %8 = vector.load %assume_align_3[%arg0, %7, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %9 = vector.insert %8, %6 [1] : vector<64xf32> into vector<8x64xf32>
    %10 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %11 = vector.load %assume_align_3[%arg0, %10, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %12 = vector.insert %11, %9 [2] : vector<64xf32> into vector<8x64xf32>
    %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %15 = vector.insert %14, %12 [3] : vector<64xf32> into vector<8x64xf32>
    %16 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %17 = vector.load %assume_align_3[%arg0, %16, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %18 = vector.insert %17, %15 [4] : vector<64xf32> into vector<8x64xf32>
    %19 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %21 = vector.insert %20, %18 [5] : vector<64xf32> into vector<8x64xf32>
    %22 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %23 = vector.load %assume_align_3[%arg0, %22, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %24 = vector.insert %23, %21 [6] : vector<64xf32> into vector<8x64xf32>
    %25 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %26 = vector.load %assume_align_3[%arg0, %25, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %27 = vector.insert %26, %24 [7] : vector<64xf32> into vector<8x64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %28 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
    %29 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
    %30 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
    %31 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
    %32 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
    %33 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
    %34 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
    %35 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
    %36 = vector.shape_cast %27 : vector<8x64xf32> to vector<512xf32>
    %37 = vector.shuffle %36, %36 [0, 64, 128, 192, 256, 320, 384, 448, 1, 65, 129, 193, 257, 321, 385, 449, 2, 66, 130, 194, 258, 322, 386, 450, 3, 67, 131, 195, 259, 323, 387, 451, 4, 68, 132, 196, 260, 324, 388, 452, 5, 69, 133, 197, 261, 325, 389, 453, 6, 70, 134, 198, 262, 326, 390, 454, 7, 71, 135, 199, 263, 327, 391, 455, 8, 72, 136, 200, 264, 328, 392, 456, 9, 73, 137, 201, 265, 329, 393, 457, 10, 74, 138, 202, 266, 330, 394, 458, 11, 75, 139, 203, 267, 331, 395, 459, 12, 76, 140, 204, 268, 332, 396, 460, 13, 77, 141, 205, 269, 333, 397, 461, 14, 78, 142, 206, 270, 334, 398, 462, 15, 79, 143, 207, 271, 335, 399, 463, 16, 80, 144, 208, 272, 336, 400, 464, 17, 81, 145, 209, 273, 337, 401, 465, 18, 82, 146, 210, 274, 338, 402, 466, 19, 83, 147, 211, 275, 339, 403, 467, 20, 84, 148, 212, 276, 340, 404, 468, 21, 85, 149, 213, 277, 341, 405, 469, 22, 86, 150, 214, 278, 342, 406, 470, 23, 87, 151, 215, 279, 343, 407, 471, 24, 88, 152, 216, 280, 344, 408, 472, 25, 89, 153, 217, 281, 345, 409, 473, 26, 90, 154, 218, 282, 346, 410, 474, 27, 91, 155, 219, 283, 347, 411, 475, 28, 92, 156, 220, 284, 348, 412, 476, 29, 93, 157, 221, 285, 349, 413, 477, 30, 94, 158, 222, 286, 350, 414, 478, 31, 95, 159, 223, 287, 351, 415, 479, 32, 96, 160, 224, 288, 352, 416, 480, 33, 97, 161, 225, 289, 353, 417, 481, 34, 98, 162, 226, 290, 354, 418, 482, 35, 99, 163, 227, 291, 355, 419, 483, 36, 100, 164, 228, 292, 356, 420, 484, 37, 101, 165, 229, 293, 357, 421, 485, 38, 102, 166, 230, 294, 358, 422, 486, 39, 103, 167, 231, 295, 359, 423, 487, 40, 104, 168, 232, 296, 360, 424, 488, 41, 105, 169, 233, 297, 361, 425, 489, 42, 106, 170, 234, 298, 362, 426, 490, 43, 107, 171, 235, 299, 363, 427, 491, 44, 108, 172, 236, 300, 364, 428, 492, 45, 109, 173, 237, 301, 365, 429, 493, 46, 110, 174, 238, 302, 366, 430, 494, 47, 111, 175, 239, 303, 367, 431, 495, 48, 112, 176, 240, 304, 368, 432, 496, 49, 113, 177, 241, 305, 369, 433, 497, 50, 114, 178, 242, 306, 370, 434, 498, 51, 115, 179, 243, 307, 371, 435, 499, 52, 116, 180, 244, 308, 372, 436, 500, 53, 117, 181, 245, 309, 373, 437, 501, 54, 118, 182, 246, 310, 374, 438, 502, 55, 119, 183, 247, 311, 375, 439, 503, 56, 120, 184, 248, 312, 376, 440, 504, 57, 121, 185, 249, 313, 377, 441, 505, 58, 122, 186, 250, 314, 378, 442, 506, 59, 123, 187, 251, 315, 379, 443, 507, 60, 124, 188, 252, 316, 380, 444, 508, 61, 125, 189, 253, 317, 381, 445, 509, 62, 126, 190, 254, 318, 382, 446, 510, 63, 127, 191, 255, 319, 383, 447, 511] : vector<512xf32>, vector<512xf32>
    %38 = vector.shape_cast %37 : vector<512xf32> to vector<64x8xf32>
    %39 = vector.extract %38[0] : vector<8xf32> from vector<64x8xf32>
    %40 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %41 = vector.broadcast %40 : f32 to vector<8xf32>
    %42 = vector.fma %41, %39, %28 : vector<8xf32>
    %43 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %44 = memref.load %assume_align[%arg0, %43, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %45 = vector.broadcast %44 : f32 to vector<8xf32>
    %46 = vector.fma %45, %39, %29 : vector<8xf32>
    %47 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %48 = memref.load %assume_align[%arg0, %47, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %49 = vector.broadcast %48 : f32 to vector<8xf32>
    %50 = vector.fma %49, %39, %30 : vector<8xf32>
    %51 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %52 = memref.load %assume_align[%arg0, %51, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %53 = vector.broadcast %52 : f32 to vector<8xf32>
    %54 = vector.fma %53, %39, %31 : vector<8xf32>
    %55 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %56 = memref.load %assume_align[%arg0, %55, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %57 = vector.broadcast %56 : f32 to vector<8xf32>
    %58 = vector.fma %57, %39, %32 : vector<8xf32>
    %59 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %60 = memref.load %assume_align[%arg0, %59, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %61 = vector.broadcast %60 : f32 to vector<8xf32>
    %62 = vector.fma %61, %39, %33 : vector<8xf32>
    %63 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %64 = memref.load %assume_align[%arg0, %63, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %65 = vector.broadcast %64 : f32 to vector<8xf32>
    %66 = vector.fma %65, %39, %34 : vector<8xf32>
    %67 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %68 = memref.load %assume_align[%arg0, %67, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %69 = vector.broadcast %68 : f32 to vector<8xf32>
    %70 = vector.fma %69, %39, %35 : vector<8xf32>
    %71 = vector.extract %38[1] : vector<8xf32> from vector<64x8xf32>
    %72 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %73 = vector.broadcast %72 : f32 to vector<8xf32>
    %74 = vector.fma %73, %71, %42 : vector<8xf32>
    %75 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %76 = memref.load %assume_align[%arg0, %75, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %77 = vector.broadcast %76 : f32 to vector<8xf32>
    %78 = vector.fma %77, %71, %46 : vector<8xf32>
    %79 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %80 = memref.load %assume_align[%arg0, %79, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %81 = vector.broadcast %80 : f32 to vector<8xf32>
    %82 = vector.fma %81, %71, %50 : vector<8xf32>
    %83 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %84 = memref.load %assume_align[%arg0, %83, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %85 = vector.broadcast %84 : f32 to vector<8xf32>
    %86 = vector.fma %85, %71, %54 : vector<8xf32>
    %87 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %88 = memref.load %assume_align[%arg0, %87, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %89 = vector.broadcast %88 : f32 to vector<8xf32>
    %90 = vector.fma %89, %71, %58 : vector<8xf32>
    %91 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %92 = memref.load %assume_align[%arg0, %91, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %93 = vector.broadcast %92 : f32 to vector<8xf32>
    %94 = vector.fma %93, %71, %62 : vector<8xf32>
    %95 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %96 = memref.load %assume_align[%arg0, %95, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %97 = vector.broadcast %96 : f32 to vector<8xf32>
    %98 = vector.fma %97, %71, %66 : vector<8xf32>
    %99 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %100 = memref.load %assume_align[%arg0, %99, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %101 = vector.broadcast %100 : f32 to vector<8xf32>
    %102 = vector.fma %101, %71, %70 : vector<8xf32>
    %103 = vector.extract %38[2] : vector<8xf32> from vector<64x8xf32>
    %104 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %105 = vector.broadcast %104 : f32 to vector<8xf32>
    %106 = vector.fma %105, %103, %74 : vector<8xf32>
    %107 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %108 = memref.load %assume_align[%arg0, %107, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %109 = vector.broadcast %108 : f32 to vector<8xf32>
    %110 = vector.fma %109, %103, %78 : vector<8xf32>
    %111 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %112 = memref.load %assume_align[%arg0, %111, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %113 = vector.broadcast %112 : f32 to vector<8xf32>
    %114 = vector.fma %113, %103, %82 : vector<8xf32>
    %115 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %116 = memref.load %assume_align[%arg0, %115, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %117 = vector.broadcast %116 : f32 to vector<8xf32>
    %118 = vector.fma %117, %103, %86 : vector<8xf32>
    %119 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %120 = memref.load %assume_align[%arg0, %119, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %121 = vector.broadcast %120 : f32 to vector<8xf32>
    %122 = vector.fma %121, %103, %90 : vector<8xf32>
    %123 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %124 = memref.load %assume_align[%arg0, %123, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %125 = vector.broadcast %124 : f32 to vector<8xf32>
    %126 = vector.fma %125, %103, %94 : vector<8xf32>
    %127 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %128 = memref.load %assume_align[%arg0, %127, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %129 = vector.broadcast %128 : f32 to vector<8xf32>
    %130 = vector.fma %129, %103, %98 : vector<8xf32>
    %131 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %132 = memref.load %assume_align[%arg0, %131, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %133 = vector.broadcast %132 : f32 to vector<8xf32>
    %134 = vector.fma %133, %103, %102 : vector<8xf32>
    %135 = vector.extract %38[3] : vector<8xf32> from vector<64x8xf32>
    %136 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %137 = vector.broadcast %136 : f32 to vector<8xf32>
    %138 = vector.fma %137, %135, %106 : vector<8xf32>
    %139 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %140 = memref.load %assume_align[%arg0, %139, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %141 = vector.broadcast %140 : f32 to vector<8xf32>
    %142 = vector.fma %141, %135, %110 : vector<8xf32>
    %143 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %144 = memref.load %assume_align[%arg0, %143, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %145 = vector.broadcast %144 : f32 to vector<8xf32>
    %146 = vector.fma %145, %135, %114 : vector<8xf32>
    %147 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %148 = memref.load %assume_align[%arg0, %147, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %149 = vector.broadcast %148 : f32 to vector<8xf32>
    %150 = vector.fma %149, %135, %118 : vector<8xf32>
    %151 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %152 = memref.load %assume_align[%arg0, %151, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %153 = vector.broadcast %152 : f32 to vector<8xf32>
    %154 = vector.fma %153, %135, %122 : vector<8xf32>
    %155 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %156 = memref.load %assume_align[%arg0, %155, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %157 = vector.broadcast %156 : f32 to vector<8xf32>
    %158 = vector.fma %157, %135, %126 : vector<8xf32>
    %159 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %160 = memref.load %assume_align[%arg0, %159, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %161 = vector.broadcast %160 : f32 to vector<8xf32>
    %162 = vector.fma %161, %135, %130 : vector<8xf32>
    %163 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %164 = memref.load %assume_align[%arg0, %163, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %165 = vector.broadcast %164 : f32 to vector<8xf32>
    %166 = vector.fma %165, %135, %134 : vector<8xf32>
    %167 = vector.extract %38[4] : vector<8xf32> from vector<64x8xf32>
    %168 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %169 = vector.broadcast %168 : f32 to vector<8xf32>
    %170 = vector.fma %169, %167, %138 : vector<8xf32>
    %171 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %172 = memref.load %assume_align[%arg0, %171, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %173 = vector.broadcast %172 : f32 to vector<8xf32>
    %174 = vector.fma %173, %167, %142 : vector<8xf32>
    %175 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %176 = memref.load %assume_align[%arg0, %175, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %177 = vector.broadcast %176 : f32 to vector<8xf32>
    %178 = vector.fma %177, %167, %146 : vector<8xf32>
    %179 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %180 = memref.load %assume_align[%arg0, %179, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %181 = vector.broadcast %180 : f32 to vector<8xf32>
    %182 = vector.fma %181, %167, %150 : vector<8xf32>
    %183 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %184 = memref.load %assume_align[%arg0, %183, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %185 = vector.broadcast %184 : f32 to vector<8xf32>
    %186 = vector.fma %185, %167, %154 : vector<8xf32>
    %187 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %188 = memref.load %assume_align[%arg0, %187, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %189 = vector.broadcast %188 : f32 to vector<8xf32>
    %190 = vector.fma %189, %167, %158 : vector<8xf32>
    %191 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %192 = memref.load %assume_align[%arg0, %191, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %193 = vector.broadcast %192 : f32 to vector<8xf32>
    %194 = vector.fma %193, %167, %162 : vector<8xf32>
    %195 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %196 = memref.load %assume_align[%arg0, %195, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %197 = vector.broadcast %196 : f32 to vector<8xf32>
    %198 = vector.fma %197, %167, %166 : vector<8xf32>
    %199 = vector.extract %38[5] : vector<8xf32> from vector<64x8xf32>
    %200 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %201 = vector.broadcast %200 : f32 to vector<8xf32>
    %202 = vector.fma %201, %199, %170 : vector<8xf32>
    %203 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %204 = memref.load %assume_align[%arg0, %203, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %205 = vector.broadcast %204 : f32 to vector<8xf32>
    %206 = vector.fma %205, %199, %174 : vector<8xf32>
    %207 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %208 = memref.load %assume_align[%arg0, %207, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %209 = vector.broadcast %208 : f32 to vector<8xf32>
    %210 = vector.fma %209, %199, %178 : vector<8xf32>
    %211 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %212 = memref.load %assume_align[%arg0, %211, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %213 = vector.broadcast %212 : f32 to vector<8xf32>
    %214 = vector.fma %213, %199, %182 : vector<8xf32>
    %215 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %216 = memref.load %assume_align[%arg0, %215, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %217 = vector.broadcast %216 : f32 to vector<8xf32>
    %218 = vector.fma %217, %199, %186 : vector<8xf32>
    %219 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %220 = memref.load %assume_align[%arg0, %219, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %221 = vector.broadcast %220 : f32 to vector<8xf32>
    %222 = vector.fma %221, %199, %190 : vector<8xf32>
    %223 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %224 = memref.load %assume_align[%arg0, %223, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %225 = vector.broadcast %224 : f32 to vector<8xf32>
    %226 = vector.fma %225, %199, %194 : vector<8xf32>
    %227 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %228 = memref.load %assume_align[%arg0, %227, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %229 = vector.broadcast %228 : f32 to vector<8xf32>
    %230 = vector.fma %229, %199, %198 : vector<8xf32>
    %231 = vector.extract %38[6] : vector<8xf32> from vector<64x8xf32>
    %232 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %233 = vector.broadcast %232 : f32 to vector<8xf32>
    %234 = vector.fma %233, %231, %202 : vector<8xf32>
    %235 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %236 = memref.load %assume_align[%arg0, %235, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %237 = vector.broadcast %236 : f32 to vector<8xf32>
    %238 = vector.fma %237, %231, %206 : vector<8xf32>
    %239 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %240 = memref.load %assume_align[%arg0, %239, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %241 = vector.broadcast %240 : f32 to vector<8xf32>
    %242 = vector.fma %241, %231, %210 : vector<8xf32>
    %243 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %244 = memref.load %assume_align[%arg0, %243, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %245 = vector.broadcast %244 : f32 to vector<8xf32>
    %246 = vector.fma %245, %231, %214 : vector<8xf32>
    %247 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %248 = memref.load %assume_align[%arg0, %247, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %249 = vector.broadcast %248 : f32 to vector<8xf32>
    %250 = vector.fma %249, %231, %218 : vector<8xf32>
    %251 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %252 = memref.load %assume_align[%arg0, %251, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %253 = vector.broadcast %252 : f32 to vector<8xf32>
    %254 = vector.fma %253, %231, %222 : vector<8xf32>
    %255 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %256 = memref.load %assume_align[%arg0, %255, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %257 = vector.broadcast %256 : f32 to vector<8xf32>
    %258 = vector.fma %257, %231, %226 : vector<8xf32>
    %259 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %260 = memref.load %assume_align[%arg0, %259, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %261 = vector.broadcast %260 : f32 to vector<8xf32>
    %262 = vector.fma %261, %231, %230 : vector<8xf32>
    %263 = vector.extract %38[7] : vector<8xf32> from vector<64x8xf32>
    %264 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %265 = vector.broadcast %264 : f32 to vector<8xf32>
    %266 = vector.fma %265, %263, %234 : vector<8xf32>
    %267 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %268 = memref.load %assume_align[%arg0, %267, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %269 = vector.broadcast %268 : f32 to vector<8xf32>
    %270 = vector.fma %269, %263, %238 : vector<8xf32>
    %271 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %272 = memref.load %assume_align[%arg0, %271, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %273 = vector.broadcast %272 : f32 to vector<8xf32>
    %274 = vector.fma %273, %263, %242 : vector<8xf32>
    %275 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %276 = memref.load %assume_align[%arg0, %275, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %277 = vector.broadcast %276 : f32 to vector<8xf32>
    %278 = vector.fma %277, %263, %246 : vector<8xf32>
    %279 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %280 = memref.load %assume_align[%arg0, %279, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %281 = vector.broadcast %280 : f32 to vector<8xf32>
    %282 = vector.fma %281, %263, %250 : vector<8xf32>
    %283 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %284 = memref.load %assume_align[%arg0, %283, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %285 = vector.broadcast %284 : f32 to vector<8xf32>
    %286 = vector.fma %285, %263, %254 : vector<8xf32>
    %287 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %288 = memref.load %assume_align[%arg0, %287, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %289 = vector.broadcast %288 : f32 to vector<8xf32>
    %290 = vector.fma %289, %263, %258 : vector<8xf32>
    %291 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %292 = memref.load %assume_align[%arg0, %291, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %293 = vector.broadcast %292 : f32 to vector<8xf32>
    %294 = vector.fma %293, %263, %262 : vector<8xf32>
    %295 = vector.extract %38[8] : vector<8xf32> from vector<64x8xf32>
    %296 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %297 = vector.broadcast %296 : f32 to vector<8xf32>
    %298 = vector.fma %297, %295, %266 : vector<8xf32>
    %299 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %300 = memref.load %assume_align[%arg0, %299, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %301 = vector.broadcast %300 : f32 to vector<8xf32>
    %302 = vector.fma %301, %295, %270 : vector<8xf32>
    %303 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %304 = memref.load %assume_align[%arg0, %303, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %305 = vector.broadcast %304 : f32 to vector<8xf32>
    %306 = vector.fma %305, %295, %274 : vector<8xf32>
    %307 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %308 = memref.load %assume_align[%arg0, %307, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %309 = vector.broadcast %308 : f32 to vector<8xf32>
    %310 = vector.fma %309, %295, %278 : vector<8xf32>
    %311 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %312 = memref.load %assume_align[%arg0, %311, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %313 = vector.broadcast %312 : f32 to vector<8xf32>
    %314 = vector.fma %313, %295, %282 : vector<8xf32>
    %315 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %316 = memref.load %assume_align[%arg0, %315, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %317 = vector.broadcast %316 : f32 to vector<8xf32>
    %318 = vector.fma %317, %295, %286 : vector<8xf32>
    %319 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %320 = memref.load %assume_align[%arg0, %319, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %321 = vector.broadcast %320 : f32 to vector<8xf32>
    %322 = vector.fma %321, %295, %290 : vector<8xf32>
    %323 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %324 = memref.load %assume_align[%arg0, %323, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %325 = vector.broadcast %324 : f32 to vector<8xf32>
    %326 = vector.fma %325, %295, %294 : vector<8xf32>
    %327 = vector.extract %38[9] : vector<8xf32> from vector<64x8xf32>
    %328 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %329 = vector.broadcast %328 : f32 to vector<8xf32>
    %330 = vector.fma %329, %327, %298 : vector<8xf32>
    %331 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %332 = memref.load %assume_align[%arg0, %331, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %333 = vector.broadcast %332 : f32 to vector<8xf32>
    %334 = vector.fma %333, %327, %302 : vector<8xf32>
    %335 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %336 = memref.load %assume_align[%arg0, %335, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %337 = vector.broadcast %336 : f32 to vector<8xf32>
    %338 = vector.fma %337, %327, %306 : vector<8xf32>
    %339 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %340 = memref.load %assume_align[%arg0, %339, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %341 = vector.broadcast %340 : f32 to vector<8xf32>
    %342 = vector.fma %341, %327, %310 : vector<8xf32>
    %343 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %344 = memref.load %assume_align[%arg0, %343, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %345 = vector.broadcast %344 : f32 to vector<8xf32>
    %346 = vector.fma %345, %327, %314 : vector<8xf32>
    %347 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %348 = memref.load %assume_align[%arg0, %347, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %349 = vector.broadcast %348 : f32 to vector<8xf32>
    %350 = vector.fma %349, %327, %318 : vector<8xf32>
    %351 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %352 = memref.load %assume_align[%arg0, %351, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %353 = vector.broadcast %352 : f32 to vector<8xf32>
    %354 = vector.fma %353, %327, %322 : vector<8xf32>
    %355 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %356 = memref.load %assume_align[%arg0, %355, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %357 = vector.broadcast %356 : f32 to vector<8xf32>
    %358 = vector.fma %357, %327, %326 : vector<8xf32>
    %359 = vector.extract %38[10] : vector<8xf32> from vector<64x8xf32>
    %360 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %361 = vector.broadcast %360 : f32 to vector<8xf32>
    %362 = vector.fma %361, %359, %330 : vector<8xf32>
    %363 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %364 = memref.load %assume_align[%arg0, %363, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %365 = vector.broadcast %364 : f32 to vector<8xf32>
    %366 = vector.fma %365, %359, %334 : vector<8xf32>
    %367 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %368 = memref.load %assume_align[%arg0, %367, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %369 = vector.broadcast %368 : f32 to vector<8xf32>
    %370 = vector.fma %369, %359, %338 : vector<8xf32>
    %371 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %372 = memref.load %assume_align[%arg0, %371, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %373 = vector.broadcast %372 : f32 to vector<8xf32>
    %374 = vector.fma %373, %359, %342 : vector<8xf32>
    %375 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %376 = memref.load %assume_align[%arg0, %375, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %377 = vector.broadcast %376 : f32 to vector<8xf32>
    %378 = vector.fma %377, %359, %346 : vector<8xf32>
    %379 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %380 = memref.load %assume_align[%arg0, %379, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %381 = vector.broadcast %380 : f32 to vector<8xf32>
    %382 = vector.fma %381, %359, %350 : vector<8xf32>
    %383 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %384 = memref.load %assume_align[%arg0, %383, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %385 = vector.broadcast %384 : f32 to vector<8xf32>
    %386 = vector.fma %385, %359, %354 : vector<8xf32>
    %387 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %388 = memref.load %assume_align[%arg0, %387, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %389 = vector.broadcast %388 : f32 to vector<8xf32>
    %390 = vector.fma %389, %359, %358 : vector<8xf32>
    %391 = vector.extract %38[11] : vector<8xf32> from vector<64x8xf32>
    %392 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %393 = vector.broadcast %392 : f32 to vector<8xf32>
    %394 = vector.fma %393, %391, %362 : vector<8xf32>
    %395 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %396 = memref.load %assume_align[%arg0, %395, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %397 = vector.broadcast %396 : f32 to vector<8xf32>
    %398 = vector.fma %397, %391, %366 : vector<8xf32>
    %399 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %400 = memref.load %assume_align[%arg0, %399, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %401 = vector.broadcast %400 : f32 to vector<8xf32>
    %402 = vector.fma %401, %391, %370 : vector<8xf32>
    %403 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %404 = memref.load %assume_align[%arg0, %403, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %405 = vector.broadcast %404 : f32 to vector<8xf32>
    %406 = vector.fma %405, %391, %374 : vector<8xf32>
    %407 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %408 = memref.load %assume_align[%arg0, %407, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %409 = vector.broadcast %408 : f32 to vector<8xf32>
    %410 = vector.fma %409, %391, %378 : vector<8xf32>
    %411 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %412 = memref.load %assume_align[%arg0, %411, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %413 = vector.broadcast %412 : f32 to vector<8xf32>
    %414 = vector.fma %413, %391, %382 : vector<8xf32>
    %415 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %416 = memref.load %assume_align[%arg0, %415, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %417 = vector.broadcast %416 : f32 to vector<8xf32>
    %418 = vector.fma %417, %391, %386 : vector<8xf32>
    %419 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %420 = memref.load %assume_align[%arg0, %419, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %421 = vector.broadcast %420 : f32 to vector<8xf32>
    %422 = vector.fma %421, %391, %390 : vector<8xf32>
    %423 = vector.extract %38[12] : vector<8xf32> from vector<64x8xf32>
    %424 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %425 = vector.broadcast %424 : f32 to vector<8xf32>
    %426 = vector.fma %425, %423, %394 : vector<8xf32>
    %427 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %428 = memref.load %assume_align[%arg0, %427, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %429 = vector.broadcast %428 : f32 to vector<8xf32>
    %430 = vector.fma %429, %423, %398 : vector<8xf32>
    %431 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %432 = memref.load %assume_align[%arg0, %431, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %433 = vector.broadcast %432 : f32 to vector<8xf32>
    %434 = vector.fma %433, %423, %402 : vector<8xf32>
    %435 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %436 = memref.load %assume_align[%arg0, %435, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %437 = vector.broadcast %436 : f32 to vector<8xf32>
    %438 = vector.fma %437, %423, %406 : vector<8xf32>
    %439 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %440 = memref.load %assume_align[%arg0, %439, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %441 = vector.broadcast %440 : f32 to vector<8xf32>
    %442 = vector.fma %441, %423, %410 : vector<8xf32>
    %443 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %444 = memref.load %assume_align[%arg0, %443, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %445 = vector.broadcast %444 : f32 to vector<8xf32>
    %446 = vector.fma %445, %423, %414 : vector<8xf32>
    %447 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %448 = memref.load %assume_align[%arg0, %447, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %449 = vector.broadcast %448 : f32 to vector<8xf32>
    %450 = vector.fma %449, %423, %418 : vector<8xf32>
    %451 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %452 = memref.load %assume_align[%arg0, %451, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %453 = vector.broadcast %452 : f32 to vector<8xf32>
    %454 = vector.fma %453, %423, %422 : vector<8xf32>
    %455 = vector.extract %38[13] : vector<8xf32> from vector<64x8xf32>
    %456 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %457 = vector.broadcast %456 : f32 to vector<8xf32>
    %458 = vector.fma %457, %455, %426 : vector<8xf32>
    %459 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %460 = memref.load %assume_align[%arg0, %459, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %461 = vector.broadcast %460 : f32 to vector<8xf32>
    %462 = vector.fma %461, %455, %430 : vector<8xf32>
    %463 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %464 = memref.load %assume_align[%arg0, %463, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %465 = vector.broadcast %464 : f32 to vector<8xf32>
    %466 = vector.fma %465, %455, %434 : vector<8xf32>
    %467 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %468 = memref.load %assume_align[%arg0, %467, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %469 = vector.broadcast %468 : f32 to vector<8xf32>
    %470 = vector.fma %469, %455, %438 : vector<8xf32>
    %471 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %472 = memref.load %assume_align[%arg0, %471, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %473 = vector.broadcast %472 : f32 to vector<8xf32>
    %474 = vector.fma %473, %455, %442 : vector<8xf32>
    %475 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %476 = memref.load %assume_align[%arg0, %475, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %477 = vector.broadcast %476 : f32 to vector<8xf32>
    %478 = vector.fma %477, %455, %446 : vector<8xf32>
    %479 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %480 = memref.load %assume_align[%arg0, %479, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %481 = vector.broadcast %480 : f32 to vector<8xf32>
    %482 = vector.fma %481, %455, %450 : vector<8xf32>
    %483 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %484 = memref.load %assume_align[%arg0, %483, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %485 = vector.broadcast %484 : f32 to vector<8xf32>
    %486 = vector.fma %485, %455, %454 : vector<8xf32>
    %487 = vector.extract %38[14] : vector<8xf32> from vector<64x8xf32>
    %488 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %489 = vector.broadcast %488 : f32 to vector<8xf32>
    %490 = vector.fma %489, %487, %458 : vector<8xf32>
    %491 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %492 = memref.load %assume_align[%arg0, %491, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %493 = vector.broadcast %492 : f32 to vector<8xf32>
    %494 = vector.fma %493, %487, %462 : vector<8xf32>
    %495 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %496 = memref.load %assume_align[%arg0, %495, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %497 = vector.broadcast %496 : f32 to vector<8xf32>
    %498 = vector.fma %497, %487, %466 : vector<8xf32>
    %499 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %500 = memref.load %assume_align[%arg0, %499, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %501 = vector.broadcast %500 : f32 to vector<8xf32>
    %502 = vector.fma %501, %487, %470 : vector<8xf32>
    %503 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %504 = memref.load %assume_align[%arg0, %503, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %505 = vector.broadcast %504 : f32 to vector<8xf32>
    %506 = vector.fma %505, %487, %474 : vector<8xf32>
    %507 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %508 = memref.load %assume_align[%arg0, %507, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %509 = vector.broadcast %508 : f32 to vector<8xf32>
    %510 = vector.fma %509, %487, %478 : vector<8xf32>
    %511 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %512 = memref.load %assume_align[%arg0, %511, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %513 = vector.broadcast %512 : f32 to vector<8xf32>
    %514 = vector.fma %513, %487, %482 : vector<8xf32>
    %515 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %516 = memref.load %assume_align[%arg0, %515, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %517 = vector.broadcast %516 : f32 to vector<8xf32>
    %518 = vector.fma %517, %487, %486 : vector<8xf32>
    %519 = vector.extract %38[15] : vector<8xf32> from vector<64x8xf32>
    %520 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %521 = vector.broadcast %520 : f32 to vector<8xf32>
    %522 = vector.fma %521, %519, %490 : vector<8xf32>
    %523 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %524 = memref.load %assume_align[%arg0, %523, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %525 = vector.broadcast %524 : f32 to vector<8xf32>
    %526 = vector.fma %525, %519, %494 : vector<8xf32>
    %527 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %528 = memref.load %assume_align[%arg0, %527, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %529 = vector.broadcast %528 : f32 to vector<8xf32>
    %530 = vector.fma %529, %519, %498 : vector<8xf32>
    %531 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %532 = memref.load %assume_align[%arg0, %531, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %533 = vector.broadcast %532 : f32 to vector<8xf32>
    %534 = vector.fma %533, %519, %502 : vector<8xf32>
    %535 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %536 = memref.load %assume_align[%arg0, %535, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %537 = vector.broadcast %536 : f32 to vector<8xf32>
    %538 = vector.fma %537, %519, %506 : vector<8xf32>
    %539 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %540 = memref.load %assume_align[%arg0, %539, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %541 = vector.broadcast %540 : f32 to vector<8xf32>
    %542 = vector.fma %541, %519, %510 : vector<8xf32>
    %543 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %544 = memref.load %assume_align[%arg0, %543, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %545 = vector.broadcast %544 : f32 to vector<8xf32>
    %546 = vector.fma %545, %519, %514 : vector<8xf32>
    %547 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %548 = memref.load %assume_align[%arg0, %547, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %549 = vector.broadcast %548 : f32 to vector<8xf32>
    %550 = vector.fma %549, %519, %518 : vector<8xf32>
    %551 = vector.extract %38[16] : vector<8xf32> from vector<64x8xf32>
    %552 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %553 = vector.broadcast %552 : f32 to vector<8xf32>
    %554 = vector.fma %553, %551, %522 : vector<8xf32>
    %555 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %556 = memref.load %assume_align[%arg0, %555, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %557 = vector.broadcast %556 : f32 to vector<8xf32>
    %558 = vector.fma %557, %551, %526 : vector<8xf32>
    %559 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %560 = memref.load %assume_align[%arg0, %559, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %561 = vector.broadcast %560 : f32 to vector<8xf32>
    %562 = vector.fma %561, %551, %530 : vector<8xf32>
    %563 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %564 = memref.load %assume_align[%arg0, %563, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %565 = vector.broadcast %564 : f32 to vector<8xf32>
    %566 = vector.fma %565, %551, %534 : vector<8xf32>
    %567 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %568 = memref.load %assume_align[%arg0, %567, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %569 = vector.broadcast %568 : f32 to vector<8xf32>
    %570 = vector.fma %569, %551, %538 : vector<8xf32>
    %571 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %572 = memref.load %assume_align[%arg0, %571, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %573 = vector.broadcast %572 : f32 to vector<8xf32>
    %574 = vector.fma %573, %551, %542 : vector<8xf32>
    %575 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %576 = memref.load %assume_align[%arg0, %575, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %577 = vector.broadcast %576 : f32 to vector<8xf32>
    %578 = vector.fma %577, %551, %546 : vector<8xf32>
    %579 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %580 = memref.load %assume_align[%arg0, %579, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %581 = vector.broadcast %580 : f32 to vector<8xf32>
    %582 = vector.fma %581, %551, %550 : vector<8xf32>
    %583 = vector.extract %38[17] : vector<8xf32> from vector<64x8xf32>
    %584 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %585 = vector.broadcast %584 : f32 to vector<8xf32>
    %586 = vector.fma %585, %583, %554 : vector<8xf32>
    %587 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %588 = memref.load %assume_align[%arg0, %587, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %589 = vector.broadcast %588 : f32 to vector<8xf32>
    %590 = vector.fma %589, %583, %558 : vector<8xf32>
    %591 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %592 = memref.load %assume_align[%arg0, %591, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %593 = vector.broadcast %592 : f32 to vector<8xf32>
    %594 = vector.fma %593, %583, %562 : vector<8xf32>
    %595 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %596 = memref.load %assume_align[%arg0, %595, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %597 = vector.broadcast %596 : f32 to vector<8xf32>
    %598 = vector.fma %597, %583, %566 : vector<8xf32>
    %599 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %600 = memref.load %assume_align[%arg0, %599, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %601 = vector.broadcast %600 : f32 to vector<8xf32>
    %602 = vector.fma %601, %583, %570 : vector<8xf32>
    %603 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %604 = memref.load %assume_align[%arg0, %603, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %605 = vector.broadcast %604 : f32 to vector<8xf32>
    %606 = vector.fma %605, %583, %574 : vector<8xf32>
    %607 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %608 = memref.load %assume_align[%arg0, %607, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %609 = vector.broadcast %608 : f32 to vector<8xf32>
    %610 = vector.fma %609, %583, %578 : vector<8xf32>
    %611 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %612 = memref.load %assume_align[%arg0, %611, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %613 = vector.broadcast %612 : f32 to vector<8xf32>
    %614 = vector.fma %613, %583, %582 : vector<8xf32>
    %615 = vector.extract %38[18] : vector<8xf32> from vector<64x8xf32>
    %616 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %617 = vector.broadcast %616 : f32 to vector<8xf32>
    %618 = vector.fma %617, %615, %586 : vector<8xf32>
    %619 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %620 = memref.load %assume_align[%arg0, %619, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %621 = vector.broadcast %620 : f32 to vector<8xf32>
    %622 = vector.fma %621, %615, %590 : vector<8xf32>
    %623 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %624 = memref.load %assume_align[%arg0, %623, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %625 = vector.broadcast %624 : f32 to vector<8xf32>
    %626 = vector.fma %625, %615, %594 : vector<8xf32>
    %627 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %628 = memref.load %assume_align[%arg0, %627, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %629 = vector.broadcast %628 : f32 to vector<8xf32>
    %630 = vector.fma %629, %615, %598 : vector<8xf32>
    %631 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %632 = memref.load %assume_align[%arg0, %631, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %633 = vector.broadcast %632 : f32 to vector<8xf32>
    %634 = vector.fma %633, %615, %602 : vector<8xf32>
    %635 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %636 = memref.load %assume_align[%arg0, %635, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %637 = vector.broadcast %636 : f32 to vector<8xf32>
    %638 = vector.fma %637, %615, %606 : vector<8xf32>
    %639 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %640 = memref.load %assume_align[%arg0, %639, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %641 = vector.broadcast %640 : f32 to vector<8xf32>
    %642 = vector.fma %641, %615, %610 : vector<8xf32>
    %643 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %644 = memref.load %assume_align[%arg0, %643, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %645 = vector.broadcast %644 : f32 to vector<8xf32>
    %646 = vector.fma %645, %615, %614 : vector<8xf32>
    %647 = vector.extract %38[19] : vector<8xf32> from vector<64x8xf32>
    %648 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %649 = vector.broadcast %648 : f32 to vector<8xf32>
    %650 = vector.fma %649, %647, %618 : vector<8xf32>
    %651 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %652 = memref.load %assume_align[%arg0, %651, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %653 = vector.broadcast %652 : f32 to vector<8xf32>
    %654 = vector.fma %653, %647, %622 : vector<8xf32>
    %655 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %656 = memref.load %assume_align[%arg0, %655, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %657 = vector.broadcast %656 : f32 to vector<8xf32>
    %658 = vector.fma %657, %647, %626 : vector<8xf32>
    %659 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %660 = memref.load %assume_align[%arg0, %659, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %661 = vector.broadcast %660 : f32 to vector<8xf32>
    %662 = vector.fma %661, %647, %630 : vector<8xf32>
    %663 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %664 = memref.load %assume_align[%arg0, %663, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %665 = vector.broadcast %664 : f32 to vector<8xf32>
    %666 = vector.fma %665, %647, %634 : vector<8xf32>
    %667 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %668 = memref.load %assume_align[%arg0, %667, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %669 = vector.broadcast %668 : f32 to vector<8xf32>
    %670 = vector.fma %669, %647, %638 : vector<8xf32>
    %671 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %672 = memref.load %assume_align[%arg0, %671, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %673 = vector.broadcast %672 : f32 to vector<8xf32>
    %674 = vector.fma %673, %647, %642 : vector<8xf32>
    %675 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %676 = memref.load %assume_align[%arg0, %675, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %677 = vector.broadcast %676 : f32 to vector<8xf32>
    %678 = vector.fma %677, %647, %646 : vector<8xf32>
    %679 = vector.extract %38[20] : vector<8xf32> from vector<64x8xf32>
    %680 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %681 = vector.broadcast %680 : f32 to vector<8xf32>
    %682 = vector.fma %681, %679, %650 : vector<8xf32>
    %683 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %684 = memref.load %assume_align[%arg0, %683, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %685 = vector.broadcast %684 : f32 to vector<8xf32>
    %686 = vector.fma %685, %679, %654 : vector<8xf32>
    %687 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %688 = memref.load %assume_align[%arg0, %687, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %689 = vector.broadcast %688 : f32 to vector<8xf32>
    %690 = vector.fma %689, %679, %658 : vector<8xf32>
    %691 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %692 = memref.load %assume_align[%arg0, %691, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %693 = vector.broadcast %692 : f32 to vector<8xf32>
    %694 = vector.fma %693, %679, %662 : vector<8xf32>
    %695 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %696 = memref.load %assume_align[%arg0, %695, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %697 = vector.broadcast %696 : f32 to vector<8xf32>
    %698 = vector.fma %697, %679, %666 : vector<8xf32>
    %699 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %700 = memref.load %assume_align[%arg0, %699, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %701 = vector.broadcast %700 : f32 to vector<8xf32>
    %702 = vector.fma %701, %679, %670 : vector<8xf32>
    %703 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %704 = memref.load %assume_align[%arg0, %703, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %705 = vector.broadcast %704 : f32 to vector<8xf32>
    %706 = vector.fma %705, %679, %674 : vector<8xf32>
    %707 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %708 = memref.load %assume_align[%arg0, %707, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %709 = vector.broadcast %708 : f32 to vector<8xf32>
    %710 = vector.fma %709, %679, %678 : vector<8xf32>
    %711 = vector.extract %38[21] : vector<8xf32> from vector<64x8xf32>
    %712 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %713 = vector.broadcast %712 : f32 to vector<8xf32>
    %714 = vector.fma %713, %711, %682 : vector<8xf32>
    %715 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %716 = memref.load %assume_align[%arg0, %715, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %717 = vector.broadcast %716 : f32 to vector<8xf32>
    %718 = vector.fma %717, %711, %686 : vector<8xf32>
    %719 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %720 = memref.load %assume_align[%arg0, %719, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %721 = vector.broadcast %720 : f32 to vector<8xf32>
    %722 = vector.fma %721, %711, %690 : vector<8xf32>
    %723 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %724 = memref.load %assume_align[%arg0, %723, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %725 = vector.broadcast %724 : f32 to vector<8xf32>
    %726 = vector.fma %725, %711, %694 : vector<8xf32>
    %727 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %728 = memref.load %assume_align[%arg0, %727, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %729 = vector.broadcast %728 : f32 to vector<8xf32>
    %730 = vector.fma %729, %711, %698 : vector<8xf32>
    %731 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %732 = memref.load %assume_align[%arg0, %731, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %733 = vector.broadcast %732 : f32 to vector<8xf32>
    %734 = vector.fma %733, %711, %702 : vector<8xf32>
    %735 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %736 = memref.load %assume_align[%arg0, %735, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %737 = vector.broadcast %736 : f32 to vector<8xf32>
    %738 = vector.fma %737, %711, %706 : vector<8xf32>
    %739 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %740 = memref.load %assume_align[%arg0, %739, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %741 = vector.broadcast %740 : f32 to vector<8xf32>
    %742 = vector.fma %741, %711, %710 : vector<8xf32>
    %743 = vector.extract %38[22] : vector<8xf32> from vector<64x8xf32>
    %744 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %745 = vector.broadcast %744 : f32 to vector<8xf32>
    %746 = vector.fma %745, %743, %714 : vector<8xf32>
    %747 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %748 = memref.load %assume_align[%arg0, %747, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %749 = vector.broadcast %748 : f32 to vector<8xf32>
    %750 = vector.fma %749, %743, %718 : vector<8xf32>
    %751 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %752 = memref.load %assume_align[%arg0, %751, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %753 = vector.broadcast %752 : f32 to vector<8xf32>
    %754 = vector.fma %753, %743, %722 : vector<8xf32>
    %755 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %756 = memref.load %assume_align[%arg0, %755, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %757 = vector.broadcast %756 : f32 to vector<8xf32>
    %758 = vector.fma %757, %743, %726 : vector<8xf32>
    %759 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %760 = memref.load %assume_align[%arg0, %759, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %761 = vector.broadcast %760 : f32 to vector<8xf32>
    %762 = vector.fma %761, %743, %730 : vector<8xf32>
    %763 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %764 = memref.load %assume_align[%arg0, %763, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %765 = vector.broadcast %764 : f32 to vector<8xf32>
    %766 = vector.fma %765, %743, %734 : vector<8xf32>
    %767 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %768 = memref.load %assume_align[%arg0, %767, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %769 = vector.broadcast %768 : f32 to vector<8xf32>
    %770 = vector.fma %769, %743, %738 : vector<8xf32>
    %771 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %772 = memref.load %assume_align[%arg0, %771, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %773 = vector.broadcast %772 : f32 to vector<8xf32>
    %774 = vector.fma %773, %743, %742 : vector<8xf32>
    %775 = vector.extract %38[23] : vector<8xf32> from vector<64x8xf32>
    %776 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %777 = vector.broadcast %776 : f32 to vector<8xf32>
    %778 = vector.fma %777, %775, %746 : vector<8xf32>
    %779 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %780 = memref.load %assume_align[%arg0, %779, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %781 = vector.broadcast %780 : f32 to vector<8xf32>
    %782 = vector.fma %781, %775, %750 : vector<8xf32>
    %783 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %784 = memref.load %assume_align[%arg0, %783, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %785 = vector.broadcast %784 : f32 to vector<8xf32>
    %786 = vector.fma %785, %775, %754 : vector<8xf32>
    %787 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %788 = memref.load %assume_align[%arg0, %787, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %789 = vector.broadcast %788 : f32 to vector<8xf32>
    %790 = vector.fma %789, %775, %758 : vector<8xf32>
    %791 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %792 = memref.load %assume_align[%arg0, %791, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %793 = vector.broadcast %792 : f32 to vector<8xf32>
    %794 = vector.fma %793, %775, %762 : vector<8xf32>
    %795 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %796 = memref.load %assume_align[%arg0, %795, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %797 = vector.broadcast %796 : f32 to vector<8xf32>
    %798 = vector.fma %797, %775, %766 : vector<8xf32>
    %799 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %800 = memref.load %assume_align[%arg0, %799, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %801 = vector.broadcast %800 : f32 to vector<8xf32>
    %802 = vector.fma %801, %775, %770 : vector<8xf32>
    %803 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %804 = memref.load %assume_align[%arg0, %803, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %805 = vector.broadcast %804 : f32 to vector<8xf32>
    %806 = vector.fma %805, %775, %774 : vector<8xf32>
    %807 = vector.extract %38[24] : vector<8xf32> from vector<64x8xf32>
    %808 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %809 = vector.broadcast %808 : f32 to vector<8xf32>
    %810 = vector.fma %809, %807, %778 : vector<8xf32>
    %811 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %812 = memref.load %assume_align[%arg0, %811, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %813 = vector.broadcast %812 : f32 to vector<8xf32>
    %814 = vector.fma %813, %807, %782 : vector<8xf32>
    %815 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %816 = memref.load %assume_align[%arg0, %815, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %817 = vector.broadcast %816 : f32 to vector<8xf32>
    %818 = vector.fma %817, %807, %786 : vector<8xf32>
    %819 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %820 = memref.load %assume_align[%arg0, %819, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %821 = vector.broadcast %820 : f32 to vector<8xf32>
    %822 = vector.fma %821, %807, %790 : vector<8xf32>
    %823 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %824 = memref.load %assume_align[%arg0, %823, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %825 = vector.broadcast %824 : f32 to vector<8xf32>
    %826 = vector.fma %825, %807, %794 : vector<8xf32>
    %827 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %828 = memref.load %assume_align[%arg0, %827, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %829 = vector.broadcast %828 : f32 to vector<8xf32>
    %830 = vector.fma %829, %807, %798 : vector<8xf32>
    %831 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %832 = memref.load %assume_align[%arg0, %831, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %833 = vector.broadcast %832 : f32 to vector<8xf32>
    %834 = vector.fma %833, %807, %802 : vector<8xf32>
    %835 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %836 = memref.load %assume_align[%arg0, %835, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %837 = vector.broadcast %836 : f32 to vector<8xf32>
    %838 = vector.fma %837, %807, %806 : vector<8xf32>
    %839 = vector.extract %38[25] : vector<8xf32> from vector<64x8xf32>
    %840 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %841 = vector.broadcast %840 : f32 to vector<8xf32>
    %842 = vector.fma %841, %839, %810 : vector<8xf32>
    %843 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %844 = memref.load %assume_align[%arg0, %843, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %845 = vector.broadcast %844 : f32 to vector<8xf32>
    %846 = vector.fma %845, %839, %814 : vector<8xf32>
    %847 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %848 = memref.load %assume_align[%arg0, %847, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %849 = vector.broadcast %848 : f32 to vector<8xf32>
    %850 = vector.fma %849, %839, %818 : vector<8xf32>
    %851 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %852 = memref.load %assume_align[%arg0, %851, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %853 = vector.broadcast %852 : f32 to vector<8xf32>
    %854 = vector.fma %853, %839, %822 : vector<8xf32>
    %855 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %856 = memref.load %assume_align[%arg0, %855, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %857 = vector.broadcast %856 : f32 to vector<8xf32>
    %858 = vector.fma %857, %839, %826 : vector<8xf32>
    %859 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %860 = memref.load %assume_align[%arg0, %859, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %861 = vector.broadcast %860 : f32 to vector<8xf32>
    %862 = vector.fma %861, %839, %830 : vector<8xf32>
    %863 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %864 = memref.load %assume_align[%arg0, %863, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %865 = vector.broadcast %864 : f32 to vector<8xf32>
    %866 = vector.fma %865, %839, %834 : vector<8xf32>
    %867 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %868 = memref.load %assume_align[%arg0, %867, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %869 = vector.broadcast %868 : f32 to vector<8xf32>
    %870 = vector.fma %869, %839, %838 : vector<8xf32>
    %871 = vector.extract %38[26] : vector<8xf32> from vector<64x8xf32>
    %872 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %873 = vector.broadcast %872 : f32 to vector<8xf32>
    %874 = vector.fma %873, %871, %842 : vector<8xf32>
    %875 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %876 = memref.load %assume_align[%arg0, %875, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %877 = vector.broadcast %876 : f32 to vector<8xf32>
    %878 = vector.fma %877, %871, %846 : vector<8xf32>
    %879 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %880 = memref.load %assume_align[%arg0, %879, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %881 = vector.broadcast %880 : f32 to vector<8xf32>
    %882 = vector.fma %881, %871, %850 : vector<8xf32>
    %883 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %884 = memref.load %assume_align[%arg0, %883, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %885 = vector.broadcast %884 : f32 to vector<8xf32>
    %886 = vector.fma %885, %871, %854 : vector<8xf32>
    %887 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %888 = memref.load %assume_align[%arg0, %887, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %889 = vector.broadcast %888 : f32 to vector<8xf32>
    %890 = vector.fma %889, %871, %858 : vector<8xf32>
    %891 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %892 = memref.load %assume_align[%arg0, %891, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %893 = vector.broadcast %892 : f32 to vector<8xf32>
    %894 = vector.fma %893, %871, %862 : vector<8xf32>
    %895 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %896 = memref.load %assume_align[%arg0, %895, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %897 = vector.broadcast %896 : f32 to vector<8xf32>
    %898 = vector.fma %897, %871, %866 : vector<8xf32>
    %899 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %900 = memref.load %assume_align[%arg0, %899, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %901 = vector.broadcast %900 : f32 to vector<8xf32>
    %902 = vector.fma %901, %871, %870 : vector<8xf32>
    %903 = vector.extract %38[27] : vector<8xf32> from vector<64x8xf32>
    %904 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %905 = vector.broadcast %904 : f32 to vector<8xf32>
    %906 = vector.fma %905, %903, %874 : vector<8xf32>
    %907 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %908 = memref.load %assume_align[%arg0, %907, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %909 = vector.broadcast %908 : f32 to vector<8xf32>
    %910 = vector.fma %909, %903, %878 : vector<8xf32>
    %911 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %912 = memref.load %assume_align[%arg0, %911, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %913 = vector.broadcast %912 : f32 to vector<8xf32>
    %914 = vector.fma %913, %903, %882 : vector<8xf32>
    %915 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %916 = memref.load %assume_align[%arg0, %915, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %917 = vector.broadcast %916 : f32 to vector<8xf32>
    %918 = vector.fma %917, %903, %886 : vector<8xf32>
    %919 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %920 = memref.load %assume_align[%arg0, %919, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %921 = vector.broadcast %920 : f32 to vector<8xf32>
    %922 = vector.fma %921, %903, %890 : vector<8xf32>
    %923 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %924 = memref.load %assume_align[%arg0, %923, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %925 = vector.broadcast %924 : f32 to vector<8xf32>
    %926 = vector.fma %925, %903, %894 : vector<8xf32>
    %927 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %928 = memref.load %assume_align[%arg0, %927, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %929 = vector.broadcast %928 : f32 to vector<8xf32>
    %930 = vector.fma %929, %903, %898 : vector<8xf32>
    %931 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %932 = memref.load %assume_align[%arg0, %931, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %933 = vector.broadcast %932 : f32 to vector<8xf32>
    %934 = vector.fma %933, %903, %902 : vector<8xf32>
    %935 = vector.extract %38[28] : vector<8xf32> from vector<64x8xf32>
    %936 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %937 = vector.broadcast %936 : f32 to vector<8xf32>
    %938 = vector.fma %937, %935, %906 : vector<8xf32>
    %939 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %940 = memref.load %assume_align[%arg0, %939, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %941 = vector.broadcast %940 : f32 to vector<8xf32>
    %942 = vector.fma %941, %935, %910 : vector<8xf32>
    %943 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %944 = memref.load %assume_align[%arg0, %943, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %945 = vector.broadcast %944 : f32 to vector<8xf32>
    %946 = vector.fma %945, %935, %914 : vector<8xf32>
    %947 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %948 = memref.load %assume_align[%arg0, %947, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %949 = vector.broadcast %948 : f32 to vector<8xf32>
    %950 = vector.fma %949, %935, %918 : vector<8xf32>
    %951 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %952 = memref.load %assume_align[%arg0, %951, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %953 = vector.broadcast %952 : f32 to vector<8xf32>
    %954 = vector.fma %953, %935, %922 : vector<8xf32>
    %955 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %956 = memref.load %assume_align[%arg0, %955, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %957 = vector.broadcast %956 : f32 to vector<8xf32>
    %958 = vector.fma %957, %935, %926 : vector<8xf32>
    %959 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %960 = memref.load %assume_align[%arg0, %959, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %961 = vector.broadcast %960 : f32 to vector<8xf32>
    %962 = vector.fma %961, %935, %930 : vector<8xf32>
    %963 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %964 = memref.load %assume_align[%arg0, %963, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %965 = vector.broadcast %964 : f32 to vector<8xf32>
    %966 = vector.fma %965, %935, %934 : vector<8xf32>
    %967 = vector.extract %38[29] : vector<8xf32> from vector<64x8xf32>
    %968 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %969 = vector.broadcast %968 : f32 to vector<8xf32>
    %970 = vector.fma %969, %967, %938 : vector<8xf32>
    %971 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %972 = memref.load %assume_align[%arg0, %971, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %973 = vector.broadcast %972 : f32 to vector<8xf32>
    %974 = vector.fma %973, %967, %942 : vector<8xf32>
    %975 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %976 = memref.load %assume_align[%arg0, %975, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %977 = vector.broadcast %976 : f32 to vector<8xf32>
    %978 = vector.fma %977, %967, %946 : vector<8xf32>
    %979 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %980 = memref.load %assume_align[%arg0, %979, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %981 = vector.broadcast %980 : f32 to vector<8xf32>
    %982 = vector.fma %981, %967, %950 : vector<8xf32>
    %983 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %984 = memref.load %assume_align[%arg0, %983, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %985 = vector.broadcast %984 : f32 to vector<8xf32>
    %986 = vector.fma %985, %967, %954 : vector<8xf32>
    %987 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %988 = memref.load %assume_align[%arg0, %987, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %989 = vector.broadcast %988 : f32 to vector<8xf32>
    %990 = vector.fma %989, %967, %958 : vector<8xf32>
    %991 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %992 = memref.load %assume_align[%arg0, %991, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %993 = vector.broadcast %992 : f32 to vector<8xf32>
    %994 = vector.fma %993, %967, %962 : vector<8xf32>
    %995 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %996 = memref.load %assume_align[%arg0, %995, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %997 = vector.broadcast %996 : f32 to vector<8xf32>
    %998 = vector.fma %997, %967, %966 : vector<8xf32>
    %999 = vector.extract %38[30] : vector<8xf32> from vector<64x8xf32>
    %1000 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1001 = vector.broadcast %1000 : f32 to vector<8xf32>
    %1002 = vector.fma %1001, %999, %970 : vector<8xf32>
    %1003 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1004 = memref.load %assume_align[%arg0, %1003, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1005 = vector.broadcast %1004 : f32 to vector<8xf32>
    %1006 = vector.fma %1005, %999, %974 : vector<8xf32>
    %1007 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1008 = memref.load %assume_align[%arg0, %1007, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1009 = vector.broadcast %1008 : f32 to vector<8xf32>
    %1010 = vector.fma %1009, %999, %978 : vector<8xf32>
    %1011 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1012 = memref.load %assume_align[%arg0, %1011, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1013 = vector.broadcast %1012 : f32 to vector<8xf32>
    %1014 = vector.fma %1013, %999, %982 : vector<8xf32>
    %1015 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1016 = memref.load %assume_align[%arg0, %1015, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1017 = vector.broadcast %1016 : f32 to vector<8xf32>
    %1018 = vector.fma %1017, %999, %986 : vector<8xf32>
    %1019 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1020 = memref.load %assume_align[%arg0, %1019, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1021 = vector.broadcast %1020 : f32 to vector<8xf32>
    %1022 = vector.fma %1021, %999, %990 : vector<8xf32>
    %1023 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1024 = memref.load %assume_align[%arg0, %1023, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1025 = vector.broadcast %1024 : f32 to vector<8xf32>
    %1026 = vector.fma %1025, %999, %994 : vector<8xf32>
    %1027 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1028 = memref.load %assume_align[%arg0, %1027, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1029 = vector.broadcast %1028 : f32 to vector<8xf32>
    %1030 = vector.fma %1029, %999, %998 : vector<8xf32>
    %1031 = vector.extract %38[31] : vector<8xf32> from vector<64x8xf32>
    %1032 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1033 = vector.broadcast %1032 : f32 to vector<8xf32>
    %1034 = vector.fma %1033, %1031, %1002 : vector<8xf32>
    %1035 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1036 = memref.load %assume_align[%arg0, %1035, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1037 = vector.broadcast %1036 : f32 to vector<8xf32>
    %1038 = vector.fma %1037, %1031, %1006 : vector<8xf32>
    %1039 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1040 = memref.load %assume_align[%arg0, %1039, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1041 = vector.broadcast %1040 : f32 to vector<8xf32>
    %1042 = vector.fma %1041, %1031, %1010 : vector<8xf32>
    %1043 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1044 = memref.load %assume_align[%arg0, %1043, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1045 = vector.broadcast %1044 : f32 to vector<8xf32>
    %1046 = vector.fma %1045, %1031, %1014 : vector<8xf32>
    %1047 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1048 = memref.load %assume_align[%arg0, %1047, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1049 = vector.broadcast %1048 : f32 to vector<8xf32>
    %1050 = vector.fma %1049, %1031, %1018 : vector<8xf32>
    %1051 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1052 = memref.load %assume_align[%arg0, %1051, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1053 = vector.broadcast %1052 : f32 to vector<8xf32>
    %1054 = vector.fma %1053, %1031, %1022 : vector<8xf32>
    %1055 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1056 = memref.load %assume_align[%arg0, %1055, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1057 = vector.broadcast %1056 : f32 to vector<8xf32>
    %1058 = vector.fma %1057, %1031, %1026 : vector<8xf32>
    %1059 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1060 = memref.load %assume_align[%arg0, %1059, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1061 = vector.broadcast %1060 : f32 to vector<8xf32>
    %1062 = vector.fma %1061, %1031, %1030 : vector<8xf32>
    %1063 = vector.extract %38[32] : vector<8xf32> from vector<64x8xf32>
    %1064 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1065 = vector.broadcast %1064 : f32 to vector<8xf32>
    %1066 = vector.fma %1065, %1063, %1034 : vector<8xf32>
    %1067 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1068 = memref.load %assume_align[%arg0, %1067, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1069 = vector.broadcast %1068 : f32 to vector<8xf32>
    %1070 = vector.fma %1069, %1063, %1038 : vector<8xf32>
    %1071 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1072 = memref.load %assume_align[%arg0, %1071, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1073 = vector.broadcast %1072 : f32 to vector<8xf32>
    %1074 = vector.fma %1073, %1063, %1042 : vector<8xf32>
    %1075 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1076 = memref.load %assume_align[%arg0, %1075, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1077 = vector.broadcast %1076 : f32 to vector<8xf32>
    %1078 = vector.fma %1077, %1063, %1046 : vector<8xf32>
    %1079 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1080 = memref.load %assume_align[%arg0, %1079, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1081 = vector.broadcast %1080 : f32 to vector<8xf32>
    %1082 = vector.fma %1081, %1063, %1050 : vector<8xf32>
    %1083 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1084 = memref.load %assume_align[%arg0, %1083, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1085 = vector.broadcast %1084 : f32 to vector<8xf32>
    %1086 = vector.fma %1085, %1063, %1054 : vector<8xf32>
    %1087 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1088 = memref.load %assume_align[%arg0, %1087, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1089 = vector.broadcast %1088 : f32 to vector<8xf32>
    %1090 = vector.fma %1089, %1063, %1058 : vector<8xf32>
    %1091 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1092 = memref.load %assume_align[%arg0, %1091, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1093 = vector.broadcast %1092 : f32 to vector<8xf32>
    %1094 = vector.fma %1093, %1063, %1062 : vector<8xf32>
    %1095 = vector.extract %38[33] : vector<8xf32> from vector<64x8xf32>
    %1096 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1097 = vector.broadcast %1096 : f32 to vector<8xf32>
    %1098 = vector.fma %1097, %1095, %1066 : vector<8xf32>
    %1099 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1100 = memref.load %assume_align[%arg0, %1099, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1101 = vector.broadcast %1100 : f32 to vector<8xf32>
    %1102 = vector.fma %1101, %1095, %1070 : vector<8xf32>
    %1103 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1104 = memref.load %assume_align[%arg0, %1103, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1105 = vector.broadcast %1104 : f32 to vector<8xf32>
    %1106 = vector.fma %1105, %1095, %1074 : vector<8xf32>
    %1107 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1108 = memref.load %assume_align[%arg0, %1107, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1109 = vector.broadcast %1108 : f32 to vector<8xf32>
    %1110 = vector.fma %1109, %1095, %1078 : vector<8xf32>
    %1111 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1112 = memref.load %assume_align[%arg0, %1111, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1113 = vector.broadcast %1112 : f32 to vector<8xf32>
    %1114 = vector.fma %1113, %1095, %1082 : vector<8xf32>
    %1115 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1116 = memref.load %assume_align[%arg0, %1115, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1117 = vector.broadcast %1116 : f32 to vector<8xf32>
    %1118 = vector.fma %1117, %1095, %1086 : vector<8xf32>
    %1119 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1120 = memref.load %assume_align[%arg0, %1119, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1121 = vector.broadcast %1120 : f32 to vector<8xf32>
    %1122 = vector.fma %1121, %1095, %1090 : vector<8xf32>
    %1123 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1124 = memref.load %assume_align[%arg0, %1123, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1125 = vector.broadcast %1124 : f32 to vector<8xf32>
    %1126 = vector.fma %1125, %1095, %1094 : vector<8xf32>
    %1127 = vector.extract %38[34] : vector<8xf32> from vector<64x8xf32>
    %1128 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1129 = vector.broadcast %1128 : f32 to vector<8xf32>
    %1130 = vector.fma %1129, %1127, %1098 : vector<8xf32>
    %1131 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1132 = memref.load %assume_align[%arg0, %1131, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1133 = vector.broadcast %1132 : f32 to vector<8xf32>
    %1134 = vector.fma %1133, %1127, %1102 : vector<8xf32>
    %1135 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1136 = memref.load %assume_align[%arg0, %1135, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1137 = vector.broadcast %1136 : f32 to vector<8xf32>
    %1138 = vector.fma %1137, %1127, %1106 : vector<8xf32>
    %1139 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1140 = memref.load %assume_align[%arg0, %1139, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1141 = vector.broadcast %1140 : f32 to vector<8xf32>
    %1142 = vector.fma %1141, %1127, %1110 : vector<8xf32>
    %1143 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1144 = memref.load %assume_align[%arg0, %1143, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1145 = vector.broadcast %1144 : f32 to vector<8xf32>
    %1146 = vector.fma %1145, %1127, %1114 : vector<8xf32>
    %1147 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1148 = memref.load %assume_align[%arg0, %1147, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1149 = vector.broadcast %1148 : f32 to vector<8xf32>
    %1150 = vector.fma %1149, %1127, %1118 : vector<8xf32>
    %1151 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1152 = memref.load %assume_align[%arg0, %1151, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1153 = vector.broadcast %1152 : f32 to vector<8xf32>
    %1154 = vector.fma %1153, %1127, %1122 : vector<8xf32>
    %1155 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1156 = memref.load %assume_align[%arg0, %1155, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1157 = vector.broadcast %1156 : f32 to vector<8xf32>
    %1158 = vector.fma %1157, %1127, %1126 : vector<8xf32>
    %1159 = vector.extract %38[35] : vector<8xf32> from vector<64x8xf32>
    %1160 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1161 = vector.broadcast %1160 : f32 to vector<8xf32>
    %1162 = vector.fma %1161, %1159, %1130 : vector<8xf32>
    %1163 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1164 = memref.load %assume_align[%arg0, %1163, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1165 = vector.broadcast %1164 : f32 to vector<8xf32>
    %1166 = vector.fma %1165, %1159, %1134 : vector<8xf32>
    %1167 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1168 = memref.load %assume_align[%arg0, %1167, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1169 = vector.broadcast %1168 : f32 to vector<8xf32>
    %1170 = vector.fma %1169, %1159, %1138 : vector<8xf32>
    %1171 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1172 = memref.load %assume_align[%arg0, %1171, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1173 = vector.broadcast %1172 : f32 to vector<8xf32>
    %1174 = vector.fma %1173, %1159, %1142 : vector<8xf32>
    %1175 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1176 = memref.load %assume_align[%arg0, %1175, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1177 = vector.broadcast %1176 : f32 to vector<8xf32>
    %1178 = vector.fma %1177, %1159, %1146 : vector<8xf32>
    %1179 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1180 = memref.load %assume_align[%arg0, %1179, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1181 = vector.broadcast %1180 : f32 to vector<8xf32>
    %1182 = vector.fma %1181, %1159, %1150 : vector<8xf32>
    %1183 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1184 = memref.load %assume_align[%arg0, %1183, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1185 = vector.broadcast %1184 : f32 to vector<8xf32>
    %1186 = vector.fma %1185, %1159, %1154 : vector<8xf32>
    %1187 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1188 = memref.load %assume_align[%arg0, %1187, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1189 = vector.broadcast %1188 : f32 to vector<8xf32>
    %1190 = vector.fma %1189, %1159, %1158 : vector<8xf32>
    %1191 = vector.extract %38[36] : vector<8xf32> from vector<64x8xf32>
    %1192 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1193 = vector.broadcast %1192 : f32 to vector<8xf32>
    %1194 = vector.fma %1193, %1191, %1162 : vector<8xf32>
    %1195 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1196 = memref.load %assume_align[%arg0, %1195, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1197 = vector.broadcast %1196 : f32 to vector<8xf32>
    %1198 = vector.fma %1197, %1191, %1166 : vector<8xf32>
    %1199 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1200 = memref.load %assume_align[%arg0, %1199, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1201 = vector.broadcast %1200 : f32 to vector<8xf32>
    %1202 = vector.fma %1201, %1191, %1170 : vector<8xf32>
    %1203 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1204 = memref.load %assume_align[%arg0, %1203, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1205 = vector.broadcast %1204 : f32 to vector<8xf32>
    %1206 = vector.fma %1205, %1191, %1174 : vector<8xf32>
    %1207 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1208 = memref.load %assume_align[%arg0, %1207, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1209 = vector.broadcast %1208 : f32 to vector<8xf32>
    %1210 = vector.fma %1209, %1191, %1178 : vector<8xf32>
    %1211 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1212 = memref.load %assume_align[%arg0, %1211, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1213 = vector.broadcast %1212 : f32 to vector<8xf32>
    %1214 = vector.fma %1213, %1191, %1182 : vector<8xf32>
    %1215 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1216 = memref.load %assume_align[%arg0, %1215, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1217 = vector.broadcast %1216 : f32 to vector<8xf32>
    %1218 = vector.fma %1217, %1191, %1186 : vector<8xf32>
    %1219 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1220 = memref.load %assume_align[%arg0, %1219, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1221 = vector.broadcast %1220 : f32 to vector<8xf32>
    %1222 = vector.fma %1221, %1191, %1190 : vector<8xf32>
    %1223 = vector.extract %38[37] : vector<8xf32> from vector<64x8xf32>
    %1224 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1225 = vector.broadcast %1224 : f32 to vector<8xf32>
    %1226 = vector.fma %1225, %1223, %1194 : vector<8xf32>
    %1227 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1228 = memref.load %assume_align[%arg0, %1227, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1229 = vector.broadcast %1228 : f32 to vector<8xf32>
    %1230 = vector.fma %1229, %1223, %1198 : vector<8xf32>
    %1231 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1232 = memref.load %assume_align[%arg0, %1231, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1233 = vector.broadcast %1232 : f32 to vector<8xf32>
    %1234 = vector.fma %1233, %1223, %1202 : vector<8xf32>
    %1235 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1236 = memref.load %assume_align[%arg0, %1235, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1237 = vector.broadcast %1236 : f32 to vector<8xf32>
    %1238 = vector.fma %1237, %1223, %1206 : vector<8xf32>
    %1239 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1240 = memref.load %assume_align[%arg0, %1239, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1241 = vector.broadcast %1240 : f32 to vector<8xf32>
    %1242 = vector.fma %1241, %1223, %1210 : vector<8xf32>
    %1243 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1244 = memref.load %assume_align[%arg0, %1243, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1245 = vector.broadcast %1244 : f32 to vector<8xf32>
    %1246 = vector.fma %1245, %1223, %1214 : vector<8xf32>
    %1247 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1248 = memref.load %assume_align[%arg0, %1247, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1249 = vector.broadcast %1248 : f32 to vector<8xf32>
    %1250 = vector.fma %1249, %1223, %1218 : vector<8xf32>
    %1251 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1252 = memref.load %assume_align[%arg0, %1251, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1253 = vector.broadcast %1252 : f32 to vector<8xf32>
    %1254 = vector.fma %1253, %1223, %1222 : vector<8xf32>
    %1255 = vector.extract %38[38] : vector<8xf32> from vector<64x8xf32>
    %1256 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1257 = vector.broadcast %1256 : f32 to vector<8xf32>
    %1258 = vector.fma %1257, %1255, %1226 : vector<8xf32>
    %1259 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1260 = memref.load %assume_align[%arg0, %1259, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1261 = vector.broadcast %1260 : f32 to vector<8xf32>
    %1262 = vector.fma %1261, %1255, %1230 : vector<8xf32>
    %1263 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1264 = memref.load %assume_align[%arg0, %1263, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1265 = vector.broadcast %1264 : f32 to vector<8xf32>
    %1266 = vector.fma %1265, %1255, %1234 : vector<8xf32>
    %1267 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1268 = memref.load %assume_align[%arg0, %1267, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1269 = vector.broadcast %1268 : f32 to vector<8xf32>
    %1270 = vector.fma %1269, %1255, %1238 : vector<8xf32>
    %1271 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1272 = memref.load %assume_align[%arg0, %1271, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1273 = vector.broadcast %1272 : f32 to vector<8xf32>
    %1274 = vector.fma %1273, %1255, %1242 : vector<8xf32>
    %1275 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1276 = memref.load %assume_align[%arg0, %1275, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1277 = vector.broadcast %1276 : f32 to vector<8xf32>
    %1278 = vector.fma %1277, %1255, %1246 : vector<8xf32>
    %1279 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1280 = memref.load %assume_align[%arg0, %1279, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1281 = vector.broadcast %1280 : f32 to vector<8xf32>
    %1282 = vector.fma %1281, %1255, %1250 : vector<8xf32>
    %1283 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1284 = memref.load %assume_align[%arg0, %1283, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1285 = vector.broadcast %1284 : f32 to vector<8xf32>
    %1286 = vector.fma %1285, %1255, %1254 : vector<8xf32>
    %1287 = vector.extract %38[39] : vector<8xf32> from vector<64x8xf32>
    %1288 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1289 = vector.broadcast %1288 : f32 to vector<8xf32>
    %1290 = vector.fma %1289, %1287, %1258 : vector<8xf32>
    %1291 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1292 = memref.load %assume_align[%arg0, %1291, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1293 = vector.broadcast %1292 : f32 to vector<8xf32>
    %1294 = vector.fma %1293, %1287, %1262 : vector<8xf32>
    %1295 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1296 = memref.load %assume_align[%arg0, %1295, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1297 = vector.broadcast %1296 : f32 to vector<8xf32>
    %1298 = vector.fma %1297, %1287, %1266 : vector<8xf32>
    %1299 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1300 = memref.load %assume_align[%arg0, %1299, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1301 = vector.broadcast %1300 : f32 to vector<8xf32>
    %1302 = vector.fma %1301, %1287, %1270 : vector<8xf32>
    %1303 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1304 = memref.load %assume_align[%arg0, %1303, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1305 = vector.broadcast %1304 : f32 to vector<8xf32>
    %1306 = vector.fma %1305, %1287, %1274 : vector<8xf32>
    %1307 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1308 = memref.load %assume_align[%arg0, %1307, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1309 = vector.broadcast %1308 : f32 to vector<8xf32>
    %1310 = vector.fma %1309, %1287, %1278 : vector<8xf32>
    %1311 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1312 = memref.load %assume_align[%arg0, %1311, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1313 = vector.broadcast %1312 : f32 to vector<8xf32>
    %1314 = vector.fma %1313, %1287, %1282 : vector<8xf32>
    %1315 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1316 = memref.load %assume_align[%arg0, %1315, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1317 = vector.broadcast %1316 : f32 to vector<8xf32>
    %1318 = vector.fma %1317, %1287, %1286 : vector<8xf32>
    %1319 = vector.extract %38[40] : vector<8xf32> from vector<64x8xf32>
    %1320 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1321 = vector.broadcast %1320 : f32 to vector<8xf32>
    %1322 = vector.fma %1321, %1319, %1290 : vector<8xf32>
    %1323 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1324 = memref.load %assume_align[%arg0, %1323, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1325 = vector.broadcast %1324 : f32 to vector<8xf32>
    %1326 = vector.fma %1325, %1319, %1294 : vector<8xf32>
    %1327 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1328 = memref.load %assume_align[%arg0, %1327, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1329 = vector.broadcast %1328 : f32 to vector<8xf32>
    %1330 = vector.fma %1329, %1319, %1298 : vector<8xf32>
    %1331 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1332 = memref.load %assume_align[%arg0, %1331, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1333 = vector.broadcast %1332 : f32 to vector<8xf32>
    %1334 = vector.fma %1333, %1319, %1302 : vector<8xf32>
    %1335 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1336 = memref.load %assume_align[%arg0, %1335, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1337 = vector.broadcast %1336 : f32 to vector<8xf32>
    %1338 = vector.fma %1337, %1319, %1306 : vector<8xf32>
    %1339 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1340 = memref.load %assume_align[%arg0, %1339, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1341 = vector.broadcast %1340 : f32 to vector<8xf32>
    %1342 = vector.fma %1341, %1319, %1310 : vector<8xf32>
    %1343 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1344 = memref.load %assume_align[%arg0, %1343, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1345 = vector.broadcast %1344 : f32 to vector<8xf32>
    %1346 = vector.fma %1345, %1319, %1314 : vector<8xf32>
    %1347 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1348 = memref.load %assume_align[%arg0, %1347, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1349 = vector.broadcast %1348 : f32 to vector<8xf32>
    %1350 = vector.fma %1349, %1319, %1318 : vector<8xf32>
    %1351 = vector.extract %38[41] : vector<8xf32> from vector<64x8xf32>
    %1352 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1353 = vector.broadcast %1352 : f32 to vector<8xf32>
    %1354 = vector.fma %1353, %1351, %1322 : vector<8xf32>
    %1355 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1356 = memref.load %assume_align[%arg0, %1355, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1357 = vector.broadcast %1356 : f32 to vector<8xf32>
    %1358 = vector.fma %1357, %1351, %1326 : vector<8xf32>
    %1359 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1360 = memref.load %assume_align[%arg0, %1359, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1361 = vector.broadcast %1360 : f32 to vector<8xf32>
    %1362 = vector.fma %1361, %1351, %1330 : vector<8xf32>
    %1363 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1364 = memref.load %assume_align[%arg0, %1363, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1365 = vector.broadcast %1364 : f32 to vector<8xf32>
    %1366 = vector.fma %1365, %1351, %1334 : vector<8xf32>
    %1367 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1368 = memref.load %assume_align[%arg0, %1367, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1369 = vector.broadcast %1368 : f32 to vector<8xf32>
    %1370 = vector.fma %1369, %1351, %1338 : vector<8xf32>
    %1371 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1372 = memref.load %assume_align[%arg0, %1371, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1373 = vector.broadcast %1372 : f32 to vector<8xf32>
    %1374 = vector.fma %1373, %1351, %1342 : vector<8xf32>
    %1375 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1376 = memref.load %assume_align[%arg0, %1375, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1377 = vector.broadcast %1376 : f32 to vector<8xf32>
    %1378 = vector.fma %1377, %1351, %1346 : vector<8xf32>
    %1379 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1380 = memref.load %assume_align[%arg0, %1379, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1381 = vector.broadcast %1380 : f32 to vector<8xf32>
    %1382 = vector.fma %1381, %1351, %1350 : vector<8xf32>
    %1383 = vector.extract %38[42] : vector<8xf32> from vector<64x8xf32>
    %1384 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1385 = vector.broadcast %1384 : f32 to vector<8xf32>
    %1386 = vector.fma %1385, %1383, %1354 : vector<8xf32>
    %1387 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1388 = memref.load %assume_align[%arg0, %1387, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1389 = vector.broadcast %1388 : f32 to vector<8xf32>
    %1390 = vector.fma %1389, %1383, %1358 : vector<8xf32>
    %1391 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1392 = memref.load %assume_align[%arg0, %1391, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1393 = vector.broadcast %1392 : f32 to vector<8xf32>
    %1394 = vector.fma %1393, %1383, %1362 : vector<8xf32>
    %1395 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1396 = memref.load %assume_align[%arg0, %1395, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1397 = vector.broadcast %1396 : f32 to vector<8xf32>
    %1398 = vector.fma %1397, %1383, %1366 : vector<8xf32>
    %1399 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1400 = memref.load %assume_align[%arg0, %1399, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1401 = vector.broadcast %1400 : f32 to vector<8xf32>
    %1402 = vector.fma %1401, %1383, %1370 : vector<8xf32>
    %1403 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1404 = memref.load %assume_align[%arg0, %1403, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1405 = vector.broadcast %1404 : f32 to vector<8xf32>
    %1406 = vector.fma %1405, %1383, %1374 : vector<8xf32>
    %1407 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1408 = memref.load %assume_align[%arg0, %1407, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1409 = vector.broadcast %1408 : f32 to vector<8xf32>
    %1410 = vector.fma %1409, %1383, %1378 : vector<8xf32>
    %1411 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1412 = memref.load %assume_align[%arg0, %1411, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1413 = vector.broadcast %1412 : f32 to vector<8xf32>
    %1414 = vector.fma %1413, %1383, %1382 : vector<8xf32>
    %1415 = vector.extract %38[43] : vector<8xf32> from vector<64x8xf32>
    %1416 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1417 = vector.broadcast %1416 : f32 to vector<8xf32>
    %1418 = vector.fma %1417, %1415, %1386 : vector<8xf32>
    %1419 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1420 = memref.load %assume_align[%arg0, %1419, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1421 = vector.broadcast %1420 : f32 to vector<8xf32>
    %1422 = vector.fma %1421, %1415, %1390 : vector<8xf32>
    %1423 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1424 = memref.load %assume_align[%arg0, %1423, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1425 = vector.broadcast %1424 : f32 to vector<8xf32>
    %1426 = vector.fma %1425, %1415, %1394 : vector<8xf32>
    %1427 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1428 = memref.load %assume_align[%arg0, %1427, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1429 = vector.broadcast %1428 : f32 to vector<8xf32>
    %1430 = vector.fma %1429, %1415, %1398 : vector<8xf32>
    %1431 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1432 = memref.load %assume_align[%arg0, %1431, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1433 = vector.broadcast %1432 : f32 to vector<8xf32>
    %1434 = vector.fma %1433, %1415, %1402 : vector<8xf32>
    %1435 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1436 = memref.load %assume_align[%arg0, %1435, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1437 = vector.broadcast %1436 : f32 to vector<8xf32>
    %1438 = vector.fma %1437, %1415, %1406 : vector<8xf32>
    %1439 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1440 = memref.load %assume_align[%arg0, %1439, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1441 = vector.broadcast %1440 : f32 to vector<8xf32>
    %1442 = vector.fma %1441, %1415, %1410 : vector<8xf32>
    %1443 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1444 = memref.load %assume_align[%arg0, %1443, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1445 = vector.broadcast %1444 : f32 to vector<8xf32>
    %1446 = vector.fma %1445, %1415, %1414 : vector<8xf32>
    %1447 = vector.extract %38[44] : vector<8xf32> from vector<64x8xf32>
    %1448 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1449 = vector.broadcast %1448 : f32 to vector<8xf32>
    %1450 = vector.fma %1449, %1447, %1418 : vector<8xf32>
    %1451 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1452 = memref.load %assume_align[%arg0, %1451, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1453 = vector.broadcast %1452 : f32 to vector<8xf32>
    %1454 = vector.fma %1453, %1447, %1422 : vector<8xf32>
    %1455 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1456 = memref.load %assume_align[%arg0, %1455, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1457 = vector.broadcast %1456 : f32 to vector<8xf32>
    %1458 = vector.fma %1457, %1447, %1426 : vector<8xf32>
    %1459 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1460 = memref.load %assume_align[%arg0, %1459, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1461 = vector.broadcast %1460 : f32 to vector<8xf32>
    %1462 = vector.fma %1461, %1447, %1430 : vector<8xf32>
    %1463 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1464 = memref.load %assume_align[%arg0, %1463, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1465 = vector.broadcast %1464 : f32 to vector<8xf32>
    %1466 = vector.fma %1465, %1447, %1434 : vector<8xf32>
    %1467 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1468 = memref.load %assume_align[%arg0, %1467, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1469 = vector.broadcast %1468 : f32 to vector<8xf32>
    %1470 = vector.fma %1469, %1447, %1438 : vector<8xf32>
    %1471 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1472 = memref.load %assume_align[%arg0, %1471, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1473 = vector.broadcast %1472 : f32 to vector<8xf32>
    %1474 = vector.fma %1473, %1447, %1442 : vector<8xf32>
    %1475 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1476 = memref.load %assume_align[%arg0, %1475, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1477 = vector.broadcast %1476 : f32 to vector<8xf32>
    %1478 = vector.fma %1477, %1447, %1446 : vector<8xf32>
    %1479 = vector.extract %38[45] : vector<8xf32> from vector<64x8xf32>
    %1480 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1481 = vector.broadcast %1480 : f32 to vector<8xf32>
    %1482 = vector.fma %1481, %1479, %1450 : vector<8xf32>
    %1483 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1484 = memref.load %assume_align[%arg0, %1483, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1485 = vector.broadcast %1484 : f32 to vector<8xf32>
    %1486 = vector.fma %1485, %1479, %1454 : vector<8xf32>
    %1487 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1488 = memref.load %assume_align[%arg0, %1487, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1489 = vector.broadcast %1488 : f32 to vector<8xf32>
    %1490 = vector.fma %1489, %1479, %1458 : vector<8xf32>
    %1491 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1492 = memref.load %assume_align[%arg0, %1491, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1493 = vector.broadcast %1492 : f32 to vector<8xf32>
    %1494 = vector.fma %1493, %1479, %1462 : vector<8xf32>
    %1495 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1496 = memref.load %assume_align[%arg0, %1495, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1497 = vector.broadcast %1496 : f32 to vector<8xf32>
    %1498 = vector.fma %1497, %1479, %1466 : vector<8xf32>
    %1499 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1500 = memref.load %assume_align[%arg0, %1499, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1501 = vector.broadcast %1500 : f32 to vector<8xf32>
    %1502 = vector.fma %1501, %1479, %1470 : vector<8xf32>
    %1503 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1504 = memref.load %assume_align[%arg0, %1503, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1505 = vector.broadcast %1504 : f32 to vector<8xf32>
    %1506 = vector.fma %1505, %1479, %1474 : vector<8xf32>
    %1507 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1508 = memref.load %assume_align[%arg0, %1507, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1509 = vector.broadcast %1508 : f32 to vector<8xf32>
    %1510 = vector.fma %1509, %1479, %1478 : vector<8xf32>
    %1511 = vector.extract %38[46] : vector<8xf32> from vector<64x8xf32>
    %1512 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1513 = vector.broadcast %1512 : f32 to vector<8xf32>
    %1514 = vector.fma %1513, %1511, %1482 : vector<8xf32>
    %1515 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1516 = memref.load %assume_align[%arg0, %1515, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1517 = vector.broadcast %1516 : f32 to vector<8xf32>
    %1518 = vector.fma %1517, %1511, %1486 : vector<8xf32>
    %1519 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1520 = memref.load %assume_align[%arg0, %1519, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1521 = vector.broadcast %1520 : f32 to vector<8xf32>
    %1522 = vector.fma %1521, %1511, %1490 : vector<8xf32>
    %1523 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1524 = memref.load %assume_align[%arg0, %1523, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1525 = vector.broadcast %1524 : f32 to vector<8xf32>
    %1526 = vector.fma %1525, %1511, %1494 : vector<8xf32>
    %1527 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1528 = memref.load %assume_align[%arg0, %1527, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1529 = vector.broadcast %1528 : f32 to vector<8xf32>
    %1530 = vector.fma %1529, %1511, %1498 : vector<8xf32>
    %1531 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1532 = memref.load %assume_align[%arg0, %1531, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1533 = vector.broadcast %1532 : f32 to vector<8xf32>
    %1534 = vector.fma %1533, %1511, %1502 : vector<8xf32>
    %1535 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1536 = memref.load %assume_align[%arg0, %1535, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1537 = vector.broadcast %1536 : f32 to vector<8xf32>
    %1538 = vector.fma %1537, %1511, %1506 : vector<8xf32>
    %1539 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1540 = memref.load %assume_align[%arg0, %1539, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1541 = vector.broadcast %1540 : f32 to vector<8xf32>
    %1542 = vector.fma %1541, %1511, %1510 : vector<8xf32>
    %1543 = vector.extract %38[47] : vector<8xf32> from vector<64x8xf32>
    %1544 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1545 = vector.broadcast %1544 : f32 to vector<8xf32>
    %1546 = vector.fma %1545, %1543, %1514 : vector<8xf32>
    %1547 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1548 = memref.load %assume_align[%arg0, %1547, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1549 = vector.broadcast %1548 : f32 to vector<8xf32>
    %1550 = vector.fma %1549, %1543, %1518 : vector<8xf32>
    %1551 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1552 = memref.load %assume_align[%arg0, %1551, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1553 = vector.broadcast %1552 : f32 to vector<8xf32>
    %1554 = vector.fma %1553, %1543, %1522 : vector<8xf32>
    %1555 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1556 = memref.load %assume_align[%arg0, %1555, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1557 = vector.broadcast %1556 : f32 to vector<8xf32>
    %1558 = vector.fma %1557, %1543, %1526 : vector<8xf32>
    %1559 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1560 = memref.load %assume_align[%arg0, %1559, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1561 = vector.broadcast %1560 : f32 to vector<8xf32>
    %1562 = vector.fma %1561, %1543, %1530 : vector<8xf32>
    %1563 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1564 = memref.load %assume_align[%arg0, %1563, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1565 = vector.broadcast %1564 : f32 to vector<8xf32>
    %1566 = vector.fma %1565, %1543, %1534 : vector<8xf32>
    %1567 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1568 = memref.load %assume_align[%arg0, %1567, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1569 = vector.broadcast %1568 : f32 to vector<8xf32>
    %1570 = vector.fma %1569, %1543, %1538 : vector<8xf32>
    %1571 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1572 = memref.load %assume_align[%arg0, %1571, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1573 = vector.broadcast %1572 : f32 to vector<8xf32>
    %1574 = vector.fma %1573, %1543, %1542 : vector<8xf32>
    %1575 = vector.extract %38[48] : vector<8xf32> from vector<64x8xf32>
    %1576 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1577 = vector.broadcast %1576 : f32 to vector<8xf32>
    %1578 = vector.fma %1577, %1575, %1546 : vector<8xf32>
    %1579 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1580 = memref.load %assume_align[%arg0, %1579, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1581 = vector.broadcast %1580 : f32 to vector<8xf32>
    %1582 = vector.fma %1581, %1575, %1550 : vector<8xf32>
    %1583 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1584 = memref.load %assume_align[%arg0, %1583, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1585 = vector.broadcast %1584 : f32 to vector<8xf32>
    %1586 = vector.fma %1585, %1575, %1554 : vector<8xf32>
    %1587 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1588 = memref.load %assume_align[%arg0, %1587, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1589 = vector.broadcast %1588 : f32 to vector<8xf32>
    %1590 = vector.fma %1589, %1575, %1558 : vector<8xf32>
    %1591 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1592 = memref.load %assume_align[%arg0, %1591, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1593 = vector.broadcast %1592 : f32 to vector<8xf32>
    %1594 = vector.fma %1593, %1575, %1562 : vector<8xf32>
    %1595 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1596 = memref.load %assume_align[%arg0, %1595, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1597 = vector.broadcast %1596 : f32 to vector<8xf32>
    %1598 = vector.fma %1597, %1575, %1566 : vector<8xf32>
    %1599 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1600 = memref.load %assume_align[%arg0, %1599, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1601 = vector.broadcast %1600 : f32 to vector<8xf32>
    %1602 = vector.fma %1601, %1575, %1570 : vector<8xf32>
    %1603 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1604 = memref.load %assume_align[%arg0, %1603, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1605 = vector.broadcast %1604 : f32 to vector<8xf32>
    %1606 = vector.fma %1605, %1575, %1574 : vector<8xf32>
    %1607 = vector.extract %38[49] : vector<8xf32> from vector<64x8xf32>
    %1608 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1609 = vector.broadcast %1608 : f32 to vector<8xf32>
    %1610 = vector.fma %1609, %1607, %1578 : vector<8xf32>
    %1611 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1612 = memref.load %assume_align[%arg0, %1611, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1613 = vector.broadcast %1612 : f32 to vector<8xf32>
    %1614 = vector.fma %1613, %1607, %1582 : vector<8xf32>
    %1615 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1616 = memref.load %assume_align[%arg0, %1615, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1617 = vector.broadcast %1616 : f32 to vector<8xf32>
    %1618 = vector.fma %1617, %1607, %1586 : vector<8xf32>
    %1619 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1620 = memref.load %assume_align[%arg0, %1619, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1621 = vector.broadcast %1620 : f32 to vector<8xf32>
    %1622 = vector.fma %1621, %1607, %1590 : vector<8xf32>
    %1623 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1624 = memref.load %assume_align[%arg0, %1623, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1625 = vector.broadcast %1624 : f32 to vector<8xf32>
    %1626 = vector.fma %1625, %1607, %1594 : vector<8xf32>
    %1627 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1628 = memref.load %assume_align[%arg0, %1627, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1629 = vector.broadcast %1628 : f32 to vector<8xf32>
    %1630 = vector.fma %1629, %1607, %1598 : vector<8xf32>
    %1631 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1632 = memref.load %assume_align[%arg0, %1631, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1633 = vector.broadcast %1632 : f32 to vector<8xf32>
    %1634 = vector.fma %1633, %1607, %1602 : vector<8xf32>
    %1635 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1636 = memref.load %assume_align[%arg0, %1635, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1637 = vector.broadcast %1636 : f32 to vector<8xf32>
    %1638 = vector.fma %1637, %1607, %1606 : vector<8xf32>
    %1639 = vector.extract %38[50] : vector<8xf32> from vector<64x8xf32>
    %1640 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1641 = vector.broadcast %1640 : f32 to vector<8xf32>
    %1642 = vector.fma %1641, %1639, %1610 : vector<8xf32>
    %1643 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1644 = memref.load %assume_align[%arg0, %1643, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1645 = vector.broadcast %1644 : f32 to vector<8xf32>
    %1646 = vector.fma %1645, %1639, %1614 : vector<8xf32>
    %1647 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1648 = memref.load %assume_align[%arg0, %1647, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1649 = vector.broadcast %1648 : f32 to vector<8xf32>
    %1650 = vector.fma %1649, %1639, %1618 : vector<8xf32>
    %1651 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1652 = memref.load %assume_align[%arg0, %1651, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1653 = vector.broadcast %1652 : f32 to vector<8xf32>
    %1654 = vector.fma %1653, %1639, %1622 : vector<8xf32>
    %1655 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1656 = memref.load %assume_align[%arg0, %1655, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1657 = vector.broadcast %1656 : f32 to vector<8xf32>
    %1658 = vector.fma %1657, %1639, %1626 : vector<8xf32>
    %1659 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1660 = memref.load %assume_align[%arg0, %1659, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1661 = vector.broadcast %1660 : f32 to vector<8xf32>
    %1662 = vector.fma %1661, %1639, %1630 : vector<8xf32>
    %1663 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1664 = memref.load %assume_align[%arg0, %1663, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1665 = vector.broadcast %1664 : f32 to vector<8xf32>
    %1666 = vector.fma %1665, %1639, %1634 : vector<8xf32>
    %1667 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1668 = memref.load %assume_align[%arg0, %1667, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1669 = vector.broadcast %1668 : f32 to vector<8xf32>
    %1670 = vector.fma %1669, %1639, %1638 : vector<8xf32>
    %1671 = vector.extract %38[51] : vector<8xf32> from vector<64x8xf32>
    %1672 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1673 = vector.broadcast %1672 : f32 to vector<8xf32>
    %1674 = vector.fma %1673, %1671, %1642 : vector<8xf32>
    %1675 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1676 = memref.load %assume_align[%arg0, %1675, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1677 = vector.broadcast %1676 : f32 to vector<8xf32>
    %1678 = vector.fma %1677, %1671, %1646 : vector<8xf32>
    %1679 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1680 = memref.load %assume_align[%arg0, %1679, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1681 = vector.broadcast %1680 : f32 to vector<8xf32>
    %1682 = vector.fma %1681, %1671, %1650 : vector<8xf32>
    %1683 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1684 = memref.load %assume_align[%arg0, %1683, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1685 = vector.broadcast %1684 : f32 to vector<8xf32>
    %1686 = vector.fma %1685, %1671, %1654 : vector<8xf32>
    %1687 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1688 = memref.load %assume_align[%arg0, %1687, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1689 = vector.broadcast %1688 : f32 to vector<8xf32>
    %1690 = vector.fma %1689, %1671, %1658 : vector<8xf32>
    %1691 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1692 = memref.load %assume_align[%arg0, %1691, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1693 = vector.broadcast %1692 : f32 to vector<8xf32>
    %1694 = vector.fma %1693, %1671, %1662 : vector<8xf32>
    %1695 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1696 = memref.load %assume_align[%arg0, %1695, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1697 = vector.broadcast %1696 : f32 to vector<8xf32>
    %1698 = vector.fma %1697, %1671, %1666 : vector<8xf32>
    %1699 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1700 = memref.load %assume_align[%arg0, %1699, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1701 = vector.broadcast %1700 : f32 to vector<8xf32>
    %1702 = vector.fma %1701, %1671, %1670 : vector<8xf32>
    %1703 = vector.extract %38[52] : vector<8xf32> from vector<64x8xf32>
    %1704 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1705 = vector.broadcast %1704 : f32 to vector<8xf32>
    %1706 = vector.fma %1705, %1703, %1674 : vector<8xf32>
    %1707 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1708 = memref.load %assume_align[%arg0, %1707, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1709 = vector.broadcast %1708 : f32 to vector<8xf32>
    %1710 = vector.fma %1709, %1703, %1678 : vector<8xf32>
    %1711 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1712 = memref.load %assume_align[%arg0, %1711, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1713 = vector.broadcast %1712 : f32 to vector<8xf32>
    %1714 = vector.fma %1713, %1703, %1682 : vector<8xf32>
    %1715 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1716 = memref.load %assume_align[%arg0, %1715, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1717 = vector.broadcast %1716 : f32 to vector<8xf32>
    %1718 = vector.fma %1717, %1703, %1686 : vector<8xf32>
    %1719 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1720 = memref.load %assume_align[%arg0, %1719, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1721 = vector.broadcast %1720 : f32 to vector<8xf32>
    %1722 = vector.fma %1721, %1703, %1690 : vector<8xf32>
    %1723 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1724 = memref.load %assume_align[%arg0, %1723, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1725 = vector.broadcast %1724 : f32 to vector<8xf32>
    %1726 = vector.fma %1725, %1703, %1694 : vector<8xf32>
    %1727 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1728 = memref.load %assume_align[%arg0, %1727, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1729 = vector.broadcast %1728 : f32 to vector<8xf32>
    %1730 = vector.fma %1729, %1703, %1698 : vector<8xf32>
    %1731 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1732 = memref.load %assume_align[%arg0, %1731, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1733 = vector.broadcast %1732 : f32 to vector<8xf32>
    %1734 = vector.fma %1733, %1703, %1702 : vector<8xf32>
    %1735 = vector.extract %38[53] : vector<8xf32> from vector<64x8xf32>
    %1736 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1737 = vector.broadcast %1736 : f32 to vector<8xf32>
    %1738 = vector.fma %1737, %1735, %1706 : vector<8xf32>
    %1739 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1740 = memref.load %assume_align[%arg0, %1739, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1741 = vector.broadcast %1740 : f32 to vector<8xf32>
    %1742 = vector.fma %1741, %1735, %1710 : vector<8xf32>
    %1743 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1744 = memref.load %assume_align[%arg0, %1743, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1745 = vector.broadcast %1744 : f32 to vector<8xf32>
    %1746 = vector.fma %1745, %1735, %1714 : vector<8xf32>
    %1747 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1748 = memref.load %assume_align[%arg0, %1747, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1749 = vector.broadcast %1748 : f32 to vector<8xf32>
    %1750 = vector.fma %1749, %1735, %1718 : vector<8xf32>
    %1751 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1752 = memref.load %assume_align[%arg0, %1751, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1753 = vector.broadcast %1752 : f32 to vector<8xf32>
    %1754 = vector.fma %1753, %1735, %1722 : vector<8xf32>
    %1755 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1756 = memref.load %assume_align[%arg0, %1755, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1757 = vector.broadcast %1756 : f32 to vector<8xf32>
    %1758 = vector.fma %1757, %1735, %1726 : vector<8xf32>
    %1759 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1760 = memref.load %assume_align[%arg0, %1759, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1761 = vector.broadcast %1760 : f32 to vector<8xf32>
    %1762 = vector.fma %1761, %1735, %1730 : vector<8xf32>
    %1763 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1764 = memref.load %assume_align[%arg0, %1763, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1765 = vector.broadcast %1764 : f32 to vector<8xf32>
    %1766 = vector.fma %1765, %1735, %1734 : vector<8xf32>
    %1767 = vector.extract %38[54] : vector<8xf32> from vector<64x8xf32>
    %1768 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1769 = vector.broadcast %1768 : f32 to vector<8xf32>
    %1770 = vector.fma %1769, %1767, %1738 : vector<8xf32>
    %1771 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1772 = memref.load %assume_align[%arg0, %1771, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1773 = vector.broadcast %1772 : f32 to vector<8xf32>
    %1774 = vector.fma %1773, %1767, %1742 : vector<8xf32>
    %1775 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1776 = memref.load %assume_align[%arg0, %1775, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1777 = vector.broadcast %1776 : f32 to vector<8xf32>
    %1778 = vector.fma %1777, %1767, %1746 : vector<8xf32>
    %1779 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1780 = memref.load %assume_align[%arg0, %1779, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1781 = vector.broadcast %1780 : f32 to vector<8xf32>
    %1782 = vector.fma %1781, %1767, %1750 : vector<8xf32>
    %1783 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1784 = memref.load %assume_align[%arg0, %1783, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1785 = vector.broadcast %1784 : f32 to vector<8xf32>
    %1786 = vector.fma %1785, %1767, %1754 : vector<8xf32>
    %1787 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1788 = memref.load %assume_align[%arg0, %1787, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1789 = vector.broadcast %1788 : f32 to vector<8xf32>
    %1790 = vector.fma %1789, %1767, %1758 : vector<8xf32>
    %1791 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1792 = memref.load %assume_align[%arg0, %1791, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1793 = vector.broadcast %1792 : f32 to vector<8xf32>
    %1794 = vector.fma %1793, %1767, %1762 : vector<8xf32>
    %1795 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1796 = memref.load %assume_align[%arg0, %1795, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1797 = vector.broadcast %1796 : f32 to vector<8xf32>
    %1798 = vector.fma %1797, %1767, %1766 : vector<8xf32>
    %1799 = vector.extract %38[55] : vector<8xf32> from vector<64x8xf32>
    %1800 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1801 = vector.broadcast %1800 : f32 to vector<8xf32>
    %1802 = vector.fma %1801, %1799, %1770 : vector<8xf32>
    %1803 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1804 = memref.load %assume_align[%arg0, %1803, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1805 = vector.broadcast %1804 : f32 to vector<8xf32>
    %1806 = vector.fma %1805, %1799, %1774 : vector<8xf32>
    %1807 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1808 = memref.load %assume_align[%arg0, %1807, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1809 = vector.broadcast %1808 : f32 to vector<8xf32>
    %1810 = vector.fma %1809, %1799, %1778 : vector<8xf32>
    %1811 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1812 = memref.load %assume_align[%arg0, %1811, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1813 = vector.broadcast %1812 : f32 to vector<8xf32>
    %1814 = vector.fma %1813, %1799, %1782 : vector<8xf32>
    %1815 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1816 = memref.load %assume_align[%arg0, %1815, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1817 = vector.broadcast %1816 : f32 to vector<8xf32>
    %1818 = vector.fma %1817, %1799, %1786 : vector<8xf32>
    %1819 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1820 = memref.load %assume_align[%arg0, %1819, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1821 = vector.broadcast %1820 : f32 to vector<8xf32>
    %1822 = vector.fma %1821, %1799, %1790 : vector<8xf32>
    %1823 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1824 = memref.load %assume_align[%arg0, %1823, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1825 = vector.broadcast %1824 : f32 to vector<8xf32>
    %1826 = vector.fma %1825, %1799, %1794 : vector<8xf32>
    %1827 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1828 = memref.load %assume_align[%arg0, %1827, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1829 = vector.broadcast %1828 : f32 to vector<8xf32>
    %1830 = vector.fma %1829, %1799, %1798 : vector<8xf32>
    %1831 = vector.extract %38[56] : vector<8xf32> from vector<64x8xf32>
    %1832 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1833 = vector.broadcast %1832 : f32 to vector<8xf32>
    %1834 = vector.fma %1833, %1831, %1802 : vector<8xf32>
    %1835 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1836 = memref.load %assume_align[%arg0, %1835, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1837 = vector.broadcast %1836 : f32 to vector<8xf32>
    %1838 = vector.fma %1837, %1831, %1806 : vector<8xf32>
    %1839 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1840 = memref.load %assume_align[%arg0, %1839, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1841 = vector.broadcast %1840 : f32 to vector<8xf32>
    %1842 = vector.fma %1841, %1831, %1810 : vector<8xf32>
    %1843 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1844 = memref.load %assume_align[%arg0, %1843, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1845 = vector.broadcast %1844 : f32 to vector<8xf32>
    %1846 = vector.fma %1845, %1831, %1814 : vector<8xf32>
    %1847 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1848 = memref.load %assume_align[%arg0, %1847, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1849 = vector.broadcast %1848 : f32 to vector<8xf32>
    %1850 = vector.fma %1849, %1831, %1818 : vector<8xf32>
    %1851 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1852 = memref.load %assume_align[%arg0, %1851, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1853 = vector.broadcast %1852 : f32 to vector<8xf32>
    %1854 = vector.fma %1853, %1831, %1822 : vector<8xf32>
    %1855 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1856 = memref.load %assume_align[%arg0, %1855, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1857 = vector.broadcast %1856 : f32 to vector<8xf32>
    %1858 = vector.fma %1857, %1831, %1826 : vector<8xf32>
    %1859 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1860 = memref.load %assume_align[%arg0, %1859, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1861 = vector.broadcast %1860 : f32 to vector<8xf32>
    %1862 = vector.fma %1861, %1831, %1830 : vector<8xf32>
    %1863 = vector.extract %38[57] : vector<8xf32> from vector<64x8xf32>
    %1864 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1865 = vector.broadcast %1864 : f32 to vector<8xf32>
    %1866 = vector.fma %1865, %1863, %1834 : vector<8xf32>
    %1867 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1868 = memref.load %assume_align[%arg0, %1867, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1869 = vector.broadcast %1868 : f32 to vector<8xf32>
    %1870 = vector.fma %1869, %1863, %1838 : vector<8xf32>
    %1871 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1872 = memref.load %assume_align[%arg0, %1871, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1873 = vector.broadcast %1872 : f32 to vector<8xf32>
    %1874 = vector.fma %1873, %1863, %1842 : vector<8xf32>
    %1875 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1876 = memref.load %assume_align[%arg0, %1875, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1877 = vector.broadcast %1876 : f32 to vector<8xf32>
    %1878 = vector.fma %1877, %1863, %1846 : vector<8xf32>
    %1879 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1880 = memref.load %assume_align[%arg0, %1879, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1881 = vector.broadcast %1880 : f32 to vector<8xf32>
    %1882 = vector.fma %1881, %1863, %1850 : vector<8xf32>
    %1883 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1884 = memref.load %assume_align[%arg0, %1883, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1885 = vector.broadcast %1884 : f32 to vector<8xf32>
    %1886 = vector.fma %1885, %1863, %1854 : vector<8xf32>
    %1887 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1888 = memref.load %assume_align[%arg0, %1887, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1889 = vector.broadcast %1888 : f32 to vector<8xf32>
    %1890 = vector.fma %1889, %1863, %1858 : vector<8xf32>
    %1891 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1892 = memref.load %assume_align[%arg0, %1891, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1893 = vector.broadcast %1892 : f32 to vector<8xf32>
    %1894 = vector.fma %1893, %1863, %1862 : vector<8xf32>
    %1895 = vector.extract %38[58] : vector<8xf32> from vector<64x8xf32>
    %1896 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1897 = vector.broadcast %1896 : f32 to vector<8xf32>
    %1898 = vector.fma %1897, %1895, %1866 : vector<8xf32>
    %1899 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1900 = memref.load %assume_align[%arg0, %1899, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1901 = vector.broadcast %1900 : f32 to vector<8xf32>
    %1902 = vector.fma %1901, %1895, %1870 : vector<8xf32>
    %1903 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1904 = memref.load %assume_align[%arg0, %1903, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1905 = vector.broadcast %1904 : f32 to vector<8xf32>
    %1906 = vector.fma %1905, %1895, %1874 : vector<8xf32>
    %1907 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1908 = memref.load %assume_align[%arg0, %1907, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1909 = vector.broadcast %1908 : f32 to vector<8xf32>
    %1910 = vector.fma %1909, %1895, %1878 : vector<8xf32>
    %1911 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1912 = memref.load %assume_align[%arg0, %1911, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1913 = vector.broadcast %1912 : f32 to vector<8xf32>
    %1914 = vector.fma %1913, %1895, %1882 : vector<8xf32>
    %1915 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1916 = memref.load %assume_align[%arg0, %1915, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1917 = vector.broadcast %1916 : f32 to vector<8xf32>
    %1918 = vector.fma %1917, %1895, %1886 : vector<8xf32>
    %1919 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1920 = memref.load %assume_align[%arg0, %1919, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1921 = vector.broadcast %1920 : f32 to vector<8xf32>
    %1922 = vector.fma %1921, %1895, %1890 : vector<8xf32>
    %1923 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1924 = memref.load %assume_align[%arg0, %1923, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1925 = vector.broadcast %1924 : f32 to vector<8xf32>
    %1926 = vector.fma %1925, %1895, %1894 : vector<8xf32>
    %1927 = vector.extract %38[59] : vector<8xf32> from vector<64x8xf32>
    %1928 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1929 = vector.broadcast %1928 : f32 to vector<8xf32>
    %1930 = vector.fma %1929, %1927, %1898 : vector<8xf32>
    %1931 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1932 = memref.load %assume_align[%arg0, %1931, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1933 = vector.broadcast %1932 : f32 to vector<8xf32>
    %1934 = vector.fma %1933, %1927, %1902 : vector<8xf32>
    %1935 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1936 = memref.load %assume_align[%arg0, %1935, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1937 = vector.broadcast %1936 : f32 to vector<8xf32>
    %1938 = vector.fma %1937, %1927, %1906 : vector<8xf32>
    %1939 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1940 = memref.load %assume_align[%arg0, %1939, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1941 = vector.broadcast %1940 : f32 to vector<8xf32>
    %1942 = vector.fma %1941, %1927, %1910 : vector<8xf32>
    %1943 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1944 = memref.load %assume_align[%arg0, %1943, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1945 = vector.broadcast %1944 : f32 to vector<8xf32>
    %1946 = vector.fma %1945, %1927, %1914 : vector<8xf32>
    %1947 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1948 = memref.load %assume_align[%arg0, %1947, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1949 = vector.broadcast %1948 : f32 to vector<8xf32>
    %1950 = vector.fma %1949, %1927, %1918 : vector<8xf32>
    %1951 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1952 = memref.load %assume_align[%arg0, %1951, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1953 = vector.broadcast %1952 : f32 to vector<8xf32>
    %1954 = vector.fma %1953, %1927, %1922 : vector<8xf32>
    %1955 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1956 = memref.load %assume_align[%arg0, %1955, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1957 = vector.broadcast %1956 : f32 to vector<8xf32>
    %1958 = vector.fma %1957, %1927, %1926 : vector<8xf32>
    %1959 = vector.extract %38[60] : vector<8xf32> from vector<64x8xf32>
    %1960 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1961 = vector.broadcast %1960 : f32 to vector<8xf32>
    %1962 = vector.fma %1961, %1959, %1930 : vector<8xf32>
    %1963 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1964 = memref.load %assume_align[%arg0, %1963, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1965 = vector.broadcast %1964 : f32 to vector<8xf32>
    %1966 = vector.fma %1965, %1959, %1934 : vector<8xf32>
    %1967 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1968 = memref.load %assume_align[%arg0, %1967, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1969 = vector.broadcast %1968 : f32 to vector<8xf32>
    %1970 = vector.fma %1969, %1959, %1938 : vector<8xf32>
    %1971 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1972 = memref.load %assume_align[%arg0, %1971, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1973 = vector.broadcast %1972 : f32 to vector<8xf32>
    %1974 = vector.fma %1973, %1959, %1942 : vector<8xf32>
    %1975 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1976 = memref.load %assume_align[%arg0, %1975, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1977 = vector.broadcast %1976 : f32 to vector<8xf32>
    %1978 = vector.fma %1977, %1959, %1946 : vector<8xf32>
    %1979 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1980 = memref.load %assume_align[%arg0, %1979, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1981 = vector.broadcast %1980 : f32 to vector<8xf32>
    %1982 = vector.fma %1981, %1959, %1950 : vector<8xf32>
    %1983 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1984 = memref.load %assume_align[%arg0, %1983, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1985 = vector.broadcast %1984 : f32 to vector<8xf32>
    %1986 = vector.fma %1985, %1959, %1954 : vector<8xf32>
    %1987 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1988 = memref.load %assume_align[%arg0, %1987, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1989 = vector.broadcast %1988 : f32 to vector<8xf32>
    %1990 = vector.fma %1989, %1959, %1958 : vector<8xf32>
    %1991 = vector.extract %38[61] : vector<8xf32> from vector<64x8xf32>
    %1992 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1993 = vector.broadcast %1992 : f32 to vector<8xf32>
    %1994 = vector.fma %1993, %1991, %1962 : vector<8xf32>
    %1995 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1996 = memref.load %assume_align[%arg0, %1995, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1997 = vector.broadcast %1996 : f32 to vector<8xf32>
    %1998 = vector.fma %1997, %1991, %1966 : vector<8xf32>
    %1999 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2000 = memref.load %assume_align[%arg0, %1999, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2001 = vector.broadcast %2000 : f32 to vector<8xf32>
    %2002 = vector.fma %2001, %1991, %1970 : vector<8xf32>
    %2003 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2004 = memref.load %assume_align[%arg0, %2003, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2005 = vector.broadcast %2004 : f32 to vector<8xf32>
    %2006 = vector.fma %2005, %1991, %1974 : vector<8xf32>
    %2007 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2008 = memref.load %assume_align[%arg0, %2007, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2009 = vector.broadcast %2008 : f32 to vector<8xf32>
    %2010 = vector.fma %2009, %1991, %1978 : vector<8xf32>
    %2011 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2012 = memref.load %assume_align[%arg0, %2011, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2013 = vector.broadcast %2012 : f32 to vector<8xf32>
    %2014 = vector.fma %2013, %1991, %1982 : vector<8xf32>
    %2015 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2016 = memref.load %assume_align[%arg0, %2015, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2017 = vector.broadcast %2016 : f32 to vector<8xf32>
    %2018 = vector.fma %2017, %1991, %1986 : vector<8xf32>
    %2019 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2020 = memref.load %assume_align[%arg0, %2019, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2021 = vector.broadcast %2020 : f32 to vector<8xf32>
    %2022 = vector.fma %2021, %1991, %1990 : vector<8xf32>
    %2023 = vector.extract %38[62] : vector<8xf32> from vector<64x8xf32>
    %2024 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2025 = vector.broadcast %2024 : f32 to vector<8xf32>
    %2026 = vector.fma %2025, %2023, %1994 : vector<8xf32>
    %2027 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2028 = memref.load %assume_align[%arg0, %2027, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2029 = vector.broadcast %2028 : f32 to vector<8xf32>
    %2030 = vector.fma %2029, %2023, %1998 : vector<8xf32>
    %2031 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2032 = memref.load %assume_align[%arg0, %2031, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2033 = vector.broadcast %2032 : f32 to vector<8xf32>
    %2034 = vector.fma %2033, %2023, %2002 : vector<8xf32>
    %2035 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2036 = memref.load %assume_align[%arg0, %2035, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2037 = vector.broadcast %2036 : f32 to vector<8xf32>
    %2038 = vector.fma %2037, %2023, %2006 : vector<8xf32>
    %2039 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2040 = memref.load %assume_align[%arg0, %2039, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2041 = vector.broadcast %2040 : f32 to vector<8xf32>
    %2042 = vector.fma %2041, %2023, %2010 : vector<8xf32>
    %2043 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2044 = memref.load %assume_align[%arg0, %2043, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2045 = vector.broadcast %2044 : f32 to vector<8xf32>
    %2046 = vector.fma %2045, %2023, %2014 : vector<8xf32>
    %2047 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2048 = memref.load %assume_align[%arg0, %2047, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2049 = vector.broadcast %2048 : f32 to vector<8xf32>
    %2050 = vector.fma %2049, %2023, %2018 : vector<8xf32>
    %2051 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2052 = memref.load %assume_align[%arg0, %2051, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2053 = vector.broadcast %2052 : f32 to vector<8xf32>
    %2054 = vector.fma %2053, %2023, %2022 : vector<8xf32>
    %2055 = vector.extract %38[63] : vector<8xf32> from vector<64x8xf32>
    %2056 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2057 = vector.broadcast %2056 : f32 to vector<8xf32>
    %2058 = vector.fma %2057, %2055, %2026 : vector<8xf32>
    %2059 = vector.insert %2058, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2060 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2061 = memref.load %assume_align[%arg0, %2060, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2062 = vector.broadcast %2061 : f32 to vector<8xf32>
    %2063 = vector.fma %2062, %2055, %2030 : vector<8xf32>
    %2064 = vector.insert %2063, %2059 [1] : vector<8xf32> into vector<8x8xf32>
    %2065 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2066 = memref.load %assume_align[%arg0, %2065, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2067 = vector.broadcast %2066 : f32 to vector<8xf32>
    %2068 = vector.fma %2067, %2055, %2034 : vector<8xf32>
    %2069 = vector.insert %2068, %2064 [2] : vector<8xf32> into vector<8x8xf32>
    %2070 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2071 = memref.load %assume_align[%arg0, %2070, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2072 = vector.broadcast %2071 : f32 to vector<8xf32>
    %2073 = vector.fma %2072, %2055, %2038 : vector<8xf32>
    %2074 = vector.insert %2073, %2069 [3] : vector<8xf32> into vector<8x8xf32>
    %2075 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2076 = memref.load %assume_align[%arg0, %2075, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2077 = vector.broadcast %2076 : f32 to vector<8xf32>
    %2078 = vector.fma %2077, %2055, %2042 : vector<8xf32>
    %2079 = vector.insert %2078, %2074 [4] : vector<8xf32> into vector<8x8xf32>
    %2080 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2081 = memref.load %assume_align[%arg0, %2080, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2082 = vector.broadcast %2081 : f32 to vector<8xf32>
    %2083 = vector.fma %2082, %2055, %2046 : vector<8xf32>
    %2084 = vector.insert %2083, %2079 [5] : vector<8xf32> into vector<8x8xf32>
    %2085 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2086 = memref.load %assume_align[%arg0, %2085, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2087 = vector.broadcast %2086 : f32 to vector<8xf32>
    %2088 = vector.fma %2087, %2055, %2050 : vector<8xf32>
    %2089 = vector.insert %2088, %2084 [6] : vector<8xf32> into vector<8x8xf32>
    %2090 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2091 = memref.load %assume_align[%arg0, %2090, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2092 = vector.broadcast %2091 : f32 to vector<8xf32>
    %2093 = vector.fma %2092, %2055, %2054 : vector<8xf32>
    %2094 = vector.insert %2093, %2089 [7] : vector<8xf32> into vector<8x8xf32>
    %2095 = vector.reduction <maximumf>, %2058, %cst : vector<8xf32> into f32
    %2096 = vector.insert %2095, %cst_0 [0] : f32 into vector<8xf32>
    %2097 = vector.reduction <maximumf>, %2063, %cst : vector<8xf32> into f32
    %2098 = vector.insert %2097, %2096 [1] : f32 into vector<8xf32>
    %2099 = vector.reduction <maximumf>, %2068, %cst : vector<8xf32> into f32
    %2100 = vector.insert %2099, %2098 [2] : f32 into vector<8xf32>
    %2101 = vector.reduction <maximumf>, %2073, %cst : vector<8xf32> into f32
    %2102 = vector.insert %2101, %2100 [3] : f32 into vector<8xf32>
    %2103 = vector.reduction <maximumf>, %2078, %cst : vector<8xf32> into f32
    %2104 = vector.insert %2103, %2102 [4] : f32 into vector<8xf32>
    %2105 = vector.reduction <maximumf>, %2083, %cst : vector<8xf32> into f32
    %2106 = vector.insert %2105, %2104 [5] : f32 into vector<8xf32>
    %2107 = vector.reduction <maximumf>, %2088, %cst : vector<8xf32> into f32
    %2108 = vector.insert %2107, %2106 [6] : f32 into vector<8xf32>
    %2109 = vector.reduction <maximumf>, %2093, %cst : vector<8xf32> into f32
    %2110 = vector.insert %2109, %2108 [7] : f32 into vector<8xf32>
    %2111 = vector.shape_cast %2110 : vector<8xf32> to vector<1x8xf32>
    %2112 = arith.subf %2110, %cst_2 : vector<8xf32>
    %2113 = math.exp2 %2112 : vector<8xf32>
    %2114 = vector.shape_cast %2113 : vector<8xf32> to vector<1x8xf32>
    %2115 = vector.broadcast %2114 : vector<1x8xf32> to vector<8x8xf32>
    %2116 = arith.mulf %2115, %cst_1 : vector<8x8xf32>
    %2117 = vector.shape_cast %2116 : vector<8x8xf32> to vector<64xf32>
    %2118 = vector.shuffle %2117, %2117 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2119 = vector.shape_cast %2118 : vector<64xf32> to vector<8x8xf32>
    %2120 = vector.broadcast %2111 : vector<1x8xf32> to vector<8x8xf32>
    %2121 = vector.shape_cast %2120 : vector<8x8xf32> to vector<64xf32>
    %2122 = vector.shuffle %2121, %2121 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2123 = vector.shape_cast %2122 : vector<64xf32> to vector<8x8xf32>
    %2124 = arith.subf %2094, %2123 : vector<8x8xf32>
    %2125 = math.exp2 %2124 : vector<8x8xf32>
    %2126 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2127 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %2128 = vector.load %assume_align_4[%arg0, %2127, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2129 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %2130 = vector.load %assume_align_4[%arg0, %2129, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2131 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %2132 = vector.load %assume_align_4[%arg0, %2131, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2133 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %2134 = vector.load %assume_align_4[%arg0, %2133, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2135 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %2136 = vector.load %assume_align_4[%arg0, %2135, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2137 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %2138 = vector.load %assume_align_4[%arg0, %2137, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2139 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %2140 = vector.load %assume_align_4[%arg0, %2139, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2141 = vector.extract %2125[0, 0] : f32 from vector<8x8xf32>
    %2142 = vector.broadcast %2141 : f32 to vector<8xf32>
    %2143 = vector.extract %2119[0] : vector<8xf32> from vector<8x8xf32>
    %2144 = vector.fma %2142, %2126, %2143 : vector<8xf32>
    %2145 = vector.extract %2125[1, 0] : f32 from vector<8x8xf32>
    %2146 = vector.broadcast %2145 : f32 to vector<8xf32>
    %2147 = vector.extract %2119[1] : vector<8xf32> from vector<8x8xf32>
    %2148 = vector.fma %2146, %2126, %2147 : vector<8xf32>
    %2149 = vector.extract %2125[2, 0] : f32 from vector<8x8xf32>
    %2150 = vector.broadcast %2149 : f32 to vector<8xf32>
    %2151 = vector.extract %2119[2] : vector<8xf32> from vector<8x8xf32>
    %2152 = vector.fma %2150, %2126, %2151 : vector<8xf32>
    %2153 = vector.extract %2125[3, 0] : f32 from vector<8x8xf32>
    %2154 = vector.broadcast %2153 : f32 to vector<8xf32>
    %2155 = vector.extract %2119[3] : vector<8xf32> from vector<8x8xf32>
    %2156 = vector.fma %2154, %2126, %2155 : vector<8xf32>
    %2157 = vector.extract %2125[4, 0] : f32 from vector<8x8xf32>
    %2158 = vector.broadcast %2157 : f32 to vector<8xf32>
    %2159 = vector.extract %2119[4] : vector<8xf32> from vector<8x8xf32>
    %2160 = vector.fma %2158, %2126, %2159 : vector<8xf32>
    %2161 = vector.extract %2125[5, 0] : f32 from vector<8x8xf32>
    %2162 = vector.broadcast %2161 : f32 to vector<8xf32>
    %2163 = vector.extract %2119[5] : vector<8xf32> from vector<8x8xf32>
    %2164 = vector.fma %2162, %2126, %2163 : vector<8xf32>
    %2165 = vector.extract %2125[6, 0] : f32 from vector<8x8xf32>
    %2166 = vector.broadcast %2165 : f32 to vector<8xf32>
    %2167 = vector.extract %2119[6] : vector<8xf32> from vector<8x8xf32>
    %2168 = vector.fma %2166, %2126, %2167 : vector<8xf32>
    %2169 = vector.extract %2125[7, 0] : f32 from vector<8x8xf32>
    %2170 = vector.broadcast %2169 : f32 to vector<8xf32>
    %2171 = vector.extract %2119[7] : vector<8xf32> from vector<8x8xf32>
    %2172 = vector.fma %2170, %2126, %2171 : vector<8xf32>
    %2173 = vector.extract %2125[0, 1] : f32 from vector<8x8xf32>
    %2174 = vector.broadcast %2173 : f32 to vector<8xf32>
    %2175 = vector.fma %2174, %2128, %2144 : vector<8xf32>
    %2176 = vector.extract %2125[1, 1] : f32 from vector<8x8xf32>
    %2177 = vector.broadcast %2176 : f32 to vector<8xf32>
    %2178 = vector.fma %2177, %2128, %2148 : vector<8xf32>
    %2179 = vector.extract %2125[2, 1] : f32 from vector<8x8xf32>
    %2180 = vector.broadcast %2179 : f32 to vector<8xf32>
    %2181 = vector.fma %2180, %2128, %2152 : vector<8xf32>
    %2182 = vector.extract %2125[3, 1] : f32 from vector<8x8xf32>
    %2183 = vector.broadcast %2182 : f32 to vector<8xf32>
    %2184 = vector.fma %2183, %2128, %2156 : vector<8xf32>
    %2185 = vector.extract %2125[4, 1] : f32 from vector<8x8xf32>
    %2186 = vector.broadcast %2185 : f32 to vector<8xf32>
    %2187 = vector.fma %2186, %2128, %2160 : vector<8xf32>
    %2188 = vector.extract %2125[5, 1] : f32 from vector<8x8xf32>
    %2189 = vector.broadcast %2188 : f32 to vector<8xf32>
    %2190 = vector.fma %2189, %2128, %2164 : vector<8xf32>
    %2191 = vector.extract %2125[6, 1] : f32 from vector<8x8xf32>
    %2192 = vector.broadcast %2191 : f32 to vector<8xf32>
    %2193 = vector.fma %2192, %2128, %2168 : vector<8xf32>
    %2194 = vector.extract %2125[7, 1] : f32 from vector<8x8xf32>
    %2195 = vector.broadcast %2194 : f32 to vector<8xf32>
    %2196 = vector.fma %2195, %2128, %2172 : vector<8xf32>
    %2197 = vector.extract %2125[0, 2] : f32 from vector<8x8xf32>
    %2198 = vector.broadcast %2197 : f32 to vector<8xf32>
    %2199 = vector.fma %2198, %2130, %2175 : vector<8xf32>
    %2200 = vector.extract %2125[1, 2] : f32 from vector<8x8xf32>
    %2201 = vector.broadcast %2200 : f32 to vector<8xf32>
    %2202 = vector.fma %2201, %2130, %2178 : vector<8xf32>
    %2203 = vector.extract %2125[2, 2] : f32 from vector<8x8xf32>
    %2204 = vector.broadcast %2203 : f32 to vector<8xf32>
    %2205 = vector.fma %2204, %2130, %2181 : vector<8xf32>
    %2206 = vector.extract %2125[3, 2] : f32 from vector<8x8xf32>
    %2207 = vector.broadcast %2206 : f32 to vector<8xf32>
    %2208 = vector.fma %2207, %2130, %2184 : vector<8xf32>
    %2209 = vector.extract %2125[4, 2] : f32 from vector<8x8xf32>
    %2210 = vector.broadcast %2209 : f32 to vector<8xf32>
    %2211 = vector.fma %2210, %2130, %2187 : vector<8xf32>
    %2212 = vector.extract %2125[5, 2] : f32 from vector<8x8xf32>
    %2213 = vector.broadcast %2212 : f32 to vector<8xf32>
    %2214 = vector.fma %2213, %2130, %2190 : vector<8xf32>
    %2215 = vector.extract %2125[6, 2] : f32 from vector<8x8xf32>
    %2216 = vector.broadcast %2215 : f32 to vector<8xf32>
    %2217 = vector.fma %2216, %2130, %2193 : vector<8xf32>
    %2218 = vector.extract %2125[7, 2] : f32 from vector<8x8xf32>
    %2219 = vector.broadcast %2218 : f32 to vector<8xf32>
    %2220 = vector.fma %2219, %2130, %2196 : vector<8xf32>
    %2221 = vector.extract %2125[0, 3] : f32 from vector<8x8xf32>
    %2222 = vector.broadcast %2221 : f32 to vector<8xf32>
    %2223 = vector.fma %2222, %2132, %2199 : vector<8xf32>
    %2224 = vector.extract %2125[1, 3] : f32 from vector<8x8xf32>
    %2225 = vector.broadcast %2224 : f32 to vector<8xf32>
    %2226 = vector.fma %2225, %2132, %2202 : vector<8xf32>
    %2227 = vector.extract %2125[2, 3] : f32 from vector<8x8xf32>
    %2228 = vector.broadcast %2227 : f32 to vector<8xf32>
    %2229 = vector.fma %2228, %2132, %2205 : vector<8xf32>
    %2230 = vector.extract %2125[3, 3] : f32 from vector<8x8xf32>
    %2231 = vector.broadcast %2230 : f32 to vector<8xf32>
    %2232 = vector.fma %2231, %2132, %2208 : vector<8xf32>
    %2233 = vector.extract %2125[4, 3] : f32 from vector<8x8xf32>
    %2234 = vector.broadcast %2233 : f32 to vector<8xf32>
    %2235 = vector.fma %2234, %2132, %2211 : vector<8xf32>
    %2236 = vector.extract %2125[5, 3] : f32 from vector<8x8xf32>
    %2237 = vector.broadcast %2236 : f32 to vector<8xf32>
    %2238 = vector.fma %2237, %2132, %2214 : vector<8xf32>
    %2239 = vector.extract %2125[6, 3] : f32 from vector<8x8xf32>
    %2240 = vector.broadcast %2239 : f32 to vector<8xf32>
    %2241 = vector.fma %2240, %2132, %2217 : vector<8xf32>
    %2242 = vector.extract %2125[7, 3] : f32 from vector<8x8xf32>
    %2243 = vector.broadcast %2242 : f32 to vector<8xf32>
    %2244 = vector.fma %2243, %2132, %2220 : vector<8xf32>
    %2245 = vector.extract %2125[0, 4] : f32 from vector<8x8xf32>
    %2246 = vector.broadcast %2245 : f32 to vector<8xf32>
    %2247 = vector.fma %2246, %2134, %2223 : vector<8xf32>
    %2248 = vector.extract %2125[1, 4] : f32 from vector<8x8xf32>
    %2249 = vector.broadcast %2248 : f32 to vector<8xf32>
    %2250 = vector.fma %2249, %2134, %2226 : vector<8xf32>
    %2251 = vector.extract %2125[2, 4] : f32 from vector<8x8xf32>
    %2252 = vector.broadcast %2251 : f32 to vector<8xf32>
    %2253 = vector.fma %2252, %2134, %2229 : vector<8xf32>
    %2254 = vector.extract %2125[3, 4] : f32 from vector<8x8xf32>
    %2255 = vector.broadcast %2254 : f32 to vector<8xf32>
    %2256 = vector.fma %2255, %2134, %2232 : vector<8xf32>
    %2257 = vector.extract %2125[4, 4] : f32 from vector<8x8xf32>
    %2258 = vector.broadcast %2257 : f32 to vector<8xf32>
    %2259 = vector.fma %2258, %2134, %2235 : vector<8xf32>
    %2260 = vector.extract %2125[5, 4] : f32 from vector<8x8xf32>
    %2261 = vector.broadcast %2260 : f32 to vector<8xf32>
    %2262 = vector.fma %2261, %2134, %2238 : vector<8xf32>
    %2263 = vector.extract %2125[6, 4] : f32 from vector<8x8xf32>
    %2264 = vector.broadcast %2263 : f32 to vector<8xf32>
    %2265 = vector.fma %2264, %2134, %2241 : vector<8xf32>
    %2266 = vector.extract %2125[7, 4] : f32 from vector<8x8xf32>
    %2267 = vector.broadcast %2266 : f32 to vector<8xf32>
    %2268 = vector.fma %2267, %2134, %2244 : vector<8xf32>
    %2269 = vector.extract %2125[0, 5] : f32 from vector<8x8xf32>
    %2270 = vector.broadcast %2269 : f32 to vector<8xf32>
    %2271 = vector.fma %2270, %2136, %2247 : vector<8xf32>
    %2272 = vector.extract %2125[1, 5] : f32 from vector<8x8xf32>
    %2273 = vector.broadcast %2272 : f32 to vector<8xf32>
    %2274 = vector.fma %2273, %2136, %2250 : vector<8xf32>
    %2275 = vector.extract %2125[2, 5] : f32 from vector<8x8xf32>
    %2276 = vector.broadcast %2275 : f32 to vector<8xf32>
    %2277 = vector.fma %2276, %2136, %2253 : vector<8xf32>
    %2278 = vector.extract %2125[3, 5] : f32 from vector<8x8xf32>
    %2279 = vector.broadcast %2278 : f32 to vector<8xf32>
    %2280 = vector.fma %2279, %2136, %2256 : vector<8xf32>
    %2281 = vector.extract %2125[4, 5] : f32 from vector<8x8xf32>
    %2282 = vector.broadcast %2281 : f32 to vector<8xf32>
    %2283 = vector.fma %2282, %2136, %2259 : vector<8xf32>
    %2284 = vector.extract %2125[5, 5] : f32 from vector<8x8xf32>
    %2285 = vector.broadcast %2284 : f32 to vector<8xf32>
    %2286 = vector.fma %2285, %2136, %2262 : vector<8xf32>
    %2287 = vector.extract %2125[6, 5] : f32 from vector<8x8xf32>
    %2288 = vector.broadcast %2287 : f32 to vector<8xf32>
    %2289 = vector.fma %2288, %2136, %2265 : vector<8xf32>
    %2290 = vector.extract %2125[7, 5] : f32 from vector<8x8xf32>
    %2291 = vector.broadcast %2290 : f32 to vector<8xf32>
    %2292 = vector.fma %2291, %2136, %2268 : vector<8xf32>
    %2293 = vector.extract %2125[0, 6] : f32 from vector<8x8xf32>
    %2294 = vector.broadcast %2293 : f32 to vector<8xf32>
    %2295 = vector.fma %2294, %2138, %2271 : vector<8xf32>
    %2296 = vector.extract %2125[1, 6] : f32 from vector<8x8xf32>
    %2297 = vector.broadcast %2296 : f32 to vector<8xf32>
    %2298 = vector.fma %2297, %2138, %2274 : vector<8xf32>
    %2299 = vector.extract %2125[2, 6] : f32 from vector<8x8xf32>
    %2300 = vector.broadcast %2299 : f32 to vector<8xf32>
    %2301 = vector.fma %2300, %2138, %2277 : vector<8xf32>
    %2302 = vector.extract %2125[3, 6] : f32 from vector<8x8xf32>
    %2303 = vector.broadcast %2302 : f32 to vector<8xf32>
    %2304 = vector.fma %2303, %2138, %2280 : vector<8xf32>
    %2305 = vector.extract %2125[4, 6] : f32 from vector<8x8xf32>
    %2306 = vector.broadcast %2305 : f32 to vector<8xf32>
    %2307 = vector.fma %2306, %2138, %2283 : vector<8xf32>
    %2308 = vector.extract %2125[5, 6] : f32 from vector<8x8xf32>
    %2309 = vector.broadcast %2308 : f32 to vector<8xf32>
    %2310 = vector.fma %2309, %2138, %2286 : vector<8xf32>
    %2311 = vector.extract %2125[6, 6] : f32 from vector<8x8xf32>
    %2312 = vector.broadcast %2311 : f32 to vector<8xf32>
    %2313 = vector.fma %2312, %2138, %2289 : vector<8xf32>
    %2314 = vector.extract %2125[7, 6] : f32 from vector<8x8xf32>
    %2315 = vector.broadcast %2314 : f32 to vector<8xf32>
    %2316 = vector.fma %2315, %2138, %2292 : vector<8xf32>
    %2317 = vector.extract %2125[0, 7] : f32 from vector<8x8xf32>
    %2318 = vector.broadcast %2317 : f32 to vector<8xf32>
    %2319 = vector.fma %2318, %2140, %2295 : vector<8xf32>
    %2320 = vector.insert %2319, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2321 = vector.extract %2125[1, 7] : f32 from vector<8x8xf32>
    %2322 = vector.broadcast %2321 : f32 to vector<8xf32>
    %2323 = vector.fma %2322, %2140, %2298 : vector<8xf32>
    %2324 = vector.insert %2323, %2320 [1] : vector<8xf32> into vector<8x8xf32>
    %2325 = vector.extract %2125[2, 7] : f32 from vector<8x8xf32>
    %2326 = vector.broadcast %2325 : f32 to vector<8xf32>
    %2327 = vector.fma %2326, %2140, %2301 : vector<8xf32>
    %2328 = vector.insert %2327, %2324 [2] : vector<8xf32> into vector<8x8xf32>
    %2329 = vector.extract %2125[3, 7] : f32 from vector<8x8xf32>
    %2330 = vector.broadcast %2329 : f32 to vector<8xf32>
    %2331 = vector.fma %2330, %2140, %2304 : vector<8xf32>
    %2332 = vector.insert %2331, %2328 [3] : vector<8xf32> into vector<8x8xf32>
    %2333 = vector.extract %2125[4, 7] : f32 from vector<8x8xf32>
    %2334 = vector.broadcast %2333 : f32 to vector<8xf32>
    %2335 = vector.fma %2334, %2140, %2307 : vector<8xf32>
    %2336 = vector.insert %2335, %2332 [4] : vector<8xf32> into vector<8x8xf32>
    %2337 = vector.extract %2125[5, 7] : f32 from vector<8x8xf32>
    %2338 = vector.broadcast %2337 : f32 to vector<8xf32>
    %2339 = vector.fma %2338, %2140, %2310 : vector<8xf32>
    %2340 = vector.insert %2339, %2336 [5] : vector<8xf32> into vector<8x8xf32>
    %2341 = vector.extract %2125[6, 7] : f32 from vector<8x8xf32>
    %2342 = vector.broadcast %2341 : f32 to vector<8xf32>
    %2343 = vector.fma %2342, %2140, %2313 : vector<8xf32>
    %2344 = vector.insert %2343, %2340 [6] : vector<8xf32> into vector<8x8xf32>
    %2345 = vector.extract %2125[7, 7] : f32 from vector<8x8xf32>
    %2346 = vector.broadcast %2345 : f32 to vector<8xf32>
    %2347 = vector.fma %2346, %2140, %2316 : vector<8xf32>
    %2348 = vector.insert %2347, %2344 [7] : vector<8xf32> into vector<8x8xf32>
    %2349 = arith.mulf %2113, %cst_0 : vector<8xf32>
    %2350 = vector.extract %2125[0] : vector<8xf32> from vector<8x8xf32>
    %2351 = vector.extract %2349[0] : f32 from vector<8xf32>
    %2352 = vector.reduction <add>, %2350, %2351 : vector<8xf32> into f32
    %2353 = vector.insert %2352, %cst_0 [0] : f32 into vector<8xf32>
    %2354 = vector.extract %2125[1] : vector<8xf32> from vector<8x8xf32>
    %2355 = vector.extract %2349[1] : f32 from vector<8xf32>
    %2356 = vector.reduction <add>, %2354, %2355 : vector<8xf32> into f32
    %2357 = vector.insert %2356, %2353 [1] : f32 into vector<8xf32>
    %2358 = vector.extract %2125[2] : vector<8xf32> from vector<8x8xf32>
    %2359 = vector.extract %2349[2] : f32 from vector<8xf32>
    %2360 = vector.reduction <add>, %2358, %2359 : vector<8xf32> into f32
    %2361 = vector.insert %2360, %2357 [2] : f32 into vector<8xf32>
    %2362 = vector.extract %2125[3] : vector<8xf32> from vector<8x8xf32>
    %2363 = vector.extract %2349[3] : f32 from vector<8xf32>
    %2364 = vector.reduction <add>, %2362, %2363 : vector<8xf32> into f32
    %2365 = vector.insert %2364, %2361 [3] : f32 into vector<8xf32>
    %2366 = vector.extract %2125[4] : vector<8xf32> from vector<8x8xf32>
    %2367 = vector.extract %2349[4] : f32 from vector<8xf32>
    %2368 = vector.reduction <add>, %2366, %2367 : vector<8xf32> into f32
    %2369 = vector.insert %2368, %2365 [4] : f32 into vector<8xf32>
    %2370 = vector.extract %2125[5] : vector<8xf32> from vector<8x8xf32>
    %2371 = vector.extract %2349[5] : f32 from vector<8xf32>
    %2372 = vector.reduction <add>, %2370, %2371 : vector<8xf32> into f32
    %2373 = vector.insert %2372, %2369 [5] : f32 into vector<8xf32>
    %2374 = vector.extract %2125[6] : vector<8xf32> from vector<8x8xf32>
    %2375 = vector.extract %2349[6] : f32 from vector<8xf32>
    %2376 = vector.reduction <add>, %2374, %2375 : vector<8xf32> into f32
    %2377 = vector.insert %2376, %2373 [6] : f32 into vector<8xf32>
    %2378 = vector.extract %2125[7] : vector<8xf32> from vector<8x8xf32>
    %2379 = vector.extract %2349[7] : f32 from vector<8xf32>
    %2380 = vector.reduction <add>, %2378, %2379 : vector<8xf32> into f32
    %2381 = vector.insert %2380, %2377 [7] : f32 into vector<8xf32>
    %2382 = vector.shape_cast %2381 : vector<8xf32> to vector<1x8xf32>
    %2383 = vector.broadcast %2382 : vector<1x8xf32> to vector<8x8xf32>
    %2384 = vector.shape_cast %2383 : vector<8x8xf32> to vector<64xf32>
    %2385 = vector.shuffle %2384, %2384 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2386 = vector.shape_cast %2385 : vector<64xf32> to vector<8x8xf32>
    %2387 = arith.divf %2348, %2386 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    %2388 = vector.extract %2387[0] : vector<8xf32> from vector<8x8xf32>
    vector.store %2388, %subview_7[%c0, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2389 = vector.extract %2387[1] : vector<8xf32> from vector<8x8xf32>
    vector.store %2389, %subview_7[%c1, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2390 = vector.extract %2387[2] : vector<8xf32> from vector<8x8xf32>
    vector.store %2390, %subview_7[%c2, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2391 = vector.extract %2387[3] : vector<8xf32> from vector<8x8xf32>
    vector.store %2391, %subview_7[%c3, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2392 = vector.extract %2387[4] : vector<8xf32> from vector<8x8xf32>
    vector.store %2392, %subview_7[%c4, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2393 = vector.extract %2387[5] : vector<8xf32> from vector<8x8xf32>
    vector.store %2393, %subview_7[%c5, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2394 = vector.extract %2387[6] : vector<8xf32> from vector<8x8xf32>
    vector.store %2394, %subview_7[%c6, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2395 = vector.extract %2387[7] : vector<8xf32> from vector<8x8xf32>
    vector.store %2395, %subview_7[%c7, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVectorShapeCastLoweringPass (iree-llvmcpu-vector-shape-cast-lowering) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %0 = ub.poison : vector<8x8xf32>
  %1 = ub.poison : vector<64xf32>
  %2 = ub.poison : vector<1x8xf32>
  %3 = ub.poison : vector<512xf32>
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %5, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %6 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %6, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %7 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %7, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %8 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %9 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %10 = vector.load %assume_align_3[%arg0, %9, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %11 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %12 = vector.load %assume_align_3[%arg0, %11, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %15 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %16 = vector.load %assume_align_3[%arg0, %15, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %17 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %18 = vector.load %assume_align_3[%arg0, %17, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %19 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %21 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %22 = vector.load %assume_align_3[%arg0, %21, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %23 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
    %24 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
    %25 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
    %26 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
    %27 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
    %28 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
    %29 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
    %30 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
    %31 = vector.insert_strided_slice %8, %3 {offsets = [0], strides = [1]} : vector<64xf32> into vector<512xf32>
    %32 = vector.insert_strided_slice %10, %31 {offsets = [64], strides = [1]} : vector<64xf32> into vector<512xf32>
    %33 = vector.insert_strided_slice %12, %32 {offsets = [128], strides = [1]} : vector<64xf32> into vector<512xf32>
    %34 = vector.insert_strided_slice %14, %33 {offsets = [192], strides = [1]} : vector<64xf32> into vector<512xf32>
    %35 = vector.insert_strided_slice %16, %34 {offsets = [256], strides = [1]} : vector<64xf32> into vector<512xf32>
    %36 = vector.insert_strided_slice %18, %35 {offsets = [320], strides = [1]} : vector<64xf32> into vector<512xf32>
    %37 = vector.insert_strided_slice %20, %36 {offsets = [384], strides = [1]} : vector<64xf32> into vector<512xf32>
    %38 = vector.insert_strided_slice %22, %37 {offsets = [448], strides = [1]} : vector<64xf32> into vector<512xf32>
    %39 = vector.shuffle %38, %38 [0, 64, 128, 192, 256, 320, 384, 448, 1, 65, 129, 193, 257, 321, 385, 449, 2, 66, 130, 194, 258, 322, 386, 450, 3, 67, 131, 195, 259, 323, 387, 451, 4, 68, 132, 196, 260, 324, 388, 452, 5, 69, 133, 197, 261, 325, 389, 453, 6, 70, 134, 198, 262, 326, 390, 454, 7, 71, 135, 199, 263, 327, 391, 455, 8, 72, 136, 200, 264, 328, 392, 456, 9, 73, 137, 201, 265, 329, 393, 457, 10, 74, 138, 202, 266, 330, 394, 458, 11, 75, 139, 203, 267, 331, 395, 459, 12, 76, 140, 204, 268, 332, 396, 460, 13, 77, 141, 205, 269, 333, 397, 461, 14, 78, 142, 206, 270, 334, 398, 462, 15, 79, 143, 207, 271, 335, 399, 463, 16, 80, 144, 208, 272, 336, 400, 464, 17, 81, 145, 209, 273, 337, 401, 465, 18, 82, 146, 210, 274, 338, 402, 466, 19, 83, 147, 211, 275, 339, 403, 467, 20, 84, 148, 212, 276, 340, 404, 468, 21, 85, 149, 213, 277, 341, 405, 469, 22, 86, 150, 214, 278, 342, 406, 470, 23, 87, 151, 215, 279, 343, 407, 471, 24, 88, 152, 216, 280, 344, 408, 472, 25, 89, 153, 217, 281, 345, 409, 473, 26, 90, 154, 218, 282, 346, 410, 474, 27, 91, 155, 219, 283, 347, 411, 475, 28, 92, 156, 220, 284, 348, 412, 476, 29, 93, 157, 221, 285, 349, 413, 477, 30, 94, 158, 222, 286, 350, 414, 478, 31, 95, 159, 223, 287, 351, 415, 479, 32, 96, 160, 224, 288, 352, 416, 480, 33, 97, 161, 225, 289, 353, 417, 481, 34, 98, 162, 226, 290, 354, 418, 482, 35, 99, 163, 227, 291, 355, 419, 483, 36, 100, 164, 228, 292, 356, 420, 484, 37, 101, 165, 229, 293, 357, 421, 485, 38, 102, 166, 230, 294, 358, 422, 486, 39, 103, 167, 231, 295, 359, 423, 487, 40, 104, 168, 232, 296, 360, 424, 488, 41, 105, 169, 233, 297, 361, 425, 489, 42, 106, 170, 234, 298, 362, 426, 490, 43, 107, 171, 235, 299, 363, 427, 491, 44, 108, 172, 236, 300, 364, 428, 492, 45, 109, 173, 237, 301, 365, 429, 493, 46, 110, 174, 238, 302, 366, 430, 494, 47, 111, 175, 239, 303, 367, 431, 495, 48, 112, 176, 240, 304, 368, 432, 496, 49, 113, 177, 241, 305, 369, 433, 497, 50, 114, 178, 242, 306, 370, 434, 498, 51, 115, 179, 243, 307, 371, 435, 499, 52, 116, 180, 244, 308, 372, 436, 500, 53, 117, 181, 245, 309, 373, 437, 501, 54, 118, 182, 246, 310, 374, 438, 502, 55, 119, 183, 247, 311, 375, 439, 503, 56, 120, 184, 248, 312, 376, 440, 504, 57, 121, 185, 249, 313, 377, 441, 505, 58, 122, 186, 250, 314, 378, 442, 506, 59, 123, 187, 251, 315, 379, 443, 507, 60, 124, 188, 252, 316, 380, 444, 508, 61, 125, 189, 253, 317, 381, 445, 509, 62, 126, 190, 254, 318, 382, 446, 510, 63, 127, 191, 255, 319, 383, 447, 511] : vector<512xf32>, vector<512xf32>
    %40 = vector.extract_strided_slice %39 {offsets = [0], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %41 = vector.extract_strided_slice %39 {offsets = [8], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %42 = vector.extract_strided_slice %39 {offsets = [16], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %43 = vector.extract_strided_slice %39 {offsets = [24], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %44 = vector.extract_strided_slice %39 {offsets = [32], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %45 = vector.extract_strided_slice %39 {offsets = [40], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %46 = vector.extract_strided_slice %39 {offsets = [48], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %47 = vector.extract_strided_slice %39 {offsets = [56], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %48 = vector.extract_strided_slice %39 {offsets = [64], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %49 = vector.extract_strided_slice %39 {offsets = [72], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %50 = vector.extract_strided_slice %39 {offsets = [80], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %51 = vector.extract_strided_slice %39 {offsets = [88], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %52 = vector.extract_strided_slice %39 {offsets = [96], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %53 = vector.extract_strided_slice %39 {offsets = [104], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %54 = vector.extract_strided_slice %39 {offsets = [112], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %55 = vector.extract_strided_slice %39 {offsets = [120], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %56 = vector.extract_strided_slice %39 {offsets = [128], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %57 = vector.extract_strided_slice %39 {offsets = [136], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %58 = vector.extract_strided_slice %39 {offsets = [144], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %59 = vector.extract_strided_slice %39 {offsets = [152], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %60 = vector.extract_strided_slice %39 {offsets = [160], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %61 = vector.extract_strided_slice %39 {offsets = [168], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %62 = vector.extract_strided_slice %39 {offsets = [176], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %63 = vector.extract_strided_slice %39 {offsets = [184], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %64 = vector.extract_strided_slice %39 {offsets = [192], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %65 = vector.extract_strided_slice %39 {offsets = [200], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %66 = vector.extract_strided_slice %39 {offsets = [208], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %67 = vector.extract_strided_slice %39 {offsets = [216], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %68 = vector.extract_strided_slice %39 {offsets = [224], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %69 = vector.extract_strided_slice %39 {offsets = [232], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %70 = vector.extract_strided_slice %39 {offsets = [240], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %71 = vector.extract_strided_slice %39 {offsets = [248], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %72 = vector.extract_strided_slice %39 {offsets = [256], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %73 = vector.extract_strided_slice %39 {offsets = [264], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %74 = vector.extract_strided_slice %39 {offsets = [272], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %75 = vector.extract_strided_slice %39 {offsets = [280], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %76 = vector.extract_strided_slice %39 {offsets = [288], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %77 = vector.extract_strided_slice %39 {offsets = [296], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %78 = vector.extract_strided_slice %39 {offsets = [304], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %79 = vector.extract_strided_slice %39 {offsets = [312], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %80 = vector.extract_strided_slice %39 {offsets = [320], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %81 = vector.extract_strided_slice %39 {offsets = [328], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %82 = vector.extract_strided_slice %39 {offsets = [336], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %83 = vector.extract_strided_slice %39 {offsets = [344], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %84 = vector.extract_strided_slice %39 {offsets = [352], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %85 = vector.extract_strided_slice %39 {offsets = [360], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %86 = vector.extract_strided_slice %39 {offsets = [368], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %87 = vector.extract_strided_slice %39 {offsets = [376], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %88 = vector.extract_strided_slice %39 {offsets = [384], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %89 = vector.extract_strided_slice %39 {offsets = [392], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %90 = vector.extract_strided_slice %39 {offsets = [400], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %91 = vector.extract_strided_slice %39 {offsets = [408], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %92 = vector.extract_strided_slice %39 {offsets = [416], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %93 = vector.extract_strided_slice %39 {offsets = [424], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %94 = vector.extract_strided_slice %39 {offsets = [432], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %95 = vector.extract_strided_slice %39 {offsets = [440], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %96 = vector.extract_strided_slice %39 {offsets = [448], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %97 = vector.extract_strided_slice %39 {offsets = [456], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %98 = vector.extract_strided_slice %39 {offsets = [464], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %99 = vector.extract_strided_slice %39 {offsets = [472], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %100 = vector.extract_strided_slice %39 {offsets = [480], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %101 = vector.extract_strided_slice %39 {offsets = [488], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %102 = vector.extract_strided_slice %39 {offsets = [496], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %103 = vector.extract_strided_slice %39 {offsets = [504], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %104 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %105 = vector.broadcast %104 : f32 to vector<8xf32>
    %106 = vector.fma %105, %40, %23 : vector<8xf32>
    %107 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %108 = memref.load %assume_align[%arg0, %107, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %109 = vector.broadcast %108 : f32 to vector<8xf32>
    %110 = vector.fma %109, %40, %24 : vector<8xf32>
    %111 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %112 = memref.load %assume_align[%arg0, %111, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %113 = vector.broadcast %112 : f32 to vector<8xf32>
    %114 = vector.fma %113, %40, %25 : vector<8xf32>
    %115 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %116 = memref.load %assume_align[%arg0, %115, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %117 = vector.broadcast %116 : f32 to vector<8xf32>
    %118 = vector.fma %117, %40, %26 : vector<8xf32>
    %119 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %120 = memref.load %assume_align[%arg0, %119, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %121 = vector.broadcast %120 : f32 to vector<8xf32>
    %122 = vector.fma %121, %40, %27 : vector<8xf32>
    %123 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %124 = memref.load %assume_align[%arg0, %123, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %125 = vector.broadcast %124 : f32 to vector<8xf32>
    %126 = vector.fma %125, %40, %28 : vector<8xf32>
    %127 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %128 = memref.load %assume_align[%arg0, %127, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %129 = vector.broadcast %128 : f32 to vector<8xf32>
    %130 = vector.fma %129, %40, %29 : vector<8xf32>
    %131 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %132 = memref.load %assume_align[%arg0, %131, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %133 = vector.broadcast %132 : f32 to vector<8xf32>
    %134 = vector.fma %133, %40, %30 : vector<8xf32>
    %135 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %136 = vector.broadcast %135 : f32 to vector<8xf32>
    %137 = vector.fma %136, %41, %106 : vector<8xf32>
    %138 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %139 = memref.load %assume_align[%arg0, %138, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %140 = vector.broadcast %139 : f32 to vector<8xf32>
    %141 = vector.fma %140, %41, %110 : vector<8xf32>
    %142 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %143 = memref.load %assume_align[%arg0, %142, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %144 = vector.broadcast %143 : f32 to vector<8xf32>
    %145 = vector.fma %144, %41, %114 : vector<8xf32>
    %146 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %147 = memref.load %assume_align[%arg0, %146, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %148 = vector.broadcast %147 : f32 to vector<8xf32>
    %149 = vector.fma %148, %41, %118 : vector<8xf32>
    %150 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %151 = memref.load %assume_align[%arg0, %150, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %152 = vector.broadcast %151 : f32 to vector<8xf32>
    %153 = vector.fma %152, %41, %122 : vector<8xf32>
    %154 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %155 = memref.load %assume_align[%arg0, %154, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %156 = vector.broadcast %155 : f32 to vector<8xf32>
    %157 = vector.fma %156, %41, %126 : vector<8xf32>
    %158 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %159 = memref.load %assume_align[%arg0, %158, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %160 = vector.broadcast %159 : f32 to vector<8xf32>
    %161 = vector.fma %160, %41, %130 : vector<8xf32>
    %162 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %163 = memref.load %assume_align[%arg0, %162, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %164 = vector.broadcast %163 : f32 to vector<8xf32>
    %165 = vector.fma %164, %41, %134 : vector<8xf32>
    %166 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %167 = vector.broadcast %166 : f32 to vector<8xf32>
    %168 = vector.fma %167, %42, %137 : vector<8xf32>
    %169 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %170 = memref.load %assume_align[%arg0, %169, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %171 = vector.broadcast %170 : f32 to vector<8xf32>
    %172 = vector.fma %171, %42, %141 : vector<8xf32>
    %173 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %174 = memref.load %assume_align[%arg0, %173, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %175 = vector.broadcast %174 : f32 to vector<8xf32>
    %176 = vector.fma %175, %42, %145 : vector<8xf32>
    %177 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %178 = memref.load %assume_align[%arg0, %177, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %179 = vector.broadcast %178 : f32 to vector<8xf32>
    %180 = vector.fma %179, %42, %149 : vector<8xf32>
    %181 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %182 = memref.load %assume_align[%arg0, %181, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %183 = vector.broadcast %182 : f32 to vector<8xf32>
    %184 = vector.fma %183, %42, %153 : vector<8xf32>
    %185 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %186 = memref.load %assume_align[%arg0, %185, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %187 = vector.broadcast %186 : f32 to vector<8xf32>
    %188 = vector.fma %187, %42, %157 : vector<8xf32>
    %189 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %190 = memref.load %assume_align[%arg0, %189, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %191 = vector.broadcast %190 : f32 to vector<8xf32>
    %192 = vector.fma %191, %42, %161 : vector<8xf32>
    %193 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %194 = memref.load %assume_align[%arg0, %193, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %195 = vector.broadcast %194 : f32 to vector<8xf32>
    %196 = vector.fma %195, %42, %165 : vector<8xf32>
    %197 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %198 = vector.broadcast %197 : f32 to vector<8xf32>
    %199 = vector.fma %198, %43, %168 : vector<8xf32>
    %200 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %201 = memref.load %assume_align[%arg0, %200, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %202 = vector.broadcast %201 : f32 to vector<8xf32>
    %203 = vector.fma %202, %43, %172 : vector<8xf32>
    %204 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %205 = memref.load %assume_align[%arg0, %204, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %206 = vector.broadcast %205 : f32 to vector<8xf32>
    %207 = vector.fma %206, %43, %176 : vector<8xf32>
    %208 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %209 = memref.load %assume_align[%arg0, %208, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %210 = vector.broadcast %209 : f32 to vector<8xf32>
    %211 = vector.fma %210, %43, %180 : vector<8xf32>
    %212 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %213 = memref.load %assume_align[%arg0, %212, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %214 = vector.broadcast %213 : f32 to vector<8xf32>
    %215 = vector.fma %214, %43, %184 : vector<8xf32>
    %216 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %217 = memref.load %assume_align[%arg0, %216, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %218 = vector.broadcast %217 : f32 to vector<8xf32>
    %219 = vector.fma %218, %43, %188 : vector<8xf32>
    %220 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %221 = memref.load %assume_align[%arg0, %220, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %222 = vector.broadcast %221 : f32 to vector<8xf32>
    %223 = vector.fma %222, %43, %192 : vector<8xf32>
    %224 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %225 = memref.load %assume_align[%arg0, %224, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %226 = vector.broadcast %225 : f32 to vector<8xf32>
    %227 = vector.fma %226, %43, %196 : vector<8xf32>
    %228 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %229 = vector.broadcast %228 : f32 to vector<8xf32>
    %230 = vector.fma %229, %44, %199 : vector<8xf32>
    %231 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %232 = memref.load %assume_align[%arg0, %231, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %233 = vector.broadcast %232 : f32 to vector<8xf32>
    %234 = vector.fma %233, %44, %203 : vector<8xf32>
    %235 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %236 = memref.load %assume_align[%arg0, %235, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %237 = vector.broadcast %236 : f32 to vector<8xf32>
    %238 = vector.fma %237, %44, %207 : vector<8xf32>
    %239 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %240 = memref.load %assume_align[%arg0, %239, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %241 = vector.broadcast %240 : f32 to vector<8xf32>
    %242 = vector.fma %241, %44, %211 : vector<8xf32>
    %243 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %244 = memref.load %assume_align[%arg0, %243, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %245 = vector.broadcast %244 : f32 to vector<8xf32>
    %246 = vector.fma %245, %44, %215 : vector<8xf32>
    %247 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %248 = memref.load %assume_align[%arg0, %247, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %249 = vector.broadcast %248 : f32 to vector<8xf32>
    %250 = vector.fma %249, %44, %219 : vector<8xf32>
    %251 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %252 = memref.load %assume_align[%arg0, %251, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %253 = vector.broadcast %252 : f32 to vector<8xf32>
    %254 = vector.fma %253, %44, %223 : vector<8xf32>
    %255 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %256 = memref.load %assume_align[%arg0, %255, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %257 = vector.broadcast %256 : f32 to vector<8xf32>
    %258 = vector.fma %257, %44, %227 : vector<8xf32>
    %259 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %260 = vector.broadcast %259 : f32 to vector<8xf32>
    %261 = vector.fma %260, %45, %230 : vector<8xf32>
    %262 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %263 = memref.load %assume_align[%arg0, %262, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %264 = vector.broadcast %263 : f32 to vector<8xf32>
    %265 = vector.fma %264, %45, %234 : vector<8xf32>
    %266 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %267 = memref.load %assume_align[%arg0, %266, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %268 = vector.broadcast %267 : f32 to vector<8xf32>
    %269 = vector.fma %268, %45, %238 : vector<8xf32>
    %270 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %271 = memref.load %assume_align[%arg0, %270, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %272 = vector.broadcast %271 : f32 to vector<8xf32>
    %273 = vector.fma %272, %45, %242 : vector<8xf32>
    %274 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %275 = memref.load %assume_align[%arg0, %274, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %276 = vector.broadcast %275 : f32 to vector<8xf32>
    %277 = vector.fma %276, %45, %246 : vector<8xf32>
    %278 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %279 = memref.load %assume_align[%arg0, %278, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %280 = vector.broadcast %279 : f32 to vector<8xf32>
    %281 = vector.fma %280, %45, %250 : vector<8xf32>
    %282 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %283 = memref.load %assume_align[%arg0, %282, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %284 = vector.broadcast %283 : f32 to vector<8xf32>
    %285 = vector.fma %284, %45, %254 : vector<8xf32>
    %286 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %287 = memref.load %assume_align[%arg0, %286, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %288 = vector.broadcast %287 : f32 to vector<8xf32>
    %289 = vector.fma %288, %45, %258 : vector<8xf32>
    %290 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %291 = vector.broadcast %290 : f32 to vector<8xf32>
    %292 = vector.fma %291, %46, %261 : vector<8xf32>
    %293 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %294 = memref.load %assume_align[%arg0, %293, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %295 = vector.broadcast %294 : f32 to vector<8xf32>
    %296 = vector.fma %295, %46, %265 : vector<8xf32>
    %297 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %298 = memref.load %assume_align[%arg0, %297, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %299 = vector.broadcast %298 : f32 to vector<8xf32>
    %300 = vector.fma %299, %46, %269 : vector<8xf32>
    %301 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %302 = memref.load %assume_align[%arg0, %301, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %303 = vector.broadcast %302 : f32 to vector<8xf32>
    %304 = vector.fma %303, %46, %273 : vector<8xf32>
    %305 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %306 = memref.load %assume_align[%arg0, %305, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %307 = vector.broadcast %306 : f32 to vector<8xf32>
    %308 = vector.fma %307, %46, %277 : vector<8xf32>
    %309 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %310 = memref.load %assume_align[%arg0, %309, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %311 = vector.broadcast %310 : f32 to vector<8xf32>
    %312 = vector.fma %311, %46, %281 : vector<8xf32>
    %313 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %314 = memref.load %assume_align[%arg0, %313, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %315 = vector.broadcast %314 : f32 to vector<8xf32>
    %316 = vector.fma %315, %46, %285 : vector<8xf32>
    %317 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %318 = memref.load %assume_align[%arg0, %317, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %319 = vector.broadcast %318 : f32 to vector<8xf32>
    %320 = vector.fma %319, %46, %289 : vector<8xf32>
    %321 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %322 = vector.broadcast %321 : f32 to vector<8xf32>
    %323 = vector.fma %322, %47, %292 : vector<8xf32>
    %324 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %325 = memref.load %assume_align[%arg0, %324, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %326 = vector.broadcast %325 : f32 to vector<8xf32>
    %327 = vector.fma %326, %47, %296 : vector<8xf32>
    %328 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %329 = memref.load %assume_align[%arg0, %328, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %330 = vector.broadcast %329 : f32 to vector<8xf32>
    %331 = vector.fma %330, %47, %300 : vector<8xf32>
    %332 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %333 = memref.load %assume_align[%arg0, %332, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %334 = vector.broadcast %333 : f32 to vector<8xf32>
    %335 = vector.fma %334, %47, %304 : vector<8xf32>
    %336 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %337 = memref.load %assume_align[%arg0, %336, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %338 = vector.broadcast %337 : f32 to vector<8xf32>
    %339 = vector.fma %338, %47, %308 : vector<8xf32>
    %340 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %341 = memref.load %assume_align[%arg0, %340, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %342 = vector.broadcast %341 : f32 to vector<8xf32>
    %343 = vector.fma %342, %47, %312 : vector<8xf32>
    %344 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %345 = memref.load %assume_align[%arg0, %344, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %346 = vector.broadcast %345 : f32 to vector<8xf32>
    %347 = vector.fma %346, %47, %316 : vector<8xf32>
    %348 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %349 = memref.load %assume_align[%arg0, %348, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %350 = vector.broadcast %349 : f32 to vector<8xf32>
    %351 = vector.fma %350, %47, %320 : vector<8xf32>
    %352 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %353 = vector.broadcast %352 : f32 to vector<8xf32>
    %354 = vector.fma %353, %48, %323 : vector<8xf32>
    %355 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %356 = memref.load %assume_align[%arg0, %355, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %357 = vector.broadcast %356 : f32 to vector<8xf32>
    %358 = vector.fma %357, %48, %327 : vector<8xf32>
    %359 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %360 = memref.load %assume_align[%arg0, %359, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %361 = vector.broadcast %360 : f32 to vector<8xf32>
    %362 = vector.fma %361, %48, %331 : vector<8xf32>
    %363 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %364 = memref.load %assume_align[%arg0, %363, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %365 = vector.broadcast %364 : f32 to vector<8xf32>
    %366 = vector.fma %365, %48, %335 : vector<8xf32>
    %367 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %368 = memref.load %assume_align[%arg0, %367, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %369 = vector.broadcast %368 : f32 to vector<8xf32>
    %370 = vector.fma %369, %48, %339 : vector<8xf32>
    %371 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %372 = memref.load %assume_align[%arg0, %371, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %373 = vector.broadcast %372 : f32 to vector<8xf32>
    %374 = vector.fma %373, %48, %343 : vector<8xf32>
    %375 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %376 = memref.load %assume_align[%arg0, %375, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %377 = vector.broadcast %376 : f32 to vector<8xf32>
    %378 = vector.fma %377, %48, %347 : vector<8xf32>
    %379 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %380 = memref.load %assume_align[%arg0, %379, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %381 = vector.broadcast %380 : f32 to vector<8xf32>
    %382 = vector.fma %381, %48, %351 : vector<8xf32>
    %383 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %384 = vector.broadcast %383 : f32 to vector<8xf32>
    %385 = vector.fma %384, %49, %354 : vector<8xf32>
    %386 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %387 = memref.load %assume_align[%arg0, %386, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %388 = vector.broadcast %387 : f32 to vector<8xf32>
    %389 = vector.fma %388, %49, %358 : vector<8xf32>
    %390 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %391 = memref.load %assume_align[%arg0, %390, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %392 = vector.broadcast %391 : f32 to vector<8xf32>
    %393 = vector.fma %392, %49, %362 : vector<8xf32>
    %394 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %395 = memref.load %assume_align[%arg0, %394, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %396 = vector.broadcast %395 : f32 to vector<8xf32>
    %397 = vector.fma %396, %49, %366 : vector<8xf32>
    %398 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %399 = memref.load %assume_align[%arg0, %398, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %400 = vector.broadcast %399 : f32 to vector<8xf32>
    %401 = vector.fma %400, %49, %370 : vector<8xf32>
    %402 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %403 = memref.load %assume_align[%arg0, %402, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %404 = vector.broadcast %403 : f32 to vector<8xf32>
    %405 = vector.fma %404, %49, %374 : vector<8xf32>
    %406 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %407 = memref.load %assume_align[%arg0, %406, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %408 = vector.broadcast %407 : f32 to vector<8xf32>
    %409 = vector.fma %408, %49, %378 : vector<8xf32>
    %410 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %411 = memref.load %assume_align[%arg0, %410, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %412 = vector.broadcast %411 : f32 to vector<8xf32>
    %413 = vector.fma %412, %49, %382 : vector<8xf32>
    %414 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %415 = vector.broadcast %414 : f32 to vector<8xf32>
    %416 = vector.fma %415, %50, %385 : vector<8xf32>
    %417 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %418 = memref.load %assume_align[%arg0, %417, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %419 = vector.broadcast %418 : f32 to vector<8xf32>
    %420 = vector.fma %419, %50, %389 : vector<8xf32>
    %421 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %422 = memref.load %assume_align[%arg0, %421, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %423 = vector.broadcast %422 : f32 to vector<8xf32>
    %424 = vector.fma %423, %50, %393 : vector<8xf32>
    %425 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %426 = memref.load %assume_align[%arg0, %425, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %427 = vector.broadcast %426 : f32 to vector<8xf32>
    %428 = vector.fma %427, %50, %397 : vector<8xf32>
    %429 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %430 = memref.load %assume_align[%arg0, %429, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %431 = vector.broadcast %430 : f32 to vector<8xf32>
    %432 = vector.fma %431, %50, %401 : vector<8xf32>
    %433 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %434 = memref.load %assume_align[%arg0, %433, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %435 = vector.broadcast %434 : f32 to vector<8xf32>
    %436 = vector.fma %435, %50, %405 : vector<8xf32>
    %437 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %438 = memref.load %assume_align[%arg0, %437, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %439 = vector.broadcast %438 : f32 to vector<8xf32>
    %440 = vector.fma %439, %50, %409 : vector<8xf32>
    %441 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %442 = memref.load %assume_align[%arg0, %441, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %443 = vector.broadcast %442 : f32 to vector<8xf32>
    %444 = vector.fma %443, %50, %413 : vector<8xf32>
    %445 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %446 = vector.broadcast %445 : f32 to vector<8xf32>
    %447 = vector.fma %446, %51, %416 : vector<8xf32>
    %448 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %449 = memref.load %assume_align[%arg0, %448, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %450 = vector.broadcast %449 : f32 to vector<8xf32>
    %451 = vector.fma %450, %51, %420 : vector<8xf32>
    %452 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %453 = memref.load %assume_align[%arg0, %452, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %454 = vector.broadcast %453 : f32 to vector<8xf32>
    %455 = vector.fma %454, %51, %424 : vector<8xf32>
    %456 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %457 = memref.load %assume_align[%arg0, %456, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %458 = vector.broadcast %457 : f32 to vector<8xf32>
    %459 = vector.fma %458, %51, %428 : vector<8xf32>
    %460 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %461 = memref.load %assume_align[%arg0, %460, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %462 = vector.broadcast %461 : f32 to vector<8xf32>
    %463 = vector.fma %462, %51, %432 : vector<8xf32>
    %464 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %465 = memref.load %assume_align[%arg0, %464, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %466 = vector.broadcast %465 : f32 to vector<8xf32>
    %467 = vector.fma %466, %51, %436 : vector<8xf32>
    %468 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %469 = memref.load %assume_align[%arg0, %468, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %470 = vector.broadcast %469 : f32 to vector<8xf32>
    %471 = vector.fma %470, %51, %440 : vector<8xf32>
    %472 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %473 = memref.load %assume_align[%arg0, %472, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %474 = vector.broadcast %473 : f32 to vector<8xf32>
    %475 = vector.fma %474, %51, %444 : vector<8xf32>
    %476 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %477 = vector.broadcast %476 : f32 to vector<8xf32>
    %478 = vector.fma %477, %52, %447 : vector<8xf32>
    %479 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %480 = memref.load %assume_align[%arg0, %479, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %481 = vector.broadcast %480 : f32 to vector<8xf32>
    %482 = vector.fma %481, %52, %451 : vector<8xf32>
    %483 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %484 = memref.load %assume_align[%arg0, %483, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %485 = vector.broadcast %484 : f32 to vector<8xf32>
    %486 = vector.fma %485, %52, %455 : vector<8xf32>
    %487 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %488 = memref.load %assume_align[%arg0, %487, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %489 = vector.broadcast %488 : f32 to vector<8xf32>
    %490 = vector.fma %489, %52, %459 : vector<8xf32>
    %491 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %492 = memref.load %assume_align[%arg0, %491, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %493 = vector.broadcast %492 : f32 to vector<8xf32>
    %494 = vector.fma %493, %52, %463 : vector<8xf32>
    %495 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %496 = memref.load %assume_align[%arg0, %495, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %497 = vector.broadcast %496 : f32 to vector<8xf32>
    %498 = vector.fma %497, %52, %467 : vector<8xf32>
    %499 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %500 = memref.load %assume_align[%arg0, %499, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %501 = vector.broadcast %500 : f32 to vector<8xf32>
    %502 = vector.fma %501, %52, %471 : vector<8xf32>
    %503 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %504 = memref.load %assume_align[%arg0, %503, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %505 = vector.broadcast %504 : f32 to vector<8xf32>
    %506 = vector.fma %505, %52, %475 : vector<8xf32>
    %507 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %508 = vector.broadcast %507 : f32 to vector<8xf32>
    %509 = vector.fma %508, %53, %478 : vector<8xf32>
    %510 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %511 = memref.load %assume_align[%arg0, %510, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %512 = vector.broadcast %511 : f32 to vector<8xf32>
    %513 = vector.fma %512, %53, %482 : vector<8xf32>
    %514 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %515 = memref.load %assume_align[%arg0, %514, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %516 = vector.broadcast %515 : f32 to vector<8xf32>
    %517 = vector.fma %516, %53, %486 : vector<8xf32>
    %518 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %519 = memref.load %assume_align[%arg0, %518, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %520 = vector.broadcast %519 : f32 to vector<8xf32>
    %521 = vector.fma %520, %53, %490 : vector<8xf32>
    %522 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %523 = memref.load %assume_align[%arg0, %522, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %524 = vector.broadcast %523 : f32 to vector<8xf32>
    %525 = vector.fma %524, %53, %494 : vector<8xf32>
    %526 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %527 = memref.load %assume_align[%arg0, %526, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %528 = vector.broadcast %527 : f32 to vector<8xf32>
    %529 = vector.fma %528, %53, %498 : vector<8xf32>
    %530 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %531 = memref.load %assume_align[%arg0, %530, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %532 = vector.broadcast %531 : f32 to vector<8xf32>
    %533 = vector.fma %532, %53, %502 : vector<8xf32>
    %534 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %535 = memref.load %assume_align[%arg0, %534, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %536 = vector.broadcast %535 : f32 to vector<8xf32>
    %537 = vector.fma %536, %53, %506 : vector<8xf32>
    %538 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %539 = vector.broadcast %538 : f32 to vector<8xf32>
    %540 = vector.fma %539, %54, %509 : vector<8xf32>
    %541 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %542 = memref.load %assume_align[%arg0, %541, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %543 = vector.broadcast %542 : f32 to vector<8xf32>
    %544 = vector.fma %543, %54, %513 : vector<8xf32>
    %545 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %546 = memref.load %assume_align[%arg0, %545, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %547 = vector.broadcast %546 : f32 to vector<8xf32>
    %548 = vector.fma %547, %54, %517 : vector<8xf32>
    %549 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %550 = memref.load %assume_align[%arg0, %549, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %551 = vector.broadcast %550 : f32 to vector<8xf32>
    %552 = vector.fma %551, %54, %521 : vector<8xf32>
    %553 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %554 = memref.load %assume_align[%arg0, %553, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %555 = vector.broadcast %554 : f32 to vector<8xf32>
    %556 = vector.fma %555, %54, %525 : vector<8xf32>
    %557 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %558 = memref.load %assume_align[%arg0, %557, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %559 = vector.broadcast %558 : f32 to vector<8xf32>
    %560 = vector.fma %559, %54, %529 : vector<8xf32>
    %561 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %562 = memref.load %assume_align[%arg0, %561, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %563 = vector.broadcast %562 : f32 to vector<8xf32>
    %564 = vector.fma %563, %54, %533 : vector<8xf32>
    %565 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %566 = memref.load %assume_align[%arg0, %565, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %567 = vector.broadcast %566 : f32 to vector<8xf32>
    %568 = vector.fma %567, %54, %537 : vector<8xf32>
    %569 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %570 = vector.broadcast %569 : f32 to vector<8xf32>
    %571 = vector.fma %570, %55, %540 : vector<8xf32>
    %572 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %573 = memref.load %assume_align[%arg0, %572, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %574 = vector.broadcast %573 : f32 to vector<8xf32>
    %575 = vector.fma %574, %55, %544 : vector<8xf32>
    %576 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %577 = memref.load %assume_align[%arg0, %576, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %578 = vector.broadcast %577 : f32 to vector<8xf32>
    %579 = vector.fma %578, %55, %548 : vector<8xf32>
    %580 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %581 = memref.load %assume_align[%arg0, %580, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %582 = vector.broadcast %581 : f32 to vector<8xf32>
    %583 = vector.fma %582, %55, %552 : vector<8xf32>
    %584 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %585 = memref.load %assume_align[%arg0, %584, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %586 = vector.broadcast %585 : f32 to vector<8xf32>
    %587 = vector.fma %586, %55, %556 : vector<8xf32>
    %588 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %589 = memref.load %assume_align[%arg0, %588, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %590 = vector.broadcast %589 : f32 to vector<8xf32>
    %591 = vector.fma %590, %55, %560 : vector<8xf32>
    %592 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %593 = memref.load %assume_align[%arg0, %592, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %594 = vector.broadcast %593 : f32 to vector<8xf32>
    %595 = vector.fma %594, %55, %564 : vector<8xf32>
    %596 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %597 = memref.load %assume_align[%arg0, %596, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %598 = vector.broadcast %597 : f32 to vector<8xf32>
    %599 = vector.fma %598, %55, %568 : vector<8xf32>
    %600 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %601 = vector.broadcast %600 : f32 to vector<8xf32>
    %602 = vector.fma %601, %56, %571 : vector<8xf32>
    %603 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %604 = memref.load %assume_align[%arg0, %603, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %605 = vector.broadcast %604 : f32 to vector<8xf32>
    %606 = vector.fma %605, %56, %575 : vector<8xf32>
    %607 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %608 = memref.load %assume_align[%arg0, %607, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %609 = vector.broadcast %608 : f32 to vector<8xf32>
    %610 = vector.fma %609, %56, %579 : vector<8xf32>
    %611 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %612 = memref.load %assume_align[%arg0, %611, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %613 = vector.broadcast %612 : f32 to vector<8xf32>
    %614 = vector.fma %613, %56, %583 : vector<8xf32>
    %615 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %616 = memref.load %assume_align[%arg0, %615, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %617 = vector.broadcast %616 : f32 to vector<8xf32>
    %618 = vector.fma %617, %56, %587 : vector<8xf32>
    %619 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %620 = memref.load %assume_align[%arg0, %619, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %621 = vector.broadcast %620 : f32 to vector<8xf32>
    %622 = vector.fma %621, %56, %591 : vector<8xf32>
    %623 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %624 = memref.load %assume_align[%arg0, %623, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %625 = vector.broadcast %624 : f32 to vector<8xf32>
    %626 = vector.fma %625, %56, %595 : vector<8xf32>
    %627 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %628 = memref.load %assume_align[%arg0, %627, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %629 = vector.broadcast %628 : f32 to vector<8xf32>
    %630 = vector.fma %629, %56, %599 : vector<8xf32>
    %631 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %632 = vector.broadcast %631 : f32 to vector<8xf32>
    %633 = vector.fma %632, %57, %602 : vector<8xf32>
    %634 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %635 = memref.load %assume_align[%arg0, %634, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %636 = vector.broadcast %635 : f32 to vector<8xf32>
    %637 = vector.fma %636, %57, %606 : vector<8xf32>
    %638 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %639 = memref.load %assume_align[%arg0, %638, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %640 = vector.broadcast %639 : f32 to vector<8xf32>
    %641 = vector.fma %640, %57, %610 : vector<8xf32>
    %642 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %643 = memref.load %assume_align[%arg0, %642, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %644 = vector.broadcast %643 : f32 to vector<8xf32>
    %645 = vector.fma %644, %57, %614 : vector<8xf32>
    %646 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %647 = memref.load %assume_align[%arg0, %646, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %648 = vector.broadcast %647 : f32 to vector<8xf32>
    %649 = vector.fma %648, %57, %618 : vector<8xf32>
    %650 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %651 = memref.load %assume_align[%arg0, %650, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %652 = vector.broadcast %651 : f32 to vector<8xf32>
    %653 = vector.fma %652, %57, %622 : vector<8xf32>
    %654 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %655 = memref.load %assume_align[%arg0, %654, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %656 = vector.broadcast %655 : f32 to vector<8xf32>
    %657 = vector.fma %656, %57, %626 : vector<8xf32>
    %658 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %659 = memref.load %assume_align[%arg0, %658, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %660 = vector.broadcast %659 : f32 to vector<8xf32>
    %661 = vector.fma %660, %57, %630 : vector<8xf32>
    %662 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %663 = vector.broadcast %662 : f32 to vector<8xf32>
    %664 = vector.fma %663, %58, %633 : vector<8xf32>
    %665 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %666 = memref.load %assume_align[%arg0, %665, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %667 = vector.broadcast %666 : f32 to vector<8xf32>
    %668 = vector.fma %667, %58, %637 : vector<8xf32>
    %669 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %670 = memref.load %assume_align[%arg0, %669, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %671 = vector.broadcast %670 : f32 to vector<8xf32>
    %672 = vector.fma %671, %58, %641 : vector<8xf32>
    %673 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %674 = memref.load %assume_align[%arg0, %673, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %675 = vector.broadcast %674 : f32 to vector<8xf32>
    %676 = vector.fma %675, %58, %645 : vector<8xf32>
    %677 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %678 = memref.load %assume_align[%arg0, %677, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %679 = vector.broadcast %678 : f32 to vector<8xf32>
    %680 = vector.fma %679, %58, %649 : vector<8xf32>
    %681 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %682 = memref.load %assume_align[%arg0, %681, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %683 = vector.broadcast %682 : f32 to vector<8xf32>
    %684 = vector.fma %683, %58, %653 : vector<8xf32>
    %685 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %686 = memref.load %assume_align[%arg0, %685, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %687 = vector.broadcast %686 : f32 to vector<8xf32>
    %688 = vector.fma %687, %58, %657 : vector<8xf32>
    %689 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %690 = memref.load %assume_align[%arg0, %689, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %691 = vector.broadcast %690 : f32 to vector<8xf32>
    %692 = vector.fma %691, %58, %661 : vector<8xf32>
    %693 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %694 = vector.broadcast %693 : f32 to vector<8xf32>
    %695 = vector.fma %694, %59, %664 : vector<8xf32>
    %696 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %697 = memref.load %assume_align[%arg0, %696, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %698 = vector.broadcast %697 : f32 to vector<8xf32>
    %699 = vector.fma %698, %59, %668 : vector<8xf32>
    %700 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %701 = memref.load %assume_align[%arg0, %700, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %702 = vector.broadcast %701 : f32 to vector<8xf32>
    %703 = vector.fma %702, %59, %672 : vector<8xf32>
    %704 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %705 = memref.load %assume_align[%arg0, %704, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %706 = vector.broadcast %705 : f32 to vector<8xf32>
    %707 = vector.fma %706, %59, %676 : vector<8xf32>
    %708 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %709 = memref.load %assume_align[%arg0, %708, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %710 = vector.broadcast %709 : f32 to vector<8xf32>
    %711 = vector.fma %710, %59, %680 : vector<8xf32>
    %712 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %713 = memref.load %assume_align[%arg0, %712, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %714 = vector.broadcast %713 : f32 to vector<8xf32>
    %715 = vector.fma %714, %59, %684 : vector<8xf32>
    %716 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %717 = memref.load %assume_align[%arg0, %716, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %718 = vector.broadcast %717 : f32 to vector<8xf32>
    %719 = vector.fma %718, %59, %688 : vector<8xf32>
    %720 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %721 = memref.load %assume_align[%arg0, %720, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %722 = vector.broadcast %721 : f32 to vector<8xf32>
    %723 = vector.fma %722, %59, %692 : vector<8xf32>
    %724 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %725 = vector.broadcast %724 : f32 to vector<8xf32>
    %726 = vector.fma %725, %60, %695 : vector<8xf32>
    %727 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %728 = memref.load %assume_align[%arg0, %727, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %729 = vector.broadcast %728 : f32 to vector<8xf32>
    %730 = vector.fma %729, %60, %699 : vector<8xf32>
    %731 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %732 = memref.load %assume_align[%arg0, %731, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %733 = vector.broadcast %732 : f32 to vector<8xf32>
    %734 = vector.fma %733, %60, %703 : vector<8xf32>
    %735 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %736 = memref.load %assume_align[%arg0, %735, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %737 = vector.broadcast %736 : f32 to vector<8xf32>
    %738 = vector.fma %737, %60, %707 : vector<8xf32>
    %739 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %740 = memref.load %assume_align[%arg0, %739, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %741 = vector.broadcast %740 : f32 to vector<8xf32>
    %742 = vector.fma %741, %60, %711 : vector<8xf32>
    %743 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %744 = memref.load %assume_align[%arg0, %743, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %745 = vector.broadcast %744 : f32 to vector<8xf32>
    %746 = vector.fma %745, %60, %715 : vector<8xf32>
    %747 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %748 = memref.load %assume_align[%arg0, %747, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %749 = vector.broadcast %748 : f32 to vector<8xf32>
    %750 = vector.fma %749, %60, %719 : vector<8xf32>
    %751 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %752 = memref.load %assume_align[%arg0, %751, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %753 = vector.broadcast %752 : f32 to vector<8xf32>
    %754 = vector.fma %753, %60, %723 : vector<8xf32>
    %755 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %756 = vector.broadcast %755 : f32 to vector<8xf32>
    %757 = vector.fma %756, %61, %726 : vector<8xf32>
    %758 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %759 = memref.load %assume_align[%arg0, %758, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %760 = vector.broadcast %759 : f32 to vector<8xf32>
    %761 = vector.fma %760, %61, %730 : vector<8xf32>
    %762 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %763 = memref.load %assume_align[%arg0, %762, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %764 = vector.broadcast %763 : f32 to vector<8xf32>
    %765 = vector.fma %764, %61, %734 : vector<8xf32>
    %766 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %767 = memref.load %assume_align[%arg0, %766, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %768 = vector.broadcast %767 : f32 to vector<8xf32>
    %769 = vector.fma %768, %61, %738 : vector<8xf32>
    %770 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %771 = memref.load %assume_align[%arg0, %770, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %772 = vector.broadcast %771 : f32 to vector<8xf32>
    %773 = vector.fma %772, %61, %742 : vector<8xf32>
    %774 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %775 = memref.load %assume_align[%arg0, %774, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %776 = vector.broadcast %775 : f32 to vector<8xf32>
    %777 = vector.fma %776, %61, %746 : vector<8xf32>
    %778 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %779 = memref.load %assume_align[%arg0, %778, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %780 = vector.broadcast %779 : f32 to vector<8xf32>
    %781 = vector.fma %780, %61, %750 : vector<8xf32>
    %782 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %783 = memref.load %assume_align[%arg0, %782, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %784 = vector.broadcast %783 : f32 to vector<8xf32>
    %785 = vector.fma %784, %61, %754 : vector<8xf32>
    %786 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %787 = vector.broadcast %786 : f32 to vector<8xf32>
    %788 = vector.fma %787, %62, %757 : vector<8xf32>
    %789 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %790 = memref.load %assume_align[%arg0, %789, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %791 = vector.broadcast %790 : f32 to vector<8xf32>
    %792 = vector.fma %791, %62, %761 : vector<8xf32>
    %793 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %794 = memref.load %assume_align[%arg0, %793, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %795 = vector.broadcast %794 : f32 to vector<8xf32>
    %796 = vector.fma %795, %62, %765 : vector<8xf32>
    %797 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %798 = memref.load %assume_align[%arg0, %797, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %799 = vector.broadcast %798 : f32 to vector<8xf32>
    %800 = vector.fma %799, %62, %769 : vector<8xf32>
    %801 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %802 = memref.load %assume_align[%arg0, %801, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %803 = vector.broadcast %802 : f32 to vector<8xf32>
    %804 = vector.fma %803, %62, %773 : vector<8xf32>
    %805 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %806 = memref.load %assume_align[%arg0, %805, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %807 = vector.broadcast %806 : f32 to vector<8xf32>
    %808 = vector.fma %807, %62, %777 : vector<8xf32>
    %809 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %810 = memref.load %assume_align[%arg0, %809, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %811 = vector.broadcast %810 : f32 to vector<8xf32>
    %812 = vector.fma %811, %62, %781 : vector<8xf32>
    %813 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %814 = memref.load %assume_align[%arg0, %813, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %815 = vector.broadcast %814 : f32 to vector<8xf32>
    %816 = vector.fma %815, %62, %785 : vector<8xf32>
    %817 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %818 = vector.broadcast %817 : f32 to vector<8xf32>
    %819 = vector.fma %818, %63, %788 : vector<8xf32>
    %820 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %821 = memref.load %assume_align[%arg0, %820, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %822 = vector.broadcast %821 : f32 to vector<8xf32>
    %823 = vector.fma %822, %63, %792 : vector<8xf32>
    %824 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %825 = memref.load %assume_align[%arg0, %824, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %826 = vector.broadcast %825 : f32 to vector<8xf32>
    %827 = vector.fma %826, %63, %796 : vector<8xf32>
    %828 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %829 = memref.load %assume_align[%arg0, %828, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %830 = vector.broadcast %829 : f32 to vector<8xf32>
    %831 = vector.fma %830, %63, %800 : vector<8xf32>
    %832 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %833 = memref.load %assume_align[%arg0, %832, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %834 = vector.broadcast %833 : f32 to vector<8xf32>
    %835 = vector.fma %834, %63, %804 : vector<8xf32>
    %836 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %837 = memref.load %assume_align[%arg0, %836, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %838 = vector.broadcast %837 : f32 to vector<8xf32>
    %839 = vector.fma %838, %63, %808 : vector<8xf32>
    %840 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %841 = memref.load %assume_align[%arg0, %840, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %842 = vector.broadcast %841 : f32 to vector<8xf32>
    %843 = vector.fma %842, %63, %812 : vector<8xf32>
    %844 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %845 = memref.load %assume_align[%arg0, %844, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %846 = vector.broadcast %845 : f32 to vector<8xf32>
    %847 = vector.fma %846, %63, %816 : vector<8xf32>
    %848 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %849 = vector.broadcast %848 : f32 to vector<8xf32>
    %850 = vector.fma %849, %64, %819 : vector<8xf32>
    %851 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %852 = memref.load %assume_align[%arg0, %851, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %853 = vector.broadcast %852 : f32 to vector<8xf32>
    %854 = vector.fma %853, %64, %823 : vector<8xf32>
    %855 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %856 = memref.load %assume_align[%arg0, %855, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %857 = vector.broadcast %856 : f32 to vector<8xf32>
    %858 = vector.fma %857, %64, %827 : vector<8xf32>
    %859 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %860 = memref.load %assume_align[%arg0, %859, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %861 = vector.broadcast %860 : f32 to vector<8xf32>
    %862 = vector.fma %861, %64, %831 : vector<8xf32>
    %863 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %864 = memref.load %assume_align[%arg0, %863, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %865 = vector.broadcast %864 : f32 to vector<8xf32>
    %866 = vector.fma %865, %64, %835 : vector<8xf32>
    %867 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %868 = memref.load %assume_align[%arg0, %867, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %869 = vector.broadcast %868 : f32 to vector<8xf32>
    %870 = vector.fma %869, %64, %839 : vector<8xf32>
    %871 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %872 = memref.load %assume_align[%arg0, %871, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %873 = vector.broadcast %872 : f32 to vector<8xf32>
    %874 = vector.fma %873, %64, %843 : vector<8xf32>
    %875 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %876 = memref.load %assume_align[%arg0, %875, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %877 = vector.broadcast %876 : f32 to vector<8xf32>
    %878 = vector.fma %877, %64, %847 : vector<8xf32>
    %879 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %880 = vector.broadcast %879 : f32 to vector<8xf32>
    %881 = vector.fma %880, %65, %850 : vector<8xf32>
    %882 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %883 = memref.load %assume_align[%arg0, %882, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %884 = vector.broadcast %883 : f32 to vector<8xf32>
    %885 = vector.fma %884, %65, %854 : vector<8xf32>
    %886 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %887 = memref.load %assume_align[%arg0, %886, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %888 = vector.broadcast %887 : f32 to vector<8xf32>
    %889 = vector.fma %888, %65, %858 : vector<8xf32>
    %890 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %891 = memref.load %assume_align[%arg0, %890, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %892 = vector.broadcast %891 : f32 to vector<8xf32>
    %893 = vector.fma %892, %65, %862 : vector<8xf32>
    %894 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %895 = memref.load %assume_align[%arg0, %894, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %896 = vector.broadcast %895 : f32 to vector<8xf32>
    %897 = vector.fma %896, %65, %866 : vector<8xf32>
    %898 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %899 = memref.load %assume_align[%arg0, %898, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %900 = vector.broadcast %899 : f32 to vector<8xf32>
    %901 = vector.fma %900, %65, %870 : vector<8xf32>
    %902 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %903 = memref.load %assume_align[%arg0, %902, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %904 = vector.broadcast %903 : f32 to vector<8xf32>
    %905 = vector.fma %904, %65, %874 : vector<8xf32>
    %906 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %907 = memref.load %assume_align[%arg0, %906, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %908 = vector.broadcast %907 : f32 to vector<8xf32>
    %909 = vector.fma %908, %65, %878 : vector<8xf32>
    %910 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %911 = vector.broadcast %910 : f32 to vector<8xf32>
    %912 = vector.fma %911, %66, %881 : vector<8xf32>
    %913 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %914 = memref.load %assume_align[%arg0, %913, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %915 = vector.broadcast %914 : f32 to vector<8xf32>
    %916 = vector.fma %915, %66, %885 : vector<8xf32>
    %917 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %918 = memref.load %assume_align[%arg0, %917, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %919 = vector.broadcast %918 : f32 to vector<8xf32>
    %920 = vector.fma %919, %66, %889 : vector<8xf32>
    %921 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %922 = memref.load %assume_align[%arg0, %921, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %923 = vector.broadcast %922 : f32 to vector<8xf32>
    %924 = vector.fma %923, %66, %893 : vector<8xf32>
    %925 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %926 = memref.load %assume_align[%arg0, %925, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %927 = vector.broadcast %926 : f32 to vector<8xf32>
    %928 = vector.fma %927, %66, %897 : vector<8xf32>
    %929 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %930 = memref.load %assume_align[%arg0, %929, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %931 = vector.broadcast %930 : f32 to vector<8xf32>
    %932 = vector.fma %931, %66, %901 : vector<8xf32>
    %933 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %934 = memref.load %assume_align[%arg0, %933, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %935 = vector.broadcast %934 : f32 to vector<8xf32>
    %936 = vector.fma %935, %66, %905 : vector<8xf32>
    %937 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %938 = memref.load %assume_align[%arg0, %937, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %939 = vector.broadcast %938 : f32 to vector<8xf32>
    %940 = vector.fma %939, %66, %909 : vector<8xf32>
    %941 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %942 = vector.broadcast %941 : f32 to vector<8xf32>
    %943 = vector.fma %942, %67, %912 : vector<8xf32>
    %944 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %945 = memref.load %assume_align[%arg0, %944, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %946 = vector.broadcast %945 : f32 to vector<8xf32>
    %947 = vector.fma %946, %67, %916 : vector<8xf32>
    %948 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %949 = memref.load %assume_align[%arg0, %948, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %950 = vector.broadcast %949 : f32 to vector<8xf32>
    %951 = vector.fma %950, %67, %920 : vector<8xf32>
    %952 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %953 = memref.load %assume_align[%arg0, %952, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %954 = vector.broadcast %953 : f32 to vector<8xf32>
    %955 = vector.fma %954, %67, %924 : vector<8xf32>
    %956 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %957 = memref.load %assume_align[%arg0, %956, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %958 = vector.broadcast %957 : f32 to vector<8xf32>
    %959 = vector.fma %958, %67, %928 : vector<8xf32>
    %960 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %961 = memref.load %assume_align[%arg0, %960, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %962 = vector.broadcast %961 : f32 to vector<8xf32>
    %963 = vector.fma %962, %67, %932 : vector<8xf32>
    %964 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %965 = memref.load %assume_align[%arg0, %964, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %966 = vector.broadcast %965 : f32 to vector<8xf32>
    %967 = vector.fma %966, %67, %936 : vector<8xf32>
    %968 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %969 = memref.load %assume_align[%arg0, %968, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %970 = vector.broadcast %969 : f32 to vector<8xf32>
    %971 = vector.fma %970, %67, %940 : vector<8xf32>
    %972 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %973 = vector.broadcast %972 : f32 to vector<8xf32>
    %974 = vector.fma %973, %68, %943 : vector<8xf32>
    %975 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %976 = memref.load %assume_align[%arg0, %975, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %977 = vector.broadcast %976 : f32 to vector<8xf32>
    %978 = vector.fma %977, %68, %947 : vector<8xf32>
    %979 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %980 = memref.load %assume_align[%arg0, %979, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %981 = vector.broadcast %980 : f32 to vector<8xf32>
    %982 = vector.fma %981, %68, %951 : vector<8xf32>
    %983 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %984 = memref.load %assume_align[%arg0, %983, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %985 = vector.broadcast %984 : f32 to vector<8xf32>
    %986 = vector.fma %985, %68, %955 : vector<8xf32>
    %987 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %988 = memref.load %assume_align[%arg0, %987, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %989 = vector.broadcast %988 : f32 to vector<8xf32>
    %990 = vector.fma %989, %68, %959 : vector<8xf32>
    %991 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %992 = memref.load %assume_align[%arg0, %991, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %993 = vector.broadcast %992 : f32 to vector<8xf32>
    %994 = vector.fma %993, %68, %963 : vector<8xf32>
    %995 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %996 = memref.load %assume_align[%arg0, %995, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %997 = vector.broadcast %996 : f32 to vector<8xf32>
    %998 = vector.fma %997, %68, %967 : vector<8xf32>
    %999 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1000 = memref.load %assume_align[%arg0, %999, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1001 = vector.broadcast %1000 : f32 to vector<8xf32>
    %1002 = vector.fma %1001, %68, %971 : vector<8xf32>
    %1003 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1004 = vector.broadcast %1003 : f32 to vector<8xf32>
    %1005 = vector.fma %1004, %69, %974 : vector<8xf32>
    %1006 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1007 = memref.load %assume_align[%arg0, %1006, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1008 = vector.broadcast %1007 : f32 to vector<8xf32>
    %1009 = vector.fma %1008, %69, %978 : vector<8xf32>
    %1010 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1011 = memref.load %assume_align[%arg0, %1010, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1012 = vector.broadcast %1011 : f32 to vector<8xf32>
    %1013 = vector.fma %1012, %69, %982 : vector<8xf32>
    %1014 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1015 = memref.load %assume_align[%arg0, %1014, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1016 = vector.broadcast %1015 : f32 to vector<8xf32>
    %1017 = vector.fma %1016, %69, %986 : vector<8xf32>
    %1018 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1019 = memref.load %assume_align[%arg0, %1018, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1020 = vector.broadcast %1019 : f32 to vector<8xf32>
    %1021 = vector.fma %1020, %69, %990 : vector<8xf32>
    %1022 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1023 = memref.load %assume_align[%arg0, %1022, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1024 = vector.broadcast %1023 : f32 to vector<8xf32>
    %1025 = vector.fma %1024, %69, %994 : vector<8xf32>
    %1026 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1027 = memref.load %assume_align[%arg0, %1026, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1028 = vector.broadcast %1027 : f32 to vector<8xf32>
    %1029 = vector.fma %1028, %69, %998 : vector<8xf32>
    %1030 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1031 = memref.load %assume_align[%arg0, %1030, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1032 = vector.broadcast %1031 : f32 to vector<8xf32>
    %1033 = vector.fma %1032, %69, %1002 : vector<8xf32>
    %1034 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1035 = vector.broadcast %1034 : f32 to vector<8xf32>
    %1036 = vector.fma %1035, %70, %1005 : vector<8xf32>
    %1037 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1038 = memref.load %assume_align[%arg0, %1037, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1039 = vector.broadcast %1038 : f32 to vector<8xf32>
    %1040 = vector.fma %1039, %70, %1009 : vector<8xf32>
    %1041 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1042 = memref.load %assume_align[%arg0, %1041, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1043 = vector.broadcast %1042 : f32 to vector<8xf32>
    %1044 = vector.fma %1043, %70, %1013 : vector<8xf32>
    %1045 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1046 = memref.load %assume_align[%arg0, %1045, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1047 = vector.broadcast %1046 : f32 to vector<8xf32>
    %1048 = vector.fma %1047, %70, %1017 : vector<8xf32>
    %1049 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1050 = memref.load %assume_align[%arg0, %1049, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1051 = vector.broadcast %1050 : f32 to vector<8xf32>
    %1052 = vector.fma %1051, %70, %1021 : vector<8xf32>
    %1053 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1054 = memref.load %assume_align[%arg0, %1053, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1055 = vector.broadcast %1054 : f32 to vector<8xf32>
    %1056 = vector.fma %1055, %70, %1025 : vector<8xf32>
    %1057 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1058 = memref.load %assume_align[%arg0, %1057, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1059 = vector.broadcast %1058 : f32 to vector<8xf32>
    %1060 = vector.fma %1059, %70, %1029 : vector<8xf32>
    %1061 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1062 = memref.load %assume_align[%arg0, %1061, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1063 = vector.broadcast %1062 : f32 to vector<8xf32>
    %1064 = vector.fma %1063, %70, %1033 : vector<8xf32>
    %1065 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1066 = vector.broadcast %1065 : f32 to vector<8xf32>
    %1067 = vector.fma %1066, %71, %1036 : vector<8xf32>
    %1068 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1069 = memref.load %assume_align[%arg0, %1068, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1070 = vector.broadcast %1069 : f32 to vector<8xf32>
    %1071 = vector.fma %1070, %71, %1040 : vector<8xf32>
    %1072 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1073 = memref.load %assume_align[%arg0, %1072, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1074 = vector.broadcast %1073 : f32 to vector<8xf32>
    %1075 = vector.fma %1074, %71, %1044 : vector<8xf32>
    %1076 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1077 = memref.load %assume_align[%arg0, %1076, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1078 = vector.broadcast %1077 : f32 to vector<8xf32>
    %1079 = vector.fma %1078, %71, %1048 : vector<8xf32>
    %1080 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1081 = memref.load %assume_align[%arg0, %1080, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1082 = vector.broadcast %1081 : f32 to vector<8xf32>
    %1083 = vector.fma %1082, %71, %1052 : vector<8xf32>
    %1084 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1085 = memref.load %assume_align[%arg0, %1084, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1086 = vector.broadcast %1085 : f32 to vector<8xf32>
    %1087 = vector.fma %1086, %71, %1056 : vector<8xf32>
    %1088 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1089 = memref.load %assume_align[%arg0, %1088, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1090 = vector.broadcast %1089 : f32 to vector<8xf32>
    %1091 = vector.fma %1090, %71, %1060 : vector<8xf32>
    %1092 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1093 = memref.load %assume_align[%arg0, %1092, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1094 = vector.broadcast %1093 : f32 to vector<8xf32>
    %1095 = vector.fma %1094, %71, %1064 : vector<8xf32>
    %1096 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1097 = vector.broadcast %1096 : f32 to vector<8xf32>
    %1098 = vector.fma %1097, %72, %1067 : vector<8xf32>
    %1099 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1100 = memref.load %assume_align[%arg0, %1099, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1101 = vector.broadcast %1100 : f32 to vector<8xf32>
    %1102 = vector.fma %1101, %72, %1071 : vector<8xf32>
    %1103 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1104 = memref.load %assume_align[%arg0, %1103, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1105 = vector.broadcast %1104 : f32 to vector<8xf32>
    %1106 = vector.fma %1105, %72, %1075 : vector<8xf32>
    %1107 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1108 = memref.load %assume_align[%arg0, %1107, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1109 = vector.broadcast %1108 : f32 to vector<8xf32>
    %1110 = vector.fma %1109, %72, %1079 : vector<8xf32>
    %1111 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1112 = memref.load %assume_align[%arg0, %1111, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1113 = vector.broadcast %1112 : f32 to vector<8xf32>
    %1114 = vector.fma %1113, %72, %1083 : vector<8xf32>
    %1115 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1116 = memref.load %assume_align[%arg0, %1115, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1117 = vector.broadcast %1116 : f32 to vector<8xf32>
    %1118 = vector.fma %1117, %72, %1087 : vector<8xf32>
    %1119 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1120 = memref.load %assume_align[%arg0, %1119, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1121 = vector.broadcast %1120 : f32 to vector<8xf32>
    %1122 = vector.fma %1121, %72, %1091 : vector<8xf32>
    %1123 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1124 = memref.load %assume_align[%arg0, %1123, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1125 = vector.broadcast %1124 : f32 to vector<8xf32>
    %1126 = vector.fma %1125, %72, %1095 : vector<8xf32>
    %1127 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1128 = vector.broadcast %1127 : f32 to vector<8xf32>
    %1129 = vector.fma %1128, %73, %1098 : vector<8xf32>
    %1130 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1131 = memref.load %assume_align[%arg0, %1130, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1132 = vector.broadcast %1131 : f32 to vector<8xf32>
    %1133 = vector.fma %1132, %73, %1102 : vector<8xf32>
    %1134 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1135 = memref.load %assume_align[%arg0, %1134, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1136 = vector.broadcast %1135 : f32 to vector<8xf32>
    %1137 = vector.fma %1136, %73, %1106 : vector<8xf32>
    %1138 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1139 = memref.load %assume_align[%arg0, %1138, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1140 = vector.broadcast %1139 : f32 to vector<8xf32>
    %1141 = vector.fma %1140, %73, %1110 : vector<8xf32>
    %1142 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1143 = memref.load %assume_align[%arg0, %1142, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1144 = vector.broadcast %1143 : f32 to vector<8xf32>
    %1145 = vector.fma %1144, %73, %1114 : vector<8xf32>
    %1146 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1147 = memref.load %assume_align[%arg0, %1146, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1148 = vector.broadcast %1147 : f32 to vector<8xf32>
    %1149 = vector.fma %1148, %73, %1118 : vector<8xf32>
    %1150 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1151 = memref.load %assume_align[%arg0, %1150, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1152 = vector.broadcast %1151 : f32 to vector<8xf32>
    %1153 = vector.fma %1152, %73, %1122 : vector<8xf32>
    %1154 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1155 = memref.load %assume_align[%arg0, %1154, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1156 = vector.broadcast %1155 : f32 to vector<8xf32>
    %1157 = vector.fma %1156, %73, %1126 : vector<8xf32>
    %1158 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1159 = vector.broadcast %1158 : f32 to vector<8xf32>
    %1160 = vector.fma %1159, %74, %1129 : vector<8xf32>
    %1161 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1162 = memref.load %assume_align[%arg0, %1161, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1163 = vector.broadcast %1162 : f32 to vector<8xf32>
    %1164 = vector.fma %1163, %74, %1133 : vector<8xf32>
    %1165 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1166 = memref.load %assume_align[%arg0, %1165, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1167 = vector.broadcast %1166 : f32 to vector<8xf32>
    %1168 = vector.fma %1167, %74, %1137 : vector<8xf32>
    %1169 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1170 = memref.load %assume_align[%arg0, %1169, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1171 = vector.broadcast %1170 : f32 to vector<8xf32>
    %1172 = vector.fma %1171, %74, %1141 : vector<8xf32>
    %1173 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1174 = memref.load %assume_align[%arg0, %1173, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1175 = vector.broadcast %1174 : f32 to vector<8xf32>
    %1176 = vector.fma %1175, %74, %1145 : vector<8xf32>
    %1177 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1178 = memref.load %assume_align[%arg0, %1177, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1179 = vector.broadcast %1178 : f32 to vector<8xf32>
    %1180 = vector.fma %1179, %74, %1149 : vector<8xf32>
    %1181 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1182 = memref.load %assume_align[%arg0, %1181, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1183 = vector.broadcast %1182 : f32 to vector<8xf32>
    %1184 = vector.fma %1183, %74, %1153 : vector<8xf32>
    %1185 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1186 = memref.load %assume_align[%arg0, %1185, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1187 = vector.broadcast %1186 : f32 to vector<8xf32>
    %1188 = vector.fma %1187, %74, %1157 : vector<8xf32>
    %1189 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1190 = vector.broadcast %1189 : f32 to vector<8xf32>
    %1191 = vector.fma %1190, %75, %1160 : vector<8xf32>
    %1192 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1193 = memref.load %assume_align[%arg0, %1192, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1194 = vector.broadcast %1193 : f32 to vector<8xf32>
    %1195 = vector.fma %1194, %75, %1164 : vector<8xf32>
    %1196 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1197 = memref.load %assume_align[%arg0, %1196, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1198 = vector.broadcast %1197 : f32 to vector<8xf32>
    %1199 = vector.fma %1198, %75, %1168 : vector<8xf32>
    %1200 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1201 = memref.load %assume_align[%arg0, %1200, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1202 = vector.broadcast %1201 : f32 to vector<8xf32>
    %1203 = vector.fma %1202, %75, %1172 : vector<8xf32>
    %1204 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1205 = memref.load %assume_align[%arg0, %1204, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1206 = vector.broadcast %1205 : f32 to vector<8xf32>
    %1207 = vector.fma %1206, %75, %1176 : vector<8xf32>
    %1208 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1209 = memref.load %assume_align[%arg0, %1208, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1210 = vector.broadcast %1209 : f32 to vector<8xf32>
    %1211 = vector.fma %1210, %75, %1180 : vector<8xf32>
    %1212 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1213 = memref.load %assume_align[%arg0, %1212, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1214 = vector.broadcast %1213 : f32 to vector<8xf32>
    %1215 = vector.fma %1214, %75, %1184 : vector<8xf32>
    %1216 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1217 = memref.load %assume_align[%arg0, %1216, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1218 = vector.broadcast %1217 : f32 to vector<8xf32>
    %1219 = vector.fma %1218, %75, %1188 : vector<8xf32>
    %1220 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1221 = vector.broadcast %1220 : f32 to vector<8xf32>
    %1222 = vector.fma %1221, %76, %1191 : vector<8xf32>
    %1223 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1224 = memref.load %assume_align[%arg0, %1223, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1225 = vector.broadcast %1224 : f32 to vector<8xf32>
    %1226 = vector.fma %1225, %76, %1195 : vector<8xf32>
    %1227 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1228 = memref.load %assume_align[%arg0, %1227, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1229 = vector.broadcast %1228 : f32 to vector<8xf32>
    %1230 = vector.fma %1229, %76, %1199 : vector<8xf32>
    %1231 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1232 = memref.load %assume_align[%arg0, %1231, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1233 = vector.broadcast %1232 : f32 to vector<8xf32>
    %1234 = vector.fma %1233, %76, %1203 : vector<8xf32>
    %1235 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1236 = memref.load %assume_align[%arg0, %1235, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1237 = vector.broadcast %1236 : f32 to vector<8xf32>
    %1238 = vector.fma %1237, %76, %1207 : vector<8xf32>
    %1239 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1240 = memref.load %assume_align[%arg0, %1239, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1241 = vector.broadcast %1240 : f32 to vector<8xf32>
    %1242 = vector.fma %1241, %76, %1211 : vector<8xf32>
    %1243 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1244 = memref.load %assume_align[%arg0, %1243, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1245 = vector.broadcast %1244 : f32 to vector<8xf32>
    %1246 = vector.fma %1245, %76, %1215 : vector<8xf32>
    %1247 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1248 = memref.load %assume_align[%arg0, %1247, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1249 = vector.broadcast %1248 : f32 to vector<8xf32>
    %1250 = vector.fma %1249, %76, %1219 : vector<8xf32>
    %1251 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1252 = vector.broadcast %1251 : f32 to vector<8xf32>
    %1253 = vector.fma %1252, %77, %1222 : vector<8xf32>
    %1254 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1255 = memref.load %assume_align[%arg0, %1254, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1256 = vector.broadcast %1255 : f32 to vector<8xf32>
    %1257 = vector.fma %1256, %77, %1226 : vector<8xf32>
    %1258 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1259 = memref.load %assume_align[%arg0, %1258, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1260 = vector.broadcast %1259 : f32 to vector<8xf32>
    %1261 = vector.fma %1260, %77, %1230 : vector<8xf32>
    %1262 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1263 = memref.load %assume_align[%arg0, %1262, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1264 = vector.broadcast %1263 : f32 to vector<8xf32>
    %1265 = vector.fma %1264, %77, %1234 : vector<8xf32>
    %1266 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1267 = memref.load %assume_align[%arg0, %1266, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1268 = vector.broadcast %1267 : f32 to vector<8xf32>
    %1269 = vector.fma %1268, %77, %1238 : vector<8xf32>
    %1270 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1271 = memref.load %assume_align[%arg0, %1270, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1272 = vector.broadcast %1271 : f32 to vector<8xf32>
    %1273 = vector.fma %1272, %77, %1242 : vector<8xf32>
    %1274 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1275 = memref.load %assume_align[%arg0, %1274, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1276 = vector.broadcast %1275 : f32 to vector<8xf32>
    %1277 = vector.fma %1276, %77, %1246 : vector<8xf32>
    %1278 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1279 = memref.load %assume_align[%arg0, %1278, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1280 = vector.broadcast %1279 : f32 to vector<8xf32>
    %1281 = vector.fma %1280, %77, %1250 : vector<8xf32>
    %1282 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1283 = vector.broadcast %1282 : f32 to vector<8xf32>
    %1284 = vector.fma %1283, %78, %1253 : vector<8xf32>
    %1285 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1286 = memref.load %assume_align[%arg0, %1285, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1287 = vector.broadcast %1286 : f32 to vector<8xf32>
    %1288 = vector.fma %1287, %78, %1257 : vector<8xf32>
    %1289 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1290 = memref.load %assume_align[%arg0, %1289, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1291 = vector.broadcast %1290 : f32 to vector<8xf32>
    %1292 = vector.fma %1291, %78, %1261 : vector<8xf32>
    %1293 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1294 = memref.load %assume_align[%arg0, %1293, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1295 = vector.broadcast %1294 : f32 to vector<8xf32>
    %1296 = vector.fma %1295, %78, %1265 : vector<8xf32>
    %1297 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1298 = memref.load %assume_align[%arg0, %1297, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1299 = vector.broadcast %1298 : f32 to vector<8xf32>
    %1300 = vector.fma %1299, %78, %1269 : vector<8xf32>
    %1301 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1302 = memref.load %assume_align[%arg0, %1301, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1303 = vector.broadcast %1302 : f32 to vector<8xf32>
    %1304 = vector.fma %1303, %78, %1273 : vector<8xf32>
    %1305 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1306 = memref.load %assume_align[%arg0, %1305, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1307 = vector.broadcast %1306 : f32 to vector<8xf32>
    %1308 = vector.fma %1307, %78, %1277 : vector<8xf32>
    %1309 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1310 = memref.load %assume_align[%arg0, %1309, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1311 = vector.broadcast %1310 : f32 to vector<8xf32>
    %1312 = vector.fma %1311, %78, %1281 : vector<8xf32>
    %1313 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1314 = vector.broadcast %1313 : f32 to vector<8xf32>
    %1315 = vector.fma %1314, %79, %1284 : vector<8xf32>
    %1316 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1317 = memref.load %assume_align[%arg0, %1316, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1318 = vector.broadcast %1317 : f32 to vector<8xf32>
    %1319 = vector.fma %1318, %79, %1288 : vector<8xf32>
    %1320 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1321 = memref.load %assume_align[%arg0, %1320, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1322 = vector.broadcast %1321 : f32 to vector<8xf32>
    %1323 = vector.fma %1322, %79, %1292 : vector<8xf32>
    %1324 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1325 = memref.load %assume_align[%arg0, %1324, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1326 = vector.broadcast %1325 : f32 to vector<8xf32>
    %1327 = vector.fma %1326, %79, %1296 : vector<8xf32>
    %1328 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1329 = memref.load %assume_align[%arg0, %1328, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1330 = vector.broadcast %1329 : f32 to vector<8xf32>
    %1331 = vector.fma %1330, %79, %1300 : vector<8xf32>
    %1332 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1333 = memref.load %assume_align[%arg0, %1332, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1334 = vector.broadcast %1333 : f32 to vector<8xf32>
    %1335 = vector.fma %1334, %79, %1304 : vector<8xf32>
    %1336 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1337 = memref.load %assume_align[%arg0, %1336, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1338 = vector.broadcast %1337 : f32 to vector<8xf32>
    %1339 = vector.fma %1338, %79, %1308 : vector<8xf32>
    %1340 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1341 = memref.load %assume_align[%arg0, %1340, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1342 = vector.broadcast %1341 : f32 to vector<8xf32>
    %1343 = vector.fma %1342, %79, %1312 : vector<8xf32>
    %1344 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1345 = vector.broadcast %1344 : f32 to vector<8xf32>
    %1346 = vector.fma %1345, %80, %1315 : vector<8xf32>
    %1347 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1348 = memref.load %assume_align[%arg0, %1347, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1349 = vector.broadcast %1348 : f32 to vector<8xf32>
    %1350 = vector.fma %1349, %80, %1319 : vector<8xf32>
    %1351 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1352 = memref.load %assume_align[%arg0, %1351, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1353 = vector.broadcast %1352 : f32 to vector<8xf32>
    %1354 = vector.fma %1353, %80, %1323 : vector<8xf32>
    %1355 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1356 = memref.load %assume_align[%arg0, %1355, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1357 = vector.broadcast %1356 : f32 to vector<8xf32>
    %1358 = vector.fma %1357, %80, %1327 : vector<8xf32>
    %1359 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1360 = memref.load %assume_align[%arg0, %1359, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1361 = vector.broadcast %1360 : f32 to vector<8xf32>
    %1362 = vector.fma %1361, %80, %1331 : vector<8xf32>
    %1363 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1364 = memref.load %assume_align[%arg0, %1363, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1365 = vector.broadcast %1364 : f32 to vector<8xf32>
    %1366 = vector.fma %1365, %80, %1335 : vector<8xf32>
    %1367 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1368 = memref.load %assume_align[%arg0, %1367, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1369 = vector.broadcast %1368 : f32 to vector<8xf32>
    %1370 = vector.fma %1369, %80, %1339 : vector<8xf32>
    %1371 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1372 = memref.load %assume_align[%arg0, %1371, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1373 = vector.broadcast %1372 : f32 to vector<8xf32>
    %1374 = vector.fma %1373, %80, %1343 : vector<8xf32>
    %1375 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1376 = vector.broadcast %1375 : f32 to vector<8xf32>
    %1377 = vector.fma %1376, %81, %1346 : vector<8xf32>
    %1378 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1379 = memref.load %assume_align[%arg0, %1378, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1380 = vector.broadcast %1379 : f32 to vector<8xf32>
    %1381 = vector.fma %1380, %81, %1350 : vector<8xf32>
    %1382 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1383 = memref.load %assume_align[%arg0, %1382, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1384 = vector.broadcast %1383 : f32 to vector<8xf32>
    %1385 = vector.fma %1384, %81, %1354 : vector<8xf32>
    %1386 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1387 = memref.load %assume_align[%arg0, %1386, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1388 = vector.broadcast %1387 : f32 to vector<8xf32>
    %1389 = vector.fma %1388, %81, %1358 : vector<8xf32>
    %1390 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1391 = memref.load %assume_align[%arg0, %1390, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1392 = vector.broadcast %1391 : f32 to vector<8xf32>
    %1393 = vector.fma %1392, %81, %1362 : vector<8xf32>
    %1394 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1395 = memref.load %assume_align[%arg0, %1394, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1396 = vector.broadcast %1395 : f32 to vector<8xf32>
    %1397 = vector.fma %1396, %81, %1366 : vector<8xf32>
    %1398 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1399 = memref.load %assume_align[%arg0, %1398, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1400 = vector.broadcast %1399 : f32 to vector<8xf32>
    %1401 = vector.fma %1400, %81, %1370 : vector<8xf32>
    %1402 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1403 = memref.load %assume_align[%arg0, %1402, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1404 = vector.broadcast %1403 : f32 to vector<8xf32>
    %1405 = vector.fma %1404, %81, %1374 : vector<8xf32>
    %1406 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1407 = vector.broadcast %1406 : f32 to vector<8xf32>
    %1408 = vector.fma %1407, %82, %1377 : vector<8xf32>
    %1409 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1410 = memref.load %assume_align[%arg0, %1409, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1411 = vector.broadcast %1410 : f32 to vector<8xf32>
    %1412 = vector.fma %1411, %82, %1381 : vector<8xf32>
    %1413 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1414 = memref.load %assume_align[%arg0, %1413, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1415 = vector.broadcast %1414 : f32 to vector<8xf32>
    %1416 = vector.fma %1415, %82, %1385 : vector<8xf32>
    %1417 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1418 = memref.load %assume_align[%arg0, %1417, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1419 = vector.broadcast %1418 : f32 to vector<8xf32>
    %1420 = vector.fma %1419, %82, %1389 : vector<8xf32>
    %1421 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1422 = memref.load %assume_align[%arg0, %1421, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1423 = vector.broadcast %1422 : f32 to vector<8xf32>
    %1424 = vector.fma %1423, %82, %1393 : vector<8xf32>
    %1425 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1426 = memref.load %assume_align[%arg0, %1425, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1427 = vector.broadcast %1426 : f32 to vector<8xf32>
    %1428 = vector.fma %1427, %82, %1397 : vector<8xf32>
    %1429 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1430 = memref.load %assume_align[%arg0, %1429, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1431 = vector.broadcast %1430 : f32 to vector<8xf32>
    %1432 = vector.fma %1431, %82, %1401 : vector<8xf32>
    %1433 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1434 = memref.load %assume_align[%arg0, %1433, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1435 = vector.broadcast %1434 : f32 to vector<8xf32>
    %1436 = vector.fma %1435, %82, %1405 : vector<8xf32>
    %1437 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1438 = vector.broadcast %1437 : f32 to vector<8xf32>
    %1439 = vector.fma %1438, %83, %1408 : vector<8xf32>
    %1440 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1441 = memref.load %assume_align[%arg0, %1440, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1442 = vector.broadcast %1441 : f32 to vector<8xf32>
    %1443 = vector.fma %1442, %83, %1412 : vector<8xf32>
    %1444 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1445 = memref.load %assume_align[%arg0, %1444, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1446 = vector.broadcast %1445 : f32 to vector<8xf32>
    %1447 = vector.fma %1446, %83, %1416 : vector<8xf32>
    %1448 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1449 = memref.load %assume_align[%arg0, %1448, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1450 = vector.broadcast %1449 : f32 to vector<8xf32>
    %1451 = vector.fma %1450, %83, %1420 : vector<8xf32>
    %1452 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1453 = memref.load %assume_align[%arg0, %1452, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1454 = vector.broadcast %1453 : f32 to vector<8xf32>
    %1455 = vector.fma %1454, %83, %1424 : vector<8xf32>
    %1456 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1457 = memref.load %assume_align[%arg0, %1456, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1458 = vector.broadcast %1457 : f32 to vector<8xf32>
    %1459 = vector.fma %1458, %83, %1428 : vector<8xf32>
    %1460 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1461 = memref.load %assume_align[%arg0, %1460, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1462 = vector.broadcast %1461 : f32 to vector<8xf32>
    %1463 = vector.fma %1462, %83, %1432 : vector<8xf32>
    %1464 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1465 = memref.load %assume_align[%arg0, %1464, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1466 = vector.broadcast %1465 : f32 to vector<8xf32>
    %1467 = vector.fma %1466, %83, %1436 : vector<8xf32>
    %1468 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1469 = vector.broadcast %1468 : f32 to vector<8xf32>
    %1470 = vector.fma %1469, %84, %1439 : vector<8xf32>
    %1471 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1472 = memref.load %assume_align[%arg0, %1471, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1473 = vector.broadcast %1472 : f32 to vector<8xf32>
    %1474 = vector.fma %1473, %84, %1443 : vector<8xf32>
    %1475 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1476 = memref.load %assume_align[%arg0, %1475, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1477 = vector.broadcast %1476 : f32 to vector<8xf32>
    %1478 = vector.fma %1477, %84, %1447 : vector<8xf32>
    %1479 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1480 = memref.load %assume_align[%arg0, %1479, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1481 = vector.broadcast %1480 : f32 to vector<8xf32>
    %1482 = vector.fma %1481, %84, %1451 : vector<8xf32>
    %1483 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1484 = memref.load %assume_align[%arg0, %1483, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1485 = vector.broadcast %1484 : f32 to vector<8xf32>
    %1486 = vector.fma %1485, %84, %1455 : vector<8xf32>
    %1487 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1488 = memref.load %assume_align[%arg0, %1487, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1489 = vector.broadcast %1488 : f32 to vector<8xf32>
    %1490 = vector.fma %1489, %84, %1459 : vector<8xf32>
    %1491 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1492 = memref.load %assume_align[%arg0, %1491, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1493 = vector.broadcast %1492 : f32 to vector<8xf32>
    %1494 = vector.fma %1493, %84, %1463 : vector<8xf32>
    %1495 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1496 = memref.load %assume_align[%arg0, %1495, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1497 = vector.broadcast %1496 : f32 to vector<8xf32>
    %1498 = vector.fma %1497, %84, %1467 : vector<8xf32>
    %1499 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1500 = vector.broadcast %1499 : f32 to vector<8xf32>
    %1501 = vector.fma %1500, %85, %1470 : vector<8xf32>
    %1502 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1503 = memref.load %assume_align[%arg0, %1502, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1504 = vector.broadcast %1503 : f32 to vector<8xf32>
    %1505 = vector.fma %1504, %85, %1474 : vector<8xf32>
    %1506 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1507 = memref.load %assume_align[%arg0, %1506, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1508 = vector.broadcast %1507 : f32 to vector<8xf32>
    %1509 = vector.fma %1508, %85, %1478 : vector<8xf32>
    %1510 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1511 = memref.load %assume_align[%arg0, %1510, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1512 = vector.broadcast %1511 : f32 to vector<8xf32>
    %1513 = vector.fma %1512, %85, %1482 : vector<8xf32>
    %1514 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1515 = memref.load %assume_align[%arg0, %1514, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1516 = vector.broadcast %1515 : f32 to vector<8xf32>
    %1517 = vector.fma %1516, %85, %1486 : vector<8xf32>
    %1518 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1519 = memref.load %assume_align[%arg0, %1518, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1520 = vector.broadcast %1519 : f32 to vector<8xf32>
    %1521 = vector.fma %1520, %85, %1490 : vector<8xf32>
    %1522 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1523 = memref.load %assume_align[%arg0, %1522, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1524 = vector.broadcast %1523 : f32 to vector<8xf32>
    %1525 = vector.fma %1524, %85, %1494 : vector<8xf32>
    %1526 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1527 = memref.load %assume_align[%arg0, %1526, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1528 = vector.broadcast %1527 : f32 to vector<8xf32>
    %1529 = vector.fma %1528, %85, %1498 : vector<8xf32>
    %1530 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1531 = vector.broadcast %1530 : f32 to vector<8xf32>
    %1532 = vector.fma %1531, %86, %1501 : vector<8xf32>
    %1533 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1534 = memref.load %assume_align[%arg0, %1533, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1535 = vector.broadcast %1534 : f32 to vector<8xf32>
    %1536 = vector.fma %1535, %86, %1505 : vector<8xf32>
    %1537 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1538 = memref.load %assume_align[%arg0, %1537, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1539 = vector.broadcast %1538 : f32 to vector<8xf32>
    %1540 = vector.fma %1539, %86, %1509 : vector<8xf32>
    %1541 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1542 = memref.load %assume_align[%arg0, %1541, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1543 = vector.broadcast %1542 : f32 to vector<8xf32>
    %1544 = vector.fma %1543, %86, %1513 : vector<8xf32>
    %1545 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1546 = memref.load %assume_align[%arg0, %1545, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1547 = vector.broadcast %1546 : f32 to vector<8xf32>
    %1548 = vector.fma %1547, %86, %1517 : vector<8xf32>
    %1549 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1550 = memref.load %assume_align[%arg0, %1549, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1551 = vector.broadcast %1550 : f32 to vector<8xf32>
    %1552 = vector.fma %1551, %86, %1521 : vector<8xf32>
    %1553 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1554 = memref.load %assume_align[%arg0, %1553, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1555 = vector.broadcast %1554 : f32 to vector<8xf32>
    %1556 = vector.fma %1555, %86, %1525 : vector<8xf32>
    %1557 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1558 = memref.load %assume_align[%arg0, %1557, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1559 = vector.broadcast %1558 : f32 to vector<8xf32>
    %1560 = vector.fma %1559, %86, %1529 : vector<8xf32>
    %1561 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1562 = vector.broadcast %1561 : f32 to vector<8xf32>
    %1563 = vector.fma %1562, %87, %1532 : vector<8xf32>
    %1564 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1565 = memref.load %assume_align[%arg0, %1564, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1566 = vector.broadcast %1565 : f32 to vector<8xf32>
    %1567 = vector.fma %1566, %87, %1536 : vector<8xf32>
    %1568 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1569 = memref.load %assume_align[%arg0, %1568, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1570 = vector.broadcast %1569 : f32 to vector<8xf32>
    %1571 = vector.fma %1570, %87, %1540 : vector<8xf32>
    %1572 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1573 = memref.load %assume_align[%arg0, %1572, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1574 = vector.broadcast %1573 : f32 to vector<8xf32>
    %1575 = vector.fma %1574, %87, %1544 : vector<8xf32>
    %1576 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1577 = memref.load %assume_align[%arg0, %1576, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1578 = vector.broadcast %1577 : f32 to vector<8xf32>
    %1579 = vector.fma %1578, %87, %1548 : vector<8xf32>
    %1580 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1581 = memref.load %assume_align[%arg0, %1580, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1582 = vector.broadcast %1581 : f32 to vector<8xf32>
    %1583 = vector.fma %1582, %87, %1552 : vector<8xf32>
    %1584 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1585 = memref.load %assume_align[%arg0, %1584, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1586 = vector.broadcast %1585 : f32 to vector<8xf32>
    %1587 = vector.fma %1586, %87, %1556 : vector<8xf32>
    %1588 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1589 = memref.load %assume_align[%arg0, %1588, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1590 = vector.broadcast %1589 : f32 to vector<8xf32>
    %1591 = vector.fma %1590, %87, %1560 : vector<8xf32>
    %1592 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1593 = vector.broadcast %1592 : f32 to vector<8xf32>
    %1594 = vector.fma %1593, %88, %1563 : vector<8xf32>
    %1595 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1596 = memref.load %assume_align[%arg0, %1595, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1597 = vector.broadcast %1596 : f32 to vector<8xf32>
    %1598 = vector.fma %1597, %88, %1567 : vector<8xf32>
    %1599 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1600 = memref.load %assume_align[%arg0, %1599, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1601 = vector.broadcast %1600 : f32 to vector<8xf32>
    %1602 = vector.fma %1601, %88, %1571 : vector<8xf32>
    %1603 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1604 = memref.load %assume_align[%arg0, %1603, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1605 = vector.broadcast %1604 : f32 to vector<8xf32>
    %1606 = vector.fma %1605, %88, %1575 : vector<8xf32>
    %1607 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1608 = memref.load %assume_align[%arg0, %1607, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1609 = vector.broadcast %1608 : f32 to vector<8xf32>
    %1610 = vector.fma %1609, %88, %1579 : vector<8xf32>
    %1611 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1612 = memref.load %assume_align[%arg0, %1611, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1613 = vector.broadcast %1612 : f32 to vector<8xf32>
    %1614 = vector.fma %1613, %88, %1583 : vector<8xf32>
    %1615 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1616 = memref.load %assume_align[%arg0, %1615, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1617 = vector.broadcast %1616 : f32 to vector<8xf32>
    %1618 = vector.fma %1617, %88, %1587 : vector<8xf32>
    %1619 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1620 = memref.load %assume_align[%arg0, %1619, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1621 = vector.broadcast %1620 : f32 to vector<8xf32>
    %1622 = vector.fma %1621, %88, %1591 : vector<8xf32>
    %1623 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1624 = vector.broadcast %1623 : f32 to vector<8xf32>
    %1625 = vector.fma %1624, %89, %1594 : vector<8xf32>
    %1626 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1627 = memref.load %assume_align[%arg0, %1626, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1628 = vector.broadcast %1627 : f32 to vector<8xf32>
    %1629 = vector.fma %1628, %89, %1598 : vector<8xf32>
    %1630 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1631 = memref.load %assume_align[%arg0, %1630, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1632 = vector.broadcast %1631 : f32 to vector<8xf32>
    %1633 = vector.fma %1632, %89, %1602 : vector<8xf32>
    %1634 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1635 = memref.load %assume_align[%arg0, %1634, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1636 = vector.broadcast %1635 : f32 to vector<8xf32>
    %1637 = vector.fma %1636, %89, %1606 : vector<8xf32>
    %1638 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1639 = memref.load %assume_align[%arg0, %1638, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1640 = vector.broadcast %1639 : f32 to vector<8xf32>
    %1641 = vector.fma %1640, %89, %1610 : vector<8xf32>
    %1642 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1643 = memref.load %assume_align[%arg0, %1642, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1644 = vector.broadcast %1643 : f32 to vector<8xf32>
    %1645 = vector.fma %1644, %89, %1614 : vector<8xf32>
    %1646 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1647 = memref.load %assume_align[%arg0, %1646, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1648 = vector.broadcast %1647 : f32 to vector<8xf32>
    %1649 = vector.fma %1648, %89, %1618 : vector<8xf32>
    %1650 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1651 = memref.load %assume_align[%arg0, %1650, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1652 = vector.broadcast %1651 : f32 to vector<8xf32>
    %1653 = vector.fma %1652, %89, %1622 : vector<8xf32>
    %1654 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1655 = vector.broadcast %1654 : f32 to vector<8xf32>
    %1656 = vector.fma %1655, %90, %1625 : vector<8xf32>
    %1657 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1658 = memref.load %assume_align[%arg0, %1657, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1659 = vector.broadcast %1658 : f32 to vector<8xf32>
    %1660 = vector.fma %1659, %90, %1629 : vector<8xf32>
    %1661 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1662 = memref.load %assume_align[%arg0, %1661, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1663 = vector.broadcast %1662 : f32 to vector<8xf32>
    %1664 = vector.fma %1663, %90, %1633 : vector<8xf32>
    %1665 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1666 = memref.load %assume_align[%arg0, %1665, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1667 = vector.broadcast %1666 : f32 to vector<8xf32>
    %1668 = vector.fma %1667, %90, %1637 : vector<8xf32>
    %1669 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1670 = memref.load %assume_align[%arg0, %1669, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1671 = vector.broadcast %1670 : f32 to vector<8xf32>
    %1672 = vector.fma %1671, %90, %1641 : vector<8xf32>
    %1673 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1674 = memref.load %assume_align[%arg0, %1673, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1675 = vector.broadcast %1674 : f32 to vector<8xf32>
    %1676 = vector.fma %1675, %90, %1645 : vector<8xf32>
    %1677 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1678 = memref.load %assume_align[%arg0, %1677, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1679 = vector.broadcast %1678 : f32 to vector<8xf32>
    %1680 = vector.fma %1679, %90, %1649 : vector<8xf32>
    %1681 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1682 = memref.load %assume_align[%arg0, %1681, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1683 = vector.broadcast %1682 : f32 to vector<8xf32>
    %1684 = vector.fma %1683, %90, %1653 : vector<8xf32>
    %1685 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1686 = vector.broadcast %1685 : f32 to vector<8xf32>
    %1687 = vector.fma %1686, %91, %1656 : vector<8xf32>
    %1688 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1689 = memref.load %assume_align[%arg0, %1688, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1690 = vector.broadcast %1689 : f32 to vector<8xf32>
    %1691 = vector.fma %1690, %91, %1660 : vector<8xf32>
    %1692 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1693 = memref.load %assume_align[%arg0, %1692, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1694 = vector.broadcast %1693 : f32 to vector<8xf32>
    %1695 = vector.fma %1694, %91, %1664 : vector<8xf32>
    %1696 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1697 = memref.load %assume_align[%arg0, %1696, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1698 = vector.broadcast %1697 : f32 to vector<8xf32>
    %1699 = vector.fma %1698, %91, %1668 : vector<8xf32>
    %1700 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1701 = memref.load %assume_align[%arg0, %1700, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1702 = vector.broadcast %1701 : f32 to vector<8xf32>
    %1703 = vector.fma %1702, %91, %1672 : vector<8xf32>
    %1704 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1705 = memref.load %assume_align[%arg0, %1704, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1706 = vector.broadcast %1705 : f32 to vector<8xf32>
    %1707 = vector.fma %1706, %91, %1676 : vector<8xf32>
    %1708 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1709 = memref.load %assume_align[%arg0, %1708, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1710 = vector.broadcast %1709 : f32 to vector<8xf32>
    %1711 = vector.fma %1710, %91, %1680 : vector<8xf32>
    %1712 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1713 = memref.load %assume_align[%arg0, %1712, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1714 = vector.broadcast %1713 : f32 to vector<8xf32>
    %1715 = vector.fma %1714, %91, %1684 : vector<8xf32>
    %1716 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1717 = vector.broadcast %1716 : f32 to vector<8xf32>
    %1718 = vector.fma %1717, %92, %1687 : vector<8xf32>
    %1719 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1720 = memref.load %assume_align[%arg0, %1719, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1721 = vector.broadcast %1720 : f32 to vector<8xf32>
    %1722 = vector.fma %1721, %92, %1691 : vector<8xf32>
    %1723 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1724 = memref.load %assume_align[%arg0, %1723, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1725 = vector.broadcast %1724 : f32 to vector<8xf32>
    %1726 = vector.fma %1725, %92, %1695 : vector<8xf32>
    %1727 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1728 = memref.load %assume_align[%arg0, %1727, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1729 = vector.broadcast %1728 : f32 to vector<8xf32>
    %1730 = vector.fma %1729, %92, %1699 : vector<8xf32>
    %1731 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1732 = memref.load %assume_align[%arg0, %1731, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1733 = vector.broadcast %1732 : f32 to vector<8xf32>
    %1734 = vector.fma %1733, %92, %1703 : vector<8xf32>
    %1735 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1736 = memref.load %assume_align[%arg0, %1735, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1737 = vector.broadcast %1736 : f32 to vector<8xf32>
    %1738 = vector.fma %1737, %92, %1707 : vector<8xf32>
    %1739 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1740 = memref.load %assume_align[%arg0, %1739, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1741 = vector.broadcast %1740 : f32 to vector<8xf32>
    %1742 = vector.fma %1741, %92, %1711 : vector<8xf32>
    %1743 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1744 = memref.load %assume_align[%arg0, %1743, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1745 = vector.broadcast %1744 : f32 to vector<8xf32>
    %1746 = vector.fma %1745, %92, %1715 : vector<8xf32>
    %1747 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1748 = vector.broadcast %1747 : f32 to vector<8xf32>
    %1749 = vector.fma %1748, %93, %1718 : vector<8xf32>
    %1750 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1751 = memref.load %assume_align[%arg0, %1750, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1752 = vector.broadcast %1751 : f32 to vector<8xf32>
    %1753 = vector.fma %1752, %93, %1722 : vector<8xf32>
    %1754 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1755 = memref.load %assume_align[%arg0, %1754, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1756 = vector.broadcast %1755 : f32 to vector<8xf32>
    %1757 = vector.fma %1756, %93, %1726 : vector<8xf32>
    %1758 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1759 = memref.load %assume_align[%arg0, %1758, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1760 = vector.broadcast %1759 : f32 to vector<8xf32>
    %1761 = vector.fma %1760, %93, %1730 : vector<8xf32>
    %1762 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1763 = memref.load %assume_align[%arg0, %1762, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1764 = vector.broadcast %1763 : f32 to vector<8xf32>
    %1765 = vector.fma %1764, %93, %1734 : vector<8xf32>
    %1766 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1767 = memref.load %assume_align[%arg0, %1766, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1768 = vector.broadcast %1767 : f32 to vector<8xf32>
    %1769 = vector.fma %1768, %93, %1738 : vector<8xf32>
    %1770 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1771 = memref.load %assume_align[%arg0, %1770, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1772 = vector.broadcast %1771 : f32 to vector<8xf32>
    %1773 = vector.fma %1772, %93, %1742 : vector<8xf32>
    %1774 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1775 = memref.load %assume_align[%arg0, %1774, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1776 = vector.broadcast %1775 : f32 to vector<8xf32>
    %1777 = vector.fma %1776, %93, %1746 : vector<8xf32>
    %1778 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1779 = vector.broadcast %1778 : f32 to vector<8xf32>
    %1780 = vector.fma %1779, %94, %1749 : vector<8xf32>
    %1781 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1782 = memref.load %assume_align[%arg0, %1781, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1783 = vector.broadcast %1782 : f32 to vector<8xf32>
    %1784 = vector.fma %1783, %94, %1753 : vector<8xf32>
    %1785 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1786 = memref.load %assume_align[%arg0, %1785, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1787 = vector.broadcast %1786 : f32 to vector<8xf32>
    %1788 = vector.fma %1787, %94, %1757 : vector<8xf32>
    %1789 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1790 = memref.load %assume_align[%arg0, %1789, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1791 = vector.broadcast %1790 : f32 to vector<8xf32>
    %1792 = vector.fma %1791, %94, %1761 : vector<8xf32>
    %1793 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1794 = memref.load %assume_align[%arg0, %1793, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1795 = vector.broadcast %1794 : f32 to vector<8xf32>
    %1796 = vector.fma %1795, %94, %1765 : vector<8xf32>
    %1797 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1798 = memref.load %assume_align[%arg0, %1797, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1799 = vector.broadcast %1798 : f32 to vector<8xf32>
    %1800 = vector.fma %1799, %94, %1769 : vector<8xf32>
    %1801 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1802 = memref.load %assume_align[%arg0, %1801, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1803 = vector.broadcast %1802 : f32 to vector<8xf32>
    %1804 = vector.fma %1803, %94, %1773 : vector<8xf32>
    %1805 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1806 = memref.load %assume_align[%arg0, %1805, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1807 = vector.broadcast %1806 : f32 to vector<8xf32>
    %1808 = vector.fma %1807, %94, %1777 : vector<8xf32>
    %1809 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1810 = vector.broadcast %1809 : f32 to vector<8xf32>
    %1811 = vector.fma %1810, %95, %1780 : vector<8xf32>
    %1812 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1813 = memref.load %assume_align[%arg0, %1812, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1814 = vector.broadcast %1813 : f32 to vector<8xf32>
    %1815 = vector.fma %1814, %95, %1784 : vector<8xf32>
    %1816 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1817 = memref.load %assume_align[%arg0, %1816, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1818 = vector.broadcast %1817 : f32 to vector<8xf32>
    %1819 = vector.fma %1818, %95, %1788 : vector<8xf32>
    %1820 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1821 = memref.load %assume_align[%arg0, %1820, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1822 = vector.broadcast %1821 : f32 to vector<8xf32>
    %1823 = vector.fma %1822, %95, %1792 : vector<8xf32>
    %1824 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1825 = memref.load %assume_align[%arg0, %1824, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1826 = vector.broadcast %1825 : f32 to vector<8xf32>
    %1827 = vector.fma %1826, %95, %1796 : vector<8xf32>
    %1828 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1829 = memref.load %assume_align[%arg0, %1828, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1830 = vector.broadcast %1829 : f32 to vector<8xf32>
    %1831 = vector.fma %1830, %95, %1800 : vector<8xf32>
    %1832 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1833 = memref.load %assume_align[%arg0, %1832, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1834 = vector.broadcast %1833 : f32 to vector<8xf32>
    %1835 = vector.fma %1834, %95, %1804 : vector<8xf32>
    %1836 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1837 = memref.load %assume_align[%arg0, %1836, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1838 = vector.broadcast %1837 : f32 to vector<8xf32>
    %1839 = vector.fma %1838, %95, %1808 : vector<8xf32>
    %1840 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1841 = vector.broadcast %1840 : f32 to vector<8xf32>
    %1842 = vector.fma %1841, %96, %1811 : vector<8xf32>
    %1843 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1844 = memref.load %assume_align[%arg0, %1843, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1845 = vector.broadcast %1844 : f32 to vector<8xf32>
    %1846 = vector.fma %1845, %96, %1815 : vector<8xf32>
    %1847 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1848 = memref.load %assume_align[%arg0, %1847, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1849 = vector.broadcast %1848 : f32 to vector<8xf32>
    %1850 = vector.fma %1849, %96, %1819 : vector<8xf32>
    %1851 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1852 = memref.load %assume_align[%arg0, %1851, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1853 = vector.broadcast %1852 : f32 to vector<8xf32>
    %1854 = vector.fma %1853, %96, %1823 : vector<8xf32>
    %1855 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1856 = memref.load %assume_align[%arg0, %1855, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1857 = vector.broadcast %1856 : f32 to vector<8xf32>
    %1858 = vector.fma %1857, %96, %1827 : vector<8xf32>
    %1859 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1860 = memref.load %assume_align[%arg0, %1859, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1861 = vector.broadcast %1860 : f32 to vector<8xf32>
    %1862 = vector.fma %1861, %96, %1831 : vector<8xf32>
    %1863 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1864 = memref.load %assume_align[%arg0, %1863, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1865 = vector.broadcast %1864 : f32 to vector<8xf32>
    %1866 = vector.fma %1865, %96, %1835 : vector<8xf32>
    %1867 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1868 = memref.load %assume_align[%arg0, %1867, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1869 = vector.broadcast %1868 : f32 to vector<8xf32>
    %1870 = vector.fma %1869, %96, %1839 : vector<8xf32>
    %1871 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1872 = vector.broadcast %1871 : f32 to vector<8xf32>
    %1873 = vector.fma %1872, %97, %1842 : vector<8xf32>
    %1874 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1875 = memref.load %assume_align[%arg0, %1874, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1876 = vector.broadcast %1875 : f32 to vector<8xf32>
    %1877 = vector.fma %1876, %97, %1846 : vector<8xf32>
    %1878 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1879 = memref.load %assume_align[%arg0, %1878, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1880 = vector.broadcast %1879 : f32 to vector<8xf32>
    %1881 = vector.fma %1880, %97, %1850 : vector<8xf32>
    %1882 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1883 = memref.load %assume_align[%arg0, %1882, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1884 = vector.broadcast %1883 : f32 to vector<8xf32>
    %1885 = vector.fma %1884, %97, %1854 : vector<8xf32>
    %1886 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1887 = memref.load %assume_align[%arg0, %1886, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1888 = vector.broadcast %1887 : f32 to vector<8xf32>
    %1889 = vector.fma %1888, %97, %1858 : vector<8xf32>
    %1890 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1891 = memref.load %assume_align[%arg0, %1890, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1892 = vector.broadcast %1891 : f32 to vector<8xf32>
    %1893 = vector.fma %1892, %97, %1862 : vector<8xf32>
    %1894 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1895 = memref.load %assume_align[%arg0, %1894, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1896 = vector.broadcast %1895 : f32 to vector<8xf32>
    %1897 = vector.fma %1896, %97, %1866 : vector<8xf32>
    %1898 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1899 = memref.load %assume_align[%arg0, %1898, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1900 = vector.broadcast %1899 : f32 to vector<8xf32>
    %1901 = vector.fma %1900, %97, %1870 : vector<8xf32>
    %1902 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1903 = vector.broadcast %1902 : f32 to vector<8xf32>
    %1904 = vector.fma %1903, %98, %1873 : vector<8xf32>
    %1905 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1906 = memref.load %assume_align[%arg0, %1905, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1907 = vector.broadcast %1906 : f32 to vector<8xf32>
    %1908 = vector.fma %1907, %98, %1877 : vector<8xf32>
    %1909 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1910 = memref.load %assume_align[%arg0, %1909, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1911 = vector.broadcast %1910 : f32 to vector<8xf32>
    %1912 = vector.fma %1911, %98, %1881 : vector<8xf32>
    %1913 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1914 = memref.load %assume_align[%arg0, %1913, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1915 = vector.broadcast %1914 : f32 to vector<8xf32>
    %1916 = vector.fma %1915, %98, %1885 : vector<8xf32>
    %1917 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1918 = memref.load %assume_align[%arg0, %1917, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1919 = vector.broadcast %1918 : f32 to vector<8xf32>
    %1920 = vector.fma %1919, %98, %1889 : vector<8xf32>
    %1921 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1922 = memref.load %assume_align[%arg0, %1921, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1923 = vector.broadcast %1922 : f32 to vector<8xf32>
    %1924 = vector.fma %1923, %98, %1893 : vector<8xf32>
    %1925 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1926 = memref.load %assume_align[%arg0, %1925, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1927 = vector.broadcast %1926 : f32 to vector<8xf32>
    %1928 = vector.fma %1927, %98, %1897 : vector<8xf32>
    %1929 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1930 = memref.load %assume_align[%arg0, %1929, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1931 = vector.broadcast %1930 : f32 to vector<8xf32>
    %1932 = vector.fma %1931, %98, %1901 : vector<8xf32>
    %1933 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1934 = vector.broadcast %1933 : f32 to vector<8xf32>
    %1935 = vector.fma %1934, %99, %1904 : vector<8xf32>
    %1936 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1937 = memref.load %assume_align[%arg0, %1936, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1938 = vector.broadcast %1937 : f32 to vector<8xf32>
    %1939 = vector.fma %1938, %99, %1908 : vector<8xf32>
    %1940 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1941 = memref.load %assume_align[%arg0, %1940, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1942 = vector.broadcast %1941 : f32 to vector<8xf32>
    %1943 = vector.fma %1942, %99, %1912 : vector<8xf32>
    %1944 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1945 = memref.load %assume_align[%arg0, %1944, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1946 = vector.broadcast %1945 : f32 to vector<8xf32>
    %1947 = vector.fma %1946, %99, %1916 : vector<8xf32>
    %1948 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1949 = memref.load %assume_align[%arg0, %1948, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1950 = vector.broadcast %1949 : f32 to vector<8xf32>
    %1951 = vector.fma %1950, %99, %1920 : vector<8xf32>
    %1952 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1953 = memref.load %assume_align[%arg0, %1952, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1954 = vector.broadcast %1953 : f32 to vector<8xf32>
    %1955 = vector.fma %1954, %99, %1924 : vector<8xf32>
    %1956 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1957 = memref.load %assume_align[%arg0, %1956, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1958 = vector.broadcast %1957 : f32 to vector<8xf32>
    %1959 = vector.fma %1958, %99, %1928 : vector<8xf32>
    %1960 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1961 = memref.load %assume_align[%arg0, %1960, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1962 = vector.broadcast %1961 : f32 to vector<8xf32>
    %1963 = vector.fma %1962, %99, %1932 : vector<8xf32>
    %1964 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1965 = vector.broadcast %1964 : f32 to vector<8xf32>
    %1966 = vector.fma %1965, %100, %1935 : vector<8xf32>
    %1967 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1968 = memref.load %assume_align[%arg0, %1967, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1969 = vector.broadcast %1968 : f32 to vector<8xf32>
    %1970 = vector.fma %1969, %100, %1939 : vector<8xf32>
    %1971 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1972 = memref.load %assume_align[%arg0, %1971, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1973 = vector.broadcast %1972 : f32 to vector<8xf32>
    %1974 = vector.fma %1973, %100, %1943 : vector<8xf32>
    %1975 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1976 = memref.load %assume_align[%arg0, %1975, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1977 = vector.broadcast %1976 : f32 to vector<8xf32>
    %1978 = vector.fma %1977, %100, %1947 : vector<8xf32>
    %1979 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1980 = memref.load %assume_align[%arg0, %1979, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1981 = vector.broadcast %1980 : f32 to vector<8xf32>
    %1982 = vector.fma %1981, %100, %1951 : vector<8xf32>
    %1983 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1984 = memref.load %assume_align[%arg0, %1983, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1985 = vector.broadcast %1984 : f32 to vector<8xf32>
    %1986 = vector.fma %1985, %100, %1955 : vector<8xf32>
    %1987 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1988 = memref.load %assume_align[%arg0, %1987, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1989 = vector.broadcast %1988 : f32 to vector<8xf32>
    %1990 = vector.fma %1989, %100, %1959 : vector<8xf32>
    %1991 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1992 = memref.load %assume_align[%arg0, %1991, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1993 = vector.broadcast %1992 : f32 to vector<8xf32>
    %1994 = vector.fma %1993, %100, %1963 : vector<8xf32>
    %1995 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1996 = vector.broadcast %1995 : f32 to vector<8xf32>
    %1997 = vector.fma %1996, %101, %1966 : vector<8xf32>
    %1998 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1999 = memref.load %assume_align[%arg0, %1998, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2000 = vector.broadcast %1999 : f32 to vector<8xf32>
    %2001 = vector.fma %2000, %101, %1970 : vector<8xf32>
    %2002 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2003 = memref.load %assume_align[%arg0, %2002, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2004 = vector.broadcast %2003 : f32 to vector<8xf32>
    %2005 = vector.fma %2004, %101, %1974 : vector<8xf32>
    %2006 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2007 = memref.load %assume_align[%arg0, %2006, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2008 = vector.broadcast %2007 : f32 to vector<8xf32>
    %2009 = vector.fma %2008, %101, %1978 : vector<8xf32>
    %2010 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2011 = memref.load %assume_align[%arg0, %2010, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2012 = vector.broadcast %2011 : f32 to vector<8xf32>
    %2013 = vector.fma %2012, %101, %1982 : vector<8xf32>
    %2014 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2015 = memref.load %assume_align[%arg0, %2014, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2016 = vector.broadcast %2015 : f32 to vector<8xf32>
    %2017 = vector.fma %2016, %101, %1986 : vector<8xf32>
    %2018 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2019 = memref.load %assume_align[%arg0, %2018, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2020 = vector.broadcast %2019 : f32 to vector<8xf32>
    %2021 = vector.fma %2020, %101, %1990 : vector<8xf32>
    %2022 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2023 = memref.load %assume_align[%arg0, %2022, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2024 = vector.broadcast %2023 : f32 to vector<8xf32>
    %2025 = vector.fma %2024, %101, %1994 : vector<8xf32>
    %2026 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2027 = vector.broadcast %2026 : f32 to vector<8xf32>
    %2028 = vector.fma %2027, %102, %1997 : vector<8xf32>
    %2029 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2030 = memref.load %assume_align[%arg0, %2029, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2031 = vector.broadcast %2030 : f32 to vector<8xf32>
    %2032 = vector.fma %2031, %102, %2001 : vector<8xf32>
    %2033 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2034 = memref.load %assume_align[%arg0, %2033, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2035 = vector.broadcast %2034 : f32 to vector<8xf32>
    %2036 = vector.fma %2035, %102, %2005 : vector<8xf32>
    %2037 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2038 = memref.load %assume_align[%arg0, %2037, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
    %2040 = vector.fma %2039, %102, %2009 : vector<8xf32>
    %2041 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2042 = memref.load %assume_align[%arg0, %2041, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2043 = vector.broadcast %2042 : f32 to vector<8xf32>
    %2044 = vector.fma %2043, %102, %2013 : vector<8xf32>
    %2045 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2046 = memref.load %assume_align[%arg0, %2045, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2047 = vector.broadcast %2046 : f32 to vector<8xf32>
    %2048 = vector.fma %2047, %102, %2017 : vector<8xf32>
    %2049 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2050 = memref.load %assume_align[%arg0, %2049, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2051 = vector.broadcast %2050 : f32 to vector<8xf32>
    %2052 = vector.fma %2051, %102, %2021 : vector<8xf32>
    %2053 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2054 = memref.load %assume_align[%arg0, %2053, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2055 = vector.broadcast %2054 : f32 to vector<8xf32>
    %2056 = vector.fma %2055, %102, %2025 : vector<8xf32>
    %2057 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2058 = vector.broadcast %2057 : f32 to vector<8xf32>
    %2059 = vector.fma %2058, %103, %2028 : vector<8xf32>
    %2060 = vector.insert %2059, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2061 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2062 = memref.load %assume_align[%arg0, %2061, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2063 = vector.broadcast %2062 : f32 to vector<8xf32>
    %2064 = vector.fma %2063, %103, %2032 : vector<8xf32>
    %2065 = vector.insert %2064, %2060 [1] : vector<8xf32> into vector<8x8xf32>
    %2066 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2067 = memref.load %assume_align[%arg0, %2066, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2068 = vector.broadcast %2067 : f32 to vector<8xf32>
    %2069 = vector.fma %2068, %103, %2036 : vector<8xf32>
    %2070 = vector.insert %2069, %2065 [2] : vector<8xf32> into vector<8x8xf32>
    %2071 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2072 = memref.load %assume_align[%arg0, %2071, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2073 = vector.broadcast %2072 : f32 to vector<8xf32>
    %2074 = vector.fma %2073, %103, %2040 : vector<8xf32>
    %2075 = vector.insert %2074, %2070 [3] : vector<8xf32> into vector<8x8xf32>
    %2076 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2077 = memref.load %assume_align[%arg0, %2076, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2078 = vector.broadcast %2077 : f32 to vector<8xf32>
    %2079 = vector.fma %2078, %103, %2044 : vector<8xf32>
    %2080 = vector.insert %2079, %2075 [4] : vector<8xf32> into vector<8x8xf32>
    %2081 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2082 = memref.load %assume_align[%arg0, %2081, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2083 = vector.broadcast %2082 : f32 to vector<8xf32>
    %2084 = vector.fma %2083, %103, %2048 : vector<8xf32>
    %2085 = vector.insert %2084, %2080 [5] : vector<8xf32> into vector<8x8xf32>
    %2086 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2087 = memref.load %assume_align[%arg0, %2086, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2088 = vector.broadcast %2087 : f32 to vector<8xf32>
    %2089 = vector.fma %2088, %103, %2052 : vector<8xf32>
    %2090 = vector.insert %2089, %2085 [6] : vector<8xf32> into vector<8x8xf32>
    %2091 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2092 = memref.load %assume_align[%arg0, %2091, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2093 = vector.broadcast %2092 : f32 to vector<8xf32>
    %2094 = vector.fma %2093, %103, %2056 : vector<8xf32>
    %2095 = vector.insert %2094, %2090 [7] : vector<8xf32> into vector<8x8xf32>
    %2096 = vector.reduction <maximumf>, %2059, %cst : vector<8xf32> into f32
    %2097 = vector.insert %2096, %cst_0 [0] : f32 into vector<8xf32>
    %2098 = vector.reduction <maximumf>, %2064, %cst : vector<8xf32> into f32
    %2099 = vector.insert %2098, %2097 [1] : f32 into vector<8xf32>
    %2100 = vector.reduction <maximumf>, %2069, %cst : vector<8xf32> into f32
    %2101 = vector.insert %2100, %2099 [2] : f32 into vector<8xf32>
    %2102 = vector.reduction <maximumf>, %2074, %cst : vector<8xf32> into f32
    %2103 = vector.insert %2102, %2101 [3] : f32 into vector<8xf32>
    %2104 = vector.reduction <maximumf>, %2079, %cst : vector<8xf32> into f32
    %2105 = vector.insert %2104, %2103 [4] : f32 into vector<8xf32>
    %2106 = vector.reduction <maximumf>, %2084, %cst : vector<8xf32> into f32
    %2107 = vector.insert %2106, %2105 [5] : f32 into vector<8xf32>
    %2108 = vector.reduction <maximumf>, %2089, %cst : vector<8xf32> into f32
    %2109 = vector.insert %2108, %2107 [6] : f32 into vector<8xf32>
    %2110 = vector.reduction <maximumf>, %2094, %cst : vector<8xf32> into f32
    %2111 = vector.insert %2110, %2109 [7] : f32 into vector<8xf32>
    %2112 = arith.subf %2111, %cst_2 : vector<8xf32>
    %2113 = math.exp2 %2112 : vector<8xf32>
    %2114 = vector.insert %2113, %2 [0] : vector<8xf32> into vector<1x8xf32>
    %2115 = vector.broadcast %2114 : vector<1x8xf32> to vector<8x8xf32>
    %2116 = arith.mulf %2115, %cst_1 : vector<8x8xf32>
    %2117 = vector.extract %2116[0] : vector<8xf32> from vector<8x8xf32>
    %2118 = vector.insert_strided_slice %2117, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2119 = vector.extract %2116[1] : vector<8xf32> from vector<8x8xf32>
    %2120 = vector.insert_strided_slice %2119, %2118 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2121 = vector.extract %2116[2] : vector<8xf32> from vector<8x8xf32>
    %2122 = vector.insert_strided_slice %2121, %2120 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2123 = vector.extract %2116[3] : vector<8xf32> from vector<8x8xf32>
    %2124 = vector.insert_strided_slice %2123, %2122 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2125 = vector.extract %2116[4] : vector<8xf32> from vector<8x8xf32>
    %2126 = vector.insert_strided_slice %2125, %2124 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2127 = vector.extract %2116[5] : vector<8xf32> from vector<8x8xf32>
    %2128 = vector.insert_strided_slice %2127, %2126 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2129 = vector.extract %2116[6] : vector<8xf32> from vector<8x8xf32>
    %2130 = vector.insert_strided_slice %2129, %2128 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2131 = vector.extract %2116[7] : vector<8xf32> from vector<8x8xf32>
    %2132 = vector.insert_strided_slice %2131, %2130 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2133 = vector.shuffle %2132, %2132 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2134 = vector.extract_strided_slice %2133 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2135 = vector.extract_strided_slice %2133 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2136 = vector.extract_strided_slice %2133 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2137 = vector.extract_strided_slice %2133 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2138 = vector.extract_strided_slice %2133 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2139 = vector.extract_strided_slice %2133 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2140 = vector.extract_strided_slice %2133 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2141 = vector.extract_strided_slice %2133 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2142 = vector.insert_strided_slice %2111, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2143 = vector.insert_strided_slice %2111, %2142 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2144 = vector.insert_strided_slice %2111, %2143 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2145 = vector.insert_strided_slice %2111, %2144 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2146 = vector.insert_strided_slice %2111, %2145 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2147 = vector.insert_strided_slice %2111, %2146 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2148 = vector.insert_strided_slice %2111, %2147 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2149 = vector.insert_strided_slice %2111, %2148 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2150 = vector.shuffle %2149, %2149 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2151 = vector.extract_strided_slice %2150 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2152 = vector.insert %2151, %0 [0] : vector<8xf32> into vector<8x8xf32>
    %2153 = vector.extract_strided_slice %2150 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2154 = vector.insert %2153, %2152 [1] : vector<8xf32> into vector<8x8xf32>
    %2155 = vector.extract_strided_slice %2150 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2156 = vector.insert %2155, %2154 [2] : vector<8xf32> into vector<8x8xf32>
    %2157 = vector.extract_strided_slice %2150 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2158 = vector.insert %2157, %2156 [3] : vector<8xf32> into vector<8x8xf32>
    %2159 = vector.extract_strided_slice %2150 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2160 = vector.insert %2159, %2158 [4] : vector<8xf32> into vector<8x8xf32>
    %2161 = vector.extract_strided_slice %2150 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2162 = vector.insert %2161, %2160 [5] : vector<8xf32> into vector<8x8xf32>
    %2163 = vector.extract_strided_slice %2150 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2164 = vector.insert %2163, %2162 [6] : vector<8xf32> into vector<8x8xf32>
    %2165 = vector.extract_strided_slice %2150 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2166 = vector.insert %2165, %2164 [7] : vector<8xf32> into vector<8x8xf32>
    %2167 = arith.subf %2095, %2166 : vector<8x8xf32>
    %2168 = math.exp2 %2167 : vector<8x8xf32>
    %2169 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2170 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %2171 = vector.load %assume_align_4[%arg0, %2170, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2172 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %2173 = vector.load %assume_align_4[%arg0, %2172, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2174 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %2175 = vector.load %assume_align_4[%arg0, %2174, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2176 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %2177 = vector.load %assume_align_4[%arg0, %2176, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2178 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %2179 = vector.load %assume_align_4[%arg0, %2178, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2180 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %2181 = vector.load %assume_align_4[%arg0, %2180, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2182 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %2183 = vector.load %assume_align_4[%arg0, %2182, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2184 = vector.extract %2168[0, 0] : f32 from vector<8x8xf32>
    %2185 = vector.broadcast %2184 : f32 to vector<8xf32>
    %2186 = vector.fma %2185, %2169, %2134 : vector<8xf32>
    %2187 = vector.extract %2168[1, 0] : f32 from vector<8x8xf32>
    %2188 = vector.broadcast %2187 : f32 to vector<8xf32>
    %2189 = vector.fma %2188, %2169, %2135 : vector<8xf32>
    %2190 = vector.extract %2168[2, 0] : f32 from vector<8x8xf32>
    %2191 = vector.broadcast %2190 : f32 to vector<8xf32>
    %2192 = vector.fma %2191, %2169, %2136 : vector<8xf32>
    %2193 = vector.extract %2168[3, 0] : f32 from vector<8x8xf32>
    %2194 = vector.broadcast %2193 : f32 to vector<8xf32>
    %2195 = vector.fma %2194, %2169, %2137 : vector<8xf32>
    %2196 = vector.extract %2168[4, 0] : f32 from vector<8x8xf32>
    %2197 = vector.broadcast %2196 : f32 to vector<8xf32>
    %2198 = vector.fma %2197, %2169, %2138 : vector<8xf32>
    %2199 = vector.extract %2168[5, 0] : f32 from vector<8x8xf32>
    %2200 = vector.broadcast %2199 : f32 to vector<8xf32>
    %2201 = vector.fma %2200, %2169, %2139 : vector<8xf32>
    %2202 = vector.extract %2168[6, 0] : f32 from vector<8x8xf32>
    %2203 = vector.broadcast %2202 : f32 to vector<8xf32>
    %2204 = vector.fma %2203, %2169, %2140 : vector<8xf32>
    %2205 = vector.extract %2168[7, 0] : f32 from vector<8x8xf32>
    %2206 = vector.broadcast %2205 : f32 to vector<8xf32>
    %2207 = vector.fma %2206, %2169, %2141 : vector<8xf32>
    %2208 = vector.extract %2168[0, 1] : f32 from vector<8x8xf32>
    %2209 = vector.broadcast %2208 : f32 to vector<8xf32>
    %2210 = vector.fma %2209, %2171, %2186 : vector<8xf32>
    %2211 = vector.extract %2168[1, 1] : f32 from vector<8x8xf32>
    %2212 = vector.broadcast %2211 : f32 to vector<8xf32>
    %2213 = vector.fma %2212, %2171, %2189 : vector<8xf32>
    %2214 = vector.extract %2168[2, 1] : f32 from vector<8x8xf32>
    %2215 = vector.broadcast %2214 : f32 to vector<8xf32>
    %2216 = vector.fma %2215, %2171, %2192 : vector<8xf32>
    %2217 = vector.extract %2168[3, 1] : f32 from vector<8x8xf32>
    %2218 = vector.broadcast %2217 : f32 to vector<8xf32>
    %2219 = vector.fma %2218, %2171, %2195 : vector<8xf32>
    %2220 = vector.extract %2168[4, 1] : f32 from vector<8x8xf32>
    %2221 = vector.broadcast %2220 : f32 to vector<8xf32>
    %2222 = vector.fma %2221, %2171, %2198 : vector<8xf32>
    %2223 = vector.extract %2168[5, 1] : f32 from vector<8x8xf32>
    %2224 = vector.broadcast %2223 : f32 to vector<8xf32>
    %2225 = vector.fma %2224, %2171, %2201 : vector<8xf32>
    %2226 = vector.extract %2168[6, 1] : f32 from vector<8x8xf32>
    %2227 = vector.broadcast %2226 : f32 to vector<8xf32>
    %2228 = vector.fma %2227, %2171, %2204 : vector<8xf32>
    %2229 = vector.extract %2168[7, 1] : f32 from vector<8x8xf32>
    %2230 = vector.broadcast %2229 : f32 to vector<8xf32>
    %2231 = vector.fma %2230, %2171, %2207 : vector<8xf32>
    %2232 = vector.extract %2168[0, 2] : f32 from vector<8x8xf32>
    %2233 = vector.broadcast %2232 : f32 to vector<8xf32>
    %2234 = vector.fma %2233, %2173, %2210 : vector<8xf32>
    %2235 = vector.extract %2168[1, 2] : f32 from vector<8x8xf32>
    %2236 = vector.broadcast %2235 : f32 to vector<8xf32>
    %2237 = vector.fma %2236, %2173, %2213 : vector<8xf32>
    %2238 = vector.extract %2168[2, 2] : f32 from vector<8x8xf32>
    %2239 = vector.broadcast %2238 : f32 to vector<8xf32>
    %2240 = vector.fma %2239, %2173, %2216 : vector<8xf32>
    %2241 = vector.extract %2168[3, 2] : f32 from vector<8x8xf32>
    %2242 = vector.broadcast %2241 : f32 to vector<8xf32>
    %2243 = vector.fma %2242, %2173, %2219 : vector<8xf32>
    %2244 = vector.extract %2168[4, 2] : f32 from vector<8x8xf32>
    %2245 = vector.broadcast %2244 : f32 to vector<8xf32>
    %2246 = vector.fma %2245, %2173, %2222 : vector<8xf32>
    %2247 = vector.extract %2168[5, 2] : f32 from vector<8x8xf32>
    %2248 = vector.broadcast %2247 : f32 to vector<8xf32>
    %2249 = vector.fma %2248, %2173, %2225 : vector<8xf32>
    %2250 = vector.extract %2168[6, 2] : f32 from vector<8x8xf32>
    %2251 = vector.broadcast %2250 : f32 to vector<8xf32>
    %2252 = vector.fma %2251, %2173, %2228 : vector<8xf32>
    %2253 = vector.extract %2168[7, 2] : f32 from vector<8x8xf32>
    %2254 = vector.broadcast %2253 : f32 to vector<8xf32>
    %2255 = vector.fma %2254, %2173, %2231 : vector<8xf32>
    %2256 = vector.extract %2168[0, 3] : f32 from vector<8x8xf32>
    %2257 = vector.broadcast %2256 : f32 to vector<8xf32>
    %2258 = vector.fma %2257, %2175, %2234 : vector<8xf32>
    %2259 = vector.extract %2168[1, 3] : f32 from vector<8x8xf32>
    %2260 = vector.broadcast %2259 : f32 to vector<8xf32>
    %2261 = vector.fma %2260, %2175, %2237 : vector<8xf32>
    %2262 = vector.extract %2168[2, 3] : f32 from vector<8x8xf32>
    %2263 = vector.broadcast %2262 : f32 to vector<8xf32>
    %2264 = vector.fma %2263, %2175, %2240 : vector<8xf32>
    %2265 = vector.extract %2168[3, 3] : f32 from vector<8x8xf32>
    %2266 = vector.broadcast %2265 : f32 to vector<8xf32>
    %2267 = vector.fma %2266, %2175, %2243 : vector<8xf32>
    %2268 = vector.extract %2168[4, 3] : f32 from vector<8x8xf32>
    %2269 = vector.broadcast %2268 : f32 to vector<8xf32>
    %2270 = vector.fma %2269, %2175, %2246 : vector<8xf32>
    %2271 = vector.extract %2168[5, 3] : f32 from vector<8x8xf32>
    %2272 = vector.broadcast %2271 : f32 to vector<8xf32>
    %2273 = vector.fma %2272, %2175, %2249 : vector<8xf32>
    %2274 = vector.extract %2168[6, 3] : f32 from vector<8x8xf32>
    %2275 = vector.broadcast %2274 : f32 to vector<8xf32>
    %2276 = vector.fma %2275, %2175, %2252 : vector<8xf32>
    %2277 = vector.extract %2168[7, 3] : f32 from vector<8x8xf32>
    %2278 = vector.broadcast %2277 : f32 to vector<8xf32>
    %2279 = vector.fma %2278, %2175, %2255 : vector<8xf32>
    %2280 = vector.extract %2168[0, 4] : f32 from vector<8x8xf32>
    %2281 = vector.broadcast %2280 : f32 to vector<8xf32>
    %2282 = vector.fma %2281, %2177, %2258 : vector<8xf32>
    %2283 = vector.extract %2168[1, 4] : f32 from vector<8x8xf32>
    %2284 = vector.broadcast %2283 : f32 to vector<8xf32>
    %2285 = vector.fma %2284, %2177, %2261 : vector<8xf32>
    %2286 = vector.extract %2168[2, 4] : f32 from vector<8x8xf32>
    %2287 = vector.broadcast %2286 : f32 to vector<8xf32>
    %2288 = vector.fma %2287, %2177, %2264 : vector<8xf32>
    %2289 = vector.extract %2168[3, 4] : f32 from vector<8x8xf32>
    %2290 = vector.broadcast %2289 : f32 to vector<8xf32>
    %2291 = vector.fma %2290, %2177, %2267 : vector<8xf32>
    %2292 = vector.extract %2168[4, 4] : f32 from vector<8x8xf32>
    %2293 = vector.broadcast %2292 : f32 to vector<8xf32>
    %2294 = vector.fma %2293, %2177, %2270 : vector<8xf32>
    %2295 = vector.extract %2168[5, 4] : f32 from vector<8x8xf32>
    %2296 = vector.broadcast %2295 : f32 to vector<8xf32>
    %2297 = vector.fma %2296, %2177, %2273 : vector<8xf32>
    %2298 = vector.extract %2168[6, 4] : f32 from vector<8x8xf32>
    %2299 = vector.broadcast %2298 : f32 to vector<8xf32>
    %2300 = vector.fma %2299, %2177, %2276 : vector<8xf32>
    %2301 = vector.extract %2168[7, 4] : f32 from vector<8x8xf32>
    %2302 = vector.broadcast %2301 : f32 to vector<8xf32>
    %2303 = vector.fma %2302, %2177, %2279 : vector<8xf32>
    %2304 = vector.extract %2168[0, 5] : f32 from vector<8x8xf32>
    %2305 = vector.broadcast %2304 : f32 to vector<8xf32>
    %2306 = vector.fma %2305, %2179, %2282 : vector<8xf32>
    %2307 = vector.extract %2168[1, 5] : f32 from vector<8x8xf32>
    %2308 = vector.broadcast %2307 : f32 to vector<8xf32>
    %2309 = vector.fma %2308, %2179, %2285 : vector<8xf32>
    %2310 = vector.extract %2168[2, 5] : f32 from vector<8x8xf32>
    %2311 = vector.broadcast %2310 : f32 to vector<8xf32>
    %2312 = vector.fma %2311, %2179, %2288 : vector<8xf32>
    %2313 = vector.extract %2168[3, 5] : f32 from vector<8x8xf32>
    %2314 = vector.broadcast %2313 : f32 to vector<8xf32>
    %2315 = vector.fma %2314, %2179, %2291 : vector<8xf32>
    %2316 = vector.extract %2168[4, 5] : f32 from vector<8x8xf32>
    %2317 = vector.broadcast %2316 : f32 to vector<8xf32>
    %2318 = vector.fma %2317, %2179, %2294 : vector<8xf32>
    %2319 = vector.extract %2168[5, 5] : f32 from vector<8x8xf32>
    %2320 = vector.broadcast %2319 : f32 to vector<8xf32>
    %2321 = vector.fma %2320, %2179, %2297 : vector<8xf32>
    %2322 = vector.extract %2168[6, 5] : f32 from vector<8x8xf32>
    %2323 = vector.broadcast %2322 : f32 to vector<8xf32>
    %2324 = vector.fma %2323, %2179, %2300 : vector<8xf32>
    %2325 = vector.extract %2168[7, 5] : f32 from vector<8x8xf32>
    %2326 = vector.broadcast %2325 : f32 to vector<8xf32>
    %2327 = vector.fma %2326, %2179, %2303 : vector<8xf32>
    %2328 = vector.extract %2168[0, 6] : f32 from vector<8x8xf32>
    %2329 = vector.broadcast %2328 : f32 to vector<8xf32>
    %2330 = vector.fma %2329, %2181, %2306 : vector<8xf32>
    %2331 = vector.extract %2168[1, 6] : f32 from vector<8x8xf32>
    %2332 = vector.broadcast %2331 : f32 to vector<8xf32>
    %2333 = vector.fma %2332, %2181, %2309 : vector<8xf32>
    %2334 = vector.extract %2168[2, 6] : f32 from vector<8x8xf32>
    %2335 = vector.broadcast %2334 : f32 to vector<8xf32>
    %2336 = vector.fma %2335, %2181, %2312 : vector<8xf32>
    %2337 = vector.extract %2168[3, 6] : f32 from vector<8x8xf32>
    %2338 = vector.broadcast %2337 : f32 to vector<8xf32>
    %2339 = vector.fma %2338, %2181, %2315 : vector<8xf32>
    %2340 = vector.extract %2168[4, 6] : f32 from vector<8x8xf32>
    %2341 = vector.broadcast %2340 : f32 to vector<8xf32>
    %2342 = vector.fma %2341, %2181, %2318 : vector<8xf32>
    %2343 = vector.extract %2168[5, 6] : f32 from vector<8x8xf32>
    %2344 = vector.broadcast %2343 : f32 to vector<8xf32>
    %2345 = vector.fma %2344, %2181, %2321 : vector<8xf32>
    %2346 = vector.extract %2168[6, 6] : f32 from vector<8x8xf32>
    %2347 = vector.broadcast %2346 : f32 to vector<8xf32>
    %2348 = vector.fma %2347, %2181, %2324 : vector<8xf32>
    %2349 = vector.extract %2168[7, 6] : f32 from vector<8x8xf32>
    %2350 = vector.broadcast %2349 : f32 to vector<8xf32>
    %2351 = vector.fma %2350, %2181, %2327 : vector<8xf32>
    %2352 = vector.extract %2168[0, 7] : f32 from vector<8x8xf32>
    %2353 = vector.broadcast %2352 : f32 to vector<8xf32>
    %2354 = vector.fma %2353, %2183, %2330 : vector<8xf32>
    %2355 = vector.insert %2354, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2356 = vector.extract %2168[1, 7] : f32 from vector<8x8xf32>
    %2357 = vector.broadcast %2356 : f32 to vector<8xf32>
    %2358 = vector.fma %2357, %2183, %2333 : vector<8xf32>
    %2359 = vector.insert %2358, %2355 [1] : vector<8xf32> into vector<8x8xf32>
    %2360 = vector.extract %2168[2, 7] : f32 from vector<8x8xf32>
    %2361 = vector.broadcast %2360 : f32 to vector<8xf32>
    %2362 = vector.fma %2361, %2183, %2336 : vector<8xf32>
    %2363 = vector.insert %2362, %2359 [2] : vector<8xf32> into vector<8x8xf32>
    %2364 = vector.extract %2168[3, 7] : f32 from vector<8x8xf32>
    %2365 = vector.broadcast %2364 : f32 to vector<8xf32>
    %2366 = vector.fma %2365, %2183, %2339 : vector<8xf32>
    %2367 = vector.insert %2366, %2363 [3] : vector<8xf32> into vector<8x8xf32>
    %2368 = vector.extract %2168[4, 7] : f32 from vector<8x8xf32>
    %2369 = vector.broadcast %2368 : f32 to vector<8xf32>
    %2370 = vector.fma %2369, %2183, %2342 : vector<8xf32>
    %2371 = vector.insert %2370, %2367 [4] : vector<8xf32> into vector<8x8xf32>
    %2372 = vector.extract %2168[5, 7] : f32 from vector<8x8xf32>
    %2373 = vector.broadcast %2372 : f32 to vector<8xf32>
    %2374 = vector.fma %2373, %2183, %2345 : vector<8xf32>
    %2375 = vector.insert %2374, %2371 [5] : vector<8xf32> into vector<8x8xf32>
    %2376 = vector.extract %2168[6, 7] : f32 from vector<8x8xf32>
    %2377 = vector.broadcast %2376 : f32 to vector<8xf32>
    %2378 = vector.fma %2377, %2183, %2348 : vector<8xf32>
    %2379 = vector.insert %2378, %2375 [6] : vector<8xf32> into vector<8x8xf32>
    %2380 = vector.extract %2168[7, 7] : f32 from vector<8x8xf32>
    %2381 = vector.broadcast %2380 : f32 to vector<8xf32>
    %2382 = vector.fma %2381, %2183, %2351 : vector<8xf32>
    %2383 = vector.insert %2382, %2379 [7] : vector<8xf32> into vector<8x8xf32>
    %2384 = arith.mulf %2113, %cst_0 : vector<8xf32>
    %2385 = vector.extract %2168[0] : vector<8xf32> from vector<8x8xf32>
    %2386 = vector.extract %2384[0] : f32 from vector<8xf32>
    %2387 = vector.reduction <add>, %2385, %2386 : vector<8xf32> into f32
    %2388 = vector.insert %2387, %cst_0 [0] : f32 into vector<8xf32>
    %2389 = vector.extract %2168[1] : vector<8xf32> from vector<8x8xf32>
    %2390 = vector.extract %2384[1] : f32 from vector<8xf32>
    %2391 = vector.reduction <add>, %2389, %2390 : vector<8xf32> into f32
    %2392 = vector.insert %2391, %2388 [1] : f32 into vector<8xf32>
    %2393 = vector.extract %2168[2] : vector<8xf32> from vector<8x8xf32>
    %2394 = vector.extract %2384[2] : f32 from vector<8xf32>
    %2395 = vector.reduction <add>, %2393, %2394 : vector<8xf32> into f32
    %2396 = vector.insert %2395, %2392 [2] : f32 into vector<8xf32>
    %2397 = vector.extract %2168[3] : vector<8xf32> from vector<8x8xf32>
    %2398 = vector.extract %2384[3] : f32 from vector<8xf32>
    %2399 = vector.reduction <add>, %2397, %2398 : vector<8xf32> into f32
    %2400 = vector.insert %2399, %2396 [3] : f32 into vector<8xf32>
    %2401 = vector.extract %2168[4] : vector<8xf32> from vector<8x8xf32>
    %2402 = vector.extract %2384[4] : f32 from vector<8xf32>
    %2403 = vector.reduction <add>, %2401, %2402 : vector<8xf32> into f32
    %2404 = vector.insert %2403, %2400 [4] : f32 into vector<8xf32>
    %2405 = vector.extract %2168[5] : vector<8xf32> from vector<8x8xf32>
    %2406 = vector.extract %2384[5] : f32 from vector<8xf32>
    %2407 = vector.reduction <add>, %2405, %2406 : vector<8xf32> into f32
    %2408 = vector.insert %2407, %2404 [5] : f32 into vector<8xf32>
    %2409 = vector.extract %2168[6] : vector<8xf32> from vector<8x8xf32>
    %2410 = vector.extract %2384[6] : f32 from vector<8xf32>
    %2411 = vector.reduction <add>, %2409, %2410 : vector<8xf32> into f32
    %2412 = vector.insert %2411, %2408 [6] : f32 into vector<8xf32>
    %2413 = vector.extract %2168[7] : vector<8xf32> from vector<8x8xf32>
    %2414 = vector.extract %2384[7] : f32 from vector<8xf32>
    %2415 = vector.reduction <add>, %2413, %2414 : vector<8xf32> into f32
    %2416 = vector.insert %2415, %2412 [7] : f32 into vector<8xf32>
    %2417 = vector.insert_strided_slice %2416, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2418 = vector.insert_strided_slice %2416, %2417 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2419 = vector.insert_strided_slice %2416, %2418 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2420 = vector.insert_strided_slice %2416, %2419 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2421 = vector.insert_strided_slice %2416, %2420 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2422 = vector.insert_strided_slice %2416, %2421 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2423 = vector.insert_strided_slice %2416, %2422 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2424 = vector.insert_strided_slice %2416, %2423 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2425 = vector.shuffle %2424, %2424 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2426 = vector.extract_strided_slice %2425 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2427 = vector.insert %2426, %0 [0] : vector<8xf32> into vector<8x8xf32>
    %2428 = vector.extract_strided_slice %2425 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2429 = vector.insert %2428, %2427 [1] : vector<8xf32> into vector<8x8xf32>
    %2430 = vector.extract_strided_slice %2425 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2431 = vector.insert %2430, %2429 [2] : vector<8xf32> into vector<8x8xf32>
    %2432 = vector.extract_strided_slice %2425 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2433 = vector.insert %2432, %2431 [3] : vector<8xf32> into vector<8x8xf32>
    %2434 = vector.extract_strided_slice %2425 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2435 = vector.insert %2434, %2433 [4] : vector<8xf32> into vector<8x8xf32>
    %2436 = vector.extract_strided_slice %2425 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2437 = vector.insert %2436, %2435 [5] : vector<8xf32> into vector<8x8xf32>
    %2438 = vector.extract_strided_slice %2425 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2439 = vector.insert %2438, %2437 [6] : vector<8xf32> into vector<8x8xf32>
    %2440 = vector.extract_strided_slice %2425 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2441 = vector.insert %2440, %2439 [7] : vector<8xf32> into vector<8x8xf32>
    %2442 = arith.divf %2383, %2441 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    %2443 = vector.extract %2442[0] : vector<8xf32> from vector<8x8xf32>
    vector.store %2443, %subview_7[%c0, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2444 = vector.extract %2442[1] : vector<8xf32> from vector<8x8xf32>
    vector.store %2444, %subview_7[%c1, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2445 = vector.extract %2442[2] : vector<8xf32> from vector<8x8xf32>
    vector.store %2445, %subview_7[%c2, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2446 = vector.extract %2442[3] : vector<8xf32> from vector<8x8xf32>
    vector.store %2446, %subview_7[%c3, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2447 = vector.extract %2442[4] : vector<8xf32> from vector<8x8xf32>
    vector.store %2447, %subview_7[%c4, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2448 = vector.extract %2442[5] : vector<8xf32> from vector<8x8xf32>
    vector.store %2448, %subview_7[%c5, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2449 = vector.extract %2442[6] : vector<8xf32> from vector<8x8xf32>
    vector.store %2449, %subview_7[%c6, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2450 = vector.extract %2442[7] : vector<8xf32> from vector<8x8xf32>
    vector.store %2450, %subview_7[%c7, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPULowerExecutableTargetPass (iree-llvmcpu-lower-executable-target) //----- //
func.func @no_peel_static_matmul() attributes {hal.executable.target = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>, translation_info = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>} {
  %0 = ub.poison : vector<8x8xf32>
  %1 = ub.poison : vector<64xf32>
  %2 = ub.poison : vector<1x8xf32>
  %3 = ub.poison : vector<512xf32>
  %c63 = arith.constant 63 : index
  %c62 = arith.constant 62 : index
  %c61 = arith.constant 61 : index
  %c60 = arith.constant 60 : index
  %c59 = arith.constant 59 : index
  %c58 = arith.constant 58 : index
  %c57 = arith.constant 57 : index
  %c56 = arith.constant 56 : index
  %c55 = arith.constant 55 : index
  %c54 = arith.constant 54 : index
  %c53 = arith.constant 53 : index
  %c52 = arith.constant 52 : index
  %c51 = arith.constant 51 : index
  %c50 = arith.constant 50 : index
  %c49 = arith.constant 49 : index
  %c48 = arith.constant 48 : index
  %c47 = arith.constant 47 : index
  %c46 = arith.constant 46 : index
  %c45 = arith.constant 45 : index
  %c44 = arith.constant 44 : index
  %c43 = arith.constant 43 : index
  %c42 = arith.constant 42 : index
  %c41 = arith.constant 41 : index
  %c40 = arith.constant 40 : index
  %c39 = arith.constant 39 : index
  %c38 = arith.constant 38 : index
  %c37 = arith.constant 37 : index
  %c36 = arith.constant 36 : index
  %c35 = arith.constant 35 : index
  %c34 = arith.constant 34 : index
  %c33 = arith.constant 33 : index
  %c32 = arith.constant 32 : index
  %c31 = arith.constant 31 : index
  %c30 = arith.constant 30 : index
  %c29 = arith.constant 29 : index
  %c28 = arith.constant 28 : index
  %c27 = arith.constant 27 : index
  %c26 = arith.constant 26 : index
  %c25 = arith.constant 25 : index
  %c24 = arith.constant 24 : index
  %c23 = arith.constant 23 : index
  %c22 = arith.constant 22 : index
  %c21 = arith.constant 21 : index
  %c20 = arith.constant 20 : index
  %c19 = arith.constant 19 : index
  %c18 = arith.constant 18 : index
  %c17 = arith.constant 17 : index
  %c16 = arith.constant 16 : index
  %c15 = arith.constant 15 : index
  %c14 = arith.constant 14 : index
  %c13 = arith.constant 13 : index
  %c12 = arith.constant 12 : index
  %c11 = arith.constant 11 : index
  %c10 = arith.constant 10 : index
  %c9 = arith.constant 9 : index
  %c8 = arith.constant 8 : index
  %c7 = arith.constant 7 : index
  %c6 = arith.constant 6 : index
  %c5 = arith.constant 5 : index
  %c4 = arith.constant 4 : index
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
  %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
  %c0 = arith.constant 0 : index
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_3 = memref.assume_alignment %5, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %6 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_4 = memref.assume_alignment %6, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %7 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_5 = memref.assume_alignment %7, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
    %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %8 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %9 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %10 = vector.load %assume_align_3[%arg0, %9, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %11 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %12 = vector.load %assume_align_3[%arg0, %11, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %15 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %16 = vector.load %assume_align_3[%arg0, %15, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %17 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %18 = vector.load %assume_align_3[%arg0, %17, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %19 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %21 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %22 = vector.load %assume_align_3[%arg0, %21, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
    %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
    %23 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
    %24 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
    %25 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
    %26 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
    %27 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
    %28 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
    %29 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
    %30 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
    %31 = vector.insert_strided_slice %8, %3 {offsets = [0], strides = [1]} : vector<64xf32> into vector<512xf32>
    %32 = vector.insert_strided_slice %10, %31 {offsets = [64], strides = [1]} : vector<64xf32> into vector<512xf32>
    %33 = vector.insert_strided_slice %12, %32 {offsets = [128], strides = [1]} : vector<64xf32> into vector<512xf32>
    %34 = vector.insert_strided_slice %14, %33 {offsets = [192], strides = [1]} : vector<64xf32> into vector<512xf32>
    %35 = vector.insert_strided_slice %16, %34 {offsets = [256], strides = [1]} : vector<64xf32> into vector<512xf32>
    %36 = vector.insert_strided_slice %18, %35 {offsets = [320], strides = [1]} : vector<64xf32> into vector<512xf32>
    %37 = vector.insert_strided_slice %20, %36 {offsets = [384], strides = [1]} : vector<64xf32> into vector<512xf32>
    %38 = vector.insert_strided_slice %22, %37 {offsets = [448], strides = [1]} : vector<64xf32> into vector<512xf32>
    %39 = vector.shuffle %38, %38 [0, 64, 128, 192, 256, 320, 384, 448, 1, 65, 129, 193, 257, 321, 385, 449, 2, 66, 130, 194, 258, 322, 386, 450, 3, 67, 131, 195, 259, 323, 387, 451, 4, 68, 132, 196, 260, 324, 388, 452, 5, 69, 133, 197, 261, 325, 389, 453, 6, 70, 134, 198, 262, 326, 390, 454, 7, 71, 135, 199, 263, 327, 391, 455, 8, 72, 136, 200, 264, 328, 392, 456, 9, 73, 137, 201, 265, 329, 393, 457, 10, 74, 138, 202, 266, 330, 394, 458, 11, 75, 139, 203, 267, 331, 395, 459, 12, 76, 140, 204, 268, 332, 396, 460, 13, 77, 141, 205, 269, 333, 397, 461, 14, 78, 142, 206, 270, 334, 398, 462, 15, 79, 143, 207, 271, 335, 399, 463, 16, 80, 144, 208, 272, 336, 400, 464, 17, 81, 145, 209, 273, 337, 401, 465, 18, 82, 146, 210, 274, 338, 402, 466, 19, 83, 147, 211, 275, 339, 403, 467, 20, 84, 148, 212, 276, 340, 404, 468, 21, 85, 149, 213, 277, 341, 405, 469, 22, 86, 150, 214, 278, 342, 406, 470, 23, 87, 151, 215, 279, 343, 407, 471, 24, 88, 152, 216, 280, 344, 408, 472, 25, 89, 153, 217, 281, 345, 409, 473, 26, 90, 154, 218, 282, 346, 410, 474, 27, 91, 155, 219, 283, 347, 411, 475, 28, 92, 156, 220, 284, 348, 412, 476, 29, 93, 157, 221, 285, 349, 413, 477, 30, 94, 158, 222, 286, 350, 414, 478, 31, 95, 159, 223, 287, 351, 415, 479, 32, 96, 160, 224, 288, 352, 416, 480, 33, 97, 161, 225, 289, 353, 417, 481, 34, 98, 162, 226, 290, 354, 418, 482, 35, 99, 163, 227, 291, 355, 419, 483, 36, 100, 164, 228, 292, 356, 420, 484, 37, 101, 165, 229, 293, 357, 421, 485, 38, 102, 166, 230, 294, 358, 422, 486, 39, 103, 167, 231, 295, 359, 423, 487, 40, 104, 168, 232, 296, 360, 424, 488, 41, 105, 169, 233, 297, 361, 425, 489, 42, 106, 170, 234, 298, 362, 426, 490, 43, 107, 171, 235, 299, 363, 427, 491, 44, 108, 172, 236, 300, 364, 428, 492, 45, 109, 173, 237, 301, 365, 429, 493, 46, 110, 174, 238, 302, 366, 430, 494, 47, 111, 175, 239, 303, 367, 431, 495, 48, 112, 176, 240, 304, 368, 432, 496, 49, 113, 177, 241, 305, 369, 433, 497, 50, 114, 178, 242, 306, 370, 434, 498, 51, 115, 179, 243, 307, 371, 435, 499, 52, 116, 180, 244, 308, 372, 436, 500, 53, 117, 181, 245, 309, 373, 437, 501, 54, 118, 182, 246, 310, 374, 438, 502, 55, 119, 183, 247, 311, 375, 439, 503, 56, 120, 184, 248, 312, 376, 440, 504, 57, 121, 185, 249, 313, 377, 441, 505, 58, 122, 186, 250, 314, 378, 442, 506, 59, 123, 187, 251, 315, 379, 443, 507, 60, 124, 188, 252, 316, 380, 444, 508, 61, 125, 189, 253, 317, 381, 445, 509, 62, 126, 190, 254, 318, 382, 446, 510, 63, 127, 191, 255, 319, 383, 447, 511] : vector<512xf32>, vector<512xf32>
    %40 = vector.extract_strided_slice %39 {offsets = [0], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %41 = vector.extract_strided_slice %39 {offsets = [8], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %42 = vector.extract_strided_slice %39 {offsets = [16], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %43 = vector.extract_strided_slice %39 {offsets = [24], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %44 = vector.extract_strided_slice %39 {offsets = [32], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %45 = vector.extract_strided_slice %39 {offsets = [40], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %46 = vector.extract_strided_slice %39 {offsets = [48], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %47 = vector.extract_strided_slice %39 {offsets = [56], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %48 = vector.extract_strided_slice %39 {offsets = [64], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %49 = vector.extract_strided_slice %39 {offsets = [72], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %50 = vector.extract_strided_slice %39 {offsets = [80], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %51 = vector.extract_strided_slice %39 {offsets = [88], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %52 = vector.extract_strided_slice %39 {offsets = [96], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %53 = vector.extract_strided_slice %39 {offsets = [104], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %54 = vector.extract_strided_slice %39 {offsets = [112], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %55 = vector.extract_strided_slice %39 {offsets = [120], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %56 = vector.extract_strided_slice %39 {offsets = [128], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %57 = vector.extract_strided_slice %39 {offsets = [136], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %58 = vector.extract_strided_slice %39 {offsets = [144], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %59 = vector.extract_strided_slice %39 {offsets = [152], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %60 = vector.extract_strided_slice %39 {offsets = [160], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %61 = vector.extract_strided_slice %39 {offsets = [168], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %62 = vector.extract_strided_slice %39 {offsets = [176], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %63 = vector.extract_strided_slice %39 {offsets = [184], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %64 = vector.extract_strided_slice %39 {offsets = [192], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %65 = vector.extract_strided_slice %39 {offsets = [200], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %66 = vector.extract_strided_slice %39 {offsets = [208], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %67 = vector.extract_strided_slice %39 {offsets = [216], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %68 = vector.extract_strided_slice %39 {offsets = [224], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %69 = vector.extract_strided_slice %39 {offsets = [232], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %70 = vector.extract_strided_slice %39 {offsets = [240], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %71 = vector.extract_strided_slice %39 {offsets = [248], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %72 = vector.extract_strided_slice %39 {offsets = [256], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %73 = vector.extract_strided_slice %39 {offsets = [264], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %74 = vector.extract_strided_slice %39 {offsets = [272], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %75 = vector.extract_strided_slice %39 {offsets = [280], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %76 = vector.extract_strided_slice %39 {offsets = [288], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %77 = vector.extract_strided_slice %39 {offsets = [296], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %78 = vector.extract_strided_slice %39 {offsets = [304], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %79 = vector.extract_strided_slice %39 {offsets = [312], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %80 = vector.extract_strided_slice %39 {offsets = [320], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %81 = vector.extract_strided_slice %39 {offsets = [328], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %82 = vector.extract_strided_slice %39 {offsets = [336], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %83 = vector.extract_strided_slice %39 {offsets = [344], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %84 = vector.extract_strided_slice %39 {offsets = [352], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %85 = vector.extract_strided_slice %39 {offsets = [360], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %86 = vector.extract_strided_slice %39 {offsets = [368], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %87 = vector.extract_strided_slice %39 {offsets = [376], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %88 = vector.extract_strided_slice %39 {offsets = [384], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %89 = vector.extract_strided_slice %39 {offsets = [392], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %90 = vector.extract_strided_slice %39 {offsets = [400], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %91 = vector.extract_strided_slice %39 {offsets = [408], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %92 = vector.extract_strided_slice %39 {offsets = [416], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %93 = vector.extract_strided_slice %39 {offsets = [424], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %94 = vector.extract_strided_slice %39 {offsets = [432], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %95 = vector.extract_strided_slice %39 {offsets = [440], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %96 = vector.extract_strided_slice %39 {offsets = [448], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %97 = vector.extract_strided_slice %39 {offsets = [456], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %98 = vector.extract_strided_slice %39 {offsets = [464], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %99 = vector.extract_strided_slice %39 {offsets = [472], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %100 = vector.extract_strided_slice %39 {offsets = [480], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %101 = vector.extract_strided_slice %39 {offsets = [488], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %102 = vector.extract_strided_slice %39 {offsets = [496], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %103 = vector.extract_strided_slice %39 {offsets = [504], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
    %104 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %105 = vector.broadcast %104 : f32 to vector<8xf32>
    %106 = vector.fma %105, %40, %23 : vector<8xf32>
    %107 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %108 = memref.load %assume_align[%arg0, %107, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %109 = vector.broadcast %108 : f32 to vector<8xf32>
    %110 = vector.fma %109, %40, %24 : vector<8xf32>
    %111 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %112 = memref.load %assume_align[%arg0, %111, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %113 = vector.broadcast %112 : f32 to vector<8xf32>
    %114 = vector.fma %113, %40, %25 : vector<8xf32>
    %115 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %116 = memref.load %assume_align[%arg0, %115, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %117 = vector.broadcast %116 : f32 to vector<8xf32>
    %118 = vector.fma %117, %40, %26 : vector<8xf32>
    %119 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %120 = memref.load %assume_align[%arg0, %119, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %121 = vector.broadcast %120 : f32 to vector<8xf32>
    %122 = vector.fma %121, %40, %27 : vector<8xf32>
    %123 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %124 = memref.load %assume_align[%arg0, %123, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %125 = vector.broadcast %124 : f32 to vector<8xf32>
    %126 = vector.fma %125, %40, %28 : vector<8xf32>
    %127 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %128 = memref.load %assume_align[%arg0, %127, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %129 = vector.broadcast %128 : f32 to vector<8xf32>
    %130 = vector.fma %129, %40, %29 : vector<8xf32>
    %131 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %132 = memref.load %assume_align[%arg0, %131, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %133 = vector.broadcast %132 : f32 to vector<8xf32>
    %134 = vector.fma %133, %40, %30 : vector<8xf32>
    %135 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %136 = vector.broadcast %135 : f32 to vector<8xf32>
    %137 = vector.fma %136, %41, %106 : vector<8xf32>
    %138 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %139 = memref.load %assume_align[%arg0, %138, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %140 = vector.broadcast %139 : f32 to vector<8xf32>
    %141 = vector.fma %140, %41, %110 : vector<8xf32>
    %142 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %143 = memref.load %assume_align[%arg0, %142, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %144 = vector.broadcast %143 : f32 to vector<8xf32>
    %145 = vector.fma %144, %41, %114 : vector<8xf32>
    %146 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %147 = memref.load %assume_align[%arg0, %146, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %148 = vector.broadcast %147 : f32 to vector<8xf32>
    %149 = vector.fma %148, %41, %118 : vector<8xf32>
    %150 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %151 = memref.load %assume_align[%arg0, %150, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %152 = vector.broadcast %151 : f32 to vector<8xf32>
    %153 = vector.fma %152, %41, %122 : vector<8xf32>
    %154 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %155 = memref.load %assume_align[%arg0, %154, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %156 = vector.broadcast %155 : f32 to vector<8xf32>
    %157 = vector.fma %156, %41, %126 : vector<8xf32>
    %158 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %159 = memref.load %assume_align[%arg0, %158, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %160 = vector.broadcast %159 : f32 to vector<8xf32>
    %161 = vector.fma %160, %41, %130 : vector<8xf32>
    %162 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %163 = memref.load %assume_align[%arg0, %162, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %164 = vector.broadcast %163 : f32 to vector<8xf32>
    %165 = vector.fma %164, %41, %134 : vector<8xf32>
    %166 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %167 = vector.broadcast %166 : f32 to vector<8xf32>
    %168 = vector.fma %167, %42, %137 : vector<8xf32>
    %169 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %170 = memref.load %assume_align[%arg0, %169, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %171 = vector.broadcast %170 : f32 to vector<8xf32>
    %172 = vector.fma %171, %42, %141 : vector<8xf32>
    %173 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %174 = memref.load %assume_align[%arg0, %173, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %175 = vector.broadcast %174 : f32 to vector<8xf32>
    %176 = vector.fma %175, %42, %145 : vector<8xf32>
    %177 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %178 = memref.load %assume_align[%arg0, %177, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %179 = vector.broadcast %178 : f32 to vector<8xf32>
    %180 = vector.fma %179, %42, %149 : vector<8xf32>
    %181 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %182 = memref.load %assume_align[%arg0, %181, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %183 = vector.broadcast %182 : f32 to vector<8xf32>
    %184 = vector.fma %183, %42, %153 : vector<8xf32>
    %185 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %186 = memref.load %assume_align[%arg0, %185, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %187 = vector.broadcast %186 : f32 to vector<8xf32>
    %188 = vector.fma %187, %42, %157 : vector<8xf32>
    %189 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %190 = memref.load %assume_align[%arg0, %189, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %191 = vector.broadcast %190 : f32 to vector<8xf32>
    %192 = vector.fma %191, %42, %161 : vector<8xf32>
    %193 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %194 = memref.load %assume_align[%arg0, %193, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %195 = vector.broadcast %194 : f32 to vector<8xf32>
    %196 = vector.fma %195, %42, %165 : vector<8xf32>
    %197 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %198 = vector.broadcast %197 : f32 to vector<8xf32>
    %199 = vector.fma %198, %43, %168 : vector<8xf32>
    %200 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %201 = memref.load %assume_align[%arg0, %200, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %202 = vector.broadcast %201 : f32 to vector<8xf32>
    %203 = vector.fma %202, %43, %172 : vector<8xf32>
    %204 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %205 = memref.load %assume_align[%arg0, %204, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %206 = vector.broadcast %205 : f32 to vector<8xf32>
    %207 = vector.fma %206, %43, %176 : vector<8xf32>
    %208 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %209 = memref.load %assume_align[%arg0, %208, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %210 = vector.broadcast %209 : f32 to vector<8xf32>
    %211 = vector.fma %210, %43, %180 : vector<8xf32>
    %212 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %213 = memref.load %assume_align[%arg0, %212, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %214 = vector.broadcast %213 : f32 to vector<8xf32>
    %215 = vector.fma %214, %43, %184 : vector<8xf32>
    %216 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %217 = memref.load %assume_align[%arg0, %216, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %218 = vector.broadcast %217 : f32 to vector<8xf32>
    %219 = vector.fma %218, %43, %188 : vector<8xf32>
    %220 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %221 = memref.load %assume_align[%arg0, %220, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %222 = vector.broadcast %221 : f32 to vector<8xf32>
    %223 = vector.fma %222, %43, %192 : vector<8xf32>
    %224 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %225 = memref.load %assume_align[%arg0, %224, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %226 = vector.broadcast %225 : f32 to vector<8xf32>
    %227 = vector.fma %226, %43, %196 : vector<8xf32>
    %228 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %229 = vector.broadcast %228 : f32 to vector<8xf32>
    %230 = vector.fma %229, %44, %199 : vector<8xf32>
    %231 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %232 = memref.load %assume_align[%arg0, %231, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %233 = vector.broadcast %232 : f32 to vector<8xf32>
    %234 = vector.fma %233, %44, %203 : vector<8xf32>
    %235 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %236 = memref.load %assume_align[%arg0, %235, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %237 = vector.broadcast %236 : f32 to vector<8xf32>
    %238 = vector.fma %237, %44, %207 : vector<8xf32>
    %239 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %240 = memref.load %assume_align[%arg0, %239, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %241 = vector.broadcast %240 : f32 to vector<8xf32>
    %242 = vector.fma %241, %44, %211 : vector<8xf32>
    %243 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %244 = memref.load %assume_align[%arg0, %243, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %245 = vector.broadcast %244 : f32 to vector<8xf32>
    %246 = vector.fma %245, %44, %215 : vector<8xf32>
    %247 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %248 = memref.load %assume_align[%arg0, %247, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %249 = vector.broadcast %248 : f32 to vector<8xf32>
    %250 = vector.fma %249, %44, %219 : vector<8xf32>
    %251 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %252 = memref.load %assume_align[%arg0, %251, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %253 = vector.broadcast %252 : f32 to vector<8xf32>
    %254 = vector.fma %253, %44, %223 : vector<8xf32>
    %255 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %256 = memref.load %assume_align[%arg0, %255, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %257 = vector.broadcast %256 : f32 to vector<8xf32>
    %258 = vector.fma %257, %44, %227 : vector<8xf32>
    %259 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %260 = vector.broadcast %259 : f32 to vector<8xf32>
    %261 = vector.fma %260, %45, %230 : vector<8xf32>
    %262 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %263 = memref.load %assume_align[%arg0, %262, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %264 = vector.broadcast %263 : f32 to vector<8xf32>
    %265 = vector.fma %264, %45, %234 : vector<8xf32>
    %266 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %267 = memref.load %assume_align[%arg0, %266, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %268 = vector.broadcast %267 : f32 to vector<8xf32>
    %269 = vector.fma %268, %45, %238 : vector<8xf32>
    %270 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %271 = memref.load %assume_align[%arg0, %270, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %272 = vector.broadcast %271 : f32 to vector<8xf32>
    %273 = vector.fma %272, %45, %242 : vector<8xf32>
    %274 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %275 = memref.load %assume_align[%arg0, %274, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %276 = vector.broadcast %275 : f32 to vector<8xf32>
    %277 = vector.fma %276, %45, %246 : vector<8xf32>
    %278 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %279 = memref.load %assume_align[%arg0, %278, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %280 = vector.broadcast %279 : f32 to vector<8xf32>
    %281 = vector.fma %280, %45, %250 : vector<8xf32>
    %282 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %283 = memref.load %assume_align[%arg0, %282, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %284 = vector.broadcast %283 : f32 to vector<8xf32>
    %285 = vector.fma %284, %45, %254 : vector<8xf32>
    %286 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %287 = memref.load %assume_align[%arg0, %286, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %288 = vector.broadcast %287 : f32 to vector<8xf32>
    %289 = vector.fma %288, %45, %258 : vector<8xf32>
    %290 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %291 = vector.broadcast %290 : f32 to vector<8xf32>
    %292 = vector.fma %291, %46, %261 : vector<8xf32>
    %293 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %294 = memref.load %assume_align[%arg0, %293, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %295 = vector.broadcast %294 : f32 to vector<8xf32>
    %296 = vector.fma %295, %46, %265 : vector<8xf32>
    %297 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %298 = memref.load %assume_align[%arg0, %297, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %299 = vector.broadcast %298 : f32 to vector<8xf32>
    %300 = vector.fma %299, %46, %269 : vector<8xf32>
    %301 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %302 = memref.load %assume_align[%arg0, %301, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %303 = vector.broadcast %302 : f32 to vector<8xf32>
    %304 = vector.fma %303, %46, %273 : vector<8xf32>
    %305 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %306 = memref.load %assume_align[%arg0, %305, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %307 = vector.broadcast %306 : f32 to vector<8xf32>
    %308 = vector.fma %307, %46, %277 : vector<8xf32>
    %309 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %310 = memref.load %assume_align[%arg0, %309, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %311 = vector.broadcast %310 : f32 to vector<8xf32>
    %312 = vector.fma %311, %46, %281 : vector<8xf32>
    %313 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %314 = memref.load %assume_align[%arg0, %313, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %315 = vector.broadcast %314 : f32 to vector<8xf32>
    %316 = vector.fma %315, %46, %285 : vector<8xf32>
    %317 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %318 = memref.load %assume_align[%arg0, %317, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %319 = vector.broadcast %318 : f32 to vector<8xf32>
    %320 = vector.fma %319, %46, %289 : vector<8xf32>
    %321 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %322 = vector.broadcast %321 : f32 to vector<8xf32>
    %323 = vector.fma %322, %47, %292 : vector<8xf32>
    %324 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %325 = memref.load %assume_align[%arg0, %324, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %326 = vector.broadcast %325 : f32 to vector<8xf32>
    %327 = vector.fma %326, %47, %296 : vector<8xf32>
    %328 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %329 = memref.load %assume_align[%arg0, %328, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %330 = vector.broadcast %329 : f32 to vector<8xf32>
    %331 = vector.fma %330, %47, %300 : vector<8xf32>
    %332 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %333 = memref.load %assume_align[%arg0, %332, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %334 = vector.broadcast %333 : f32 to vector<8xf32>
    %335 = vector.fma %334, %47, %304 : vector<8xf32>
    %336 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %337 = memref.load %assume_align[%arg0, %336, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %338 = vector.broadcast %337 : f32 to vector<8xf32>
    %339 = vector.fma %338, %47, %308 : vector<8xf32>
    %340 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %341 = memref.load %assume_align[%arg0, %340, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %342 = vector.broadcast %341 : f32 to vector<8xf32>
    %343 = vector.fma %342, %47, %312 : vector<8xf32>
    %344 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %345 = memref.load %assume_align[%arg0, %344, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %346 = vector.broadcast %345 : f32 to vector<8xf32>
    %347 = vector.fma %346, %47, %316 : vector<8xf32>
    %348 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %349 = memref.load %assume_align[%arg0, %348, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %350 = vector.broadcast %349 : f32 to vector<8xf32>
    %351 = vector.fma %350, %47, %320 : vector<8xf32>
    %352 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %353 = vector.broadcast %352 : f32 to vector<8xf32>
    %354 = vector.fma %353, %48, %323 : vector<8xf32>
    %355 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %356 = memref.load %assume_align[%arg0, %355, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %357 = vector.broadcast %356 : f32 to vector<8xf32>
    %358 = vector.fma %357, %48, %327 : vector<8xf32>
    %359 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %360 = memref.load %assume_align[%arg0, %359, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %361 = vector.broadcast %360 : f32 to vector<8xf32>
    %362 = vector.fma %361, %48, %331 : vector<8xf32>
    %363 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %364 = memref.load %assume_align[%arg0, %363, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %365 = vector.broadcast %364 : f32 to vector<8xf32>
    %366 = vector.fma %365, %48, %335 : vector<8xf32>
    %367 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %368 = memref.load %assume_align[%arg0, %367, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %369 = vector.broadcast %368 : f32 to vector<8xf32>
    %370 = vector.fma %369, %48, %339 : vector<8xf32>
    %371 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %372 = memref.load %assume_align[%arg0, %371, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %373 = vector.broadcast %372 : f32 to vector<8xf32>
    %374 = vector.fma %373, %48, %343 : vector<8xf32>
    %375 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %376 = memref.load %assume_align[%arg0, %375, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %377 = vector.broadcast %376 : f32 to vector<8xf32>
    %378 = vector.fma %377, %48, %347 : vector<8xf32>
    %379 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %380 = memref.load %assume_align[%arg0, %379, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %381 = vector.broadcast %380 : f32 to vector<8xf32>
    %382 = vector.fma %381, %48, %351 : vector<8xf32>
    %383 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %384 = vector.broadcast %383 : f32 to vector<8xf32>
    %385 = vector.fma %384, %49, %354 : vector<8xf32>
    %386 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %387 = memref.load %assume_align[%arg0, %386, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %388 = vector.broadcast %387 : f32 to vector<8xf32>
    %389 = vector.fma %388, %49, %358 : vector<8xf32>
    %390 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %391 = memref.load %assume_align[%arg0, %390, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %392 = vector.broadcast %391 : f32 to vector<8xf32>
    %393 = vector.fma %392, %49, %362 : vector<8xf32>
    %394 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %395 = memref.load %assume_align[%arg0, %394, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %396 = vector.broadcast %395 : f32 to vector<8xf32>
    %397 = vector.fma %396, %49, %366 : vector<8xf32>
    %398 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %399 = memref.load %assume_align[%arg0, %398, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %400 = vector.broadcast %399 : f32 to vector<8xf32>
    %401 = vector.fma %400, %49, %370 : vector<8xf32>
    %402 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %403 = memref.load %assume_align[%arg0, %402, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %404 = vector.broadcast %403 : f32 to vector<8xf32>
    %405 = vector.fma %404, %49, %374 : vector<8xf32>
    %406 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %407 = memref.load %assume_align[%arg0, %406, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %408 = vector.broadcast %407 : f32 to vector<8xf32>
    %409 = vector.fma %408, %49, %378 : vector<8xf32>
    %410 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %411 = memref.load %assume_align[%arg0, %410, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %412 = vector.broadcast %411 : f32 to vector<8xf32>
    %413 = vector.fma %412, %49, %382 : vector<8xf32>
    %414 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %415 = vector.broadcast %414 : f32 to vector<8xf32>
    %416 = vector.fma %415, %50, %385 : vector<8xf32>
    %417 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %418 = memref.load %assume_align[%arg0, %417, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %419 = vector.broadcast %418 : f32 to vector<8xf32>
    %420 = vector.fma %419, %50, %389 : vector<8xf32>
    %421 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %422 = memref.load %assume_align[%arg0, %421, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %423 = vector.broadcast %422 : f32 to vector<8xf32>
    %424 = vector.fma %423, %50, %393 : vector<8xf32>
    %425 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %426 = memref.load %assume_align[%arg0, %425, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %427 = vector.broadcast %426 : f32 to vector<8xf32>
    %428 = vector.fma %427, %50, %397 : vector<8xf32>
    %429 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %430 = memref.load %assume_align[%arg0, %429, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %431 = vector.broadcast %430 : f32 to vector<8xf32>
    %432 = vector.fma %431, %50, %401 : vector<8xf32>
    %433 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %434 = memref.load %assume_align[%arg0, %433, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %435 = vector.broadcast %434 : f32 to vector<8xf32>
    %436 = vector.fma %435, %50, %405 : vector<8xf32>
    %437 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %438 = memref.load %assume_align[%arg0, %437, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %439 = vector.broadcast %438 : f32 to vector<8xf32>
    %440 = vector.fma %439, %50, %409 : vector<8xf32>
    %441 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %442 = memref.load %assume_align[%arg0, %441, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %443 = vector.broadcast %442 : f32 to vector<8xf32>
    %444 = vector.fma %443, %50, %413 : vector<8xf32>
    %445 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %446 = vector.broadcast %445 : f32 to vector<8xf32>
    %447 = vector.fma %446, %51, %416 : vector<8xf32>
    %448 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %449 = memref.load %assume_align[%arg0, %448, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %450 = vector.broadcast %449 : f32 to vector<8xf32>
    %451 = vector.fma %450, %51, %420 : vector<8xf32>
    %452 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %453 = memref.load %assume_align[%arg0, %452, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %454 = vector.broadcast %453 : f32 to vector<8xf32>
    %455 = vector.fma %454, %51, %424 : vector<8xf32>
    %456 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %457 = memref.load %assume_align[%arg0, %456, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %458 = vector.broadcast %457 : f32 to vector<8xf32>
    %459 = vector.fma %458, %51, %428 : vector<8xf32>
    %460 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %461 = memref.load %assume_align[%arg0, %460, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %462 = vector.broadcast %461 : f32 to vector<8xf32>
    %463 = vector.fma %462, %51, %432 : vector<8xf32>
    %464 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %465 = memref.load %assume_align[%arg0, %464, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %466 = vector.broadcast %465 : f32 to vector<8xf32>
    %467 = vector.fma %466, %51, %436 : vector<8xf32>
    %468 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %469 = memref.load %assume_align[%arg0, %468, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %470 = vector.broadcast %469 : f32 to vector<8xf32>
    %471 = vector.fma %470, %51, %440 : vector<8xf32>
    %472 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %473 = memref.load %assume_align[%arg0, %472, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %474 = vector.broadcast %473 : f32 to vector<8xf32>
    %475 = vector.fma %474, %51, %444 : vector<8xf32>
    %476 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %477 = vector.broadcast %476 : f32 to vector<8xf32>
    %478 = vector.fma %477, %52, %447 : vector<8xf32>
    %479 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %480 = memref.load %assume_align[%arg0, %479, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %481 = vector.broadcast %480 : f32 to vector<8xf32>
    %482 = vector.fma %481, %52, %451 : vector<8xf32>
    %483 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %484 = memref.load %assume_align[%arg0, %483, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %485 = vector.broadcast %484 : f32 to vector<8xf32>
    %486 = vector.fma %485, %52, %455 : vector<8xf32>
    %487 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %488 = memref.load %assume_align[%arg0, %487, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %489 = vector.broadcast %488 : f32 to vector<8xf32>
    %490 = vector.fma %489, %52, %459 : vector<8xf32>
    %491 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %492 = memref.load %assume_align[%arg0, %491, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %493 = vector.broadcast %492 : f32 to vector<8xf32>
    %494 = vector.fma %493, %52, %463 : vector<8xf32>
    %495 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %496 = memref.load %assume_align[%arg0, %495, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %497 = vector.broadcast %496 : f32 to vector<8xf32>
    %498 = vector.fma %497, %52, %467 : vector<8xf32>
    %499 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %500 = memref.load %assume_align[%arg0, %499, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %501 = vector.broadcast %500 : f32 to vector<8xf32>
    %502 = vector.fma %501, %52, %471 : vector<8xf32>
    %503 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %504 = memref.load %assume_align[%arg0, %503, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %505 = vector.broadcast %504 : f32 to vector<8xf32>
    %506 = vector.fma %505, %52, %475 : vector<8xf32>
    %507 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %508 = vector.broadcast %507 : f32 to vector<8xf32>
    %509 = vector.fma %508, %53, %478 : vector<8xf32>
    %510 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %511 = memref.load %assume_align[%arg0, %510, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %512 = vector.broadcast %511 : f32 to vector<8xf32>
    %513 = vector.fma %512, %53, %482 : vector<8xf32>
    %514 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %515 = memref.load %assume_align[%arg0, %514, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %516 = vector.broadcast %515 : f32 to vector<8xf32>
    %517 = vector.fma %516, %53, %486 : vector<8xf32>
    %518 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %519 = memref.load %assume_align[%arg0, %518, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %520 = vector.broadcast %519 : f32 to vector<8xf32>
    %521 = vector.fma %520, %53, %490 : vector<8xf32>
    %522 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %523 = memref.load %assume_align[%arg0, %522, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %524 = vector.broadcast %523 : f32 to vector<8xf32>
    %525 = vector.fma %524, %53, %494 : vector<8xf32>
    %526 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %527 = memref.load %assume_align[%arg0, %526, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %528 = vector.broadcast %527 : f32 to vector<8xf32>
    %529 = vector.fma %528, %53, %498 : vector<8xf32>
    %530 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %531 = memref.load %assume_align[%arg0, %530, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %532 = vector.broadcast %531 : f32 to vector<8xf32>
    %533 = vector.fma %532, %53, %502 : vector<8xf32>
    %534 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %535 = memref.load %assume_align[%arg0, %534, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %536 = vector.broadcast %535 : f32 to vector<8xf32>
    %537 = vector.fma %536, %53, %506 : vector<8xf32>
    %538 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %539 = vector.broadcast %538 : f32 to vector<8xf32>
    %540 = vector.fma %539, %54, %509 : vector<8xf32>
    %541 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %542 = memref.load %assume_align[%arg0, %541, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %543 = vector.broadcast %542 : f32 to vector<8xf32>
    %544 = vector.fma %543, %54, %513 : vector<8xf32>
    %545 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %546 = memref.load %assume_align[%arg0, %545, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %547 = vector.broadcast %546 : f32 to vector<8xf32>
    %548 = vector.fma %547, %54, %517 : vector<8xf32>
    %549 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %550 = memref.load %assume_align[%arg0, %549, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %551 = vector.broadcast %550 : f32 to vector<8xf32>
    %552 = vector.fma %551, %54, %521 : vector<8xf32>
    %553 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %554 = memref.load %assume_align[%arg0, %553, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %555 = vector.broadcast %554 : f32 to vector<8xf32>
    %556 = vector.fma %555, %54, %525 : vector<8xf32>
    %557 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %558 = memref.load %assume_align[%arg0, %557, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %559 = vector.broadcast %558 : f32 to vector<8xf32>
    %560 = vector.fma %559, %54, %529 : vector<8xf32>
    %561 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %562 = memref.load %assume_align[%arg0, %561, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %563 = vector.broadcast %562 : f32 to vector<8xf32>
    %564 = vector.fma %563, %54, %533 : vector<8xf32>
    %565 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %566 = memref.load %assume_align[%arg0, %565, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %567 = vector.broadcast %566 : f32 to vector<8xf32>
    %568 = vector.fma %567, %54, %537 : vector<8xf32>
    %569 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %570 = vector.broadcast %569 : f32 to vector<8xf32>
    %571 = vector.fma %570, %55, %540 : vector<8xf32>
    %572 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %573 = memref.load %assume_align[%arg0, %572, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %574 = vector.broadcast %573 : f32 to vector<8xf32>
    %575 = vector.fma %574, %55, %544 : vector<8xf32>
    %576 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %577 = memref.load %assume_align[%arg0, %576, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %578 = vector.broadcast %577 : f32 to vector<8xf32>
    %579 = vector.fma %578, %55, %548 : vector<8xf32>
    %580 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %581 = memref.load %assume_align[%arg0, %580, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %582 = vector.broadcast %581 : f32 to vector<8xf32>
    %583 = vector.fma %582, %55, %552 : vector<8xf32>
    %584 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %585 = memref.load %assume_align[%arg0, %584, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %586 = vector.broadcast %585 : f32 to vector<8xf32>
    %587 = vector.fma %586, %55, %556 : vector<8xf32>
    %588 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %589 = memref.load %assume_align[%arg0, %588, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %590 = vector.broadcast %589 : f32 to vector<8xf32>
    %591 = vector.fma %590, %55, %560 : vector<8xf32>
    %592 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %593 = memref.load %assume_align[%arg0, %592, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %594 = vector.broadcast %593 : f32 to vector<8xf32>
    %595 = vector.fma %594, %55, %564 : vector<8xf32>
    %596 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %597 = memref.load %assume_align[%arg0, %596, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %598 = vector.broadcast %597 : f32 to vector<8xf32>
    %599 = vector.fma %598, %55, %568 : vector<8xf32>
    %600 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %601 = vector.broadcast %600 : f32 to vector<8xf32>
    %602 = vector.fma %601, %56, %571 : vector<8xf32>
    %603 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %604 = memref.load %assume_align[%arg0, %603, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %605 = vector.broadcast %604 : f32 to vector<8xf32>
    %606 = vector.fma %605, %56, %575 : vector<8xf32>
    %607 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %608 = memref.load %assume_align[%arg0, %607, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %609 = vector.broadcast %608 : f32 to vector<8xf32>
    %610 = vector.fma %609, %56, %579 : vector<8xf32>
    %611 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %612 = memref.load %assume_align[%arg0, %611, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %613 = vector.broadcast %612 : f32 to vector<8xf32>
    %614 = vector.fma %613, %56, %583 : vector<8xf32>
    %615 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %616 = memref.load %assume_align[%arg0, %615, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %617 = vector.broadcast %616 : f32 to vector<8xf32>
    %618 = vector.fma %617, %56, %587 : vector<8xf32>
    %619 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %620 = memref.load %assume_align[%arg0, %619, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %621 = vector.broadcast %620 : f32 to vector<8xf32>
    %622 = vector.fma %621, %56, %591 : vector<8xf32>
    %623 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %624 = memref.load %assume_align[%arg0, %623, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %625 = vector.broadcast %624 : f32 to vector<8xf32>
    %626 = vector.fma %625, %56, %595 : vector<8xf32>
    %627 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %628 = memref.load %assume_align[%arg0, %627, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %629 = vector.broadcast %628 : f32 to vector<8xf32>
    %630 = vector.fma %629, %56, %599 : vector<8xf32>
    %631 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %632 = vector.broadcast %631 : f32 to vector<8xf32>
    %633 = vector.fma %632, %57, %602 : vector<8xf32>
    %634 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %635 = memref.load %assume_align[%arg0, %634, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %636 = vector.broadcast %635 : f32 to vector<8xf32>
    %637 = vector.fma %636, %57, %606 : vector<8xf32>
    %638 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %639 = memref.load %assume_align[%arg0, %638, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %640 = vector.broadcast %639 : f32 to vector<8xf32>
    %641 = vector.fma %640, %57, %610 : vector<8xf32>
    %642 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %643 = memref.load %assume_align[%arg0, %642, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %644 = vector.broadcast %643 : f32 to vector<8xf32>
    %645 = vector.fma %644, %57, %614 : vector<8xf32>
    %646 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %647 = memref.load %assume_align[%arg0, %646, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %648 = vector.broadcast %647 : f32 to vector<8xf32>
    %649 = vector.fma %648, %57, %618 : vector<8xf32>
    %650 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %651 = memref.load %assume_align[%arg0, %650, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %652 = vector.broadcast %651 : f32 to vector<8xf32>
    %653 = vector.fma %652, %57, %622 : vector<8xf32>
    %654 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %655 = memref.load %assume_align[%arg0, %654, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %656 = vector.broadcast %655 : f32 to vector<8xf32>
    %657 = vector.fma %656, %57, %626 : vector<8xf32>
    %658 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %659 = memref.load %assume_align[%arg0, %658, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %660 = vector.broadcast %659 : f32 to vector<8xf32>
    %661 = vector.fma %660, %57, %630 : vector<8xf32>
    %662 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %663 = vector.broadcast %662 : f32 to vector<8xf32>
    %664 = vector.fma %663, %58, %633 : vector<8xf32>
    %665 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %666 = memref.load %assume_align[%arg0, %665, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %667 = vector.broadcast %666 : f32 to vector<8xf32>
    %668 = vector.fma %667, %58, %637 : vector<8xf32>
    %669 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %670 = memref.load %assume_align[%arg0, %669, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %671 = vector.broadcast %670 : f32 to vector<8xf32>
    %672 = vector.fma %671, %58, %641 : vector<8xf32>
    %673 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %674 = memref.load %assume_align[%arg0, %673, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %675 = vector.broadcast %674 : f32 to vector<8xf32>
    %676 = vector.fma %675, %58, %645 : vector<8xf32>
    %677 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %678 = memref.load %assume_align[%arg0, %677, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %679 = vector.broadcast %678 : f32 to vector<8xf32>
    %680 = vector.fma %679, %58, %649 : vector<8xf32>
    %681 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %682 = memref.load %assume_align[%arg0, %681, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %683 = vector.broadcast %682 : f32 to vector<8xf32>
    %684 = vector.fma %683, %58, %653 : vector<8xf32>
    %685 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %686 = memref.load %assume_align[%arg0, %685, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %687 = vector.broadcast %686 : f32 to vector<8xf32>
    %688 = vector.fma %687, %58, %657 : vector<8xf32>
    %689 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %690 = memref.load %assume_align[%arg0, %689, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %691 = vector.broadcast %690 : f32 to vector<8xf32>
    %692 = vector.fma %691, %58, %661 : vector<8xf32>
    %693 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %694 = vector.broadcast %693 : f32 to vector<8xf32>
    %695 = vector.fma %694, %59, %664 : vector<8xf32>
    %696 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %697 = memref.load %assume_align[%arg0, %696, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %698 = vector.broadcast %697 : f32 to vector<8xf32>
    %699 = vector.fma %698, %59, %668 : vector<8xf32>
    %700 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %701 = memref.load %assume_align[%arg0, %700, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %702 = vector.broadcast %701 : f32 to vector<8xf32>
    %703 = vector.fma %702, %59, %672 : vector<8xf32>
    %704 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %705 = memref.load %assume_align[%arg0, %704, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %706 = vector.broadcast %705 : f32 to vector<8xf32>
    %707 = vector.fma %706, %59, %676 : vector<8xf32>
    %708 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %709 = memref.load %assume_align[%arg0, %708, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %710 = vector.broadcast %709 : f32 to vector<8xf32>
    %711 = vector.fma %710, %59, %680 : vector<8xf32>
    %712 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %713 = memref.load %assume_align[%arg0, %712, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %714 = vector.broadcast %713 : f32 to vector<8xf32>
    %715 = vector.fma %714, %59, %684 : vector<8xf32>
    %716 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %717 = memref.load %assume_align[%arg0, %716, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %718 = vector.broadcast %717 : f32 to vector<8xf32>
    %719 = vector.fma %718, %59, %688 : vector<8xf32>
    %720 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %721 = memref.load %assume_align[%arg0, %720, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %722 = vector.broadcast %721 : f32 to vector<8xf32>
    %723 = vector.fma %722, %59, %692 : vector<8xf32>
    %724 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %725 = vector.broadcast %724 : f32 to vector<8xf32>
    %726 = vector.fma %725, %60, %695 : vector<8xf32>
    %727 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %728 = memref.load %assume_align[%arg0, %727, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %729 = vector.broadcast %728 : f32 to vector<8xf32>
    %730 = vector.fma %729, %60, %699 : vector<8xf32>
    %731 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %732 = memref.load %assume_align[%arg0, %731, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %733 = vector.broadcast %732 : f32 to vector<8xf32>
    %734 = vector.fma %733, %60, %703 : vector<8xf32>
    %735 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %736 = memref.load %assume_align[%arg0, %735, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %737 = vector.broadcast %736 : f32 to vector<8xf32>
    %738 = vector.fma %737, %60, %707 : vector<8xf32>
    %739 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %740 = memref.load %assume_align[%arg0, %739, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %741 = vector.broadcast %740 : f32 to vector<8xf32>
    %742 = vector.fma %741, %60, %711 : vector<8xf32>
    %743 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %744 = memref.load %assume_align[%arg0, %743, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %745 = vector.broadcast %744 : f32 to vector<8xf32>
    %746 = vector.fma %745, %60, %715 : vector<8xf32>
    %747 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %748 = memref.load %assume_align[%arg0, %747, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %749 = vector.broadcast %748 : f32 to vector<8xf32>
    %750 = vector.fma %749, %60, %719 : vector<8xf32>
    %751 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %752 = memref.load %assume_align[%arg0, %751, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %753 = vector.broadcast %752 : f32 to vector<8xf32>
    %754 = vector.fma %753, %60, %723 : vector<8xf32>
    %755 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %756 = vector.broadcast %755 : f32 to vector<8xf32>
    %757 = vector.fma %756, %61, %726 : vector<8xf32>
    %758 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %759 = memref.load %assume_align[%arg0, %758, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %760 = vector.broadcast %759 : f32 to vector<8xf32>
    %761 = vector.fma %760, %61, %730 : vector<8xf32>
    %762 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %763 = memref.load %assume_align[%arg0, %762, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %764 = vector.broadcast %763 : f32 to vector<8xf32>
    %765 = vector.fma %764, %61, %734 : vector<8xf32>
    %766 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %767 = memref.load %assume_align[%arg0, %766, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %768 = vector.broadcast %767 : f32 to vector<8xf32>
    %769 = vector.fma %768, %61, %738 : vector<8xf32>
    %770 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %771 = memref.load %assume_align[%arg0, %770, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %772 = vector.broadcast %771 : f32 to vector<8xf32>
    %773 = vector.fma %772, %61, %742 : vector<8xf32>
    %774 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %775 = memref.load %assume_align[%arg0, %774, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %776 = vector.broadcast %775 : f32 to vector<8xf32>
    %777 = vector.fma %776, %61, %746 : vector<8xf32>
    %778 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %779 = memref.load %assume_align[%arg0, %778, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %780 = vector.broadcast %779 : f32 to vector<8xf32>
    %781 = vector.fma %780, %61, %750 : vector<8xf32>
    %782 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %783 = memref.load %assume_align[%arg0, %782, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %784 = vector.broadcast %783 : f32 to vector<8xf32>
    %785 = vector.fma %784, %61, %754 : vector<8xf32>
    %786 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %787 = vector.broadcast %786 : f32 to vector<8xf32>
    %788 = vector.fma %787, %62, %757 : vector<8xf32>
    %789 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %790 = memref.load %assume_align[%arg0, %789, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %791 = vector.broadcast %790 : f32 to vector<8xf32>
    %792 = vector.fma %791, %62, %761 : vector<8xf32>
    %793 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %794 = memref.load %assume_align[%arg0, %793, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %795 = vector.broadcast %794 : f32 to vector<8xf32>
    %796 = vector.fma %795, %62, %765 : vector<8xf32>
    %797 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %798 = memref.load %assume_align[%arg0, %797, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %799 = vector.broadcast %798 : f32 to vector<8xf32>
    %800 = vector.fma %799, %62, %769 : vector<8xf32>
    %801 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %802 = memref.load %assume_align[%arg0, %801, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %803 = vector.broadcast %802 : f32 to vector<8xf32>
    %804 = vector.fma %803, %62, %773 : vector<8xf32>
    %805 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %806 = memref.load %assume_align[%arg0, %805, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %807 = vector.broadcast %806 : f32 to vector<8xf32>
    %808 = vector.fma %807, %62, %777 : vector<8xf32>
    %809 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %810 = memref.load %assume_align[%arg0, %809, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %811 = vector.broadcast %810 : f32 to vector<8xf32>
    %812 = vector.fma %811, %62, %781 : vector<8xf32>
    %813 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %814 = memref.load %assume_align[%arg0, %813, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %815 = vector.broadcast %814 : f32 to vector<8xf32>
    %816 = vector.fma %815, %62, %785 : vector<8xf32>
    %817 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %818 = vector.broadcast %817 : f32 to vector<8xf32>
    %819 = vector.fma %818, %63, %788 : vector<8xf32>
    %820 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %821 = memref.load %assume_align[%arg0, %820, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %822 = vector.broadcast %821 : f32 to vector<8xf32>
    %823 = vector.fma %822, %63, %792 : vector<8xf32>
    %824 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %825 = memref.load %assume_align[%arg0, %824, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %826 = vector.broadcast %825 : f32 to vector<8xf32>
    %827 = vector.fma %826, %63, %796 : vector<8xf32>
    %828 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %829 = memref.load %assume_align[%arg0, %828, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %830 = vector.broadcast %829 : f32 to vector<8xf32>
    %831 = vector.fma %830, %63, %800 : vector<8xf32>
    %832 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %833 = memref.load %assume_align[%arg0, %832, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %834 = vector.broadcast %833 : f32 to vector<8xf32>
    %835 = vector.fma %834, %63, %804 : vector<8xf32>
    %836 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %837 = memref.load %assume_align[%arg0, %836, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %838 = vector.broadcast %837 : f32 to vector<8xf32>
    %839 = vector.fma %838, %63, %808 : vector<8xf32>
    %840 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %841 = memref.load %assume_align[%arg0, %840, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %842 = vector.broadcast %841 : f32 to vector<8xf32>
    %843 = vector.fma %842, %63, %812 : vector<8xf32>
    %844 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %845 = memref.load %assume_align[%arg0, %844, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %846 = vector.broadcast %845 : f32 to vector<8xf32>
    %847 = vector.fma %846, %63, %816 : vector<8xf32>
    %848 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %849 = vector.broadcast %848 : f32 to vector<8xf32>
    %850 = vector.fma %849, %64, %819 : vector<8xf32>
    %851 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %852 = memref.load %assume_align[%arg0, %851, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %853 = vector.broadcast %852 : f32 to vector<8xf32>
    %854 = vector.fma %853, %64, %823 : vector<8xf32>
    %855 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %856 = memref.load %assume_align[%arg0, %855, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %857 = vector.broadcast %856 : f32 to vector<8xf32>
    %858 = vector.fma %857, %64, %827 : vector<8xf32>
    %859 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %860 = memref.load %assume_align[%arg0, %859, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %861 = vector.broadcast %860 : f32 to vector<8xf32>
    %862 = vector.fma %861, %64, %831 : vector<8xf32>
    %863 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %864 = memref.load %assume_align[%arg0, %863, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %865 = vector.broadcast %864 : f32 to vector<8xf32>
    %866 = vector.fma %865, %64, %835 : vector<8xf32>
    %867 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %868 = memref.load %assume_align[%arg0, %867, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %869 = vector.broadcast %868 : f32 to vector<8xf32>
    %870 = vector.fma %869, %64, %839 : vector<8xf32>
    %871 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %872 = memref.load %assume_align[%arg0, %871, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %873 = vector.broadcast %872 : f32 to vector<8xf32>
    %874 = vector.fma %873, %64, %843 : vector<8xf32>
    %875 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %876 = memref.load %assume_align[%arg0, %875, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %877 = vector.broadcast %876 : f32 to vector<8xf32>
    %878 = vector.fma %877, %64, %847 : vector<8xf32>
    %879 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %880 = vector.broadcast %879 : f32 to vector<8xf32>
    %881 = vector.fma %880, %65, %850 : vector<8xf32>
    %882 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %883 = memref.load %assume_align[%arg0, %882, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %884 = vector.broadcast %883 : f32 to vector<8xf32>
    %885 = vector.fma %884, %65, %854 : vector<8xf32>
    %886 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %887 = memref.load %assume_align[%arg0, %886, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %888 = vector.broadcast %887 : f32 to vector<8xf32>
    %889 = vector.fma %888, %65, %858 : vector<8xf32>
    %890 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %891 = memref.load %assume_align[%arg0, %890, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %892 = vector.broadcast %891 : f32 to vector<8xf32>
    %893 = vector.fma %892, %65, %862 : vector<8xf32>
    %894 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %895 = memref.load %assume_align[%arg0, %894, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %896 = vector.broadcast %895 : f32 to vector<8xf32>
    %897 = vector.fma %896, %65, %866 : vector<8xf32>
    %898 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %899 = memref.load %assume_align[%arg0, %898, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %900 = vector.broadcast %899 : f32 to vector<8xf32>
    %901 = vector.fma %900, %65, %870 : vector<8xf32>
    %902 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %903 = memref.load %assume_align[%arg0, %902, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %904 = vector.broadcast %903 : f32 to vector<8xf32>
    %905 = vector.fma %904, %65, %874 : vector<8xf32>
    %906 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %907 = memref.load %assume_align[%arg0, %906, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %908 = vector.broadcast %907 : f32 to vector<8xf32>
    %909 = vector.fma %908, %65, %878 : vector<8xf32>
    %910 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %911 = vector.broadcast %910 : f32 to vector<8xf32>
    %912 = vector.fma %911, %66, %881 : vector<8xf32>
    %913 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %914 = memref.load %assume_align[%arg0, %913, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %915 = vector.broadcast %914 : f32 to vector<8xf32>
    %916 = vector.fma %915, %66, %885 : vector<8xf32>
    %917 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %918 = memref.load %assume_align[%arg0, %917, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %919 = vector.broadcast %918 : f32 to vector<8xf32>
    %920 = vector.fma %919, %66, %889 : vector<8xf32>
    %921 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %922 = memref.load %assume_align[%arg0, %921, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %923 = vector.broadcast %922 : f32 to vector<8xf32>
    %924 = vector.fma %923, %66, %893 : vector<8xf32>
    %925 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %926 = memref.load %assume_align[%arg0, %925, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %927 = vector.broadcast %926 : f32 to vector<8xf32>
    %928 = vector.fma %927, %66, %897 : vector<8xf32>
    %929 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %930 = memref.load %assume_align[%arg0, %929, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %931 = vector.broadcast %930 : f32 to vector<8xf32>
    %932 = vector.fma %931, %66, %901 : vector<8xf32>
    %933 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %934 = memref.load %assume_align[%arg0, %933, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %935 = vector.broadcast %934 : f32 to vector<8xf32>
    %936 = vector.fma %935, %66, %905 : vector<8xf32>
    %937 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %938 = memref.load %assume_align[%arg0, %937, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %939 = vector.broadcast %938 : f32 to vector<8xf32>
    %940 = vector.fma %939, %66, %909 : vector<8xf32>
    %941 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %942 = vector.broadcast %941 : f32 to vector<8xf32>
    %943 = vector.fma %942, %67, %912 : vector<8xf32>
    %944 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %945 = memref.load %assume_align[%arg0, %944, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %946 = vector.broadcast %945 : f32 to vector<8xf32>
    %947 = vector.fma %946, %67, %916 : vector<8xf32>
    %948 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %949 = memref.load %assume_align[%arg0, %948, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %950 = vector.broadcast %949 : f32 to vector<8xf32>
    %951 = vector.fma %950, %67, %920 : vector<8xf32>
    %952 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %953 = memref.load %assume_align[%arg0, %952, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %954 = vector.broadcast %953 : f32 to vector<8xf32>
    %955 = vector.fma %954, %67, %924 : vector<8xf32>
    %956 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %957 = memref.load %assume_align[%arg0, %956, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %958 = vector.broadcast %957 : f32 to vector<8xf32>
    %959 = vector.fma %958, %67, %928 : vector<8xf32>
    %960 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %961 = memref.load %assume_align[%arg0, %960, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %962 = vector.broadcast %961 : f32 to vector<8xf32>
    %963 = vector.fma %962, %67, %932 : vector<8xf32>
    %964 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %965 = memref.load %assume_align[%arg0, %964, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %966 = vector.broadcast %965 : f32 to vector<8xf32>
    %967 = vector.fma %966, %67, %936 : vector<8xf32>
    %968 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %969 = memref.load %assume_align[%arg0, %968, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %970 = vector.broadcast %969 : f32 to vector<8xf32>
    %971 = vector.fma %970, %67, %940 : vector<8xf32>
    %972 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %973 = vector.broadcast %972 : f32 to vector<8xf32>
    %974 = vector.fma %973, %68, %943 : vector<8xf32>
    %975 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %976 = memref.load %assume_align[%arg0, %975, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %977 = vector.broadcast %976 : f32 to vector<8xf32>
    %978 = vector.fma %977, %68, %947 : vector<8xf32>
    %979 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %980 = memref.load %assume_align[%arg0, %979, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %981 = vector.broadcast %980 : f32 to vector<8xf32>
    %982 = vector.fma %981, %68, %951 : vector<8xf32>
    %983 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %984 = memref.load %assume_align[%arg0, %983, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %985 = vector.broadcast %984 : f32 to vector<8xf32>
    %986 = vector.fma %985, %68, %955 : vector<8xf32>
    %987 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %988 = memref.load %assume_align[%arg0, %987, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %989 = vector.broadcast %988 : f32 to vector<8xf32>
    %990 = vector.fma %989, %68, %959 : vector<8xf32>
    %991 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %992 = memref.load %assume_align[%arg0, %991, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %993 = vector.broadcast %992 : f32 to vector<8xf32>
    %994 = vector.fma %993, %68, %963 : vector<8xf32>
    %995 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %996 = memref.load %assume_align[%arg0, %995, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %997 = vector.broadcast %996 : f32 to vector<8xf32>
    %998 = vector.fma %997, %68, %967 : vector<8xf32>
    %999 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1000 = memref.load %assume_align[%arg0, %999, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1001 = vector.broadcast %1000 : f32 to vector<8xf32>
    %1002 = vector.fma %1001, %68, %971 : vector<8xf32>
    %1003 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1004 = vector.broadcast %1003 : f32 to vector<8xf32>
    %1005 = vector.fma %1004, %69, %974 : vector<8xf32>
    %1006 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1007 = memref.load %assume_align[%arg0, %1006, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1008 = vector.broadcast %1007 : f32 to vector<8xf32>
    %1009 = vector.fma %1008, %69, %978 : vector<8xf32>
    %1010 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1011 = memref.load %assume_align[%arg0, %1010, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1012 = vector.broadcast %1011 : f32 to vector<8xf32>
    %1013 = vector.fma %1012, %69, %982 : vector<8xf32>
    %1014 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1015 = memref.load %assume_align[%arg0, %1014, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1016 = vector.broadcast %1015 : f32 to vector<8xf32>
    %1017 = vector.fma %1016, %69, %986 : vector<8xf32>
    %1018 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1019 = memref.load %assume_align[%arg0, %1018, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1020 = vector.broadcast %1019 : f32 to vector<8xf32>
    %1021 = vector.fma %1020, %69, %990 : vector<8xf32>
    %1022 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1023 = memref.load %assume_align[%arg0, %1022, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1024 = vector.broadcast %1023 : f32 to vector<8xf32>
    %1025 = vector.fma %1024, %69, %994 : vector<8xf32>
    %1026 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1027 = memref.load %assume_align[%arg0, %1026, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1028 = vector.broadcast %1027 : f32 to vector<8xf32>
    %1029 = vector.fma %1028, %69, %998 : vector<8xf32>
    %1030 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1031 = memref.load %assume_align[%arg0, %1030, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1032 = vector.broadcast %1031 : f32 to vector<8xf32>
    %1033 = vector.fma %1032, %69, %1002 : vector<8xf32>
    %1034 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1035 = vector.broadcast %1034 : f32 to vector<8xf32>
    %1036 = vector.fma %1035, %70, %1005 : vector<8xf32>
    %1037 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1038 = memref.load %assume_align[%arg0, %1037, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1039 = vector.broadcast %1038 : f32 to vector<8xf32>
    %1040 = vector.fma %1039, %70, %1009 : vector<8xf32>
    %1041 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1042 = memref.load %assume_align[%arg0, %1041, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1043 = vector.broadcast %1042 : f32 to vector<8xf32>
    %1044 = vector.fma %1043, %70, %1013 : vector<8xf32>
    %1045 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1046 = memref.load %assume_align[%arg0, %1045, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1047 = vector.broadcast %1046 : f32 to vector<8xf32>
    %1048 = vector.fma %1047, %70, %1017 : vector<8xf32>
    %1049 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1050 = memref.load %assume_align[%arg0, %1049, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1051 = vector.broadcast %1050 : f32 to vector<8xf32>
    %1052 = vector.fma %1051, %70, %1021 : vector<8xf32>
    %1053 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1054 = memref.load %assume_align[%arg0, %1053, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1055 = vector.broadcast %1054 : f32 to vector<8xf32>
    %1056 = vector.fma %1055, %70, %1025 : vector<8xf32>
    %1057 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1058 = memref.load %assume_align[%arg0, %1057, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1059 = vector.broadcast %1058 : f32 to vector<8xf32>
    %1060 = vector.fma %1059, %70, %1029 : vector<8xf32>
    %1061 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1062 = memref.load %assume_align[%arg0, %1061, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1063 = vector.broadcast %1062 : f32 to vector<8xf32>
    %1064 = vector.fma %1063, %70, %1033 : vector<8xf32>
    %1065 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1066 = vector.broadcast %1065 : f32 to vector<8xf32>
    %1067 = vector.fma %1066, %71, %1036 : vector<8xf32>
    %1068 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1069 = memref.load %assume_align[%arg0, %1068, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1070 = vector.broadcast %1069 : f32 to vector<8xf32>
    %1071 = vector.fma %1070, %71, %1040 : vector<8xf32>
    %1072 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1073 = memref.load %assume_align[%arg0, %1072, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1074 = vector.broadcast %1073 : f32 to vector<8xf32>
    %1075 = vector.fma %1074, %71, %1044 : vector<8xf32>
    %1076 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1077 = memref.load %assume_align[%arg0, %1076, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1078 = vector.broadcast %1077 : f32 to vector<8xf32>
    %1079 = vector.fma %1078, %71, %1048 : vector<8xf32>
    %1080 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1081 = memref.load %assume_align[%arg0, %1080, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1082 = vector.broadcast %1081 : f32 to vector<8xf32>
    %1083 = vector.fma %1082, %71, %1052 : vector<8xf32>
    %1084 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1085 = memref.load %assume_align[%arg0, %1084, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1086 = vector.broadcast %1085 : f32 to vector<8xf32>
    %1087 = vector.fma %1086, %71, %1056 : vector<8xf32>
    %1088 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1089 = memref.load %assume_align[%arg0, %1088, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1090 = vector.broadcast %1089 : f32 to vector<8xf32>
    %1091 = vector.fma %1090, %71, %1060 : vector<8xf32>
    %1092 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1093 = memref.load %assume_align[%arg0, %1092, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1094 = vector.broadcast %1093 : f32 to vector<8xf32>
    %1095 = vector.fma %1094, %71, %1064 : vector<8xf32>
    %1096 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1097 = vector.broadcast %1096 : f32 to vector<8xf32>
    %1098 = vector.fma %1097, %72, %1067 : vector<8xf32>
    %1099 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1100 = memref.load %assume_align[%arg0, %1099, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1101 = vector.broadcast %1100 : f32 to vector<8xf32>
    %1102 = vector.fma %1101, %72, %1071 : vector<8xf32>
    %1103 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1104 = memref.load %assume_align[%arg0, %1103, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1105 = vector.broadcast %1104 : f32 to vector<8xf32>
    %1106 = vector.fma %1105, %72, %1075 : vector<8xf32>
    %1107 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1108 = memref.load %assume_align[%arg0, %1107, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1109 = vector.broadcast %1108 : f32 to vector<8xf32>
    %1110 = vector.fma %1109, %72, %1079 : vector<8xf32>
    %1111 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1112 = memref.load %assume_align[%arg0, %1111, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1113 = vector.broadcast %1112 : f32 to vector<8xf32>
    %1114 = vector.fma %1113, %72, %1083 : vector<8xf32>
    %1115 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1116 = memref.load %assume_align[%arg0, %1115, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1117 = vector.broadcast %1116 : f32 to vector<8xf32>
    %1118 = vector.fma %1117, %72, %1087 : vector<8xf32>
    %1119 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1120 = memref.load %assume_align[%arg0, %1119, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1121 = vector.broadcast %1120 : f32 to vector<8xf32>
    %1122 = vector.fma %1121, %72, %1091 : vector<8xf32>
    %1123 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1124 = memref.load %assume_align[%arg0, %1123, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1125 = vector.broadcast %1124 : f32 to vector<8xf32>
    %1126 = vector.fma %1125, %72, %1095 : vector<8xf32>
    %1127 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1128 = vector.broadcast %1127 : f32 to vector<8xf32>
    %1129 = vector.fma %1128, %73, %1098 : vector<8xf32>
    %1130 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1131 = memref.load %assume_align[%arg0, %1130, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1132 = vector.broadcast %1131 : f32 to vector<8xf32>
    %1133 = vector.fma %1132, %73, %1102 : vector<8xf32>
    %1134 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1135 = memref.load %assume_align[%arg0, %1134, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1136 = vector.broadcast %1135 : f32 to vector<8xf32>
    %1137 = vector.fma %1136, %73, %1106 : vector<8xf32>
    %1138 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1139 = memref.load %assume_align[%arg0, %1138, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1140 = vector.broadcast %1139 : f32 to vector<8xf32>
    %1141 = vector.fma %1140, %73, %1110 : vector<8xf32>
    %1142 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1143 = memref.load %assume_align[%arg0, %1142, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1144 = vector.broadcast %1143 : f32 to vector<8xf32>
    %1145 = vector.fma %1144, %73, %1114 : vector<8xf32>
    %1146 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1147 = memref.load %assume_align[%arg0, %1146, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1148 = vector.broadcast %1147 : f32 to vector<8xf32>
    %1149 = vector.fma %1148, %73, %1118 : vector<8xf32>
    %1150 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1151 = memref.load %assume_align[%arg0, %1150, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1152 = vector.broadcast %1151 : f32 to vector<8xf32>
    %1153 = vector.fma %1152, %73, %1122 : vector<8xf32>
    %1154 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1155 = memref.load %assume_align[%arg0, %1154, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1156 = vector.broadcast %1155 : f32 to vector<8xf32>
    %1157 = vector.fma %1156, %73, %1126 : vector<8xf32>
    %1158 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1159 = vector.broadcast %1158 : f32 to vector<8xf32>
    %1160 = vector.fma %1159, %74, %1129 : vector<8xf32>
    %1161 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1162 = memref.load %assume_align[%arg0, %1161, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1163 = vector.broadcast %1162 : f32 to vector<8xf32>
    %1164 = vector.fma %1163, %74, %1133 : vector<8xf32>
    %1165 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1166 = memref.load %assume_align[%arg0, %1165, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1167 = vector.broadcast %1166 : f32 to vector<8xf32>
    %1168 = vector.fma %1167, %74, %1137 : vector<8xf32>
    %1169 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1170 = memref.load %assume_align[%arg0, %1169, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1171 = vector.broadcast %1170 : f32 to vector<8xf32>
    %1172 = vector.fma %1171, %74, %1141 : vector<8xf32>
    %1173 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1174 = memref.load %assume_align[%arg0, %1173, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1175 = vector.broadcast %1174 : f32 to vector<8xf32>
    %1176 = vector.fma %1175, %74, %1145 : vector<8xf32>
    %1177 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1178 = memref.load %assume_align[%arg0, %1177, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1179 = vector.broadcast %1178 : f32 to vector<8xf32>
    %1180 = vector.fma %1179, %74, %1149 : vector<8xf32>
    %1181 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1182 = memref.load %assume_align[%arg0, %1181, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1183 = vector.broadcast %1182 : f32 to vector<8xf32>
    %1184 = vector.fma %1183, %74, %1153 : vector<8xf32>
    %1185 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1186 = memref.load %assume_align[%arg0, %1185, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1187 = vector.broadcast %1186 : f32 to vector<8xf32>
    %1188 = vector.fma %1187, %74, %1157 : vector<8xf32>
    %1189 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1190 = vector.broadcast %1189 : f32 to vector<8xf32>
    %1191 = vector.fma %1190, %75, %1160 : vector<8xf32>
    %1192 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1193 = memref.load %assume_align[%arg0, %1192, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1194 = vector.broadcast %1193 : f32 to vector<8xf32>
    %1195 = vector.fma %1194, %75, %1164 : vector<8xf32>
    %1196 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1197 = memref.load %assume_align[%arg0, %1196, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1198 = vector.broadcast %1197 : f32 to vector<8xf32>
    %1199 = vector.fma %1198, %75, %1168 : vector<8xf32>
    %1200 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1201 = memref.load %assume_align[%arg0, %1200, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1202 = vector.broadcast %1201 : f32 to vector<8xf32>
    %1203 = vector.fma %1202, %75, %1172 : vector<8xf32>
    %1204 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1205 = memref.load %assume_align[%arg0, %1204, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1206 = vector.broadcast %1205 : f32 to vector<8xf32>
    %1207 = vector.fma %1206, %75, %1176 : vector<8xf32>
    %1208 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1209 = memref.load %assume_align[%arg0, %1208, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1210 = vector.broadcast %1209 : f32 to vector<8xf32>
    %1211 = vector.fma %1210, %75, %1180 : vector<8xf32>
    %1212 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1213 = memref.load %assume_align[%arg0, %1212, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1214 = vector.broadcast %1213 : f32 to vector<8xf32>
    %1215 = vector.fma %1214, %75, %1184 : vector<8xf32>
    %1216 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1217 = memref.load %assume_align[%arg0, %1216, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1218 = vector.broadcast %1217 : f32 to vector<8xf32>
    %1219 = vector.fma %1218, %75, %1188 : vector<8xf32>
    %1220 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1221 = vector.broadcast %1220 : f32 to vector<8xf32>
    %1222 = vector.fma %1221, %76, %1191 : vector<8xf32>
    %1223 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1224 = memref.load %assume_align[%arg0, %1223, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1225 = vector.broadcast %1224 : f32 to vector<8xf32>
    %1226 = vector.fma %1225, %76, %1195 : vector<8xf32>
    %1227 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1228 = memref.load %assume_align[%arg0, %1227, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1229 = vector.broadcast %1228 : f32 to vector<8xf32>
    %1230 = vector.fma %1229, %76, %1199 : vector<8xf32>
    %1231 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1232 = memref.load %assume_align[%arg0, %1231, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1233 = vector.broadcast %1232 : f32 to vector<8xf32>
    %1234 = vector.fma %1233, %76, %1203 : vector<8xf32>
    %1235 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1236 = memref.load %assume_align[%arg0, %1235, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1237 = vector.broadcast %1236 : f32 to vector<8xf32>
    %1238 = vector.fma %1237, %76, %1207 : vector<8xf32>
    %1239 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1240 = memref.load %assume_align[%arg0, %1239, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1241 = vector.broadcast %1240 : f32 to vector<8xf32>
    %1242 = vector.fma %1241, %76, %1211 : vector<8xf32>
    %1243 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1244 = memref.load %assume_align[%arg0, %1243, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1245 = vector.broadcast %1244 : f32 to vector<8xf32>
    %1246 = vector.fma %1245, %76, %1215 : vector<8xf32>
    %1247 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1248 = memref.load %assume_align[%arg0, %1247, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1249 = vector.broadcast %1248 : f32 to vector<8xf32>
    %1250 = vector.fma %1249, %76, %1219 : vector<8xf32>
    %1251 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1252 = vector.broadcast %1251 : f32 to vector<8xf32>
    %1253 = vector.fma %1252, %77, %1222 : vector<8xf32>
    %1254 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1255 = memref.load %assume_align[%arg0, %1254, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1256 = vector.broadcast %1255 : f32 to vector<8xf32>
    %1257 = vector.fma %1256, %77, %1226 : vector<8xf32>
    %1258 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1259 = memref.load %assume_align[%arg0, %1258, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1260 = vector.broadcast %1259 : f32 to vector<8xf32>
    %1261 = vector.fma %1260, %77, %1230 : vector<8xf32>
    %1262 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1263 = memref.load %assume_align[%arg0, %1262, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1264 = vector.broadcast %1263 : f32 to vector<8xf32>
    %1265 = vector.fma %1264, %77, %1234 : vector<8xf32>
    %1266 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1267 = memref.load %assume_align[%arg0, %1266, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1268 = vector.broadcast %1267 : f32 to vector<8xf32>
    %1269 = vector.fma %1268, %77, %1238 : vector<8xf32>
    %1270 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1271 = memref.load %assume_align[%arg0, %1270, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1272 = vector.broadcast %1271 : f32 to vector<8xf32>
    %1273 = vector.fma %1272, %77, %1242 : vector<8xf32>
    %1274 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1275 = memref.load %assume_align[%arg0, %1274, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1276 = vector.broadcast %1275 : f32 to vector<8xf32>
    %1277 = vector.fma %1276, %77, %1246 : vector<8xf32>
    %1278 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1279 = memref.load %assume_align[%arg0, %1278, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1280 = vector.broadcast %1279 : f32 to vector<8xf32>
    %1281 = vector.fma %1280, %77, %1250 : vector<8xf32>
    %1282 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1283 = vector.broadcast %1282 : f32 to vector<8xf32>
    %1284 = vector.fma %1283, %78, %1253 : vector<8xf32>
    %1285 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1286 = memref.load %assume_align[%arg0, %1285, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1287 = vector.broadcast %1286 : f32 to vector<8xf32>
    %1288 = vector.fma %1287, %78, %1257 : vector<8xf32>
    %1289 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1290 = memref.load %assume_align[%arg0, %1289, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1291 = vector.broadcast %1290 : f32 to vector<8xf32>
    %1292 = vector.fma %1291, %78, %1261 : vector<8xf32>
    %1293 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1294 = memref.load %assume_align[%arg0, %1293, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1295 = vector.broadcast %1294 : f32 to vector<8xf32>
    %1296 = vector.fma %1295, %78, %1265 : vector<8xf32>
    %1297 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1298 = memref.load %assume_align[%arg0, %1297, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1299 = vector.broadcast %1298 : f32 to vector<8xf32>
    %1300 = vector.fma %1299, %78, %1269 : vector<8xf32>
    %1301 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1302 = memref.load %assume_align[%arg0, %1301, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1303 = vector.broadcast %1302 : f32 to vector<8xf32>
    %1304 = vector.fma %1303, %78, %1273 : vector<8xf32>
    %1305 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1306 = memref.load %assume_align[%arg0, %1305, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1307 = vector.broadcast %1306 : f32 to vector<8xf32>
    %1308 = vector.fma %1307, %78, %1277 : vector<8xf32>
    %1309 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1310 = memref.load %assume_align[%arg0, %1309, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1311 = vector.broadcast %1310 : f32 to vector<8xf32>
    %1312 = vector.fma %1311, %78, %1281 : vector<8xf32>
    %1313 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1314 = vector.broadcast %1313 : f32 to vector<8xf32>
    %1315 = vector.fma %1314, %79, %1284 : vector<8xf32>
    %1316 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1317 = memref.load %assume_align[%arg0, %1316, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1318 = vector.broadcast %1317 : f32 to vector<8xf32>
    %1319 = vector.fma %1318, %79, %1288 : vector<8xf32>
    %1320 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1321 = memref.load %assume_align[%arg0, %1320, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1322 = vector.broadcast %1321 : f32 to vector<8xf32>
    %1323 = vector.fma %1322, %79, %1292 : vector<8xf32>
    %1324 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1325 = memref.load %assume_align[%arg0, %1324, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1326 = vector.broadcast %1325 : f32 to vector<8xf32>
    %1327 = vector.fma %1326, %79, %1296 : vector<8xf32>
    %1328 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1329 = memref.load %assume_align[%arg0, %1328, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1330 = vector.broadcast %1329 : f32 to vector<8xf32>
    %1331 = vector.fma %1330, %79, %1300 : vector<8xf32>
    %1332 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1333 = memref.load %assume_align[%arg0, %1332, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1334 = vector.broadcast %1333 : f32 to vector<8xf32>
    %1335 = vector.fma %1334, %79, %1304 : vector<8xf32>
    %1336 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1337 = memref.load %assume_align[%arg0, %1336, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1338 = vector.broadcast %1337 : f32 to vector<8xf32>
    %1339 = vector.fma %1338, %79, %1308 : vector<8xf32>
    %1340 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1341 = memref.load %assume_align[%arg0, %1340, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1342 = vector.broadcast %1341 : f32 to vector<8xf32>
    %1343 = vector.fma %1342, %79, %1312 : vector<8xf32>
    %1344 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1345 = vector.broadcast %1344 : f32 to vector<8xf32>
    %1346 = vector.fma %1345, %80, %1315 : vector<8xf32>
    %1347 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1348 = memref.load %assume_align[%arg0, %1347, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1349 = vector.broadcast %1348 : f32 to vector<8xf32>
    %1350 = vector.fma %1349, %80, %1319 : vector<8xf32>
    %1351 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1352 = memref.load %assume_align[%arg0, %1351, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1353 = vector.broadcast %1352 : f32 to vector<8xf32>
    %1354 = vector.fma %1353, %80, %1323 : vector<8xf32>
    %1355 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1356 = memref.load %assume_align[%arg0, %1355, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1357 = vector.broadcast %1356 : f32 to vector<8xf32>
    %1358 = vector.fma %1357, %80, %1327 : vector<8xf32>
    %1359 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1360 = memref.load %assume_align[%arg0, %1359, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1361 = vector.broadcast %1360 : f32 to vector<8xf32>
    %1362 = vector.fma %1361, %80, %1331 : vector<8xf32>
    %1363 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1364 = memref.load %assume_align[%arg0, %1363, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1365 = vector.broadcast %1364 : f32 to vector<8xf32>
    %1366 = vector.fma %1365, %80, %1335 : vector<8xf32>
    %1367 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1368 = memref.load %assume_align[%arg0, %1367, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1369 = vector.broadcast %1368 : f32 to vector<8xf32>
    %1370 = vector.fma %1369, %80, %1339 : vector<8xf32>
    %1371 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1372 = memref.load %assume_align[%arg0, %1371, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1373 = vector.broadcast %1372 : f32 to vector<8xf32>
    %1374 = vector.fma %1373, %80, %1343 : vector<8xf32>
    %1375 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1376 = vector.broadcast %1375 : f32 to vector<8xf32>
    %1377 = vector.fma %1376, %81, %1346 : vector<8xf32>
    %1378 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1379 = memref.load %assume_align[%arg0, %1378, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1380 = vector.broadcast %1379 : f32 to vector<8xf32>
    %1381 = vector.fma %1380, %81, %1350 : vector<8xf32>
    %1382 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1383 = memref.load %assume_align[%arg0, %1382, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1384 = vector.broadcast %1383 : f32 to vector<8xf32>
    %1385 = vector.fma %1384, %81, %1354 : vector<8xf32>
    %1386 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1387 = memref.load %assume_align[%arg0, %1386, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1388 = vector.broadcast %1387 : f32 to vector<8xf32>
    %1389 = vector.fma %1388, %81, %1358 : vector<8xf32>
    %1390 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1391 = memref.load %assume_align[%arg0, %1390, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1392 = vector.broadcast %1391 : f32 to vector<8xf32>
    %1393 = vector.fma %1392, %81, %1362 : vector<8xf32>
    %1394 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1395 = memref.load %assume_align[%arg0, %1394, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1396 = vector.broadcast %1395 : f32 to vector<8xf32>
    %1397 = vector.fma %1396, %81, %1366 : vector<8xf32>
    %1398 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1399 = memref.load %assume_align[%arg0, %1398, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1400 = vector.broadcast %1399 : f32 to vector<8xf32>
    %1401 = vector.fma %1400, %81, %1370 : vector<8xf32>
    %1402 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1403 = memref.load %assume_align[%arg0, %1402, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1404 = vector.broadcast %1403 : f32 to vector<8xf32>
    %1405 = vector.fma %1404, %81, %1374 : vector<8xf32>
    %1406 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1407 = vector.broadcast %1406 : f32 to vector<8xf32>
    %1408 = vector.fma %1407, %82, %1377 : vector<8xf32>
    %1409 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1410 = memref.load %assume_align[%arg0, %1409, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1411 = vector.broadcast %1410 : f32 to vector<8xf32>
    %1412 = vector.fma %1411, %82, %1381 : vector<8xf32>
    %1413 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1414 = memref.load %assume_align[%arg0, %1413, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1415 = vector.broadcast %1414 : f32 to vector<8xf32>
    %1416 = vector.fma %1415, %82, %1385 : vector<8xf32>
    %1417 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1418 = memref.load %assume_align[%arg0, %1417, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1419 = vector.broadcast %1418 : f32 to vector<8xf32>
    %1420 = vector.fma %1419, %82, %1389 : vector<8xf32>
    %1421 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1422 = memref.load %assume_align[%arg0, %1421, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1423 = vector.broadcast %1422 : f32 to vector<8xf32>
    %1424 = vector.fma %1423, %82, %1393 : vector<8xf32>
    %1425 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1426 = memref.load %assume_align[%arg0, %1425, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1427 = vector.broadcast %1426 : f32 to vector<8xf32>
    %1428 = vector.fma %1427, %82, %1397 : vector<8xf32>
    %1429 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1430 = memref.load %assume_align[%arg0, %1429, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1431 = vector.broadcast %1430 : f32 to vector<8xf32>
    %1432 = vector.fma %1431, %82, %1401 : vector<8xf32>
    %1433 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1434 = memref.load %assume_align[%arg0, %1433, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1435 = vector.broadcast %1434 : f32 to vector<8xf32>
    %1436 = vector.fma %1435, %82, %1405 : vector<8xf32>
    %1437 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1438 = vector.broadcast %1437 : f32 to vector<8xf32>
    %1439 = vector.fma %1438, %83, %1408 : vector<8xf32>
    %1440 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1441 = memref.load %assume_align[%arg0, %1440, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1442 = vector.broadcast %1441 : f32 to vector<8xf32>
    %1443 = vector.fma %1442, %83, %1412 : vector<8xf32>
    %1444 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1445 = memref.load %assume_align[%arg0, %1444, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1446 = vector.broadcast %1445 : f32 to vector<8xf32>
    %1447 = vector.fma %1446, %83, %1416 : vector<8xf32>
    %1448 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1449 = memref.load %assume_align[%arg0, %1448, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1450 = vector.broadcast %1449 : f32 to vector<8xf32>
    %1451 = vector.fma %1450, %83, %1420 : vector<8xf32>
    %1452 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1453 = memref.load %assume_align[%arg0, %1452, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1454 = vector.broadcast %1453 : f32 to vector<8xf32>
    %1455 = vector.fma %1454, %83, %1424 : vector<8xf32>
    %1456 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1457 = memref.load %assume_align[%arg0, %1456, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1458 = vector.broadcast %1457 : f32 to vector<8xf32>
    %1459 = vector.fma %1458, %83, %1428 : vector<8xf32>
    %1460 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1461 = memref.load %assume_align[%arg0, %1460, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1462 = vector.broadcast %1461 : f32 to vector<8xf32>
    %1463 = vector.fma %1462, %83, %1432 : vector<8xf32>
    %1464 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1465 = memref.load %assume_align[%arg0, %1464, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1466 = vector.broadcast %1465 : f32 to vector<8xf32>
    %1467 = vector.fma %1466, %83, %1436 : vector<8xf32>
    %1468 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1469 = vector.broadcast %1468 : f32 to vector<8xf32>
    %1470 = vector.fma %1469, %84, %1439 : vector<8xf32>
    %1471 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1472 = memref.load %assume_align[%arg0, %1471, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1473 = vector.broadcast %1472 : f32 to vector<8xf32>
    %1474 = vector.fma %1473, %84, %1443 : vector<8xf32>
    %1475 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1476 = memref.load %assume_align[%arg0, %1475, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1477 = vector.broadcast %1476 : f32 to vector<8xf32>
    %1478 = vector.fma %1477, %84, %1447 : vector<8xf32>
    %1479 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1480 = memref.load %assume_align[%arg0, %1479, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1481 = vector.broadcast %1480 : f32 to vector<8xf32>
    %1482 = vector.fma %1481, %84, %1451 : vector<8xf32>
    %1483 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1484 = memref.load %assume_align[%arg0, %1483, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1485 = vector.broadcast %1484 : f32 to vector<8xf32>
    %1486 = vector.fma %1485, %84, %1455 : vector<8xf32>
    %1487 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1488 = memref.load %assume_align[%arg0, %1487, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1489 = vector.broadcast %1488 : f32 to vector<8xf32>
    %1490 = vector.fma %1489, %84, %1459 : vector<8xf32>
    %1491 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1492 = memref.load %assume_align[%arg0, %1491, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1493 = vector.broadcast %1492 : f32 to vector<8xf32>
    %1494 = vector.fma %1493, %84, %1463 : vector<8xf32>
    %1495 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1496 = memref.load %assume_align[%arg0, %1495, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1497 = vector.broadcast %1496 : f32 to vector<8xf32>
    %1498 = vector.fma %1497, %84, %1467 : vector<8xf32>
    %1499 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1500 = vector.broadcast %1499 : f32 to vector<8xf32>
    %1501 = vector.fma %1500, %85, %1470 : vector<8xf32>
    %1502 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1503 = memref.load %assume_align[%arg0, %1502, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1504 = vector.broadcast %1503 : f32 to vector<8xf32>
    %1505 = vector.fma %1504, %85, %1474 : vector<8xf32>
    %1506 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1507 = memref.load %assume_align[%arg0, %1506, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1508 = vector.broadcast %1507 : f32 to vector<8xf32>
    %1509 = vector.fma %1508, %85, %1478 : vector<8xf32>
    %1510 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1511 = memref.load %assume_align[%arg0, %1510, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1512 = vector.broadcast %1511 : f32 to vector<8xf32>
    %1513 = vector.fma %1512, %85, %1482 : vector<8xf32>
    %1514 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1515 = memref.load %assume_align[%arg0, %1514, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1516 = vector.broadcast %1515 : f32 to vector<8xf32>
    %1517 = vector.fma %1516, %85, %1486 : vector<8xf32>
    %1518 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1519 = memref.load %assume_align[%arg0, %1518, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1520 = vector.broadcast %1519 : f32 to vector<8xf32>
    %1521 = vector.fma %1520, %85, %1490 : vector<8xf32>
    %1522 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1523 = memref.load %assume_align[%arg0, %1522, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1524 = vector.broadcast %1523 : f32 to vector<8xf32>
    %1525 = vector.fma %1524, %85, %1494 : vector<8xf32>
    %1526 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1527 = memref.load %assume_align[%arg0, %1526, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1528 = vector.broadcast %1527 : f32 to vector<8xf32>
    %1529 = vector.fma %1528, %85, %1498 : vector<8xf32>
    %1530 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1531 = vector.broadcast %1530 : f32 to vector<8xf32>
    %1532 = vector.fma %1531, %86, %1501 : vector<8xf32>
    %1533 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1534 = memref.load %assume_align[%arg0, %1533, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1535 = vector.broadcast %1534 : f32 to vector<8xf32>
    %1536 = vector.fma %1535, %86, %1505 : vector<8xf32>
    %1537 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1538 = memref.load %assume_align[%arg0, %1537, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1539 = vector.broadcast %1538 : f32 to vector<8xf32>
    %1540 = vector.fma %1539, %86, %1509 : vector<8xf32>
    %1541 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1542 = memref.load %assume_align[%arg0, %1541, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1543 = vector.broadcast %1542 : f32 to vector<8xf32>
    %1544 = vector.fma %1543, %86, %1513 : vector<8xf32>
    %1545 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1546 = memref.load %assume_align[%arg0, %1545, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1547 = vector.broadcast %1546 : f32 to vector<8xf32>
    %1548 = vector.fma %1547, %86, %1517 : vector<8xf32>
    %1549 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1550 = memref.load %assume_align[%arg0, %1549, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1551 = vector.broadcast %1550 : f32 to vector<8xf32>
    %1552 = vector.fma %1551, %86, %1521 : vector<8xf32>
    %1553 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1554 = memref.load %assume_align[%arg0, %1553, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1555 = vector.broadcast %1554 : f32 to vector<8xf32>
    %1556 = vector.fma %1555, %86, %1525 : vector<8xf32>
    %1557 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1558 = memref.load %assume_align[%arg0, %1557, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1559 = vector.broadcast %1558 : f32 to vector<8xf32>
    %1560 = vector.fma %1559, %86, %1529 : vector<8xf32>
    %1561 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1562 = vector.broadcast %1561 : f32 to vector<8xf32>
    %1563 = vector.fma %1562, %87, %1532 : vector<8xf32>
    %1564 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1565 = memref.load %assume_align[%arg0, %1564, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1566 = vector.broadcast %1565 : f32 to vector<8xf32>
    %1567 = vector.fma %1566, %87, %1536 : vector<8xf32>
    %1568 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1569 = memref.load %assume_align[%arg0, %1568, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1570 = vector.broadcast %1569 : f32 to vector<8xf32>
    %1571 = vector.fma %1570, %87, %1540 : vector<8xf32>
    %1572 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1573 = memref.load %assume_align[%arg0, %1572, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1574 = vector.broadcast %1573 : f32 to vector<8xf32>
    %1575 = vector.fma %1574, %87, %1544 : vector<8xf32>
    %1576 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1577 = memref.load %assume_align[%arg0, %1576, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1578 = vector.broadcast %1577 : f32 to vector<8xf32>
    %1579 = vector.fma %1578, %87, %1548 : vector<8xf32>
    %1580 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1581 = memref.load %assume_align[%arg0, %1580, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1582 = vector.broadcast %1581 : f32 to vector<8xf32>
    %1583 = vector.fma %1582, %87, %1552 : vector<8xf32>
    %1584 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1585 = memref.load %assume_align[%arg0, %1584, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1586 = vector.broadcast %1585 : f32 to vector<8xf32>
    %1587 = vector.fma %1586, %87, %1556 : vector<8xf32>
    %1588 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1589 = memref.load %assume_align[%arg0, %1588, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1590 = vector.broadcast %1589 : f32 to vector<8xf32>
    %1591 = vector.fma %1590, %87, %1560 : vector<8xf32>
    %1592 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1593 = vector.broadcast %1592 : f32 to vector<8xf32>
    %1594 = vector.fma %1593, %88, %1563 : vector<8xf32>
    %1595 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1596 = memref.load %assume_align[%arg0, %1595, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1597 = vector.broadcast %1596 : f32 to vector<8xf32>
    %1598 = vector.fma %1597, %88, %1567 : vector<8xf32>
    %1599 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1600 = memref.load %assume_align[%arg0, %1599, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1601 = vector.broadcast %1600 : f32 to vector<8xf32>
    %1602 = vector.fma %1601, %88, %1571 : vector<8xf32>
    %1603 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1604 = memref.load %assume_align[%arg0, %1603, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1605 = vector.broadcast %1604 : f32 to vector<8xf32>
    %1606 = vector.fma %1605, %88, %1575 : vector<8xf32>
    %1607 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1608 = memref.load %assume_align[%arg0, %1607, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1609 = vector.broadcast %1608 : f32 to vector<8xf32>
    %1610 = vector.fma %1609, %88, %1579 : vector<8xf32>
    %1611 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1612 = memref.load %assume_align[%arg0, %1611, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1613 = vector.broadcast %1612 : f32 to vector<8xf32>
    %1614 = vector.fma %1613, %88, %1583 : vector<8xf32>
    %1615 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1616 = memref.load %assume_align[%arg0, %1615, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1617 = vector.broadcast %1616 : f32 to vector<8xf32>
    %1618 = vector.fma %1617, %88, %1587 : vector<8xf32>
    %1619 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1620 = memref.load %assume_align[%arg0, %1619, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1621 = vector.broadcast %1620 : f32 to vector<8xf32>
    %1622 = vector.fma %1621, %88, %1591 : vector<8xf32>
    %1623 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1624 = vector.broadcast %1623 : f32 to vector<8xf32>
    %1625 = vector.fma %1624, %89, %1594 : vector<8xf32>
    %1626 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1627 = memref.load %assume_align[%arg0, %1626, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1628 = vector.broadcast %1627 : f32 to vector<8xf32>
    %1629 = vector.fma %1628, %89, %1598 : vector<8xf32>
    %1630 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1631 = memref.load %assume_align[%arg0, %1630, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1632 = vector.broadcast %1631 : f32 to vector<8xf32>
    %1633 = vector.fma %1632, %89, %1602 : vector<8xf32>
    %1634 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1635 = memref.load %assume_align[%arg0, %1634, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1636 = vector.broadcast %1635 : f32 to vector<8xf32>
    %1637 = vector.fma %1636, %89, %1606 : vector<8xf32>
    %1638 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1639 = memref.load %assume_align[%arg0, %1638, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1640 = vector.broadcast %1639 : f32 to vector<8xf32>
    %1641 = vector.fma %1640, %89, %1610 : vector<8xf32>
    %1642 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1643 = memref.load %assume_align[%arg0, %1642, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1644 = vector.broadcast %1643 : f32 to vector<8xf32>
    %1645 = vector.fma %1644, %89, %1614 : vector<8xf32>
    %1646 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1647 = memref.load %assume_align[%arg0, %1646, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1648 = vector.broadcast %1647 : f32 to vector<8xf32>
    %1649 = vector.fma %1648, %89, %1618 : vector<8xf32>
    %1650 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1651 = memref.load %assume_align[%arg0, %1650, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1652 = vector.broadcast %1651 : f32 to vector<8xf32>
    %1653 = vector.fma %1652, %89, %1622 : vector<8xf32>
    %1654 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1655 = vector.broadcast %1654 : f32 to vector<8xf32>
    %1656 = vector.fma %1655, %90, %1625 : vector<8xf32>
    %1657 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1658 = memref.load %assume_align[%arg0, %1657, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1659 = vector.broadcast %1658 : f32 to vector<8xf32>
    %1660 = vector.fma %1659, %90, %1629 : vector<8xf32>
    %1661 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1662 = memref.load %assume_align[%arg0, %1661, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1663 = vector.broadcast %1662 : f32 to vector<8xf32>
    %1664 = vector.fma %1663, %90, %1633 : vector<8xf32>
    %1665 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1666 = memref.load %assume_align[%arg0, %1665, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1667 = vector.broadcast %1666 : f32 to vector<8xf32>
    %1668 = vector.fma %1667, %90, %1637 : vector<8xf32>
    %1669 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1670 = memref.load %assume_align[%arg0, %1669, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1671 = vector.broadcast %1670 : f32 to vector<8xf32>
    %1672 = vector.fma %1671, %90, %1641 : vector<8xf32>
    %1673 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1674 = memref.load %assume_align[%arg0, %1673, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1675 = vector.broadcast %1674 : f32 to vector<8xf32>
    %1676 = vector.fma %1675, %90, %1645 : vector<8xf32>
    %1677 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1678 = memref.load %assume_align[%arg0, %1677, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1679 = vector.broadcast %1678 : f32 to vector<8xf32>
    %1680 = vector.fma %1679, %90, %1649 : vector<8xf32>
    %1681 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1682 = memref.load %assume_align[%arg0, %1681, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1683 = vector.broadcast %1682 : f32 to vector<8xf32>
    %1684 = vector.fma %1683, %90, %1653 : vector<8xf32>
    %1685 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1686 = vector.broadcast %1685 : f32 to vector<8xf32>
    %1687 = vector.fma %1686, %91, %1656 : vector<8xf32>
    %1688 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1689 = memref.load %assume_align[%arg0, %1688, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1690 = vector.broadcast %1689 : f32 to vector<8xf32>
    %1691 = vector.fma %1690, %91, %1660 : vector<8xf32>
    %1692 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1693 = memref.load %assume_align[%arg0, %1692, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1694 = vector.broadcast %1693 : f32 to vector<8xf32>
    %1695 = vector.fma %1694, %91, %1664 : vector<8xf32>
    %1696 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1697 = memref.load %assume_align[%arg0, %1696, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1698 = vector.broadcast %1697 : f32 to vector<8xf32>
    %1699 = vector.fma %1698, %91, %1668 : vector<8xf32>
    %1700 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1701 = memref.load %assume_align[%arg0, %1700, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1702 = vector.broadcast %1701 : f32 to vector<8xf32>
    %1703 = vector.fma %1702, %91, %1672 : vector<8xf32>
    %1704 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1705 = memref.load %assume_align[%arg0, %1704, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1706 = vector.broadcast %1705 : f32 to vector<8xf32>
    %1707 = vector.fma %1706, %91, %1676 : vector<8xf32>
    %1708 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1709 = memref.load %assume_align[%arg0, %1708, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1710 = vector.broadcast %1709 : f32 to vector<8xf32>
    %1711 = vector.fma %1710, %91, %1680 : vector<8xf32>
    %1712 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1713 = memref.load %assume_align[%arg0, %1712, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1714 = vector.broadcast %1713 : f32 to vector<8xf32>
    %1715 = vector.fma %1714, %91, %1684 : vector<8xf32>
    %1716 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1717 = vector.broadcast %1716 : f32 to vector<8xf32>
    %1718 = vector.fma %1717, %92, %1687 : vector<8xf32>
    %1719 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1720 = memref.load %assume_align[%arg0, %1719, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1721 = vector.broadcast %1720 : f32 to vector<8xf32>
    %1722 = vector.fma %1721, %92, %1691 : vector<8xf32>
    %1723 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1724 = memref.load %assume_align[%arg0, %1723, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1725 = vector.broadcast %1724 : f32 to vector<8xf32>
    %1726 = vector.fma %1725, %92, %1695 : vector<8xf32>
    %1727 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1728 = memref.load %assume_align[%arg0, %1727, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1729 = vector.broadcast %1728 : f32 to vector<8xf32>
    %1730 = vector.fma %1729, %92, %1699 : vector<8xf32>
    %1731 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1732 = memref.load %assume_align[%arg0, %1731, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1733 = vector.broadcast %1732 : f32 to vector<8xf32>
    %1734 = vector.fma %1733, %92, %1703 : vector<8xf32>
    %1735 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1736 = memref.load %assume_align[%arg0, %1735, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1737 = vector.broadcast %1736 : f32 to vector<8xf32>
    %1738 = vector.fma %1737, %92, %1707 : vector<8xf32>
    %1739 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1740 = memref.load %assume_align[%arg0, %1739, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1741 = vector.broadcast %1740 : f32 to vector<8xf32>
    %1742 = vector.fma %1741, %92, %1711 : vector<8xf32>
    %1743 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1744 = memref.load %assume_align[%arg0, %1743, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1745 = vector.broadcast %1744 : f32 to vector<8xf32>
    %1746 = vector.fma %1745, %92, %1715 : vector<8xf32>
    %1747 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1748 = vector.broadcast %1747 : f32 to vector<8xf32>
    %1749 = vector.fma %1748, %93, %1718 : vector<8xf32>
    %1750 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1751 = memref.load %assume_align[%arg0, %1750, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1752 = vector.broadcast %1751 : f32 to vector<8xf32>
    %1753 = vector.fma %1752, %93, %1722 : vector<8xf32>
    %1754 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1755 = memref.load %assume_align[%arg0, %1754, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1756 = vector.broadcast %1755 : f32 to vector<8xf32>
    %1757 = vector.fma %1756, %93, %1726 : vector<8xf32>
    %1758 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1759 = memref.load %assume_align[%arg0, %1758, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1760 = vector.broadcast %1759 : f32 to vector<8xf32>
    %1761 = vector.fma %1760, %93, %1730 : vector<8xf32>
    %1762 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1763 = memref.load %assume_align[%arg0, %1762, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1764 = vector.broadcast %1763 : f32 to vector<8xf32>
    %1765 = vector.fma %1764, %93, %1734 : vector<8xf32>
    %1766 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1767 = memref.load %assume_align[%arg0, %1766, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1768 = vector.broadcast %1767 : f32 to vector<8xf32>
    %1769 = vector.fma %1768, %93, %1738 : vector<8xf32>
    %1770 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1771 = memref.load %assume_align[%arg0, %1770, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1772 = vector.broadcast %1771 : f32 to vector<8xf32>
    %1773 = vector.fma %1772, %93, %1742 : vector<8xf32>
    %1774 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1775 = memref.load %assume_align[%arg0, %1774, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1776 = vector.broadcast %1775 : f32 to vector<8xf32>
    %1777 = vector.fma %1776, %93, %1746 : vector<8xf32>
    %1778 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1779 = vector.broadcast %1778 : f32 to vector<8xf32>
    %1780 = vector.fma %1779, %94, %1749 : vector<8xf32>
    %1781 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1782 = memref.load %assume_align[%arg0, %1781, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1783 = vector.broadcast %1782 : f32 to vector<8xf32>
    %1784 = vector.fma %1783, %94, %1753 : vector<8xf32>
    %1785 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1786 = memref.load %assume_align[%arg0, %1785, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1787 = vector.broadcast %1786 : f32 to vector<8xf32>
    %1788 = vector.fma %1787, %94, %1757 : vector<8xf32>
    %1789 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1790 = memref.load %assume_align[%arg0, %1789, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1791 = vector.broadcast %1790 : f32 to vector<8xf32>
    %1792 = vector.fma %1791, %94, %1761 : vector<8xf32>
    %1793 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1794 = memref.load %assume_align[%arg0, %1793, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1795 = vector.broadcast %1794 : f32 to vector<8xf32>
    %1796 = vector.fma %1795, %94, %1765 : vector<8xf32>
    %1797 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1798 = memref.load %assume_align[%arg0, %1797, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1799 = vector.broadcast %1798 : f32 to vector<8xf32>
    %1800 = vector.fma %1799, %94, %1769 : vector<8xf32>
    %1801 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1802 = memref.load %assume_align[%arg0, %1801, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1803 = vector.broadcast %1802 : f32 to vector<8xf32>
    %1804 = vector.fma %1803, %94, %1773 : vector<8xf32>
    %1805 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1806 = memref.load %assume_align[%arg0, %1805, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1807 = vector.broadcast %1806 : f32 to vector<8xf32>
    %1808 = vector.fma %1807, %94, %1777 : vector<8xf32>
    %1809 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1810 = vector.broadcast %1809 : f32 to vector<8xf32>
    %1811 = vector.fma %1810, %95, %1780 : vector<8xf32>
    %1812 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1813 = memref.load %assume_align[%arg0, %1812, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1814 = vector.broadcast %1813 : f32 to vector<8xf32>
    %1815 = vector.fma %1814, %95, %1784 : vector<8xf32>
    %1816 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1817 = memref.load %assume_align[%arg0, %1816, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1818 = vector.broadcast %1817 : f32 to vector<8xf32>
    %1819 = vector.fma %1818, %95, %1788 : vector<8xf32>
    %1820 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1821 = memref.load %assume_align[%arg0, %1820, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1822 = vector.broadcast %1821 : f32 to vector<8xf32>
    %1823 = vector.fma %1822, %95, %1792 : vector<8xf32>
    %1824 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1825 = memref.load %assume_align[%arg0, %1824, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1826 = vector.broadcast %1825 : f32 to vector<8xf32>
    %1827 = vector.fma %1826, %95, %1796 : vector<8xf32>
    %1828 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1829 = memref.load %assume_align[%arg0, %1828, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1830 = vector.broadcast %1829 : f32 to vector<8xf32>
    %1831 = vector.fma %1830, %95, %1800 : vector<8xf32>
    %1832 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1833 = memref.load %assume_align[%arg0, %1832, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1834 = vector.broadcast %1833 : f32 to vector<8xf32>
    %1835 = vector.fma %1834, %95, %1804 : vector<8xf32>
    %1836 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1837 = memref.load %assume_align[%arg0, %1836, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1838 = vector.broadcast %1837 : f32 to vector<8xf32>
    %1839 = vector.fma %1838, %95, %1808 : vector<8xf32>
    %1840 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1841 = vector.broadcast %1840 : f32 to vector<8xf32>
    %1842 = vector.fma %1841, %96, %1811 : vector<8xf32>
    %1843 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1844 = memref.load %assume_align[%arg0, %1843, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1845 = vector.broadcast %1844 : f32 to vector<8xf32>
    %1846 = vector.fma %1845, %96, %1815 : vector<8xf32>
    %1847 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1848 = memref.load %assume_align[%arg0, %1847, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1849 = vector.broadcast %1848 : f32 to vector<8xf32>
    %1850 = vector.fma %1849, %96, %1819 : vector<8xf32>
    %1851 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1852 = memref.load %assume_align[%arg0, %1851, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1853 = vector.broadcast %1852 : f32 to vector<8xf32>
    %1854 = vector.fma %1853, %96, %1823 : vector<8xf32>
    %1855 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1856 = memref.load %assume_align[%arg0, %1855, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1857 = vector.broadcast %1856 : f32 to vector<8xf32>
    %1858 = vector.fma %1857, %96, %1827 : vector<8xf32>
    %1859 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1860 = memref.load %assume_align[%arg0, %1859, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1861 = vector.broadcast %1860 : f32 to vector<8xf32>
    %1862 = vector.fma %1861, %96, %1831 : vector<8xf32>
    %1863 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1864 = memref.load %assume_align[%arg0, %1863, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1865 = vector.broadcast %1864 : f32 to vector<8xf32>
    %1866 = vector.fma %1865, %96, %1835 : vector<8xf32>
    %1867 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1868 = memref.load %assume_align[%arg0, %1867, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1869 = vector.broadcast %1868 : f32 to vector<8xf32>
    %1870 = vector.fma %1869, %96, %1839 : vector<8xf32>
    %1871 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1872 = vector.broadcast %1871 : f32 to vector<8xf32>
    %1873 = vector.fma %1872, %97, %1842 : vector<8xf32>
    %1874 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1875 = memref.load %assume_align[%arg0, %1874, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1876 = vector.broadcast %1875 : f32 to vector<8xf32>
    %1877 = vector.fma %1876, %97, %1846 : vector<8xf32>
    %1878 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1879 = memref.load %assume_align[%arg0, %1878, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1880 = vector.broadcast %1879 : f32 to vector<8xf32>
    %1881 = vector.fma %1880, %97, %1850 : vector<8xf32>
    %1882 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1883 = memref.load %assume_align[%arg0, %1882, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1884 = vector.broadcast %1883 : f32 to vector<8xf32>
    %1885 = vector.fma %1884, %97, %1854 : vector<8xf32>
    %1886 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1887 = memref.load %assume_align[%arg0, %1886, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1888 = vector.broadcast %1887 : f32 to vector<8xf32>
    %1889 = vector.fma %1888, %97, %1858 : vector<8xf32>
    %1890 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1891 = memref.load %assume_align[%arg0, %1890, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1892 = vector.broadcast %1891 : f32 to vector<8xf32>
    %1893 = vector.fma %1892, %97, %1862 : vector<8xf32>
    %1894 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1895 = memref.load %assume_align[%arg0, %1894, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1896 = vector.broadcast %1895 : f32 to vector<8xf32>
    %1897 = vector.fma %1896, %97, %1866 : vector<8xf32>
    %1898 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1899 = memref.load %assume_align[%arg0, %1898, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1900 = vector.broadcast %1899 : f32 to vector<8xf32>
    %1901 = vector.fma %1900, %97, %1870 : vector<8xf32>
    %1902 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1903 = vector.broadcast %1902 : f32 to vector<8xf32>
    %1904 = vector.fma %1903, %98, %1873 : vector<8xf32>
    %1905 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1906 = memref.load %assume_align[%arg0, %1905, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1907 = vector.broadcast %1906 : f32 to vector<8xf32>
    %1908 = vector.fma %1907, %98, %1877 : vector<8xf32>
    %1909 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1910 = memref.load %assume_align[%arg0, %1909, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1911 = vector.broadcast %1910 : f32 to vector<8xf32>
    %1912 = vector.fma %1911, %98, %1881 : vector<8xf32>
    %1913 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1914 = memref.load %assume_align[%arg0, %1913, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1915 = vector.broadcast %1914 : f32 to vector<8xf32>
    %1916 = vector.fma %1915, %98, %1885 : vector<8xf32>
    %1917 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1918 = memref.load %assume_align[%arg0, %1917, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1919 = vector.broadcast %1918 : f32 to vector<8xf32>
    %1920 = vector.fma %1919, %98, %1889 : vector<8xf32>
    %1921 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1922 = memref.load %assume_align[%arg0, %1921, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1923 = vector.broadcast %1922 : f32 to vector<8xf32>
    %1924 = vector.fma %1923, %98, %1893 : vector<8xf32>
    %1925 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1926 = memref.load %assume_align[%arg0, %1925, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1927 = vector.broadcast %1926 : f32 to vector<8xf32>
    %1928 = vector.fma %1927, %98, %1897 : vector<8xf32>
    %1929 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1930 = memref.load %assume_align[%arg0, %1929, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1931 = vector.broadcast %1930 : f32 to vector<8xf32>
    %1932 = vector.fma %1931, %98, %1901 : vector<8xf32>
    %1933 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1934 = vector.broadcast %1933 : f32 to vector<8xf32>
    %1935 = vector.fma %1934, %99, %1904 : vector<8xf32>
    %1936 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1937 = memref.load %assume_align[%arg0, %1936, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1938 = vector.broadcast %1937 : f32 to vector<8xf32>
    %1939 = vector.fma %1938, %99, %1908 : vector<8xf32>
    %1940 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1941 = memref.load %assume_align[%arg0, %1940, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1942 = vector.broadcast %1941 : f32 to vector<8xf32>
    %1943 = vector.fma %1942, %99, %1912 : vector<8xf32>
    %1944 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1945 = memref.load %assume_align[%arg0, %1944, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1946 = vector.broadcast %1945 : f32 to vector<8xf32>
    %1947 = vector.fma %1946, %99, %1916 : vector<8xf32>
    %1948 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1949 = memref.load %assume_align[%arg0, %1948, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1950 = vector.broadcast %1949 : f32 to vector<8xf32>
    %1951 = vector.fma %1950, %99, %1920 : vector<8xf32>
    %1952 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1953 = memref.load %assume_align[%arg0, %1952, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1954 = vector.broadcast %1953 : f32 to vector<8xf32>
    %1955 = vector.fma %1954, %99, %1924 : vector<8xf32>
    %1956 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1957 = memref.load %assume_align[%arg0, %1956, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1958 = vector.broadcast %1957 : f32 to vector<8xf32>
    %1959 = vector.fma %1958, %99, %1928 : vector<8xf32>
    %1960 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1961 = memref.load %assume_align[%arg0, %1960, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1962 = vector.broadcast %1961 : f32 to vector<8xf32>
    %1963 = vector.fma %1962, %99, %1932 : vector<8xf32>
    %1964 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1965 = vector.broadcast %1964 : f32 to vector<8xf32>
    %1966 = vector.fma %1965, %100, %1935 : vector<8xf32>
    %1967 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1968 = memref.load %assume_align[%arg0, %1967, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1969 = vector.broadcast %1968 : f32 to vector<8xf32>
    %1970 = vector.fma %1969, %100, %1939 : vector<8xf32>
    %1971 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %1972 = memref.load %assume_align[%arg0, %1971, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1973 = vector.broadcast %1972 : f32 to vector<8xf32>
    %1974 = vector.fma %1973, %100, %1943 : vector<8xf32>
    %1975 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %1976 = memref.load %assume_align[%arg0, %1975, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1977 = vector.broadcast %1976 : f32 to vector<8xf32>
    %1978 = vector.fma %1977, %100, %1947 : vector<8xf32>
    %1979 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %1980 = memref.load %assume_align[%arg0, %1979, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1981 = vector.broadcast %1980 : f32 to vector<8xf32>
    %1982 = vector.fma %1981, %100, %1951 : vector<8xf32>
    %1983 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %1984 = memref.load %assume_align[%arg0, %1983, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1985 = vector.broadcast %1984 : f32 to vector<8xf32>
    %1986 = vector.fma %1985, %100, %1955 : vector<8xf32>
    %1987 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %1988 = memref.load %assume_align[%arg0, %1987, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1989 = vector.broadcast %1988 : f32 to vector<8xf32>
    %1990 = vector.fma %1989, %100, %1959 : vector<8xf32>
    %1991 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %1992 = memref.load %assume_align[%arg0, %1991, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1993 = vector.broadcast %1992 : f32 to vector<8xf32>
    %1994 = vector.fma %1993, %100, %1963 : vector<8xf32>
    %1995 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %1996 = vector.broadcast %1995 : f32 to vector<8xf32>
    %1997 = vector.fma %1996, %101, %1966 : vector<8xf32>
    %1998 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %1999 = memref.load %assume_align[%arg0, %1998, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2000 = vector.broadcast %1999 : f32 to vector<8xf32>
    %2001 = vector.fma %2000, %101, %1970 : vector<8xf32>
    %2002 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2003 = memref.load %assume_align[%arg0, %2002, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2004 = vector.broadcast %2003 : f32 to vector<8xf32>
    %2005 = vector.fma %2004, %101, %1974 : vector<8xf32>
    %2006 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2007 = memref.load %assume_align[%arg0, %2006, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2008 = vector.broadcast %2007 : f32 to vector<8xf32>
    %2009 = vector.fma %2008, %101, %1978 : vector<8xf32>
    %2010 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2011 = memref.load %assume_align[%arg0, %2010, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2012 = vector.broadcast %2011 : f32 to vector<8xf32>
    %2013 = vector.fma %2012, %101, %1982 : vector<8xf32>
    %2014 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2015 = memref.load %assume_align[%arg0, %2014, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2016 = vector.broadcast %2015 : f32 to vector<8xf32>
    %2017 = vector.fma %2016, %101, %1986 : vector<8xf32>
    %2018 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2019 = memref.load %assume_align[%arg0, %2018, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2020 = vector.broadcast %2019 : f32 to vector<8xf32>
    %2021 = vector.fma %2020, %101, %1990 : vector<8xf32>
    %2022 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2023 = memref.load %assume_align[%arg0, %2022, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2024 = vector.broadcast %2023 : f32 to vector<8xf32>
    %2025 = vector.fma %2024, %101, %1994 : vector<8xf32>
    %2026 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2027 = vector.broadcast %2026 : f32 to vector<8xf32>
    %2028 = vector.fma %2027, %102, %1997 : vector<8xf32>
    %2029 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2030 = memref.load %assume_align[%arg0, %2029, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2031 = vector.broadcast %2030 : f32 to vector<8xf32>
    %2032 = vector.fma %2031, %102, %2001 : vector<8xf32>
    %2033 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2034 = memref.load %assume_align[%arg0, %2033, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2035 = vector.broadcast %2034 : f32 to vector<8xf32>
    %2036 = vector.fma %2035, %102, %2005 : vector<8xf32>
    %2037 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2038 = memref.load %assume_align[%arg0, %2037, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
    %2040 = vector.fma %2039, %102, %2009 : vector<8xf32>
    %2041 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2042 = memref.load %assume_align[%arg0, %2041, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2043 = vector.broadcast %2042 : f32 to vector<8xf32>
    %2044 = vector.fma %2043, %102, %2013 : vector<8xf32>
    %2045 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2046 = memref.load %assume_align[%arg0, %2045, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2047 = vector.broadcast %2046 : f32 to vector<8xf32>
    %2048 = vector.fma %2047, %102, %2017 : vector<8xf32>
    %2049 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2050 = memref.load %assume_align[%arg0, %2049, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2051 = vector.broadcast %2050 : f32 to vector<8xf32>
    %2052 = vector.fma %2051, %102, %2021 : vector<8xf32>
    %2053 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2054 = memref.load %assume_align[%arg0, %2053, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2055 = vector.broadcast %2054 : f32 to vector<8xf32>
    %2056 = vector.fma %2055, %102, %2025 : vector<8xf32>
    %2057 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2058 = vector.broadcast %2057 : f32 to vector<8xf32>
    %2059 = vector.fma %2058, %103, %2028 : vector<8xf32>
    %2060 = vector.insert %2059, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2061 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%arg1]
    %2062 = memref.load %assume_align[%arg0, %2061, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2063 = vector.broadcast %2062 : f32 to vector<8xf32>
    %2064 = vector.fma %2063, %103, %2032 : vector<8xf32>
    %2065 = vector.insert %2064, %2060 [1] : vector<8xf32> into vector<8x8xf32>
    %2066 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%arg1]
    %2067 = memref.load %assume_align[%arg0, %2066, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2068 = vector.broadcast %2067 : f32 to vector<8xf32>
    %2069 = vector.fma %2068, %103, %2036 : vector<8xf32>
    %2070 = vector.insert %2069, %2065 [2] : vector<8xf32> into vector<8x8xf32>
    %2071 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%arg1]
    %2072 = memref.load %assume_align[%arg0, %2071, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2073 = vector.broadcast %2072 : f32 to vector<8xf32>
    %2074 = vector.fma %2073, %103, %2040 : vector<8xf32>
    %2075 = vector.insert %2074, %2070 [3] : vector<8xf32> into vector<8x8xf32>
    %2076 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%arg1]
    %2077 = memref.load %assume_align[%arg0, %2076, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2078 = vector.broadcast %2077 : f32 to vector<8xf32>
    %2079 = vector.fma %2078, %103, %2044 : vector<8xf32>
    %2080 = vector.insert %2079, %2075 [4] : vector<8xf32> into vector<8x8xf32>
    %2081 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%arg1]
    %2082 = memref.load %assume_align[%arg0, %2081, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2083 = vector.broadcast %2082 : f32 to vector<8xf32>
    %2084 = vector.fma %2083, %103, %2048 : vector<8xf32>
    %2085 = vector.insert %2084, %2080 [5] : vector<8xf32> into vector<8x8xf32>
    %2086 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%arg1]
    %2087 = memref.load %assume_align[%arg0, %2086, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2088 = vector.broadcast %2087 : f32 to vector<8xf32>
    %2089 = vector.fma %2088, %103, %2052 : vector<8xf32>
    %2090 = vector.insert %2089, %2085 [6] : vector<8xf32> into vector<8x8xf32>
    %2091 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%arg1]
    %2092 = memref.load %assume_align[%arg0, %2091, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %2093 = vector.broadcast %2092 : f32 to vector<8xf32>
    %2094 = vector.fma %2093, %103, %2056 : vector<8xf32>
    %2095 = vector.insert %2094, %2090 [7] : vector<8xf32> into vector<8x8xf32>
    %2096 = vector.reduction <maximumf>, %2059, %cst : vector<8xf32> into f32
    %2097 = vector.insert %2096, %cst_0 [0] : f32 into vector<8xf32>
    %2098 = vector.reduction <maximumf>, %2064, %cst : vector<8xf32> into f32
    %2099 = vector.insert %2098, %2097 [1] : f32 into vector<8xf32>
    %2100 = vector.reduction <maximumf>, %2069, %cst : vector<8xf32> into f32
    %2101 = vector.insert %2100, %2099 [2] : f32 into vector<8xf32>
    %2102 = vector.reduction <maximumf>, %2074, %cst : vector<8xf32> into f32
    %2103 = vector.insert %2102, %2101 [3] : f32 into vector<8xf32>
    %2104 = vector.reduction <maximumf>, %2079, %cst : vector<8xf32> into f32
    %2105 = vector.insert %2104, %2103 [4] : f32 into vector<8xf32>
    %2106 = vector.reduction <maximumf>, %2084, %cst : vector<8xf32> into f32
    %2107 = vector.insert %2106, %2105 [5] : f32 into vector<8xf32>
    %2108 = vector.reduction <maximumf>, %2089, %cst : vector<8xf32> into f32
    %2109 = vector.insert %2108, %2107 [6] : f32 into vector<8xf32>
    %2110 = vector.reduction <maximumf>, %2094, %cst : vector<8xf32> into f32
    %2111 = vector.insert %2110, %2109 [7] : f32 into vector<8xf32>
    %2112 = arith.subf %2111, %cst_2 : vector<8xf32>
    %2113 = math.exp2 %2112 : vector<8xf32>
    %2114 = vector.insert %2113, %2 [0] : vector<8xf32> into vector<1x8xf32>
    %2115 = vector.broadcast %2114 : vector<1x8xf32> to vector<8x8xf32>
    %2116 = arith.mulf %2115, %cst_1 : vector<8x8xf32>
    %2117 = vector.extract %2116[0] : vector<8xf32> from vector<8x8xf32>
    %2118 = vector.insert_strided_slice %2117, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2119 = vector.extract %2116[1] : vector<8xf32> from vector<8x8xf32>
    %2120 = vector.insert_strided_slice %2119, %2118 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2121 = vector.extract %2116[2] : vector<8xf32> from vector<8x8xf32>
    %2122 = vector.insert_strided_slice %2121, %2120 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2123 = vector.extract %2116[3] : vector<8xf32> from vector<8x8xf32>
    %2124 = vector.insert_strided_slice %2123, %2122 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2125 = vector.extract %2116[4] : vector<8xf32> from vector<8x8xf32>
    %2126 = vector.insert_strided_slice %2125, %2124 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2127 = vector.extract %2116[5] : vector<8xf32> from vector<8x8xf32>
    %2128 = vector.insert_strided_slice %2127, %2126 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2129 = vector.extract %2116[6] : vector<8xf32> from vector<8x8xf32>
    %2130 = vector.insert_strided_slice %2129, %2128 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2131 = vector.extract %2116[7] : vector<8xf32> from vector<8x8xf32>
    %2132 = vector.insert_strided_slice %2131, %2130 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2133 = vector.shuffle %2132, %2132 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2134 = vector.extract_strided_slice %2133 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2135 = vector.extract_strided_slice %2133 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2136 = vector.extract_strided_slice %2133 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2137 = vector.extract_strided_slice %2133 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2138 = vector.extract_strided_slice %2133 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2139 = vector.extract_strided_slice %2133 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2140 = vector.extract_strided_slice %2133 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2141 = vector.extract_strided_slice %2133 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2142 = vector.insert_strided_slice %2111, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2143 = vector.insert_strided_slice %2111, %2142 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2144 = vector.insert_strided_slice %2111, %2143 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2145 = vector.insert_strided_slice %2111, %2144 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2146 = vector.insert_strided_slice %2111, %2145 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2147 = vector.insert_strided_slice %2111, %2146 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2148 = vector.insert_strided_slice %2111, %2147 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2149 = vector.insert_strided_slice %2111, %2148 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2150 = vector.shuffle %2149, %2149 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2151 = vector.extract_strided_slice %2150 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2152 = vector.insert %2151, %0 [0] : vector<8xf32> into vector<8x8xf32>
    %2153 = vector.extract_strided_slice %2150 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2154 = vector.insert %2153, %2152 [1] : vector<8xf32> into vector<8x8xf32>
    %2155 = vector.extract_strided_slice %2150 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2156 = vector.insert %2155, %2154 [2] : vector<8xf32> into vector<8x8xf32>
    %2157 = vector.extract_strided_slice %2150 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2158 = vector.insert %2157, %2156 [3] : vector<8xf32> into vector<8x8xf32>
    %2159 = vector.extract_strided_slice %2150 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2160 = vector.insert %2159, %2158 [4] : vector<8xf32> into vector<8x8xf32>
    %2161 = vector.extract_strided_slice %2150 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2162 = vector.insert %2161, %2160 [5] : vector<8xf32> into vector<8x8xf32>
    %2163 = vector.extract_strided_slice %2150 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2164 = vector.insert %2163, %2162 [6] : vector<8xf32> into vector<8x8xf32>
    %2165 = vector.extract_strided_slice %2150 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2166 = vector.insert %2165, %2164 [7] : vector<8xf32> into vector<8x8xf32>
    %2167 = arith.subf %2095, %2166 : vector<8x8xf32>
    %2168 = math.exp2 %2167 : vector<8x8xf32>
    %2169 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2170 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg3)
    %2171 = vector.load %assume_align_4[%arg0, %2170, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2172 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg3)
    %2173 = vector.load %assume_align_4[%arg0, %2172, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2174 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg3)
    %2175 = vector.load %assume_align_4[%arg0, %2174, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2176 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg3)
    %2177 = vector.load %assume_align_4[%arg0, %2176, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2178 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg3)
    %2179 = vector.load %assume_align_4[%arg0, %2178, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2180 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg3)
    %2181 = vector.load %assume_align_4[%arg0, %2180, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2182 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg3)
    %2183 = vector.load %assume_align_4[%arg0, %2182, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2184 = vector.extract %2168[0, 0] : f32 from vector<8x8xf32>
    %2185 = vector.broadcast %2184 : f32 to vector<8xf32>
    %2186 = vector.fma %2185, %2169, %2134 : vector<8xf32>
    %2187 = vector.extract %2168[1, 0] : f32 from vector<8x8xf32>
    %2188 = vector.broadcast %2187 : f32 to vector<8xf32>
    %2189 = vector.fma %2188, %2169, %2135 : vector<8xf32>
    %2190 = vector.extract %2168[2, 0] : f32 from vector<8x8xf32>
    %2191 = vector.broadcast %2190 : f32 to vector<8xf32>
    %2192 = vector.fma %2191, %2169, %2136 : vector<8xf32>
    %2193 = vector.extract %2168[3, 0] : f32 from vector<8x8xf32>
    %2194 = vector.broadcast %2193 : f32 to vector<8xf32>
    %2195 = vector.fma %2194, %2169, %2137 : vector<8xf32>
    %2196 = vector.extract %2168[4, 0] : f32 from vector<8x8xf32>
    %2197 = vector.broadcast %2196 : f32 to vector<8xf32>
    %2198 = vector.fma %2197, %2169, %2138 : vector<8xf32>
    %2199 = vector.extract %2168[5, 0] : f32 from vector<8x8xf32>
    %2200 = vector.broadcast %2199 : f32 to vector<8xf32>
    %2201 = vector.fma %2200, %2169, %2139 : vector<8xf32>
    %2202 = vector.extract %2168[6, 0] : f32 from vector<8x8xf32>
    %2203 = vector.broadcast %2202 : f32 to vector<8xf32>
    %2204 = vector.fma %2203, %2169, %2140 : vector<8xf32>
    %2205 = vector.extract %2168[7, 0] : f32 from vector<8x8xf32>
    %2206 = vector.broadcast %2205 : f32 to vector<8xf32>
    %2207 = vector.fma %2206, %2169, %2141 : vector<8xf32>
    %2208 = vector.extract %2168[0, 1] : f32 from vector<8x8xf32>
    %2209 = vector.broadcast %2208 : f32 to vector<8xf32>
    %2210 = vector.fma %2209, %2171, %2186 : vector<8xf32>
    %2211 = vector.extract %2168[1, 1] : f32 from vector<8x8xf32>
    %2212 = vector.broadcast %2211 : f32 to vector<8xf32>
    %2213 = vector.fma %2212, %2171, %2189 : vector<8xf32>
    %2214 = vector.extract %2168[2, 1] : f32 from vector<8x8xf32>
    %2215 = vector.broadcast %2214 : f32 to vector<8xf32>
    %2216 = vector.fma %2215, %2171, %2192 : vector<8xf32>
    %2217 = vector.extract %2168[3, 1] : f32 from vector<8x8xf32>
    %2218 = vector.broadcast %2217 : f32 to vector<8xf32>
    %2219 = vector.fma %2218, %2171, %2195 : vector<8xf32>
    %2220 = vector.extract %2168[4, 1] : f32 from vector<8x8xf32>
    %2221 = vector.broadcast %2220 : f32 to vector<8xf32>
    %2222 = vector.fma %2221, %2171, %2198 : vector<8xf32>
    %2223 = vector.extract %2168[5, 1] : f32 from vector<8x8xf32>
    %2224 = vector.broadcast %2223 : f32 to vector<8xf32>
    %2225 = vector.fma %2224, %2171, %2201 : vector<8xf32>
    %2226 = vector.extract %2168[6, 1] : f32 from vector<8x8xf32>
    %2227 = vector.broadcast %2226 : f32 to vector<8xf32>
    %2228 = vector.fma %2227, %2171, %2204 : vector<8xf32>
    %2229 = vector.extract %2168[7, 1] : f32 from vector<8x8xf32>
    %2230 = vector.broadcast %2229 : f32 to vector<8xf32>
    %2231 = vector.fma %2230, %2171, %2207 : vector<8xf32>
    %2232 = vector.extract %2168[0, 2] : f32 from vector<8x8xf32>
    %2233 = vector.broadcast %2232 : f32 to vector<8xf32>
    %2234 = vector.fma %2233, %2173, %2210 : vector<8xf32>
    %2235 = vector.extract %2168[1, 2] : f32 from vector<8x8xf32>
    %2236 = vector.broadcast %2235 : f32 to vector<8xf32>
    %2237 = vector.fma %2236, %2173, %2213 : vector<8xf32>
    %2238 = vector.extract %2168[2, 2] : f32 from vector<8x8xf32>
    %2239 = vector.broadcast %2238 : f32 to vector<8xf32>
    %2240 = vector.fma %2239, %2173, %2216 : vector<8xf32>
    %2241 = vector.extract %2168[3, 2] : f32 from vector<8x8xf32>
    %2242 = vector.broadcast %2241 : f32 to vector<8xf32>
    %2243 = vector.fma %2242, %2173, %2219 : vector<8xf32>
    %2244 = vector.extract %2168[4, 2] : f32 from vector<8x8xf32>
    %2245 = vector.broadcast %2244 : f32 to vector<8xf32>
    %2246 = vector.fma %2245, %2173, %2222 : vector<8xf32>
    %2247 = vector.extract %2168[5, 2] : f32 from vector<8x8xf32>
    %2248 = vector.broadcast %2247 : f32 to vector<8xf32>
    %2249 = vector.fma %2248, %2173, %2225 : vector<8xf32>
    %2250 = vector.extract %2168[6, 2] : f32 from vector<8x8xf32>
    %2251 = vector.broadcast %2250 : f32 to vector<8xf32>
    %2252 = vector.fma %2251, %2173, %2228 : vector<8xf32>
    %2253 = vector.extract %2168[7, 2] : f32 from vector<8x8xf32>
    %2254 = vector.broadcast %2253 : f32 to vector<8xf32>
    %2255 = vector.fma %2254, %2173, %2231 : vector<8xf32>
    %2256 = vector.extract %2168[0, 3] : f32 from vector<8x8xf32>
    %2257 = vector.broadcast %2256 : f32 to vector<8xf32>
    %2258 = vector.fma %2257, %2175, %2234 : vector<8xf32>
    %2259 = vector.extract %2168[1, 3] : f32 from vector<8x8xf32>
    %2260 = vector.broadcast %2259 : f32 to vector<8xf32>
    %2261 = vector.fma %2260, %2175, %2237 : vector<8xf32>
    %2262 = vector.extract %2168[2, 3] : f32 from vector<8x8xf32>
    %2263 = vector.broadcast %2262 : f32 to vector<8xf32>
    %2264 = vector.fma %2263, %2175, %2240 : vector<8xf32>
    %2265 = vector.extract %2168[3, 3] : f32 from vector<8x8xf32>
    %2266 = vector.broadcast %2265 : f32 to vector<8xf32>
    %2267 = vector.fma %2266, %2175, %2243 : vector<8xf32>
    %2268 = vector.extract %2168[4, 3] : f32 from vector<8x8xf32>
    %2269 = vector.broadcast %2268 : f32 to vector<8xf32>
    %2270 = vector.fma %2269, %2175, %2246 : vector<8xf32>
    %2271 = vector.extract %2168[5, 3] : f32 from vector<8x8xf32>
    %2272 = vector.broadcast %2271 : f32 to vector<8xf32>
    %2273 = vector.fma %2272, %2175, %2249 : vector<8xf32>
    %2274 = vector.extract %2168[6, 3] : f32 from vector<8x8xf32>
    %2275 = vector.broadcast %2274 : f32 to vector<8xf32>
    %2276 = vector.fma %2275, %2175, %2252 : vector<8xf32>
    %2277 = vector.extract %2168[7, 3] : f32 from vector<8x8xf32>
    %2278 = vector.broadcast %2277 : f32 to vector<8xf32>
    %2279 = vector.fma %2278, %2175, %2255 : vector<8xf32>
    %2280 = vector.extract %2168[0, 4] : f32 from vector<8x8xf32>
    %2281 = vector.broadcast %2280 : f32 to vector<8xf32>
    %2282 = vector.fma %2281, %2177, %2258 : vector<8xf32>
    %2283 = vector.extract %2168[1, 4] : f32 from vector<8x8xf32>
    %2284 = vector.broadcast %2283 : f32 to vector<8xf32>
    %2285 = vector.fma %2284, %2177, %2261 : vector<8xf32>
    %2286 = vector.extract %2168[2, 4] : f32 from vector<8x8xf32>
    %2287 = vector.broadcast %2286 : f32 to vector<8xf32>
    %2288 = vector.fma %2287, %2177, %2264 : vector<8xf32>
    %2289 = vector.extract %2168[3, 4] : f32 from vector<8x8xf32>
    %2290 = vector.broadcast %2289 : f32 to vector<8xf32>
    %2291 = vector.fma %2290, %2177, %2267 : vector<8xf32>
    %2292 = vector.extract %2168[4, 4] : f32 from vector<8x8xf32>
    %2293 = vector.broadcast %2292 : f32 to vector<8xf32>
    %2294 = vector.fma %2293, %2177, %2270 : vector<8xf32>
    %2295 = vector.extract %2168[5, 4] : f32 from vector<8x8xf32>
    %2296 = vector.broadcast %2295 : f32 to vector<8xf32>
    %2297 = vector.fma %2296, %2177, %2273 : vector<8xf32>
    %2298 = vector.extract %2168[6, 4] : f32 from vector<8x8xf32>
    %2299 = vector.broadcast %2298 : f32 to vector<8xf32>
    %2300 = vector.fma %2299, %2177, %2276 : vector<8xf32>
    %2301 = vector.extract %2168[7, 4] : f32 from vector<8x8xf32>
    %2302 = vector.broadcast %2301 : f32 to vector<8xf32>
    %2303 = vector.fma %2302, %2177, %2279 : vector<8xf32>
    %2304 = vector.extract %2168[0, 5] : f32 from vector<8x8xf32>
    %2305 = vector.broadcast %2304 : f32 to vector<8xf32>
    %2306 = vector.fma %2305, %2179, %2282 : vector<8xf32>
    %2307 = vector.extract %2168[1, 5] : f32 from vector<8x8xf32>
    %2308 = vector.broadcast %2307 : f32 to vector<8xf32>
    %2309 = vector.fma %2308, %2179, %2285 : vector<8xf32>
    %2310 = vector.extract %2168[2, 5] : f32 from vector<8x8xf32>
    %2311 = vector.broadcast %2310 : f32 to vector<8xf32>
    %2312 = vector.fma %2311, %2179, %2288 : vector<8xf32>
    %2313 = vector.extract %2168[3, 5] : f32 from vector<8x8xf32>
    %2314 = vector.broadcast %2313 : f32 to vector<8xf32>
    %2315 = vector.fma %2314, %2179, %2291 : vector<8xf32>
    %2316 = vector.extract %2168[4, 5] : f32 from vector<8x8xf32>
    %2317 = vector.broadcast %2316 : f32 to vector<8xf32>
    %2318 = vector.fma %2317, %2179, %2294 : vector<8xf32>
    %2319 = vector.extract %2168[5, 5] : f32 from vector<8x8xf32>
    %2320 = vector.broadcast %2319 : f32 to vector<8xf32>
    %2321 = vector.fma %2320, %2179, %2297 : vector<8xf32>
    %2322 = vector.extract %2168[6, 5] : f32 from vector<8x8xf32>
    %2323 = vector.broadcast %2322 : f32 to vector<8xf32>
    %2324 = vector.fma %2323, %2179, %2300 : vector<8xf32>
    %2325 = vector.extract %2168[7, 5] : f32 from vector<8x8xf32>
    %2326 = vector.broadcast %2325 : f32 to vector<8xf32>
    %2327 = vector.fma %2326, %2179, %2303 : vector<8xf32>
    %2328 = vector.extract %2168[0, 6] : f32 from vector<8x8xf32>
    %2329 = vector.broadcast %2328 : f32 to vector<8xf32>
    %2330 = vector.fma %2329, %2181, %2306 : vector<8xf32>
    %2331 = vector.extract %2168[1, 6] : f32 from vector<8x8xf32>
    %2332 = vector.broadcast %2331 : f32 to vector<8xf32>
    %2333 = vector.fma %2332, %2181, %2309 : vector<8xf32>
    %2334 = vector.extract %2168[2, 6] : f32 from vector<8x8xf32>
    %2335 = vector.broadcast %2334 : f32 to vector<8xf32>
    %2336 = vector.fma %2335, %2181, %2312 : vector<8xf32>
    %2337 = vector.extract %2168[3, 6] : f32 from vector<8x8xf32>
    %2338 = vector.broadcast %2337 : f32 to vector<8xf32>
    %2339 = vector.fma %2338, %2181, %2315 : vector<8xf32>
    %2340 = vector.extract %2168[4, 6] : f32 from vector<8x8xf32>
    %2341 = vector.broadcast %2340 : f32 to vector<8xf32>
    %2342 = vector.fma %2341, %2181, %2318 : vector<8xf32>
    %2343 = vector.extract %2168[5, 6] : f32 from vector<8x8xf32>
    %2344 = vector.broadcast %2343 : f32 to vector<8xf32>
    %2345 = vector.fma %2344, %2181, %2321 : vector<8xf32>
    %2346 = vector.extract %2168[6, 6] : f32 from vector<8x8xf32>
    %2347 = vector.broadcast %2346 : f32 to vector<8xf32>
    %2348 = vector.fma %2347, %2181, %2324 : vector<8xf32>
    %2349 = vector.extract %2168[7, 6] : f32 from vector<8x8xf32>
    %2350 = vector.broadcast %2349 : f32 to vector<8xf32>
    %2351 = vector.fma %2350, %2181, %2327 : vector<8xf32>
    %2352 = vector.extract %2168[0, 7] : f32 from vector<8x8xf32>
    %2353 = vector.broadcast %2352 : f32 to vector<8xf32>
    %2354 = vector.fma %2353, %2183, %2330 : vector<8xf32>
    %2355 = vector.insert %2354, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
    %2356 = vector.extract %2168[1, 7] : f32 from vector<8x8xf32>
    %2357 = vector.broadcast %2356 : f32 to vector<8xf32>
    %2358 = vector.fma %2357, %2183, %2333 : vector<8xf32>
    %2359 = vector.insert %2358, %2355 [1] : vector<8xf32> into vector<8x8xf32>
    %2360 = vector.extract %2168[2, 7] : f32 from vector<8x8xf32>
    %2361 = vector.broadcast %2360 : f32 to vector<8xf32>
    %2362 = vector.fma %2361, %2183, %2336 : vector<8xf32>
    %2363 = vector.insert %2362, %2359 [2] : vector<8xf32> into vector<8x8xf32>
    %2364 = vector.extract %2168[3, 7] : f32 from vector<8x8xf32>
    %2365 = vector.broadcast %2364 : f32 to vector<8xf32>
    %2366 = vector.fma %2365, %2183, %2339 : vector<8xf32>
    %2367 = vector.insert %2366, %2363 [3] : vector<8xf32> into vector<8x8xf32>
    %2368 = vector.extract %2168[4, 7] : f32 from vector<8x8xf32>
    %2369 = vector.broadcast %2368 : f32 to vector<8xf32>
    %2370 = vector.fma %2369, %2183, %2342 : vector<8xf32>
    %2371 = vector.insert %2370, %2367 [4] : vector<8xf32> into vector<8x8xf32>
    %2372 = vector.extract %2168[5, 7] : f32 from vector<8x8xf32>
    %2373 = vector.broadcast %2372 : f32 to vector<8xf32>
    %2374 = vector.fma %2373, %2183, %2345 : vector<8xf32>
    %2375 = vector.insert %2374, %2371 [5] : vector<8xf32> into vector<8x8xf32>
    %2376 = vector.extract %2168[6, 7] : f32 from vector<8x8xf32>
    %2377 = vector.broadcast %2376 : f32 to vector<8xf32>
    %2378 = vector.fma %2377, %2183, %2348 : vector<8xf32>
    %2379 = vector.insert %2378, %2375 [6] : vector<8xf32> into vector<8x8xf32>
    %2380 = vector.extract %2168[7, 7] : f32 from vector<8x8xf32>
    %2381 = vector.broadcast %2380 : f32 to vector<8xf32>
    %2382 = vector.fma %2381, %2183, %2351 : vector<8xf32>
    %2383 = vector.insert %2382, %2379 [7] : vector<8xf32> into vector<8x8xf32>
    %2384 = arith.mulf %2113, %cst_0 : vector<8xf32>
    %2385 = vector.extract %2168[0] : vector<8xf32> from vector<8x8xf32>
    %2386 = vector.extract %2384[0] : f32 from vector<8xf32>
    %2387 = vector.reduction <add>, %2385, %2386 : vector<8xf32> into f32
    %2388 = vector.insert %2387, %cst_0 [0] : f32 into vector<8xf32>
    %2389 = vector.extract %2168[1] : vector<8xf32> from vector<8x8xf32>
    %2390 = vector.extract %2384[1] : f32 from vector<8xf32>
    %2391 = vector.reduction <add>, %2389, %2390 : vector<8xf32> into f32
    %2392 = vector.insert %2391, %2388 [1] : f32 into vector<8xf32>
    %2393 = vector.extract %2168[2] : vector<8xf32> from vector<8x8xf32>
    %2394 = vector.extract %2384[2] : f32 from vector<8xf32>
    %2395 = vector.reduction <add>, %2393, %2394 : vector<8xf32> into f32
    %2396 = vector.insert %2395, %2392 [2] : f32 into vector<8xf32>
    %2397 = vector.extract %2168[3] : vector<8xf32> from vector<8x8xf32>
    %2398 = vector.extract %2384[3] : f32 from vector<8xf32>
    %2399 = vector.reduction <add>, %2397, %2398 : vector<8xf32> into f32
    %2400 = vector.insert %2399, %2396 [3] : f32 into vector<8xf32>
    %2401 = vector.extract %2168[4] : vector<8xf32> from vector<8x8xf32>
    %2402 = vector.extract %2384[4] : f32 from vector<8xf32>
    %2403 = vector.reduction <add>, %2401, %2402 : vector<8xf32> into f32
    %2404 = vector.insert %2403, %2400 [4] : f32 into vector<8xf32>
    %2405 = vector.extract %2168[5] : vector<8xf32> from vector<8x8xf32>
    %2406 = vector.extract %2384[5] : f32 from vector<8xf32>
    %2407 = vector.reduction <add>, %2405, %2406 : vector<8xf32> into f32
    %2408 = vector.insert %2407, %2404 [5] : f32 into vector<8xf32>
    %2409 = vector.extract %2168[6] : vector<8xf32> from vector<8x8xf32>
    %2410 = vector.extract %2384[6] : f32 from vector<8xf32>
    %2411 = vector.reduction <add>, %2409, %2410 : vector<8xf32> into f32
    %2412 = vector.insert %2411, %2408 [6] : f32 into vector<8xf32>
    %2413 = vector.extract %2168[7] : vector<8xf32> from vector<8x8xf32>
    %2414 = vector.extract %2384[7] : f32 from vector<8xf32>
    %2415 = vector.reduction <add>, %2413, %2414 : vector<8xf32> into f32
    %2416 = vector.insert %2415, %2412 [7] : f32 into vector<8xf32>
    %2417 = vector.insert_strided_slice %2416, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2418 = vector.insert_strided_slice %2416, %2417 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2419 = vector.insert_strided_slice %2416, %2418 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2420 = vector.insert_strided_slice %2416, %2419 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2421 = vector.insert_strided_slice %2416, %2420 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2422 = vector.insert_strided_slice %2416, %2421 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2423 = vector.insert_strided_slice %2416, %2422 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2424 = vector.insert_strided_slice %2416, %2423 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
    %2425 = vector.shuffle %2424, %2424 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
    %2426 = vector.extract_strided_slice %2425 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2427 = vector.insert %2426, %0 [0] : vector<8xf32> into vector<8x8xf32>
    %2428 = vector.extract_strided_slice %2425 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2429 = vector.insert %2428, %2427 [1] : vector<8xf32> into vector<8x8xf32>
    %2430 = vector.extract_strided_slice %2425 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2431 = vector.insert %2430, %2429 [2] : vector<8xf32> into vector<8x8xf32>
    %2432 = vector.extract_strided_slice %2425 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2433 = vector.insert %2432, %2431 [3] : vector<8xf32> into vector<8x8xf32>
    %2434 = vector.extract_strided_slice %2425 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2435 = vector.insert %2434, %2433 [4] : vector<8xf32> into vector<8x8xf32>
    %2436 = vector.extract_strided_slice %2425 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2437 = vector.insert %2436, %2435 [5] : vector<8xf32> into vector<8x8xf32>
    %2438 = vector.extract_strided_slice %2425 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2439 = vector.insert %2438, %2437 [6] : vector<8xf32> into vector<8x8xf32>
    %2440 = vector.extract_strided_slice %2425 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
    %2441 = vector.insert %2440, %2439 [7] : vector<8xf32> into vector<8x8xf32>
    %2442 = arith.divf %2383, %2441 : vector<8x8xf32>
    %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>
    %2443 = vector.extract %2442[0] : vector<8xf32> from vector<8x8xf32>
    vector.store %2443, %subview_7[%c0, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2444 = vector.extract %2442[1] : vector<8xf32> from vector<8x8xf32>
    vector.store %2444, %subview_7[%c1, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2445 = vector.extract %2442[2] : vector<8xf32> from vector<8x8xf32>
    vector.store %2445, %subview_7[%c2, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2446 = vector.extract %2442[3] : vector<8xf32> from vector<8x8xf32>
    vector.store %2446, %subview_7[%c3, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2447 = vector.extract %2442[4] : vector<8xf32> from vector<8x8xf32>
    vector.store %2447, %subview_7[%c4, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2448 = vector.extract %2442[5] : vector<8xf32> from vector<8x8xf32>
    vector.store %2448, %subview_7[%c5, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2449 = vector.extract %2442[6] : vector<8xf32> from vector<8x8xf32>
    vector.store %2449, %subview_7[%c6, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    %2450 = vector.extract %2442[7] : vector<8xf32> from vector<8x8xf32>
    vector.store %2450, %subview_7[%c7, %c0] : memref<8x8xf32, affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
  } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

#executable_target_system_elf_x86_64 = #hal.executable.target<"llvm-cpu", "system-elf-x86_64", {native_vector_size = 64 : i64}>
#map = affine_map<(d0) -> (d0 + 1)>
#map1 = affine_map<(d0) -> (d0 + 2)>
#map2 = affine_map<(d0) -> (d0 + 3)>
#map3 = affine_map<(d0) -> (d0 + 4)>
#map4 = affine_map<(d0) -> (d0 + 5)>
#map5 = affine_map<(d0) -> (d0 + 6)>
#map6 = affine_map<(d0) -> (d0 + 7)>
#map7 = affine_map<()[s0] -> (s0 + 1)>
#map8 = affine_map<()[s0] -> (s0 + 2)>
#map9 = affine_map<()[s0] -> (s0 + 3)>
#map10 = affine_map<()[s0] -> (s0 + 4)>
#map11 = affine_map<()[s0] -> (s0 + 5)>
#map12 = affine_map<()[s0] -> (s0 + 6)>
#map13 = affine_map<()[s0] -> (s0 + 7)>
#map14 = affine_map<(d0, d1)[s0] -> (d0 * 64 + d1 + s0)>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>, #hal.pipeline.binding<storage_buffer>]>
#translation = #iree_codegen.translation_info<pipeline = CPULinalgExtTileAndVectorize>
module {
  func.func @no_peel_static_matmul() attributes {hal.executable.target = #executable_target_system_elf_x86_64, translation_info = #translation} {
    %0 = ub.poison : vector<8x8xf32>
    %1 = ub.poison : vector<64xf32>
    %2 = ub.poison : vector<1x8xf32>
    %3 = ub.poison : vector<512xf32>
    %c63 = arith.constant 63 : index
    %c62 = arith.constant 62 : index
    %c61 = arith.constant 61 : index
    %c60 = arith.constant 60 : index
    %c59 = arith.constant 59 : index
    %c58 = arith.constant 58 : index
    %c57 = arith.constant 57 : index
    %c56 = arith.constant 56 : index
    %c55 = arith.constant 55 : index
    %c54 = arith.constant 54 : index
    %c53 = arith.constant 53 : index
    %c52 = arith.constant 52 : index
    %c51 = arith.constant 51 : index
    %c50 = arith.constant 50 : index
    %c49 = arith.constant 49 : index
    %c48 = arith.constant 48 : index
    %c47 = arith.constant 47 : index
    %c46 = arith.constant 46 : index
    %c45 = arith.constant 45 : index
    %c44 = arith.constant 44 : index
    %c43 = arith.constant 43 : index
    %c42 = arith.constant 42 : index
    %c41 = arith.constant 41 : index
    %c40 = arith.constant 40 : index
    %c39 = arith.constant 39 : index
    %c38 = arith.constant 38 : index
    %c37 = arith.constant 37 : index
    %c36 = arith.constant 36 : index
    %c35 = arith.constant 35 : index
    %c34 = arith.constant 34 : index
    %c33 = arith.constant 33 : index
    %c32 = arith.constant 32 : index
    %c31 = arith.constant 31 : index
    %c30 = arith.constant 30 : index
    %c29 = arith.constant 29 : index
    %c28 = arith.constant 28 : index
    %c27 = arith.constant 27 : index
    %c26 = arith.constant 26 : index
    %c25 = arith.constant 25 : index
    %c24 = arith.constant 24 : index
    %c23 = arith.constant 23 : index
    %c22 = arith.constant 22 : index
    %c21 = arith.constant 21 : index
    %c20 = arith.constant 20 : index
    %c19 = arith.constant 19 : index
    %c18 = arith.constant 18 : index
    %c17 = arith.constant 17 : index
    %c16 = arith.constant 16 : index
    %c15 = arith.constant 15 : index
    %c14 = arith.constant 14 : index
    %c13 = arith.constant 13 : index
    %c12 = arith.constant 12 : index
    %c11 = arith.constant 11 : index
    %c10 = arith.constant 10 : index
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %c7 = arith.constant 7 : index
    %c6 = arith.constant 6 : index
    %c5 = arith.constant 5 : index
    %c4 = arith.constant 4 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf32>
    %cst_1 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
    %cst_2 = arith.constant dense<-3.40282347E+38> : vector<8xf32>
    %c0 = arith.constant 0 : index
    %alloca = memref.alloca() {alignment = 64 : i64} : memref<1x8x8xf32>
    %4 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %assume_align = memref.assume_alignment %4, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %5 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %assume_align_3 = memref.assume_alignment %5, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %6 = hal.interface.binding.subspan layout(#pipeline_layout) binding(2) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %assume_align_4 = memref.assume_alignment %6, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %7 = hal.interface.binding.subspan layout(#pipeline_layout) binding(3) : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    %assume_align_5 = memref.assume_alignment %7, 4 : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg0, %arg1, %arg2, %arg3) = (0, 0, 0, 0) to (20, 4096, 64, 4096) step (1, 8, 8, 8) {
      %subview = memref.subview %assume_align_5[%arg0, %arg1, %arg2] [1, 8, 8] [1, 1, 1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>> to memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %8 = vector.load %assume_align_3[%arg0, %arg3, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %9 = affine.apply #map(%arg3)
      %10 = vector.load %assume_align_3[%arg0, %9, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %11 = affine.apply #map1(%arg3)
      %12 = vector.load %assume_align_3[%arg0, %11, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %13 = affine.apply #map2(%arg3)
      %14 = vector.load %assume_align_3[%arg0, %13, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %15 = affine.apply #map3(%arg3)
      %16 = vector.load %assume_align_3[%arg0, %15, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %17 = affine.apply #map4(%arg3)
      %18 = vector.load %assume_align_3[%arg0, %17, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %19 = affine.apply #map5(%arg3)
      %20 = vector.load %assume_align_3[%arg0, %19, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %21 = affine.apply #map6(%arg3)
      %22 = vector.load %assume_align_3[%arg0, %21, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<64xf32>
      %subview_6 = memref.subview %alloca[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32> to memref<8x8xf32>
      %23 = vector.load %subview_6[%c0, %c0] : memref<8x8xf32>, vector<8xf32>
      %24 = vector.load %subview_6[%c1, %c0] : memref<8x8xf32>, vector<8xf32>
      %25 = vector.load %subview_6[%c2, %c0] : memref<8x8xf32>, vector<8xf32>
      %26 = vector.load %subview_6[%c3, %c0] : memref<8x8xf32>, vector<8xf32>
      %27 = vector.load %subview_6[%c4, %c0] : memref<8x8xf32>, vector<8xf32>
      %28 = vector.load %subview_6[%c5, %c0] : memref<8x8xf32>, vector<8xf32>
      %29 = vector.load %subview_6[%c6, %c0] : memref<8x8xf32>, vector<8xf32>
      %30 = vector.load %subview_6[%c7, %c0] : memref<8x8xf32>, vector<8xf32>
      %31 = vector.insert_strided_slice %8, %3 {offsets = [0], strides = [1]} : vector<64xf32> into vector<512xf32>
      %32 = vector.insert_strided_slice %10, %31 {offsets = [64], strides = [1]} : vector<64xf32> into vector<512xf32>
      %33 = vector.insert_strided_slice %12, %32 {offsets = [128], strides = [1]} : vector<64xf32> into vector<512xf32>
      %34 = vector.insert_strided_slice %14, %33 {offsets = [192], strides = [1]} : vector<64xf32> into vector<512xf32>
      %35 = vector.insert_strided_slice %16, %34 {offsets = [256], strides = [1]} : vector<64xf32> into vector<512xf32>
      %36 = vector.insert_strided_slice %18, %35 {offsets = [320], strides = [1]} : vector<64xf32> into vector<512xf32>
      %37 = vector.insert_strided_slice %20, %36 {offsets = [384], strides = [1]} : vector<64xf32> into vector<512xf32>
      %38 = vector.insert_strided_slice %22, %37 {offsets = [448], strides = [1]} : vector<64xf32> into vector<512xf32>
      %39 = vector.shuffle %38, %38 [0, 64, 128, 192, 256, 320, 384, 448, 1, 65, 129, 193, 257, 321, 385, 449, 2, 66, 130, 194, 258, 322, 386, 450, 3, 67, 131, 195, 259, 323, 387, 451, 4, 68, 132, 196, 260, 324, 388, 452, 5, 69, 133, 197, 261, 325, 389, 453, 6, 70, 134, 198, 262, 326, 390, 454, 7, 71, 135, 199, 263, 327, 391, 455, 8, 72, 136, 200, 264, 328, 392, 456, 9, 73, 137, 201, 265, 329, 393, 457, 10, 74, 138, 202, 266, 330, 394, 458, 11, 75, 139, 203, 267, 331, 395, 459, 12, 76, 140, 204, 268, 332, 396, 460, 13, 77, 141, 205, 269, 333, 397, 461, 14, 78, 142, 206, 270, 334, 398, 462, 15, 79, 143, 207, 271, 335, 399, 463, 16, 80, 144, 208, 272, 336, 400, 464, 17, 81, 145, 209, 273, 337, 401, 465, 18, 82, 146, 210, 274, 338, 402, 466, 19, 83, 147, 211, 275, 339, 403, 467, 20, 84, 148, 212, 276, 340, 404, 468, 21, 85, 149, 213, 277, 341, 405, 469, 22, 86, 150, 214, 278, 342, 406, 470, 23, 87, 151, 215, 279, 343, 407, 471, 24, 88, 152, 216, 280, 344, 408, 472, 25, 89, 153, 217, 281, 345, 409, 473, 26, 90, 154, 218, 282, 346, 410, 474, 27, 91, 155, 219, 283, 347, 411, 475, 28, 92, 156, 220, 284, 348, 412, 476, 29, 93, 157, 221, 285, 349, 413, 477, 30, 94, 158, 222, 286, 350, 414, 478, 31, 95, 159, 223, 287, 351, 415, 479, 32, 96, 160, 224, 288, 352, 416, 480, 33, 97, 161, 225, 289, 353, 417, 481, 34, 98, 162, 226, 290, 354, 418, 482, 35, 99, 163, 227, 291, 355, 419, 483, 36, 100, 164, 228, 292, 356, 420, 484, 37, 101, 165, 229, 293, 357, 421, 485, 38, 102, 166, 230, 294, 358, 422, 486, 39, 103, 167, 231, 295, 359, 423, 487, 40, 104, 168, 232, 296, 360, 424, 488, 41, 105, 169, 233, 297, 361, 425, 489, 42, 106, 170, 234, 298, 362, 426, 490, 43, 107, 171, 235, 299, 363, 427, 491, 44, 108, 172, 236, 300, 364, 428, 492, 45, 109, 173, 237, 301, 365, 429, 493, 46, 110, 174, 238, 302, 366, 430, 494, 47, 111, 175, 239, 303, 367, 431, 495, 48, 112, 176, 240, 304, 368, 432, 496, 49, 113, 177, 241, 305, 369, 433, 497, 50, 114, 178, 242, 306, 370, 434, 498, 51, 115, 179, 243, 307, 371, 435, 499, 52, 116, 180, 244, 308, 372, 436, 500, 53, 117, 181, 245, 309, 373, 437, 501, 54, 118, 182, 246, 310, 374, 438, 502, 55, 119, 183, 247, 311, 375, 439, 503, 56, 120, 184, 248, 312, 376, 440, 504, 57, 121, 185, 249, 313, 377, 441, 505, 58, 122, 186, 250, 314, 378, 442, 506, 59, 123, 187, 251, 315, 379, 443, 507, 60, 124, 188, 252, 316, 380, 444, 508, 61, 125, 189, 253, 317, 381, 445, 509, 62, 126, 190, 254, 318, 382, 446, 510, 63, 127, 191, 255, 319, 383, 447, 511] : vector<512xf32>, vector<512xf32>
      %40 = vector.extract_strided_slice %39 {offsets = [0], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %41 = vector.extract_strided_slice %39 {offsets = [8], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %42 = vector.extract_strided_slice %39 {offsets = [16], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %43 = vector.extract_strided_slice %39 {offsets = [24], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %44 = vector.extract_strided_slice %39 {offsets = [32], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %45 = vector.extract_strided_slice %39 {offsets = [40], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %46 = vector.extract_strided_slice %39 {offsets = [48], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %47 = vector.extract_strided_slice %39 {offsets = [56], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %48 = vector.extract_strided_slice %39 {offsets = [64], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %49 = vector.extract_strided_slice %39 {offsets = [72], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %50 = vector.extract_strided_slice %39 {offsets = [80], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %51 = vector.extract_strided_slice %39 {offsets = [88], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %52 = vector.extract_strided_slice %39 {offsets = [96], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %53 = vector.extract_strided_slice %39 {offsets = [104], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %54 = vector.extract_strided_slice %39 {offsets = [112], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %55 = vector.extract_strided_slice %39 {offsets = [120], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %56 = vector.extract_strided_slice %39 {offsets = [128], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %57 = vector.extract_strided_slice %39 {offsets = [136], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %58 = vector.extract_strided_slice %39 {offsets = [144], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %59 = vector.extract_strided_slice %39 {offsets = [152], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %60 = vector.extract_strided_slice %39 {offsets = [160], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %61 = vector.extract_strided_slice %39 {offsets = [168], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %62 = vector.extract_strided_slice %39 {offsets = [176], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %63 = vector.extract_strided_slice %39 {offsets = [184], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %64 = vector.extract_strided_slice %39 {offsets = [192], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %65 = vector.extract_strided_slice %39 {offsets = [200], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %66 = vector.extract_strided_slice %39 {offsets = [208], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %67 = vector.extract_strided_slice %39 {offsets = [216], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %68 = vector.extract_strided_slice %39 {offsets = [224], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %69 = vector.extract_strided_slice %39 {offsets = [232], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %70 = vector.extract_strided_slice %39 {offsets = [240], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %71 = vector.extract_strided_slice %39 {offsets = [248], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %72 = vector.extract_strided_slice %39 {offsets = [256], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %73 = vector.extract_strided_slice %39 {offsets = [264], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %74 = vector.extract_strided_slice %39 {offsets = [272], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %75 = vector.extract_strided_slice %39 {offsets = [280], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %76 = vector.extract_strided_slice %39 {offsets = [288], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %77 = vector.extract_strided_slice %39 {offsets = [296], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %78 = vector.extract_strided_slice %39 {offsets = [304], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %79 = vector.extract_strided_slice %39 {offsets = [312], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %80 = vector.extract_strided_slice %39 {offsets = [320], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %81 = vector.extract_strided_slice %39 {offsets = [328], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %82 = vector.extract_strided_slice %39 {offsets = [336], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %83 = vector.extract_strided_slice %39 {offsets = [344], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %84 = vector.extract_strided_slice %39 {offsets = [352], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %85 = vector.extract_strided_slice %39 {offsets = [360], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %86 = vector.extract_strided_slice %39 {offsets = [368], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %87 = vector.extract_strided_slice %39 {offsets = [376], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %88 = vector.extract_strided_slice %39 {offsets = [384], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %89 = vector.extract_strided_slice %39 {offsets = [392], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %90 = vector.extract_strided_slice %39 {offsets = [400], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %91 = vector.extract_strided_slice %39 {offsets = [408], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %92 = vector.extract_strided_slice %39 {offsets = [416], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %93 = vector.extract_strided_slice %39 {offsets = [424], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %94 = vector.extract_strided_slice %39 {offsets = [432], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %95 = vector.extract_strided_slice %39 {offsets = [440], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %96 = vector.extract_strided_slice %39 {offsets = [448], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %97 = vector.extract_strided_slice %39 {offsets = [456], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %98 = vector.extract_strided_slice %39 {offsets = [464], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %99 = vector.extract_strided_slice %39 {offsets = [472], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %100 = vector.extract_strided_slice %39 {offsets = [480], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %101 = vector.extract_strided_slice %39 {offsets = [488], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %102 = vector.extract_strided_slice %39 {offsets = [496], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %103 = vector.extract_strided_slice %39 {offsets = [504], sizes = [8], strides = [1]} : vector<512xf32> to vector<8xf32>
      %104 = memref.load %assume_align[%arg0, %arg1, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %105 = vector.broadcast %104 : f32 to vector<8xf32>
      %106 = vector.fma %105, %40, %23 : vector<8xf32>
      %107 = affine.apply #map7()[%arg1]
      %108 = memref.load %assume_align[%arg0, %107, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %109 = vector.broadcast %108 : f32 to vector<8xf32>
      %110 = vector.fma %109, %40, %24 : vector<8xf32>
      %111 = affine.apply #map8()[%arg1]
      %112 = memref.load %assume_align[%arg0, %111, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %113 = vector.broadcast %112 : f32 to vector<8xf32>
      %114 = vector.fma %113, %40, %25 : vector<8xf32>
      %115 = affine.apply #map9()[%arg1]
      %116 = memref.load %assume_align[%arg0, %115, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %117 = vector.broadcast %116 : f32 to vector<8xf32>
      %118 = vector.fma %117, %40, %26 : vector<8xf32>
      %119 = affine.apply #map10()[%arg1]
      %120 = memref.load %assume_align[%arg0, %119, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %121 = vector.broadcast %120 : f32 to vector<8xf32>
      %122 = vector.fma %121, %40, %27 : vector<8xf32>
      %123 = affine.apply #map11()[%arg1]
      %124 = memref.load %assume_align[%arg0, %123, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %125 = vector.broadcast %124 : f32 to vector<8xf32>
      %126 = vector.fma %125, %40, %28 : vector<8xf32>
      %127 = affine.apply #map12()[%arg1]
      %128 = memref.load %assume_align[%arg0, %127, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %129 = vector.broadcast %128 : f32 to vector<8xf32>
      %130 = vector.fma %129, %40, %29 : vector<8xf32>
      %131 = affine.apply #map13()[%arg1]
      %132 = memref.load %assume_align[%arg0, %131, %c0] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %133 = vector.broadcast %132 : f32 to vector<8xf32>
      %134 = vector.fma %133, %40, %30 : vector<8xf32>
      %135 = memref.load %assume_align[%arg0, %arg1, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %136 = vector.broadcast %135 : f32 to vector<8xf32>
      %137 = vector.fma %136, %41, %106 : vector<8xf32>
      %138 = affine.apply #map7()[%arg1]
      %139 = memref.load %assume_align[%arg0, %138, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %140 = vector.broadcast %139 : f32 to vector<8xf32>
      %141 = vector.fma %140, %41, %110 : vector<8xf32>
      %142 = affine.apply #map8()[%arg1]
      %143 = memref.load %assume_align[%arg0, %142, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %144 = vector.broadcast %143 : f32 to vector<8xf32>
      %145 = vector.fma %144, %41, %114 : vector<8xf32>
      %146 = affine.apply #map9()[%arg1]
      %147 = memref.load %assume_align[%arg0, %146, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %148 = vector.broadcast %147 : f32 to vector<8xf32>
      %149 = vector.fma %148, %41, %118 : vector<8xf32>
      %150 = affine.apply #map10()[%arg1]
      %151 = memref.load %assume_align[%arg0, %150, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %152 = vector.broadcast %151 : f32 to vector<8xf32>
      %153 = vector.fma %152, %41, %122 : vector<8xf32>
      %154 = affine.apply #map11()[%arg1]
      %155 = memref.load %assume_align[%arg0, %154, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %156 = vector.broadcast %155 : f32 to vector<8xf32>
      %157 = vector.fma %156, %41, %126 : vector<8xf32>
      %158 = affine.apply #map12()[%arg1]
      %159 = memref.load %assume_align[%arg0, %158, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %160 = vector.broadcast %159 : f32 to vector<8xf32>
      %161 = vector.fma %160, %41, %130 : vector<8xf32>
      %162 = affine.apply #map13()[%arg1]
      %163 = memref.load %assume_align[%arg0, %162, %c1] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %164 = vector.broadcast %163 : f32 to vector<8xf32>
      %165 = vector.fma %164, %41, %134 : vector<8xf32>
      %166 = memref.load %assume_align[%arg0, %arg1, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %167 = vector.broadcast %166 : f32 to vector<8xf32>
      %168 = vector.fma %167, %42, %137 : vector<8xf32>
      %169 = affine.apply #map7()[%arg1]
      %170 = memref.load %assume_align[%arg0, %169, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %171 = vector.broadcast %170 : f32 to vector<8xf32>
      %172 = vector.fma %171, %42, %141 : vector<8xf32>
      %173 = affine.apply #map8()[%arg1]
      %174 = memref.load %assume_align[%arg0, %173, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %175 = vector.broadcast %174 : f32 to vector<8xf32>
      %176 = vector.fma %175, %42, %145 : vector<8xf32>
      %177 = affine.apply #map9()[%arg1]
      %178 = memref.load %assume_align[%arg0, %177, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %179 = vector.broadcast %178 : f32 to vector<8xf32>
      %180 = vector.fma %179, %42, %149 : vector<8xf32>
      %181 = affine.apply #map10()[%arg1]
      %182 = memref.load %assume_align[%arg0, %181, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %183 = vector.broadcast %182 : f32 to vector<8xf32>
      %184 = vector.fma %183, %42, %153 : vector<8xf32>
      %185 = affine.apply #map11()[%arg1]
      %186 = memref.load %assume_align[%arg0, %185, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %187 = vector.broadcast %186 : f32 to vector<8xf32>
      %188 = vector.fma %187, %42, %157 : vector<8xf32>
      %189 = affine.apply #map12()[%arg1]
      %190 = memref.load %assume_align[%arg0, %189, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %191 = vector.broadcast %190 : f32 to vector<8xf32>
      %192 = vector.fma %191, %42, %161 : vector<8xf32>
      %193 = affine.apply #map13()[%arg1]
      %194 = memref.load %assume_align[%arg0, %193, %c2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %195 = vector.broadcast %194 : f32 to vector<8xf32>
      %196 = vector.fma %195, %42, %165 : vector<8xf32>
      %197 = memref.load %assume_align[%arg0, %arg1, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %198 = vector.broadcast %197 : f32 to vector<8xf32>
      %199 = vector.fma %198, %43, %168 : vector<8xf32>
      %200 = affine.apply #map7()[%arg1]
      %201 = memref.load %assume_align[%arg0, %200, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %202 = vector.broadcast %201 : f32 to vector<8xf32>
      %203 = vector.fma %202, %43, %172 : vector<8xf32>
      %204 = affine.apply #map8()[%arg1]
      %205 = memref.load %assume_align[%arg0, %204, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %206 = vector.broadcast %205 : f32 to vector<8xf32>
      %207 = vector.fma %206, %43, %176 : vector<8xf32>
      %208 = affine.apply #map9()[%arg1]
      %209 = memref.load %assume_align[%arg0, %208, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %210 = vector.broadcast %209 : f32 to vector<8xf32>
      %211 = vector.fma %210, %43, %180 : vector<8xf32>
      %212 = affine.apply #map10()[%arg1]
      %213 = memref.load %assume_align[%arg0, %212, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %214 = vector.broadcast %213 : f32 to vector<8xf32>
      %215 = vector.fma %214, %43, %184 : vector<8xf32>
      %216 = affine.apply #map11()[%arg1]
      %217 = memref.load %assume_align[%arg0, %216, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %218 = vector.broadcast %217 : f32 to vector<8xf32>
      %219 = vector.fma %218, %43, %188 : vector<8xf32>
      %220 = affine.apply #map12()[%arg1]
      %221 = memref.load %assume_align[%arg0, %220, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %222 = vector.broadcast %221 : f32 to vector<8xf32>
      %223 = vector.fma %222, %43, %192 : vector<8xf32>
      %224 = affine.apply #map13()[%arg1]
      %225 = memref.load %assume_align[%arg0, %224, %c3] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %226 = vector.broadcast %225 : f32 to vector<8xf32>
      %227 = vector.fma %226, %43, %196 : vector<8xf32>
      %228 = memref.load %assume_align[%arg0, %arg1, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %229 = vector.broadcast %228 : f32 to vector<8xf32>
      %230 = vector.fma %229, %44, %199 : vector<8xf32>
      %231 = affine.apply #map7()[%arg1]
      %232 = memref.load %assume_align[%arg0, %231, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %233 = vector.broadcast %232 : f32 to vector<8xf32>
      %234 = vector.fma %233, %44, %203 : vector<8xf32>
      %235 = affine.apply #map8()[%arg1]
      %236 = memref.load %assume_align[%arg0, %235, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %237 = vector.broadcast %236 : f32 to vector<8xf32>
      %238 = vector.fma %237, %44, %207 : vector<8xf32>
      %239 = affine.apply #map9()[%arg1]
      %240 = memref.load %assume_align[%arg0, %239, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %241 = vector.broadcast %240 : f32 to vector<8xf32>
      %242 = vector.fma %241, %44, %211 : vector<8xf32>
      %243 = affine.apply #map10()[%arg1]
      %244 = memref.load %assume_align[%arg0, %243, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %245 = vector.broadcast %244 : f32 to vector<8xf32>
      %246 = vector.fma %245, %44, %215 : vector<8xf32>
      %247 = affine.apply #map11()[%arg1]
      %248 = memref.load %assume_align[%arg0, %247, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %249 = vector.broadcast %248 : f32 to vector<8xf32>
      %250 = vector.fma %249, %44, %219 : vector<8xf32>
      %251 = affine.apply #map12()[%arg1]
      %252 = memref.load %assume_align[%arg0, %251, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %253 = vector.broadcast %252 : f32 to vector<8xf32>
      %254 = vector.fma %253, %44, %223 : vector<8xf32>
      %255 = affine.apply #map13()[%arg1]
      %256 = memref.load %assume_align[%arg0, %255, %c4] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %257 = vector.broadcast %256 : f32 to vector<8xf32>
      %258 = vector.fma %257, %44, %227 : vector<8xf32>
      %259 = memref.load %assume_align[%arg0, %arg1, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %260 = vector.broadcast %259 : f32 to vector<8xf32>
      %261 = vector.fma %260, %45, %230 : vector<8xf32>
      %262 = affine.apply #map7()[%arg1]
      %263 = memref.load %assume_align[%arg0, %262, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %264 = vector.broadcast %263 : f32 to vector<8xf32>
      %265 = vector.fma %264, %45, %234 : vector<8xf32>
      %266 = affine.apply #map8()[%arg1]
      %267 = memref.load %assume_align[%arg0, %266, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %268 = vector.broadcast %267 : f32 to vector<8xf32>
      %269 = vector.fma %268, %45, %238 : vector<8xf32>
      %270 = affine.apply #map9()[%arg1]
      %271 = memref.load %assume_align[%arg0, %270, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %272 = vector.broadcast %271 : f32 to vector<8xf32>
      %273 = vector.fma %272, %45, %242 : vector<8xf32>
      %274 = affine.apply #map10()[%arg1]
      %275 = memref.load %assume_align[%arg0, %274, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %276 = vector.broadcast %275 : f32 to vector<8xf32>
      %277 = vector.fma %276, %45, %246 : vector<8xf32>
      %278 = affine.apply #map11()[%arg1]
      %279 = memref.load %assume_align[%arg0, %278, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %280 = vector.broadcast %279 : f32 to vector<8xf32>
      %281 = vector.fma %280, %45, %250 : vector<8xf32>
      %282 = affine.apply #map12()[%arg1]
      %283 = memref.load %assume_align[%arg0, %282, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %284 = vector.broadcast %283 : f32 to vector<8xf32>
      %285 = vector.fma %284, %45, %254 : vector<8xf32>
      %286 = affine.apply #map13()[%arg1]
      %287 = memref.load %assume_align[%arg0, %286, %c5] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %288 = vector.broadcast %287 : f32 to vector<8xf32>
      %289 = vector.fma %288, %45, %258 : vector<8xf32>
      %290 = memref.load %assume_align[%arg0, %arg1, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %291 = vector.broadcast %290 : f32 to vector<8xf32>
      %292 = vector.fma %291, %46, %261 : vector<8xf32>
      %293 = affine.apply #map7()[%arg1]
      %294 = memref.load %assume_align[%arg0, %293, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %295 = vector.broadcast %294 : f32 to vector<8xf32>
      %296 = vector.fma %295, %46, %265 : vector<8xf32>
      %297 = affine.apply #map8()[%arg1]
      %298 = memref.load %assume_align[%arg0, %297, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %299 = vector.broadcast %298 : f32 to vector<8xf32>
      %300 = vector.fma %299, %46, %269 : vector<8xf32>
      %301 = affine.apply #map9()[%arg1]
      %302 = memref.load %assume_align[%arg0, %301, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %303 = vector.broadcast %302 : f32 to vector<8xf32>
      %304 = vector.fma %303, %46, %273 : vector<8xf32>
      %305 = affine.apply #map10()[%arg1]
      %306 = memref.load %assume_align[%arg0, %305, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %307 = vector.broadcast %306 : f32 to vector<8xf32>
      %308 = vector.fma %307, %46, %277 : vector<8xf32>
      %309 = affine.apply #map11()[%arg1]
      %310 = memref.load %assume_align[%arg0, %309, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %311 = vector.broadcast %310 : f32 to vector<8xf32>
      %312 = vector.fma %311, %46, %281 : vector<8xf32>
      %313 = affine.apply #map12()[%arg1]
      %314 = memref.load %assume_align[%arg0, %313, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %315 = vector.broadcast %314 : f32 to vector<8xf32>
      %316 = vector.fma %315, %46, %285 : vector<8xf32>
      %317 = affine.apply #map13()[%arg1]
      %318 = memref.load %assume_align[%arg0, %317, %c6] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %319 = vector.broadcast %318 : f32 to vector<8xf32>
      %320 = vector.fma %319, %46, %289 : vector<8xf32>
      %321 = memref.load %assume_align[%arg0, %arg1, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %322 = vector.broadcast %321 : f32 to vector<8xf32>
      %323 = vector.fma %322, %47, %292 : vector<8xf32>
      %324 = affine.apply #map7()[%arg1]
      %325 = memref.load %assume_align[%arg0, %324, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %326 = vector.broadcast %325 : f32 to vector<8xf32>
      %327 = vector.fma %326, %47, %296 : vector<8xf32>
      %328 = affine.apply #map8()[%arg1]
      %329 = memref.load %assume_align[%arg0, %328, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %330 = vector.broadcast %329 : f32 to vector<8xf32>
      %331 = vector.fma %330, %47, %300 : vector<8xf32>
      %332 = affine.apply #map9()[%arg1]
      %333 = memref.load %assume_align[%arg0, %332, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %334 = vector.broadcast %333 : f32 to vector<8xf32>
      %335 = vector.fma %334, %47, %304 : vector<8xf32>
      %336 = affine.apply #map10()[%arg1]
      %337 = memref.load %assume_align[%arg0, %336, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %338 = vector.broadcast %337 : f32 to vector<8xf32>
      %339 = vector.fma %338, %47, %308 : vector<8xf32>
      %340 = affine.apply #map11()[%arg1]
      %341 = memref.load %assume_align[%arg0, %340, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %342 = vector.broadcast %341 : f32 to vector<8xf32>
      %343 = vector.fma %342, %47, %312 : vector<8xf32>
      %344 = affine.apply #map12()[%arg1]
      %345 = memref.load %assume_align[%arg0, %344, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %346 = vector.broadcast %345 : f32 to vector<8xf32>
      %347 = vector.fma %346, %47, %316 : vector<8xf32>
      %348 = affine.apply #map13()[%arg1]
      %349 = memref.load %assume_align[%arg0, %348, %c7] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %350 = vector.broadcast %349 : f32 to vector<8xf32>
      %351 = vector.fma %350, %47, %320 : vector<8xf32>
      %352 = memref.load %assume_align[%arg0, %arg1, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %353 = vector.broadcast %352 : f32 to vector<8xf32>
      %354 = vector.fma %353, %48, %323 : vector<8xf32>
      %355 = affine.apply #map7()[%arg1]
      %356 = memref.load %assume_align[%arg0, %355, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %357 = vector.broadcast %356 : f32 to vector<8xf32>
      %358 = vector.fma %357, %48, %327 : vector<8xf32>
      %359 = affine.apply #map8()[%arg1]
      %360 = memref.load %assume_align[%arg0, %359, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %361 = vector.broadcast %360 : f32 to vector<8xf32>
      %362 = vector.fma %361, %48, %331 : vector<8xf32>
      %363 = affine.apply #map9()[%arg1]
      %364 = memref.load %assume_align[%arg0, %363, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %365 = vector.broadcast %364 : f32 to vector<8xf32>
      %366 = vector.fma %365, %48, %335 : vector<8xf32>
      %367 = affine.apply #map10()[%arg1]
      %368 = memref.load %assume_align[%arg0, %367, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %369 = vector.broadcast %368 : f32 to vector<8xf32>
      %370 = vector.fma %369, %48, %339 : vector<8xf32>
      %371 = affine.apply #map11()[%arg1]
      %372 = memref.load %assume_align[%arg0, %371, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %373 = vector.broadcast %372 : f32 to vector<8xf32>
      %374 = vector.fma %373, %48, %343 : vector<8xf32>
      %375 = affine.apply #map12()[%arg1]
      %376 = memref.load %assume_align[%arg0, %375, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %377 = vector.broadcast %376 : f32 to vector<8xf32>
      %378 = vector.fma %377, %48, %347 : vector<8xf32>
      %379 = affine.apply #map13()[%arg1]
      %380 = memref.load %assume_align[%arg0, %379, %c8] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %381 = vector.broadcast %380 : f32 to vector<8xf32>
      %382 = vector.fma %381, %48, %351 : vector<8xf32>
      %383 = memref.load %assume_align[%arg0, %arg1, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %384 = vector.broadcast %383 : f32 to vector<8xf32>
      %385 = vector.fma %384, %49, %354 : vector<8xf32>
      %386 = affine.apply #map7()[%arg1]
      %387 = memref.load %assume_align[%arg0, %386, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %388 = vector.broadcast %387 : f32 to vector<8xf32>
      %389 = vector.fma %388, %49, %358 : vector<8xf32>
      %390 = affine.apply #map8()[%arg1]
      %391 = memref.load %assume_align[%arg0, %390, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %392 = vector.broadcast %391 : f32 to vector<8xf32>
      %393 = vector.fma %392, %49, %362 : vector<8xf32>
      %394 = affine.apply #map9()[%arg1]
      %395 = memref.load %assume_align[%arg0, %394, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %396 = vector.broadcast %395 : f32 to vector<8xf32>
      %397 = vector.fma %396, %49, %366 : vector<8xf32>
      %398 = affine.apply #map10()[%arg1]
      %399 = memref.load %assume_align[%arg0, %398, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %400 = vector.broadcast %399 : f32 to vector<8xf32>
      %401 = vector.fma %400, %49, %370 : vector<8xf32>
      %402 = affine.apply #map11()[%arg1]
      %403 = memref.load %assume_align[%arg0, %402, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %404 = vector.broadcast %403 : f32 to vector<8xf32>
      %405 = vector.fma %404, %49, %374 : vector<8xf32>
      %406 = affine.apply #map12()[%arg1]
      %407 = memref.load %assume_align[%arg0, %406, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %408 = vector.broadcast %407 : f32 to vector<8xf32>
      %409 = vector.fma %408, %49, %378 : vector<8xf32>
      %410 = affine.apply #map13()[%arg1]
      %411 = memref.load %assume_align[%arg0, %410, %c9] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %412 = vector.broadcast %411 : f32 to vector<8xf32>
      %413 = vector.fma %412, %49, %382 : vector<8xf32>
      %414 = memref.load %assume_align[%arg0, %arg1, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %415 = vector.broadcast %414 : f32 to vector<8xf32>
      %416 = vector.fma %415, %50, %385 : vector<8xf32>
      %417 = affine.apply #map7()[%arg1]
      %418 = memref.load %assume_align[%arg0, %417, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %419 = vector.broadcast %418 : f32 to vector<8xf32>
      %420 = vector.fma %419, %50, %389 : vector<8xf32>
      %421 = affine.apply #map8()[%arg1]
      %422 = memref.load %assume_align[%arg0, %421, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %423 = vector.broadcast %422 : f32 to vector<8xf32>
      %424 = vector.fma %423, %50, %393 : vector<8xf32>
      %425 = affine.apply #map9()[%arg1]
      %426 = memref.load %assume_align[%arg0, %425, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %427 = vector.broadcast %426 : f32 to vector<8xf32>
      %428 = vector.fma %427, %50, %397 : vector<8xf32>
      %429 = affine.apply #map10()[%arg1]
      %430 = memref.load %assume_align[%arg0, %429, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %431 = vector.broadcast %430 : f32 to vector<8xf32>
      %432 = vector.fma %431, %50, %401 : vector<8xf32>
      %433 = affine.apply #map11()[%arg1]
      %434 = memref.load %assume_align[%arg0, %433, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %435 = vector.broadcast %434 : f32 to vector<8xf32>
      %436 = vector.fma %435, %50, %405 : vector<8xf32>
      %437 = affine.apply #map12()[%arg1]
      %438 = memref.load %assume_align[%arg0, %437, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %439 = vector.broadcast %438 : f32 to vector<8xf32>
      %440 = vector.fma %439, %50, %409 : vector<8xf32>
      %441 = affine.apply #map13()[%arg1]
      %442 = memref.load %assume_align[%arg0, %441, %c10] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %443 = vector.broadcast %442 : f32 to vector<8xf32>
      %444 = vector.fma %443, %50, %413 : vector<8xf32>
      %445 = memref.load %assume_align[%arg0, %arg1, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %446 = vector.broadcast %445 : f32 to vector<8xf32>
      %447 = vector.fma %446, %51, %416 : vector<8xf32>
      %448 = affine.apply #map7()[%arg1]
      %449 = memref.load %assume_align[%arg0, %448, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %450 = vector.broadcast %449 : f32 to vector<8xf32>
      %451 = vector.fma %450, %51, %420 : vector<8xf32>
      %452 = affine.apply #map8()[%arg1]
      %453 = memref.load %assume_align[%arg0, %452, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %454 = vector.broadcast %453 : f32 to vector<8xf32>
      %455 = vector.fma %454, %51, %424 : vector<8xf32>
      %456 = affine.apply #map9()[%arg1]
      %457 = memref.load %assume_align[%arg0, %456, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %458 = vector.broadcast %457 : f32 to vector<8xf32>
      %459 = vector.fma %458, %51, %428 : vector<8xf32>
      %460 = affine.apply #map10()[%arg1]
      %461 = memref.load %assume_align[%arg0, %460, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %462 = vector.broadcast %461 : f32 to vector<8xf32>
      %463 = vector.fma %462, %51, %432 : vector<8xf32>
      %464 = affine.apply #map11()[%arg1]
      %465 = memref.load %assume_align[%arg0, %464, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %466 = vector.broadcast %465 : f32 to vector<8xf32>
      %467 = vector.fma %466, %51, %436 : vector<8xf32>
      %468 = affine.apply #map12()[%arg1]
      %469 = memref.load %assume_align[%arg0, %468, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %470 = vector.broadcast %469 : f32 to vector<8xf32>
      %471 = vector.fma %470, %51, %440 : vector<8xf32>
      %472 = affine.apply #map13()[%arg1]
      %473 = memref.load %assume_align[%arg0, %472, %c11] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %474 = vector.broadcast %473 : f32 to vector<8xf32>
      %475 = vector.fma %474, %51, %444 : vector<8xf32>
      %476 = memref.load %assume_align[%arg0, %arg1, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %477 = vector.broadcast %476 : f32 to vector<8xf32>
      %478 = vector.fma %477, %52, %447 : vector<8xf32>
      %479 = affine.apply #map7()[%arg1]
      %480 = memref.load %assume_align[%arg0, %479, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %481 = vector.broadcast %480 : f32 to vector<8xf32>
      %482 = vector.fma %481, %52, %451 : vector<8xf32>
      %483 = affine.apply #map8()[%arg1]
      %484 = memref.load %assume_align[%arg0, %483, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %485 = vector.broadcast %484 : f32 to vector<8xf32>
      %486 = vector.fma %485, %52, %455 : vector<8xf32>
      %487 = affine.apply #map9()[%arg1]
      %488 = memref.load %assume_align[%arg0, %487, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %489 = vector.broadcast %488 : f32 to vector<8xf32>
      %490 = vector.fma %489, %52, %459 : vector<8xf32>
      %491 = affine.apply #map10()[%arg1]
      %492 = memref.load %assume_align[%arg0, %491, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %493 = vector.broadcast %492 : f32 to vector<8xf32>
      %494 = vector.fma %493, %52, %463 : vector<8xf32>
      %495 = affine.apply #map11()[%arg1]
      %496 = memref.load %assume_align[%arg0, %495, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %497 = vector.broadcast %496 : f32 to vector<8xf32>
      %498 = vector.fma %497, %52, %467 : vector<8xf32>
      %499 = affine.apply #map12()[%arg1]
      %500 = memref.load %assume_align[%arg0, %499, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %501 = vector.broadcast %500 : f32 to vector<8xf32>
      %502 = vector.fma %501, %52, %471 : vector<8xf32>
      %503 = affine.apply #map13()[%arg1]
      %504 = memref.load %assume_align[%arg0, %503, %c12] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %505 = vector.broadcast %504 : f32 to vector<8xf32>
      %506 = vector.fma %505, %52, %475 : vector<8xf32>
      %507 = memref.load %assume_align[%arg0, %arg1, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %508 = vector.broadcast %507 : f32 to vector<8xf32>
      %509 = vector.fma %508, %53, %478 : vector<8xf32>
      %510 = affine.apply #map7()[%arg1]
      %511 = memref.load %assume_align[%arg0, %510, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %512 = vector.broadcast %511 : f32 to vector<8xf32>
      %513 = vector.fma %512, %53, %482 : vector<8xf32>
      %514 = affine.apply #map8()[%arg1]
      %515 = memref.load %assume_align[%arg0, %514, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %516 = vector.broadcast %515 : f32 to vector<8xf32>
      %517 = vector.fma %516, %53, %486 : vector<8xf32>
      %518 = affine.apply #map9()[%arg1]
      %519 = memref.load %assume_align[%arg0, %518, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %520 = vector.broadcast %519 : f32 to vector<8xf32>
      %521 = vector.fma %520, %53, %490 : vector<8xf32>
      %522 = affine.apply #map10()[%arg1]
      %523 = memref.load %assume_align[%arg0, %522, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %524 = vector.broadcast %523 : f32 to vector<8xf32>
      %525 = vector.fma %524, %53, %494 : vector<8xf32>
      %526 = affine.apply #map11()[%arg1]
      %527 = memref.load %assume_align[%arg0, %526, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %528 = vector.broadcast %527 : f32 to vector<8xf32>
      %529 = vector.fma %528, %53, %498 : vector<8xf32>
      %530 = affine.apply #map12()[%arg1]
      %531 = memref.load %assume_align[%arg0, %530, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %532 = vector.broadcast %531 : f32 to vector<8xf32>
      %533 = vector.fma %532, %53, %502 : vector<8xf32>
      %534 = affine.apply #map13()[%arg1]
      %535 = memref.load %assume_align[%arg0, %534, %c13] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %536 = vector.broadcast %535 : f32 to vector<8xf32>
      %537 = vector.fma %536, %53, %506 : vector<8xf32>
      %538 = memref.load %assume_align[%arg0, %arg1, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %539 = vector.broadcast %538 : f32 to vector<8xf32>
      %540 = vector.fma %539, %54, %509 : vector<8xf32>
      %541 = affine.apply #map7()[%arg1]
      %542 = memref.load %assume_align[%arg0, %541, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %543 = vector.broadcast %542 : f32 to vector<8xf32>
      %544 = vector.fma %543, %54, %513 : vector<8xf32>
      %545 = affine.apply #map8()[%arg1]
      %546 = memref.load %assume_align[%arg0, %545, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %547 = vector.broadcast %546 : f32 to vector<8xf32>
      %548 = vector.fma %547, %54, %517 : vector<8xf32>
      %549 = affine.apply #map9()[%arg1]
      %550 = memref.load %assume_align[%arg0, %549, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %551 = vector.broadcast %550 : f32 to vector<8xf32>
      %552 = vector.fma %551, %54, %521 : vector<8xf32>
      %553 = affine.apply #map10()[%arg1]
      %554 = memref.load %assume_align[%arg0, %553, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %555 = vector.broadcast %554 : f32 to vector<8xf32>
      %556 = vector.fma %555, %54, %525 : vector<8xf32>
      %557 = affine.apply #map11()[%arg1]
      %558 = memref.load %assume_align[%arg0, %557, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %559 = vector.broadcast %558 : f32 to vector<8xf32>
      %560 = vector.fma %559, %54, %529 : vector<8xf32>
      %561 = affine.apply #map12()[%arg1]
      %562 = memref.load %assume_align[%arg0, %561, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %563 = vector.broadcast %562 : f32 to vector<8xf32>
      %564 = vector.fma %563, %54, %533 : vector<8xf32>
      %565 = affine.apply #map13()[%arg1]
      %566 = memref.load %assume_align[%arg0, %565, %c14] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %567 = vector.broadcast %566 : f32 to vector<8xf32>
      %568 = vector.fma %567, %54, %537 : vector<8xf32>
      %569 = memref.load %assume_align[%arg0, %arg1, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %570 = vector.broadcast %569 : f32 to vector<8xf32>
      %571 = vector.fma %570, %55, %540 : vector<8xf32>
      %572 = affine.apply #map7()[%arg1]
      %573 = memref.load %assume_align[%arg0, %572, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %574 = vector.broadcast %573 : f32 to vector<8xf32>
      %575 = vector.fma %574, %55, %544 : vector<8xf32>
      %576 = affine.apply #map8()[%arg1]
      %577 = memref.load %assume_align[%arg0, %576, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %578 = vector.broadcast %577 : f32 to vector<8xf32>
      %579 = vector.fma %578, %55, %548 : vector<8xf32>
      %580 = affine.apply #map9()[%arg1]
      %581 = memref.load %assume_align[%arg0, %580, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %582 = vector.broadcast %581 : f32 to vector<8xf32>
      %583 = vector.fma %582, %55, %552 : vector<8xf32>
      %584 = affine.apply #map10()[%arg1]
      %585 = memref.load %assume_align[%arg0, %584, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %586 = vector.broadcast %585 : f32 to vector<8xf32>
      %587 = vector.fma %586, %55, %556 : vector<8xf32>
      %588 = affine.apply #map11()[%arg1]
      %589 = memref.load %assume_align[%arg0, %588, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %590 = vector.broadcast %589 : f32 to vector<8xf32>
      %591 = vector.fma %590, %55, %560 : vector<8xf32>
      %592 = affine.apply #map12()[%arg1]
      %593 = memref.load %assume_align[%arg0, %592, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %594 = vector.broadcast %593 : f32 to vector<8xf32>
      %595 = vector.fma %594, %55, %564 : vector<8xf32>
      %596 = affine.apply #map13()[%arg1]
      %597 = memref.load %assume_align[%arg0, %596, %c15] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %598 = vector.broadcast %597 : f32 to vector<8xf32>
      %599 = vector.fma %598, %55, %568 : vector<8xf32>
      %600 = memref.load %assume_align[%arg0, %arg1, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %601 = vector.broadcast %600 : f32 to vector<8xf32>
      %602 = vector.fma %601, %56, %571 : vector<8xf32>
      %603 = affine.apply #map7()[%arg1]
      %604 = memref.load %assume_align[%arg0, %603, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %605 = vector.broadcast %604 : f32 to vector<8xf32>
      %606 = vector.fma %605, %56, %575 : vector<8xf32>
      %607 = affine.apply #map8()[%arg1]
      %608 = memref.load %assume_align[%arg0, %607, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %609 = vector.broadcast %608 : f32 to vector<8xf32>
      %610 = vector.fma %609, %56, %579 : vector<8xf32>
      %611 = affine.apply #map9()[%arg1]
      %612 = memref.load %assume_align[%arg0, %611, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %613 = vector.broadcast %612 : f32 to vector<8xf32>
      %614 = vector.fma %613, %56, %583 : vector<8xf32>
      %615 = affine.apply #map10()[%arg1]
      %616 = memref.load %assume_align[%arg0, %615, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %617 = vector.broadcast %616 : f32 to vector<8xf32>
      %618 = vector.fma %617, %56, %587 : vector<8xf32>
      %619 = affine.apply #map11()[%arg1]
      %620 = memref.load %assume_align[%arg0, %619, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %621 = vector.broadcast %620 : f32 to vector<8xf32>
      %622 = vector.fma %621, %56, %591 : vector<8xf32>
      %623 = affine.apply #map12()[%arg1]
      %624 = memref.load %assume_align[%arg0, %623, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %625 = vector.broadcast %624 : f32 to vector<8xf32>
      %626 = vector.fma %625, %56, %595 : vector<8xf32>
      %627 = affine.apply #map13()[%arg1]
      %628 = memref.load %assume_align[%arg0, %627, %c16] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %629 = vector.broadcast %628 : f32 to vector<8xf32>
      %630 = vector.fma %629, %56, %599 : vector<8xf32>
      %631 = memref.load %assume_align[%arg0, %arg1, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %632 = vector.broadcast %631 : f32 to vector<8xf32>
      %633 = vector.fma %632, %57, %602 : vector<8xf32>
      %634 = affine.apply #map7()[%arg1]
      %635 = memref.load %assume_align[%arg0, %634, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %636 = vector.broadcast %635 : f32 to vector<8xf32>
      %637 = vector.fma %636, %57, %606 : vector<8xf32>
      %638 = affine.apply #map8()[%arg1]
      %639 = memref.load %assume_align[%arg0, %638, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %640 = vector.broadcast %639 : f32 to vector<8xf32>
      %641 = vector.fma %640, %57, %610 : vector<8xf32>
      %642 = affine.apply #map9()[%arg1]
      %643 = memref.load %assume_align[%arg0, %642, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %644 = vector.broadcast %643 : f32 to vector<8xf32>
      %645 = vector.fma %644, %57, %614 : vector<8xf32>
      %646 = affine.apply #map10()[%arg1]
      %647 = memref.load %assume_align[%arg0, %646, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %648 = vector.broadcast %647 : f32 to vector<8xf32>
      %649 = vector.fma %648, %57, %618 : vector<8xf32>
      %650 = affine.apply #map11()[%arg1]
      %651 = memref.load %assume_align[%arg0, %650, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %652 = vector.broadcast %651 : f32 to vector<8xf32>
      %653 = vector.fma %652, %57, %622 : vector<8xf32>
      %654 = affine.apply #map12()[%arg1]
      %655 = memref.load %assume_align[%arg0, %654, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %656 = vector.broadcast %655 : f32 to vector<8xf32>
      %657 = vector.fma %656, %57, %626 : vector<8xf32>
      %658 = affine.apply #map13()[%arg1]
      %659 = memref.load %assume_align[%arg0, %658, %c17] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %660 = vector.broadcast %659 : f32 to vector<8xf32>
      %661 = vector.fma %660, %57, %630 : vector<8xf32>
      %662 = memref.load %assume_align[%arg0, %arg1, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %663 = vector.broadcast %662 : f32 to vector<8xf32>
      %664 = vector.fma %663, %58, %633 : vector<8xf32>
      %665 = affine.apply #map7()[%arg1]
      %666 = memref.load %assume_align[%arg0, %665, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %667 = vector.broadcast %666 : f32 to vector<8xf32>
      %668 = vector.fma %667, %58, %637 : vector<8xf32>
      %669 = affine.apply #map8()[%arg1]
      %670 = memref.load %assume_align[%arg0, %669, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %671 = vector.broadcast %670 : f32 to vector<8xf32>
      %672 = vector.fma %671, %58, %641 : vector<8xf32>
      %673 = affine.apply #map9()[%arg1]
      %674 = memref.load %assume_align[%arg0, %673, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %675 = vector.broadcast %674 : f32 to vector<8xf32>
      %676 = vector.fma %675, %58, %645 : vector<8xf32>
      %677 = affine.apply #map10()[%arg1]
      %678 = memref.load %assume_align[%arg0, %677, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %679 = vector.broadcast %678 : f32 to vector<8xf32>
      %680 = vector.fma %679, %58, %649 : vector<8xf32>
      %681 = affine.apply #map11()[%arg1]
      %682 = memref.load %assume_align[%arg0, %681, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %683 = vector.broadcast %682 : f32 to vector<8xf32>
      %684 = vector.fma %683, %58, %653 : vector<8xf32>
      %685 = affine.apply #map12()[%arg1]
      %686 = memref.load %assume_align[%arg0, %685, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %687 = vector.broadcast %686 : f32 to vector<8xf32>
      %688 = vector.fma %687, %58, %657 : vector<8xf32>
      %689 = affine.apply #map13()[%arg1]
      %690 = memref.load %assume_align[%arg0, %689, %c18] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %691 = vector.broadcast %690 : f32 to vector<8xf32>
      %692 = vector.fma %691, %58, %661 : vector<8xf32>
      %693 = memref.load %assume_align[%arg0, %arg1, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %694 = vector.broadcast %693 : f32 to vector<8xf32>
      %695 = vector.fma %694, %59, %664 : vector<8xf32>
      %696 = affine.apply #map7()[%arg1]
      %697 = memref.load %assume_align[%arg0, %696, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %698 = vector.broadcast %697 : f32 to vector<8xf32>
      %699 = vector.fma %698, %59, %668 : vector<8xf32>
      %700 = affine.apply #map8()[%arg1]
      %701 = memref.load %assume_align[%arg0, %700, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %702 = vector.broadcast %701 : f32 to vector<8xf32>
      %703 = vector.fma %702, %59, %672 : vector<8xf32>
      %704 = affine.apply #map9()[%arg1]
      %705 = memref.load %assume_align[%arg0, %704, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %706 = vector.broadcast %705 : f32 to vector<8xf32>
      %707 = vector.fma %706, %59, %676 : vector<8xf32>
      %708 = affine.apply #map10()[%arg1]
      %709 = memref.load %assume_align[%arg0, %708, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %710 = vector.broadcast %709 : f32 to vector<8xf32>
      %711 = vector.fma %710, %59, %680 : vector<8xf32>
      %712 = affine.apply #map11()[%arg1]
      %713 = memref.load %assume_align[%arg0, %712, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %714 = vector.broadcast %713 : f32 to vector<8xf32>
      %715 = vector.fma %714, %59, %684 : vector<8xf32>
      %716 = affine.apply #map12()[%arg1]
      %717 = memref.load %assume_align[%arg0, %716, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %718 = vector.broadcast %717 : f32 to vector<8xf32>
      %719 = vector.fma %718, %59, %688 : vector<8xf32>
      %720 = affine.apply #map13()[%arg1]
      %721 = memref.load %assume_align[%arg0, %720, %c19] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %722 = vector.broadcast %721 : f32 to vector<8xf32>
      %723 = vector.fma %722, %59, %692 : vector<8xf32>
      %724 = memref.load %assume_align[%arg0, %arg1, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %725 = vector.broadcast %724 : f32 to vector<8xf32>
      %726 = vector.fma %725, %60, %695 : vector<8xf32>
      %727 = affine.apply #map7()[%arg1]
      %728 = memref.load %assume_align[%arg0, %727, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %729 = vector.broadcast %728 : f32 to vector<8xf32>
      %730 = vector.fma %729, %60, %699 : vector<8xf32>
      %731 = affine.apply #map8()[%arg1]
      %732 = memref.load %assume_align[%arg0, %731, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %733 = vector.broadcast %732 : f32 to vector<8xf32>
      %734 = vector.fma %733, %60, %703 : vector<8xf32>
      %735 = affine.apply #map9()[%arg1]
      %736 = memref.load %assume_align[%arg0, %735, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %737 = vector.broadcast %736 : f32 to vector<8xf32>
      %738 = vector.fma %737, %60, %707 : vector<8xf32>
      %739 = affine.apply #map10()[%arg1]
      %740 = memref.load %assume_align[%arg0, %739, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %741 = vector.broadcast %740 : f32 to vector<8xf32>
      %742 = vector.fma %741, %60, %711 : vector<8xf32>
      %743 = affine.apply #map11()[%arg1]
      %744 = memref.load %assume_align[%arg0, %743, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %745 = vector.broadcast %744 : f32 to vector<8xf32>
      %746 = vector.fma %745, %60, %715 : vector<8xf32>
      %747 = affine.apply #map12()[%arg1]
      %748 = memref.load %assume_align[%arg0, %747, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %749 = vector.broadcast %748 : f32 to vector<8xf32>
      %750 = vector.fma %749, %60, %719 : vector<8xf32>
      %751 = affine.apply #map13()[%arg1]
      %752 = memref.load %assume_align[%arg0, %751, %c20] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %753 = vector.broadcast %752 : f32 to vector<8xf32>
      %754 = vector.fma %753, %60, %723 : vector<8xf32>
      %755 = memref.load %assume_align[%arg0, %arg1, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %756 = vector.broadcast %755 : f32 to vector<8xf32>
      %757 = vector.fma %756, %61, %726 : vector<8xf32>
      %758 = affine.apply #map7()[%arg1]
      %759 = memref.load %assume_align[%arg0, %758, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %760 = vector.broadcast %759 : f32 to vector<8xf32>
      %761 = vector.fma %760, %61, %730 : vector<8xf32>
      %762 = affine.apply #map8()[%arg1]
      %763 = memref.load %assume_align[%arg0, %762, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %764 = vector.broadcast %763 : f32 to vector<8xf32>
      %765 = vector.fma %764, %61, %734 : vector<8xf32>
      %766 = affine.apply #map9()[%arg1]
      %767 = memref.load %assume_align[%arg0, %766, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %768 = vector.broadcast %767 : f32 to vector<8xf32>
      %769 = vector.fma %768, %61, %738 : vector<8xf32>
      %770 = affine.apply #map10()[%arg1]
      %771 = memref.load %assume_align[%arg0, %770, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %772 = vector.broadcast %771 : f32 to vector<8xf32>
      %773 = vector.fma %772, %61, %742 : vector<8xf32>
      %774 = affine.apply #map11()[%arg1]
      %775 = memref.load %assume_align[%arg0, %774, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %776 = vector.broadcast %775 : f32 to vector<8xf32>
      %777 = vector.fma %776, %61, %746 : vector<8xf32>
      %778 = affine.apply #map12()[%arg1]
      %779 = memref.load %assume_align[%arg0, %778, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %780 = vector.broadcast %779 : f32 to vector<8xf32>
      %781 = vector.fma %780, %61, %750 : vector<8xf32>
      %782 = affine.apply #map13()[%arg1]
      %783 = memref.load %assume_align[%arg0, %782, %c21] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %784 = vector.broadcast %783 : f32 to vector<8xf32>
      %785 = vector.fma %784, %61, %754 : vector<8xf32>
      %786 = memref.load %assume_align[%arg0, %arg1, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %787 = vector.broadcast %786 : f32 to vector<8xf32>
      %788 = vector.fma %787, %62, %757 : vector<8xf32>
      %789 = affine.apply #map7()[%arg1]
      %790 = memref.load %assume_align[%arg0, %789, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %791 = vector.broadcast %790 : f32 to vector<8xf32>
      %792 = vector.fma %791, %62, %761 : vector<8xf32>
      %793 = affine.apply #map8()[%arg1]
      %794 = memref.load %assume_align[%arg0, %793, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %795 = vector.broadcast %794 : f32 to vector<8xf32>
      %796 = vector.fma %795, %62, %765 : vector<8xf32>
      %797 = affine.apply #map9()[%arg1]
      %798 = memref.load %assume_align[%arg0, %797, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %799 = vector.broadcast %798 : f32 to vector<8xf32>
      %800 = vector.fma %799, %62, %769 : vector<8xf32>
      %801 = affine.apply #map10()[%arg1]
      %802 = memref.load %assume_align[%arg0, %801, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %803 = vector.broadcast %802 : f32 to vector<8xf32>
      %804 = vector.fma %803, %62, %773 : vector<8xf32>
      %805 = affine.apply #map11()[%arg1]
      %806 = memref.load %assume_align[%arg0, %805, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %807 = vector.broadcast %806 : f32 to vector<8xf32>
      %808 = vector.fma %807, %62, %777 : vector<8xf32>
      %809 = affine.apply #map12()[%arg1]
      %810 = memref.load %assume_align[%arg0, %809, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %811 = vector.broadcast %810 : f32 to vector<8xf32>
      %812 = vector.fma %811, %62, %781 : vector<8xf32>
      %813 = affine.apply #map13()[%arg1]
      %814 = memref.load %assume_align[%arg0, %813, %c22] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %815 = vector.broadcast %814 : f32 to vector<8xf32>
      %816 = vector.fma %815, %62, %785 : vector<8xf32>
      %817 = memref.load %assume_align[%arg0, %arg1, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %818 = vector.broadcast %817 : f32 to vector<8xf32>
      %819 = vector.fma %818, %63, %788 : vector<8xf32>
      %820 = affine.apply #map7()[%arg1]
      %821 = memref.load %assume_align[%arg0, %820, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %822 = vector.broadcast %821 : f32 to vector<8xf32>
      %823 = vector.fma %822, %63, %792 : vector<8xf32>
      %824 = affine.apply #map8()[%arg1]
      %825 = memref.load %assume_align[%arg0, %824, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %826 = vector.broadcast %825 : f32 to vector<8xf32>
      %827 = vector.fma %826, %63, %796 : vector<8xf32>
      %828 = affine.apply #map9()[%arg1]
      %829 = memref.load %assume_align[%arg0, %828, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %830 = vector.broadcast %829 : f32 to vector<8xf32>
      %831 = vector.fma %830, %63, %800 : vector<8xf32>
      %832 = affine.apply #map10()[%arg1]
      %833 = memref.load %assume_align[%arg0, %832, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %834 = vector.broadcast %833 : f32 to vector<8xf32>
      %835 = vector.fma %834, %63, %804 : vector<8xf32>
      %836 = affine.apply #map11()[%arg1]
      %837 = memref.load %assume_align[%arg0, %836, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %838 = vector.broadcast %837 : f32 to vector<8xf32>
      %839 = vector.fma %838, %63, %808 : vector<8xf32>
      %840 = affine.apply #map12()[%arg1]
      %841 = memref.load %assume_align[%arg0, %840, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %842 = vector.broadcast %841 : f32 to vector<8xf32>
      %843 = vector.fma %842, %63, %812 : vector<8xf32>
      %844 = affine.apply #map13()[%arg1]
      %845 = memref.load %assume_align[%arg0, %844, %c23] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %846 = vector.broadcast %845 : f32 to vector<8xf32>
      %847 = vector.fma %846, %63, %816 : vector<8xf32>
      %848 = memref.load %assume_align[%arg0, %arg1, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %849 = vector.broadcast %848 : f32 to vector<8xf32>
      %850 = vector.fma %849, %64, %819 : vector<8xf32>
      %851 = affine.apply #map7()[%arg1]
      %852 = memref.load %assume_align[%arg0, %851, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %853 = vector.broadcast %852 : f32 to vector<8xf32>
      %854 = vector.fma %853, %64, %823 : vector<8xf32>
      %855 = affine.apply #map8()[%arg1]
      %856 = memref.load %assume_align[%arg0, %855, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %857 = vector.broadcast %856 : f32 to vector<8xf32>
      %858 = vector.fma %857, %64, %827 : vector<8xf32>
      %859 = affine.apply #map9()[%arg1]
      %860 = memref.load %assume_align[%arg0, %859, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %861 = vector.broadcast %860 : f32 to vector<8xf32>
      %862 = vector.fma %861, %64, %831 : vector<8xf32>
      %863 = affine.apply #map10()[%arg1]
      %864 = memref.load %assume_align[%arg0, %863, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %865 = vector.broadcast %864 : f32 to vector<8xf32>
      %866 = vector.fma %865, %64, %835 : vector<8xf32>
      %867 = affine.apply #map11()[%arg1]
      %868 = memref.load %assume_align[%arg0, %867, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %869 = vector.broadcast %868 : f32 to vector<8xf32>
      %870 = vector.fma %869, %64, %839 : vector<8xf32>
      %871 = affine.apply #map12()[%arg1]
      %872 = memref.load %assume_align[%arg0, %871, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %873 = vector.broadcast %872 : f32 to vector<8xf32>
      %874 = vector.fma %873, %64, %843 : vector<8xf32>
      %875 = affine.apply #map13()[%arg1]
      %876 = memref.load %assume_align[%arg0, %875, %c24] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %877 = vector.broadcast %876 : f32 to vector<8xf32>
      %878 = vector.fma %877, %64, %847 : vector<8xf32>
      %879 = memref.load %assume_align[%arg0, %arg1, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %880 = vector.broadcast %879 : f32 to vector<8xf32>
      %881 = vector.fma %880, %65, %850 : vector<8xf32>
      %882 = affine.apply #map7()[%arg1]
      %883 = memref.load %assume_align[%arg0, %882, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %884 = vector.broadcast %883 : f32 to vector<8xf32>
      %885 = vector.fma %884, %65, %854 : vector<8xf32>
      %886 = affine.apply #map8()[%arg1]
      %887 = memref.load %assume_align[%arg0, %886, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %888 = vector.broadcast %887 : f32 to vector<8xf32>
      %889 = vector.fma %888, %65, %858 : vector<8xf32>
      %890 = affine.apply #map9()[%arg1]
      %891 = memref.load %assume_align[%arg0, %890, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %892 = vector.broadcast %891 : f32 to vector<8xf32>
      %893 = vector.fma %892, %65, %862 : vector<8xf32>
      %894 = affine.apply #map10()[%arg1]
      %895 = memref.load %assume_align[%arg0, %894, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %896 = vector.broadcast %895 : f32 to vector<8xf32>
      %897 = vector.fma %896, %65, %866 : vector<8xf32>
      %898 = affine.apply #map11()[%arg1]
      %899 = memref.load %assume_align[%arg0, %898, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %900 = vector.broadcast %899 : f32 to vector<8xf32>
      %901 = vector.fma %900, %65, %870 : vector<8xf32>
      %902 = affine.apply #map12()[%arg1]
      %903 = memref.load %assume_align[%arg0, %902, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %904 = vector.broadcast %903 : f32 to vector<8xf32>
      %905 = vector.fma %904, %65, %874 : vector<8xf32>
      %906 = affine.apply #map13()[%arg1]
      %907 = memref.load %assume_align[%arg0, %906, %c25] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %908 = vector.broadcast %907 : f32 to vector<8xf32>
      %909 = vector.fma %908, %65, %878 : vector<8xf32>
      %910 = memref.load %assume_align[%arg0, %arg1, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %911 = vector.broadcast %910 : f32 to vector<8xf32>
      %912 = vector.fma %911, %66, %881 : vector<8xf32>
      %913 = affine.apply #map7()[%arg1]
      %914 = memref.load %assume_align[%arg0, %913, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %915 = vector.broadcast %914 : f32 to vector<8xf32>
      %916 = vector.fma %915, %66, %885 : vector<8xf32>
      %917 = affine.apply #map8()[%arg1]
      %918 = memref.load %assume_align[%arg0, %917, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %919 = vector.broadcast %918 : f32 to vector<8xf32>
      %920 = vector.fma %919, %66, %889 : vector<8xf32>
      %921 = affine.apply #map9()[%arg1]
      %922 = memref.load %assume_align[%arg0, %921, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %923 = vector.broadcast %922 : f32 to vector<8xf32>
      %924 = vector.fma %923, %66, %893 : vector<8xf32>
      %925 = affine.apply #map10()[%arg1]
      %926 = memref.load %assume_align[%arg0, %925, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %927 = vector.broadcast %926 : f32 to vector<8xf32>
      %928 = vector.fma %927, %66, %897 : vector<8xf32>
      %929 = affine.apply #map11()[%arg1]
      %930 = memref.load %assume_align[%arg0, %929, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %931 = vector.broadcast %930 : f32 to vector<8xf32>
      %932 = vector.fma %931, %66, %901 : vector<8xf32>
      %933 = affine.apply #map12()[%arg1]
      %934 = memref.load %assume_align[%arg0, %933, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %935 = vector.broadcast %934 : f32 to vector<8xf32>
      %936 = vector.fma %935, %66, %905 : vector<8xf32>
      %937 = affine.apply #map13()[%arg1]
      %938 = memref.load %assume_align[%arg0, %937, %c26] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %939 = vector.broadcast %938 : f32 to vector<8xf32>
      %940 = vector.fma %939, %66, %909 : vector<8xf32>
      %941 = memref.load %assume_align[%arg0, %arg1, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %942 = vector.broadcast %941 : f32 to vector<8xf32>
      %943 = vector.fma %942, %67, %912 : vector<8xf32>
      %944 = affine.apply #map7()[%arg1]
      %945 = memref.load %assume_align[%arg0, %944, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %946 = vector.broadcast %945 : f32 to vector<8xf32>
      %947 = vector.fma %946, %67, %916 : vector<8xf32>
      %948 = affine.apply #map8()[%arg1]
      %949 = memref.load %assume_align[%arg0, %948, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %950 = vector.broadcast %949 : f32 to vector<8xf32>
      %951 = vector.fma %950, %67, %920 : vector<8xf32>
      %952 = affine.apply #map9()[%arg1]
      %953 = memref.load %assume_align[%arg0, %952, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %954 = vector.broadcast %953 : f32 to vector<8xf32>
      %955 = vector.fma %954, %67, %924 : vector<8xf32>
      %956 = affine.apply #map10()[%arg1]
      %957 = memref.load %assume_align[%arg0, %956, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %958 = vector.broadcast %957 : f32 to vector<8xf32>
      %959 = vector.fma %958, %67, %928 : vector<8xf32>
      %960 = affine.apply #map11()[%arg1]
      %961 = memref.load %assume_align[%arg0, %960, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %962 = vector.broadcast %961 : f32 to vector<8xf32>
      %963 = vector.fma %962, %67, %932 : vector<8xf32>
      %964 = affine.apply #map12()[%arg1]
      %965 = memref.load %assume_align[%arg0, %964, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %966 = vector.broadcast %965 : f32 to vector<8xf32>
      %967 = vector.fma %966, %67, %936 : vector<8xf32>
      %968 = affine.apply #map13()[%arg1]
      %969 = memref.load %assume_align[%arg0, %968, %c27] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %970 = vector.broadcast %969 : f32 to vector<8xf32>
      %971 = vector.fma %970, %67, %940 : vector<8xf32>
      %972 = memref.load %assume_align[%arg0, %arg1, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %973 = vector.broadcast %972 : f32 to vector<8xf32>
      %974 = vector.fma %973, %68, %943 : vector<8xf32>
      %975 = affine.apply #map7()[%arg1]
      %976 = memref.load %assume_align[%arg0, %975, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %977 = vector.broadcast %976 : f32 to vector<8xf32>
      %978 = vector.fma %977, %68, %947 : vector<8xf32>
      %979 = affine.apply #map8()[%arg1]
      %980 = memref.load %assume_align[%arg0, %979, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %981 = vector.broadcast %980 : f32 to vector<8xf32>
      %982 = vector.fma %981, %68, %951 : vector<8xf32>
      %983 = affine.apply #map9()[%arg1]
      %984 = memref.load %assume_align[%arg0, %983, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %985 = vector.broadcast %984 : f32 to vector<8xf32>
      %986 = vector.fma %985, %68, %955 : vector<8xf32>
      %987 = affine.apply #map10()[%arg1]
      %988 = memref.load %assume_align[%arg0, %987, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %989 = vector.broadcast %988 : f32 to vector<8xf32>
      %990 = vector.fma %989, %68, %959 : vector<8xf32>
      %991 = affine.apply #map11()[%arg1]
      %992 = memref.load %assume_align[%arg0, %991, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %993 = vector.broadcast %992 : f32 to vector<8xf32>
      %994 = vector.fma %993, %68, %963 : vector<8xf32>
      %995 = affine.apply #map12()[%arg1]
      %996 = memref.load %assume_align[%arg0, %995, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %997 = vector.broadcast %996 : f32 to vector<8xf32>
      %998 = vector.fma %997, %68, %967 : vector<8xf32>
      %999 = affine.apply #map13()[%arg1]
      %1000 = memref.load %assume_align[%arg0, %999, %c28] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1001 = vector.broadcast %1000 : f32 to vector<8xf32>
      %1002 = vector.fma %1001, %68, %971 : vector<8xf32>
      %1003 = memref.load %assume_align[%arg0, %arg1, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1004 = vector.broadcast %1003 : f32 to vector<8xf32>
      %1005 = vector.fma %1004, %69, %974 : vector<8xf32>
      %1006 = affine.apply #map7()[%arg1]
      %1007 = memref.load %assume_align[%arg0, %1006, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1008 = vector.broadcast %1007 : f32 to vector<8xf32>
      %1009 = vector.fma %1008, %69, %978 : vector<8xf32>
      %1010 = affine.apply #map8()[%arg1]
      %1011 = memref.load %assume_align[%arg0, %1010, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1012 = vector.broadcast %1011 : f32 to vector<8xf32>
      %1013 = vector.fma %1012, %69, %982 : vector<8xf32>
      %1014 = affine.apply #map9()[%arg1]
      %1015 = memref.load %assume_align[%arg0, %1014, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1016 = vector.broadcast %1015 : f32 to vector<8xf32>
      %1017 = vector.fma %1016, %69, %986 : vector<8xf32>
      %1018 = affine.apply #map10()[%arg1]
      %1019 = memref.load %assume_align[%arg0, %1018, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1020 = vector.broadcast %1019 : f32 to vector<8xf32>
      %1021 = vector.fma %1020, %69, %990 : vector<8xf32>
      %1022 = affine.apply #map11()[%arg1]
      %1023 = memref.load %assume_align[%arg0, %1022, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1024 = vector.broadcast %1023 : f32 to vector<8xf32>
      %1025 = vector.fma %1024, %69, %994 : vector<8xf32>
      %1026 = affine.apply #map12()[%arg1]
      %1027 = memref.load %assume_align[%arg0, %1026, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1028 = vector.broadcast %1027 : f32 to vector<8xf32>
      %1029 = vector.fma %1028, %69, %998 : vector<8xf32>
      %1030 = affine.apply #map13()[%arg1]
      %1031 = memref.load %assume_align[%arg0, %1030, %c29] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1032 = vector.broadcast %1031 : f32 to vector<8xf32>
      %1033 = vector.fma %1032, %69, %1002 : vector<8xf32>
      %1034 = memref.load %assume_align[%arg0, %arg1, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1035 = vector.broadcast %1034 : f32 to vector<8xf32>
      %1036 = vector.fma %1035, %70, %1005 : vector<8xf32>
      %1037 = affine.apply #map7()[%arg1]
      %1038 = memref.load %assume_align[%arg0, %1037, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1039 = vector.broadcast %1038 : f32 to vector<8xf32>
      %1040 = vector.fma %1039, %70, %1009 : vector<8xf32>
      %1041 = affine.apply #map8()[%arg1]
      %1042 = memref.load %assume_align[%arg0, %1041, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1043 = vector.broadcast %1042 : f32 to vector<8xf32>
      %1044 = vector.fma %1043, %70, %1013 : vector<8xf32>
      %1045 = affine.apply #map9()[%arg1]
      %1046 = memref.load %assume_align[%arg0, %1045, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1047 = vector.broadcast %1046 : f32 to vector<8xf32>
      %1048 = vector.fma %1047, %70, %1017 : vector<8xf32>
      %1049 = affine.apply #map10()[%arg1]
      %1050 = memref.load %assume_align[%arg0, %1049, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1051 = vector.broadcast %1050 : f32 to vector<8xf32>
      %1052 = vector.fma %1051, %70, %1021 : vector<8xf32>
      %1053 = affine.apply #map11()[%arg1]
      %1054 = memref.load %assume_align[%arg0, %1053, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1055 = vector.broadcast %1054 : f32 to vector<8xf32>
      %1056 = vector.fma %1055, %70, %1025 : vector<8xf32>
      %1057 = affine.apply #map12()[%arg1]
      %1058 = memref.load %assume_align[%arg0, %1057, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1059 = vector.broadcast %1058 : f32 to vector<8xf32>
      %1060 = vector.fma %1059, %70, %1029 : vector<8xf32>
      %1061 = affine.apply #map13()[%arg1]
      %1062 = memref.load %assume_align[%arg0, %1061, %c30] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1063 = vector.broadcast %1062 : f32 to vector<8xf32>
      %1064 = vector.fma %1063, %70, %1033 : vector<8xf32>
      %1065 = memref.load %assume_align[%arg0, %arg1, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1066 = vector.broadcast %1065 : f32 to vector<8xf32>
      %1067 = vector.fma %1066, %71, %1036 : vector<8xf32>
      %1068 = affine.apply #map7()[%arg1]
      %1069 = memref.load %assume_align[%arg0, %1068, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1070 = vector.broadcast %1069 : f32 to vector<8xf32>
      %1071 = vector.fma %1070, %71, %1040 : vector<8xf32>
      %1072 = affine.apply #map8()[%arg1]
      %1073 = memref.load %assume_align[%arg0, %1072, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1074 = vector.broadcast %1073 : f32 to vector<8xf32>
      %1075 = vector.fma %1074, %71, %1044 : vector<8xf32>
      %1076 = affine.apply #map9()[%arg1]
      %1077 = memref.load %assume_align[%arg0, %1076, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1078 = vector.broadcast %1077 : f32 to vector<8xf32>
      %1079 = vector.fma %1078, %71, %1048 : vector<8xf32>
      %1080 = affine.apply #map10()[%arg1]
      %1081 = memref.load %assume_align[%arg0, %1080, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1082 = vector.broadcast %1081 : f32 to vector<8xf32>
      %1083 = vector.fma %1082, %71, %1052 : vector<8xf32>
      %1084 = affine.apply #map11()[%arg1]
      %1085 = memref.load %assume_align[%arg0, %1084, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1086 = vector.broadcast %1085 : f32 to vector<8xf32>
      %1087 = vector.fma %1086, %71, %1056 : vector<8xf32>
      %1088 = affine.apply #map12()[%arg1]
      %1089 = memref.load %assume_align[%arg0, %1088, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1090 = vector.broadcast %1089 : f32 to vector<8xf32>
      %1091 = vector.fma %1090, %71, %1060 : vector<8xf32>
      %1092 = affine.apply #map13()[%arg1]
      %1093 = memref.load %assume_align[%arg0, %1092, %c31] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1094 = vector.broadcast %1093 : f32 to vector<8xf32>
      %1095 = vector.fma %1094, %71, %1064 : vector<8xf32>
      %1096 = memref.load %assume_align[%arg0, %arg1, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1097 = vector.broadcast %1096 : f32 to vector<8xf32>
      %1098 = vector.fma %1097, %72, %1067 : vector<8xf32>
      %1099 = affine.apply #map7()[%arg1]
      %1100 = memref.load %assume_align[%arg0, %1099, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1101 = vector.broadcast %1100 : f32 to vector<8xf32>
      %1102 = vector.fma %1101, %72, %1071 : vector<8xf32>
      %1103 = affine.apply #map8()[%arg1]
      %1104 = memref.load %assume_align[%arg0, %1103, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1105 = vector.broadcast %1104 : f32 to vector<8xf32>
      %1106 = vector.fma %1105, %72, %1075 : vector<8xf32>
      %1107 = affine.apply #map9()[%arg1]
      %1108 = memref.load %assume_align[%arg0, %1107, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1109 = vector.broadcast %1108 : f32 to vector<8xf32>
      %1110 = vector.fma %1109, %72, %1079 : vector<8xf32>
      %1111 = affine.apply #map10()[%arg1]
      %1112 = memref.load %assume_align[%arg0, %1111, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1113 = vector.broadcast %1112 : f32 to vector<8xf32>
      %1114 = vector.fma %1113, %72, %1083 : vector<8xf32>
      %1115 = affine.apply #map11()[%arg1]
      %1116 = memref.load %assume_align[%arg0, %1115, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1117 = vector.broadcast %1116 : f32 to vector<8xf32>
      %1118 = vector.fma %1117, %72, %1087 : vector<8xf32>
      %1119 = affine.apply #map12()[%arg1]
      %1120 = memref.load %assume_align[%arg0, %1119, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1121 = vector.broadcast %1120 : f32 to vector<8xf32>
      %1122 = vector.fma %1121, %72, %1091 : vector<8xf32>
      %1123 = affine.apply #map13()[%arg1]
      %1124 = memref.load %assume_align[%arg0, %1123, %c32] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1125 = vector.broadcast %1124 : f32 to vector<8xf32>
      %1126 = vector.fma %1125, %72, %1095 : vector<8xf32>
      %1127 = memref.load %assume_align[%arg0, %arg1, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1128 = vector.broadcast %1127 : f32 to vector<8xf32>
      %1129 = vector.fma %1128, %73, %1098 : vector<8xf32>
      %1130 = affine.apply #map7()[%arg1]
      %1131 = memref.load %assume_align[%arg0, %1130, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1132 = vector.broadcast %1131 : f32 to vector<8xf32>
      %1133 = vector.fma %1132, %73, %1102 : vector<8xf32>
      %1134 = affine.apply #map8()[%arg1]
      %1135 = memref.load %assume_align[%arg0, %1134, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1136 = vector.broadcast %1135 : f32 to vector<8xf32>
      %1137 = vector.fma %1136, %73, %1106 : vector<8xf32>
      %1138 = affine.apply #map9()[%arg1]
      %1139 = memref.load %assume_align[%arg0, %1138, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1140 = vector.broadcast %1139 : f32 to vector<8xf32>
      %1141 = vector.fma %1140, %73, %1110 : vector<8xf32>
      %1142 = affine.apply #map10()[%arg1]
      %1143 = memref.load %assume_align[%arg0, %1142, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1144 = vector.broadcast %1143 : f32 to vector<8xf32>
      %1145 = vector.fma %1144, %73, %1114 : vector<8xf32>
      %1146 = affine.apply #map11()[%arg1]
      %1147 = memref.load %assume_align[%arg0, %1146, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1148 = vector.broadcast %1147 : f32 to vector<8xf32>
      %1149 = vector.fma %1148, %73, %1118 : vector<8xf32>
      %1150 = affine.apply #map12()[%arg1]
      %1151 = memref.load %assume_align[%arg0, %1150, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1152 = vector.broadcast %1151 : f32 to vector<8xf32>
      %1153 = vector.fma %1152, %73, %1122 : vector<8xf32>
      %1154 = affine.apply #map13()[%arg1]
      %1155 = memref.load %assume_align[%arg0, %1154, %c33] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1156 = vector.broadcast %1155 : f32 to vector<8xf32>
      %1157 = vector.fma %1156, %73, %1126 : vector<8xf32>
      %1158 = memref.load %assume_align[%arg0, %arg1, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1159 = vector.broadcast %1158 : f32 to vector<8xf32>
      %1160 = vector.fma %1159, %74, %1129 : vector<8xf32>
      %1161 = affine.apply #map7()[%arg1]
      %1162 = memref.load %assume_align[%arg0, %1161, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1163 = vector.broadcast %1162 : f32 to vector<8xf32>
      %1164 = vector.fma %1163, %74, %1133 : vector<8xf32>
      %1165 = affine.apply #map8()[%arg1]
      %1166 = memref.load %assume_align[%arg0, %1165, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1167 = vector.broadcast %1166 : f32 to vector<8xf32>
      %1168 = vector.fma %1167, %74, %1137 : vector<8xf32>
      %1169 = affine.apply #map9()[%arg1]
      %1170 = memref.load %assume_align[%arg0, %1169, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1171 = vector.broadcast %1170 : f32 to vector<8xf32>
      %1172 = vector.fma %1171, %74, %1141 : vector<8xf32>
      %1173 = affine.apply #map10()[%arg1]
      %1174 = memref.load %assume_align[%arg0, %1173, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1175 = vector.broadcast %1174 : f32 to vector<8xf32>
      %1176 = vector.fma %1175, %74, %1145 : vector<8xf32>
      %1177 = affine.apply #map11()[%arg1]
      %1178 = memref.load %assume_align[%arg0, %1177, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1179 = vector.broadcast %1178 : f32 to vector<8xf32>
      %1180 = vector.fma %1179, %74, %1149 : vector<8xf32>
      %1181 = affine.apply #map12()[%arg1]
      %1182 = memref.load %assume_align[%arg0, %1181, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1183 = vector.broadcast %1182 : f32 to vector<8xf32>
      %1184 = vector.fma %1183, %74, %1153 : vector<8xf32>
      %1185 = affine.apply #map13()[%arg1]
      %1186 = memref.load %assume_align[%arg0, %1185, %c34] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1187 = vector.broadcast %1186 : f32 to vector<8xf32>
      %1188 = vector.fma %1187, %74, %1157 : vector<8xf32>
      %1189 = memref.load %assume_align[%arg0, %arg1, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1190 = vector.broadcast %1189 : f32 to vector<8xf32>
      %1191 = vector.fma %1190, %75, %1160 : vector<8xf32>
      %1192 = affine.apply #map7()[%arg1]
      %1193 = memref.load %assume_align[%arg0, %1192, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1194 = vector.broadcast %1193 : f32 to vector<8xf32>
      %1195 = vector.fma %1194, %75, %1164 : vector<8xf32>
      %1196 = affine.apply #map8()[%arg1]
      %1197 = memref.load %assume_align[%arg0, %1196, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1198 = vector.broadcast %1197 : f32 to vector<8xf32>
      %1199 = vector.fma %1198, %75, %1168 : vector<8xf32>
      %1200 = affine.apply #map9()[%arg1]
      %1201 = memref.load %assume_align[%arg0, %1200, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1202 = vector.broadcast %1201 : f32 to vector<8xf32>
      %1203 = vector.fma %1202, %75, %1172 : vector<8xf32>
      %1204 = affine.apply #map10()[%arg1]
      %1205 = memref.load %assume_align[%arg0, %1204, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1206 = vector.broadcast %1205 : f32 to vector<8xf32>
      %1207 = vector.fma %1206, %75, %1176 : vector<8xf32>
      %1208 = affine.apply #map11()[%arg1]
      %1209 = memref.load %assume_align[%arg0, %1208, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1210 = vector.broadcast %1209 : f32 to vector<8xf32>
      %1211 = vector.fma %1210, %75, %1180 : vector<8xf32>
      %1212 = affine.apply #map12()[%arg1]
      %1213 = memref.load %assume_align[%arg0, %1212, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1214 = vector.broadcast %1213 : f32 to vector<8xf32>
      %1215 = vector.fma %1214, %75, %1184 : vector<8xf32>
      %1216 = affine.apply #map13()[%arg1]
      %1217 = memref.load %assume_align[%arg0, %1216, %c35] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1218 = vector.broadcast %1217 : f32 to vector<8xf32>
      %1219 = vector.fma %1218, %75, %1188 : vector<8xf32>
      %1220 = memref.load %assume_align[%arg0, %arg1, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1221 = vector.broadcast %1220 : f32 to vector<8xf32>
      %1222 = vector.fma %1221, %76, %1191 : vector<8xf32>
      %1223 = affine.apply #map7()[%arg1]
      %1224 = memref.load %assume_align[%arg0, %1223, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1225 = vector.broadcast %1224 : f32 to vector<8xf32>
      %1226 = vector.fma %1225, %76, %1195 : vector<8xf32>
      %1227 = affine.apply #map8()[%arg1]
      %1228 = memref.load %assume_align[%arg0, %1227, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1229 = vector.broadcast %1228 : f32 to vector<8xf32>
      %1230 = vector.fma %1229, %76, %1199 : vector<8xf32>
      %1231 = affine.apply #map9()[%arg1]
      %1232 = memref.load %assume_align[%arg0, %1231, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1233 = vector.broadcast %1232 : f32 to vector<8xf32>
      %1234 = vector.fma %1233, %76, %1203 : vector<8xf32>
      %1235 = affine.apply #map10()[%arg1]
      %1236 = memref.load %assume_align[%arg0, %1235, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1237 = vector.broadcast %1236 : f32 to vector<8xf32>
      %1238 = vector.fma %1237, %76, %1207 : vector<8xf32>
      %1239 = affine.apply #map11()[%arg1]
      %1240 = memref.load %assume_align[%arg0, %1239, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1241 = vector.broadcast %1240 : f32 to vector<8xf32>
      %1242 = vector.fma %1241, %76, %1211 : vector<8xf32>
      %1243 = affine.apply #map12()[%arg1]
      %1244 = memref.load %assume_align[%arg0, %1243, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1245 = vector.broadcast %1244 : f32 to vector<8xf32>
      %1246 = vector.fma %1245, %76, %1215 : vector<8xf32>
      %1247 = affine.apply #map13()[%arg1]
      %1248 = memref.load %assume_align[%arg0, %1247, %c36] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1249 = vector.broadcast %1248 : f32 to vector<8xf32>
      %1250 = vector.fma %1249, %76, %1219 : vector<8xf32>
      %1251 = memref.load %assume_align[%arg0, %arg1, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1252 = vector.broadcast %1251 : f32 to vector<8xf32>
      %1253 = vector.fma %1252, %77, %1222 : vector<8xf32>
      %1254 = affine.apply #map7()[%arg1]
      %1255 = memref.load %assume_align[%arg0, %1254, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1256 = vector.broadcast %1255 : f32 to vector<8xf32>
      %1257 = vector.fma %1256, %77, %1226 : vector<8xf32>
      %1258 = affine.apply #map8()[%arg1]
      %1259 = memref.load %assume_align[%arg0, %1258, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1260 = vector.broadcast %1259 : f32 to vector<8xf32>
      %1261 = vector.fma %1260, %77, %1230 : vector<8xf32>
      %1262 = affine.apply #map9()[%arg1]
      %1263 = memref.load %assume_align[%arg0, %1262, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1264 = vector.broadcast %1263 : f32 to vector<8xf32>
      %1265 = vector.fma %1264, %77, %1234 : vector<8xf32>
      %1266 = affine.apply #map10()[%arg1]
      %1267 = memref.load %assume_align[%arg0, %1266, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1268 = vector.broadcast %1267 : f32 to vector<8xf32>
      %1269 = vector.fma %1268, %77, %1238 : vector<8xf32>
      %1270 = affine.apply #map11()[%arg1]
      %1271 = memref.load %assume_align[%arg0, %1270, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1272 = vector.broadcast %1271 : f32 to vector<8xf32>
      %1273 = vector.fma %1272, %77, %1242 : vector<8xf32>
      %1274 = affine.apply #map12()[%arg1]
      %1275 = memref.load %assume_align[%arg0, %1274, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1276 = vector.broadcast %1275 : f32 to vector<8xf32>
      %1277 = vector.fma %1276, %77, %1246 : vector<8xf32>
      %1278 = affine.apply #map13()[%arg1]
      %1279 = memref.load %assume_align[%arg0, %1278, %c37] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1280 = vector.broadcast %1279 : f32 to vector<8xf32>
      %1281 = vector.fma %1280, %77, %1250 : vector<8xf32>
      %1282 = memref.load %assume_align[%arg0, %arg1, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1283 = vector.broadcast %1282 : f32 to vector<8xf32>
      %1284 = vector.fma %1283, %78, %1253 : vector<8xf32>
      %1285 = affine.apply #map7()[%arg1]
      %1286 = memref.load %assume_align[%arg0, %1285, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1287 = vector.broadcast %1286 : f32 to vector<8xf32>
      %1288 = vector.fma %1287, %78, %1257 : vector<8xf32>
      %1289 = affine.apply #map8()[%arg1]
      %1290 = memref.load %assume_align[%arg0, %1289, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1291 = vector.broadcast %1290 : f32 to vector<8xf32>
      %1292 = vector.fma %1291, %78, %1261 : vector<8xf32>
      %1293 = affine.apply #map9()[%arg1]
      %1294 = memref.load %assume_align[%arg0, %1293, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1295 = vector.broadcast %1294 : f32 to vector<8xf32>
      %1296 = vector.fma %1295, %78, %1265 : vector<8xf32>
      %1297 = affine.apply #map10()[%arg1]
      %1298 = memref.load %assume_align[%arg0, %1297, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1299 = vector.broadcast %1298 : f32 to vector<8xf32>
      %1300 = vector.fma %1299, %78, %1269 : vector<8xf32>
      %1301 = affine.apply #map11()[%arg1]
      %1302 = memref.load %assume_align[%arg0, %1301, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1303 = vector.broadcast %1302 : f32 to vector<8xf32>
      %1304 = vector.fma %1303, %78, %1273 : vector<8xf32>
      %1305 = affine.apply #map12()[%arg1]
      %1306 = memref.load %assume_align[%arg0, %1305, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1307 = vector.broadcast %1306 : f32 to vector<8xf32>
      %1308 = vector.fma %1307, %78, %1277 : vector<8xf32>
      %1309 = affine.apply #map13()[%arg1]
      %1310 = memref.load %assume_align[%arg0, %1309, %c38] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1311 = vector.broadcast %1310 : f32 to vector<8xf32>
      %1312 = vector.fma %1311, %78, %1281 : vector<8xf32>
      %1313 = memref.load %assume_align[%arg0, %arg1, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1314 = vector.broadcast %1313 : f32 to vector<8xf32>
      %1315 = vector.fma %1314, %79, %1284 : vector<8xf32>
      %1316 = affine.apply #map7()[%arg1]
      %1317 = memref.load %assume_align[%arg0, %1316, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1318 = vector.broadcast %1317 : f32 to vector<8xf32>
      %1319 = vector.fma %1318, %79, %1288 : vector<8xf32>
      %1320 = affine.apply #map8()[%arg1]
      %1321 = memref.load %assume_align[%arg0, %1320, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1322 = vector.broadcast %1321 : f32 to vector<8xf32>
      %1323 = vector.fma %1322, %79, %1292 : vector<8xf32>
      %1324 = affine.apply #map9()[%arg1]
      %1325 = memref.load %assume_align[%arg0, %1324, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1326 = vector.broadcast %1325 : f32 to vector<8xf32>
      %1327 = vector.fma %1326, %79, %1296 : vector<8xf32>
      %1328 = affine.apply #map10()[%arg1]
      %1329 = memref.load %assume_align[%arg0, %1328, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1330 = vector.broadcast %1329 : f32 to vector<8xf32>
      %1331 = vector.fma %1330, %79, %1300 : vector<8xf32>
      %1332 = affine.apply #map11()[%arg1]
      %1333 = memref.load %assume_align[%arg0, %1332, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1334 = vector.broadcast %1333 : f32 to vector<8xf32>
      %1335 = vector.fma %1334, %79, %1304 : vector<8xf32>
      %1336 = affine.apply #map12()[%arg1]
      %1337 = memref.load %assume_align[%arg0, %1336, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1338 = vector.broadcast %1337 : f32 to vector<8xf32>
      %1339 = vector.fma %1338, %79, %1308 : vector<8xf32>
      %1340 = affine.apply #map13()[%arg1]
      %1341 = memref.load %assume_align[%arg0, %1340, %c39] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1342 = vector.broadcast %1341 : f32 to vector<8xf32>
      %1343 = vector.fma %1342, %79, %1312 : vector<8xf32>
      %1344 = memref.load %assume_align[%arg0, %arg1, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1345 = vector.broadcast %1344 : f32 to vector<8xf32>
      %1346 = vector.fma %1345, %80, %1315 : vector<8xf32>
      %1347 = affine.apply #map7()[%arg1]
      %1348 = memref.load %assume_align[%arg0, %1347, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1349 = vector.broadcast %1348 : f32 to vector<8xf32>
      %1350 = vector.fma %1349, %80, %1319 : vector<8xf32>
      %1351 = affine.apply #map8()[%arg1]
      %1352 = memref.load %assume_align[%arg0, %1351, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1353 = vector.broadcast %1352 : f32 to vector<8xf32>
      %1354 = vector.fma %1353, %80, %1323 : vector<8xf32>
      %1355 = affine.apply #map9()[%arg1]
      %1356 = memref.load %assume_align[%arg0, %1355, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1357 = vector.broadcast %1356 : f32 to vector<8xf32>
      %1358 = vector.fma %1357, %80, %1327 : vector<8xf32>
      %1359 = affine.apply #map10()[%arg1]
      %1360 = memref.load %assume_align[%arg0, %1359, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1361 = vector.broadcast %1360 : f32 to vector<8xf32>
      %1362 = vector.fma %1361, %80, %1331 : vector<8xf32>
      %1363 = affine.apply #map11()[%arg1]
      %1364 = memref.load %assume_align[%arg0, %1363, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1365 = vector.broadcast %1364 : f32 to vector<8xf32>
      %1366 = vector.fma %1365, %80, %1335 : vector<8xf32>
      %1367 = affine.apply #map12()[%arg1]
      %1368 = memref.load %assume_align[%arg0, %1367, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1369 = vector.broadcast %1368 : f32 to vector<8xf32>
      %1370 = vector.fma %1369, %80, %1339 : vector<8xf32>
      %1371 = affine.apply #map13()[%arg1]
      %1372 = memref.load %assume_align[%arg0, %1371, %c40] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1373 = vector.broadcast %1372 : f32 to vector<8xf32>
      %1374 = vector.fma %1373, %80, %1343 : vector<8xf32>
      %1375 = memref.load %assume_align[%arg0, %arg1, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1376 = vector.broadcast %1375 : f32 to vector<8xf32>
      %1377 = vector.fma %1376, %81, %1346 : vector<8xf32>
      %1378 = affine.apply #map7()[%arg1]
      %1379 = memref.load %assume_align[%arg0, %1378, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1380 = vector.broadcast %1379 : f32 to vector<8xf32>
      %1381 = vector.fma %1380, %81, %1350 : vector<8xf32>
      %1382 = affine.apply #map8()[%arg1]
      %1383 = memref.load %assume_align[%arg0, %1382, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1384 = vector.broadcast %1383 : f32 to vector<8xf32>
      %1385 = vector.fma %1384, %81, %1354 : vector<8xf32>
      %1386 = affine.apply #map9()[%arg1]
      %1387 = memref.load %assume_align[%arg0, %1386, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1388 = vector.broadcast %1387 : f32 to vector<8xf32>
      %1389 = vector.fma %1388, %81, %1358 : vector<8xf32>
      %1390 = affine.apply #map10()[%arg1]
      %1391 = memref.load %assume_align[%arg0, %1390, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1392 = vector.broadcast %1391 : f32 to vector<8xf32>
      %1393 = vector.fma %1392, %81, %1362 : vector<8xf32>
      %1394 = affine.apply #map11()[%arg1]
      %1395 = memref.load %assume_align[%arg0, %1394, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1396 = vector.broadcast %1395 : f32 to vector<8xf32>
      %1397 = vector.fma %1396, %81, %1366 : vector<8xf32>
      %1398 = affine.apply #map12()[%arg1]
      %1399 = memref.load %assume_align[%arg0, %1398, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1400 = vector.broadcast %1399 : f32 to vector<8xf32>
      %1401 = vector.fma %1400, %81, %1370 : vector<8xf32>
      %1402 = affine.apply #map13()[%arg1]
      %1403 = memref.load %assume_align[%arg0, %1402, %c41] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1404 = vector.broadcast %1403 : f32 to vector<8xf32>
      %1405 = vector.fma %1404, %81, %1374 : vector<8xf32>
      %1406 = memref.load %assume_align[%arg0, %arg1, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1407 = vector.broadcast %1406 : f32 to vector<8xf32>
      %1408 = vector.fma %1407, %82, %1377 : vector<8xf32>
      %1409 = affine.apply #map7()[%arg1]
      %1410 = memref.load %assume_align[%arg0, %1409, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1411 = vector.broadcast %1410 : f32 to vector<8xf32>
      %1412 = vector.fma %1411, %82, %1381 : vector<8xf32>
      %1413 = affine.apply #map8()[%arg1]
      %1414 = memref.load %assume_align[%arg0, %1413, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1415 = vector.broadcast %1414 : f32 to vector<8xf32>
      %1416 = vector.fma %1415, %82, %1385 : vector<8xf32>
      %1417 = affine.apply #map9()[%arg1]
      %1418 = memref.load %assume_align[%arg0, %1417, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1419 = vector.broadcast %1418 : f32 to vector<8xf32>
      %1420 = vector.fma %1419, %82, %1389 : vector<8xf32>
      %1421 = affine.apply #map10()[%arg1]
      %1422 = memref.load %assume_align[%arg0, %1421, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1423 = vector.broadcast %1422 : f32 to vector<8xf32>
      %1424 = vector.fma %1423, %82, %1393 : vector<8xf32>
      %1425 = affine.apply #map11()[%arg1]
      %1426 = memref.load %assume_align[%arg0, %1425, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1427 = vector.broadcast %1426 : f32 to vector<8xf32>
      %1428 = vector.fma %1427, %82, %1397 : vector<8xf32>
      %1429 = affine.apply #map12()[%arg1]
      %1430 = memref.load %assume_align[%arg0, %1429, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1431 = vector.broadcast %1430 : f32 to vector<8xf32>
      %1432 = vector.fma %1431, %82, %1401 : vector<8xf32>
      %1433 = affine.apply #map13()[%arg1]
      %1434 = memref.load %assume_align[%arg0, %1433, %c42] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1435 = vector.broadcast %1434 : f32 to vector<8xf32>
      %1436 = vector.fma %1435, %82, %1405 : vector<8xf32>
      %1437 = memref.load %assume_align[%arg0, %arg1, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1438 = vector.broadcast %1437 : f32 to vector<8xf32>
      %1439 = vector.fma %1438, %83, %1408 : vector<8xf32>
      %1440 = affine.apply #map7()[%arg1]
      %1441 = memref.load %assume_align[%arg0, %1440, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1442 = vector.broadcast %1441 : f32 to vector<8xf32>
      %1443 = vector.fma %1442, %83, %1412 : vector<8xf32>
      %1444 = affine.apply #map8()[%arg1]
      %1445 = memref.load %assume_align[%arg0, %1444, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1446 = vector.broadcast %1445 : f32 to vector<8xf32>
      %1447 = vector.fma %1446, %83, %1416 : vector<8xf32>
      %1448 = affine.apply #map9()[%arg1]
      %1449 = memref.load %assume_align[%arg0, %1448, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1450 = vector.broadcast %1449 : f32 to vector<8xf32>
      %1451 = vector.fma %1450, %83, %1420 : vector<8xf32>
      %1452 = affine.apply #map10()[%arg1]
      %1453 = memref.load %assume_align[%arg0, %1452, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1454 = vector.broadcast %1453 : f32 to vector<8xf32>
      %1455 = vector.fma %1454, %83, %1424 : vector<8xf32>
      %1456 = affine.apply #map11()[%arg1]
      %1457 = memref.load %assume_align[%arg0, %1456, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1458 = vector.broadcast %1457 : f32 to vector<8xf32>
      %1459 = vector.fma %1458, %83, %1428 : vector<8xf32>
      %1460 = affine.apply #map12()[%arg1]
      %1461 = memref.load %assume_align[%arg0, %1460, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1462 = vector.broadcast %1461 : f32 to vector<8xf32>
      %1463 = vector.fma %1462, %83, %1432 : vector<8xf32>
      %1464 = affine.apply #map13()[%arg1]
      %1465 = memref.load %assume_align[%arg0, %1464, %c43] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1466 = vector.broadcast %1465 : f32 to vector<8xf32>
      %1467 = vector.fma %1466, %83, %1436 : vector<8xf32>
      %1468 = memref.load %assume_align[%arg0, %arg1, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1469 = vector.broadcast %1468 : f32 to vector<8xf32>
      %1470 = vector.fma %1469, %84, %1439 : vector<8xf32>
      %1471 = affine.apply #map7()[%arg1]
      %1472 = memref.load %assume_align[%arg0, %1471, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1473 = vector.broadcast %1472 : f32 to vector<8xf32>
      %1474 = vector.fma %1473, %84, %1443 : vector<8xf32>
      %1475 = affine.apply #map8()[%arg1]
      %1476 = memref.load %assume_align[%arg0, %1475, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1477 = vector.broadcast %1476 : f32 to vector<8xf32>
      %1478 = vector.fma %1477, %84, %1447 : vector<8xf32>
      %1479 = affine.apply #map9()[%arg1]
      %1480 = memref.load %assume_align[%arg0, %1479, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1481 = vector.broadcast %1480 : f32 to vector<8xf32>
      %1482 = vector.fma %1481, %84, %1451 : vector<8xf32>
      %1483 = affine.apply #map10()[%arg1]
      %1484 = memref.load %assume_align[%arg0, %1483, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1485 = vector.broadcast %1484 : f32 to vector<8xf32>
      %1486 = vector.fma %1485, %84, %1455 : vector<8xf32>
      %1487 = affine.apply #map11()[%arg1]
      %1488 = memref.load %assume_align[%arg0, %1487, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1489 = vector.broadcast %1488 : f32 to vector<8xf32>
      %1490 = vector.fma %1489, %84, %1459 : vector<8xf32>
      %1491 = affine.apply #map12()[%arg1]
      %1492 = memref.load %assume_align[%arg0, %1491, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1493 = vector.broadcast %1492 : f32 to vector<8xf32>
      %1494 = vector.fma %1493, %84, %1463 : vector<8xf32>
      %1495 = affine.apply #map13()[%arg1]
      %1496 = memref.load %assume_align[%arg0, %1495, %c44] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1497 = vector.broadcast %1496 : f32 to vector<8xf32>
      %1498 = vector.fma %1497, %84, %1467 : vector<8xf32>
      %1499 = memref.load %assume_align[%arg0, %arg1, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1500 = vector.broadcast %1499 : f32 to vector<8xf32>
      %1501 = vector.fma %1500, %85, %1470 : vector<8xf32>
      %1502 = affine.apply #map7()[%arg1]
      %1503 = memref.load %assume_align[%arg0, %1502, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1504 = vector.broadcast %1503 : f32 to vector<8xf32>
      %1505 = vector.fma %1504, %85, %1474 : vector<8xf32>
      %1506 = affine.apply #map8()[%arg1]
      %1507 = memref.load %assume_align[%arg0, %1506, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1508 = vector.broadcast %1507 : f32 to vector<8xf32>
      %1509 = vector.fma %1508, %85, %1478 : vector<8xf32>
      %1510 = affine.apply #map9()[%arg1]
      %1511 = memref.load %assume_align[%arg0, %1510, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1512 = vector.broadcast %1511 : f32 to vector<8xf32>
      %1513 = vector.fma %1512, %85, %1482 : vector<8xf32>
      %1514 = affine.apply #map10()[%arg1]
      %1515 = memref.load %assume_align[%arg0, %1514, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1516 = vector.broadcast %1515 : f32 to vector<8xf32>
      %1517 = vector.fma %1516, %85, %1486 : vector<8xf32>
      %1518 = affine.apply #map11()[%arg1]
      %1519 = memref.load %assume_align[%arg0, %1518, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1520 = vector.broadcast %1519 : f32 to vector<8xf32>
      %1521 = vector.fma %1520, %85, %1490 : vector<8xf32>
      %1522 = affine.apply #map12()[%arg1]
      %1523 = memref.load %assume_align[%arg0, %1522, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1524 = vector.broadcast %1523 : f32 to vector<8xf32>
      %1525 = vector.fma %1524, %85, %1494 : vector<8xf32>
      %1526 = affine.apply #map13()[%arg1]
      %1527 = memref.load %assume_align[%arg0, %1526, %c45] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1528 = vector.broadcast %1527 : f32 to vector<8xf32>
      %1529 = vector.fma %1528, %85, %1498 : vector<8xf32>
      %1530 = memref.load %assume_align[%arg0, %arg1, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1531 = vector.broadcast %1530 : f32 to vector<8xf32>
      %1532 = vector.fma %1531, %86, %1501 : vector<8xf32>
      %1533 = affine.apply #map7()[%arg1]
      %1534 = memref.load %assume_align[%arg0, %1533, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1535 = vector.broadcast %1534 : f32 to vector<8xf32>
      %1536 = vector.fma %1535, %86, %1505 : vector<8xf32>
      %1537 = affine.apply #map8()[%arg1]
      %1538 = memref.load %assume_align[%arg0, %1537, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1539 = vector.broadcast %1538 : f32 to vector<8xf32>
      %1540 = vector.fma %1539, %86, %1509 : vector<8xf32>
      %1541 = affine.apply #map9()[%arg1]
      %1542 = memref.load %assume_align[%arg0, %1541, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1543 = vector.broadcast %1542 : f32 to vector<8xf32>
      %1544 = vector.fma %1543, %86, %1513 : vector<8xf32>
      %1545 = affine.apply #map10()[%arg1]
      %1546 = memref.load %assume_align[%arg0, %1545, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1547 = vector.broadcast %1546 : f32 to vector<8xf32>
      %1548 = vector.fma %1547, %86, %1517 : vector<8xf32>
      %1549 = affine.apply #map11()[%arg1]
      %1550 = memref.load %assume_align[%arg0, %1549, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1551 = vector.broadcast %1550 : f32 to vector<8xf32>
      %1552 = vector.fma %1551, %86, %1521 : vector<8xf32>
      %1553 = affine.apply #map12()[%arg1]
      %1554 = memref.load %assume_align[%arg0, %1553, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1555 = vector.broadcast %1554 : f32 to vector<8xf32>
      %1556 = vector.fma %1555, %86, %1525 : vector<8xf32>
      %1557 = affine.apply #map13()[%arg1]
      %1558 = memref.load %assume_align[%arg0, %1557, %c46] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1559 = vector.broadcast %1558 : f32 to vector<8xf32>
      %1560 = vector.fma %1559, %86, %1529 : vector<8xf32>
      %1561 = memref.load %assume_align[%arg0, %arg1, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1562 = vector.broadcast %1561 : f32 to vector<8xf32>
      %1563 = vector.fma %1562, %87, %1532 : vector<8xf32>
      %1564 = affine.apply #map7()[%arg1]
      %1565 = memref.load %assume_align[%arg0, %1564, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1566 = vector.broadcast %1565 : f32 to vector<8xf32>
      %1567 = vector.fma %1566, %87, %1536 : vector<8xf32>
      %1568 = affine.apply #map8()[%arg1]
      %1569 = memref.load %assume_align[%arg0, %1568, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1570 = vector.broadcast %1569 : f32 to vector<8xf32>
      %1571 = vector.fma %1570, %87, %1540 : vector<8xf32>
      %1572 = affine.apply #map9()[%arg1]
      %1573 = memref.load %assume_align[%arg0, %1572, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1574 = vector.broadcast %1573 : f32 to vector<8xf32>
      %1575 = vector.fma %1574, %87, %1544 : vector<8xf32>
      %1576 = affine.apply #map10()[%arg1]
      %1577 = memref.load %assume_align[%arg0, %1576, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1578 = vector.broadcast %1577 : f32 to vector<8xf32>
      %1579 = vector.fma %1578, %87, %1548 : vector<8xf32>
      %1580 = affine.apply #map11()[%arg1]
      %1581 = memref.load %assume_align[%arg0, %1580, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1582 = vector.broadcast %1581 : f32 to vector<8xf32>
      %1583 = vector.fma %1582, %87, %1552 : vector<8xf32>
      %1584 = affine.apply #map12()[%arg1]
      %1585 = memref.load %assume_align[%arg0, %1584, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1586 = vector.broadcast %1585 : f32 to vector<8xf32>
      %1587 = vector.fma %1586, %87, %1556 : vector<8xf32>
      %1588 = affine.apply #map13()[%arg1]
      %1589 = memref.load %assume_align[%arg0, %1588, %c47] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1590 = vector.broadcast %1589 : f32 to vector<8xf32>
      %1591 = vector.fma %1590, %87, %1560 : vector<8xf32>
      %1592 = memref.load %assume_align[%arg0, %arg1, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1593 = vector.broadcast %1592 : f32 to vector<8xf32>
      %1594 = vector.fma %1593, %88, %1563 : vector<8xf32>
      %1595 = affine.apply #map7()[%arg1]
      %1596 = memref.load %assume_align[%arg0, %1595, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1597 = vector.broadcast %1596 : f32 to vector<8xf32>
      %1598 = vector.fma %1597, %88, %1567 : vector<8xf32>
      %1599 = affine.apply #map8()[%arg1]
      %1600 = memref.load %assume_align[%arg0, %1599, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1601 = vector.broadcast %1600 : f32 to vector<8xf32>
      %1602 = vector.fma %1601, %88, %1571 : vector<8xf32>
      %1603 = affine.apply #map9()[%arg1]
      %1604 = memref.load %assume_align[%arg0, %1603, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1605 = vector.broadcast %1604 : f32 to vector<8xf32>
      %1606 = vector.fma %1605, %88, %1575 : vector<8xf32>
      %1607 = affine.apply #map10()[%arg1]
      %1608 = memref.load %assume_align[%arg0, %1607, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1609 = vector.broadcast %1608 : f32 to vector<8xf32>
      %1610 = vector.fma %1609, %88, %1579 : vector<8xf32>
      %1611 = affine.apply #map11()[%arg1]
      %1612 = memref.load %assume_align[%arg0, %1611, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1613 = vector.broadcast %1612 : f32 to vector<8xf32>
      %1614 = vector.fma %1613, %88, %1583 : vector<8xf32>
      %1615 = affine.apply #map12()[%arg1]
      %1616 = memref.load %assume_align[%arg0, %1615, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1617 = vector.broadcast %1616 : f32 to vector<8xf32>
      %1618 = vector.fma %1617, %88, %1587 : vector<8xf32>
      %1619 = affine.apply #map13()[%arg1]
      %1620 = memref.load %assume_align[%arg0, %1619, %c48] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1621 = vector.broadcast %1620 : f32 to vector<8xf32>
      %1622 = vector.fma %1621, %88, %1591 : vector<8xf32>
      %1623 = memref.load %assume_align[%arg0, %arg1, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1624 = vector.broadcast %1623 : f32 to vector<8xf32>
      %1625 = vector.fma %1624, %89, %1594 : vector<8xf32>
      %1626 = affine.apply #map7()[%arg1]
      %1627 = memref.load %assume_align[%arg0, %1626, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1628 = vector.broadcast %1627 : f32 to vector<8xf32>
      %1629 = vector.fma %1628, %89, %1598 : vector<8xf32>
      %1630 = affine.apply #map8()[%arg1]
      %1631 = memref.load %assume_align[%arg0, %1630, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1632 = vector.broadcast %1631 : f32 to vector<8xf32>
      %1633 = vector.fma %1632, %89, %1602 : vector<8xf32>
      %1634 = affine.apply #map9()[%arg1]
      %1635 = memref.load %assume_align[%arg0, %1634, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1636 = vector.broadcast %1635 : f32 to vector<8xf32>
      %1637 = vector.fma %1636, %89, %1606 : vector<8xf32>
      %1638 = affine.apply #map10()[%arg1]
      %1639 = memref.load %assume_align[%arg0, %1638, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1640 = vector.broadcast %1639 : f32 to vector<8xf32>
      %1641 = vector.fma %1640, %89, %1610 : vector<8xf32>
      %1642 = affine.apply #map11()[%arg1]
      %1643 = memref.load %assume_align[%arg0, %1642, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1644 = vector.broadcast %1643 : f32 to vector<8xf32>
      %1645 = vector.fma %1644, %89, %1614 : vector<8xf32>
      %1646 = affine.apply #map12()[%arg1]
      %1647 = memref.load %assume_align[%arg0, %1646, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1648 = vector.broadcast %1647 : f32 to vector<8xf32>
      %1649 = vector.fma %1648, %89, %1618 : vector<8xf32>
      %1650 = affine.apply #map13()[%arg1]
      %1651 = memref.load %assume_align[%arg0, %1650, %c49] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1652 = vector.broadcast %1651 : f32 to vector<8xf32>
      %1653 = vector.fma %1652, %89, %1622 : vector<8xf32>
      %1654 = memref.load %assume_align[%arg0, %arg1, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1655 = vector.broadcast %1654 : f32 to vector<8xf32>
      %1656 = vector.fma %1655, %90, %1625 : vector<8xf32>
      %1657 = affine.apply #map7()[%arg1]
      %1658 = memref.load %assume_align[%arg0, %1657, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1659 = vector.broadcast %1658 : f32 to vector<8xf32>
      %1660 = vector.fma %1659, %90, %1629 : vector<8xf32>
      %1661 = affine.apply #map8()[%arg1]
      %1662 = memref.load %assume_align[%arg0, %1661, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1663 = vector.broadcast %1662 : f32 to vector<8xf32>
      %1664 = vector.fma %1663, %90, %1633 : vector<8xf32>
      %1665 = affine.apply #map9()[%arg1]
      %1666 = memref.load %assume_align[%arg0, %1665, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1667 = vector.broadcast %1666 : f32 to vector<8xf32>
      %1668 = vector.fma %1667, %90, %1637 : vector<8xf32>
      %1669 = affine.apply #map10()[%arg1]
      %1670 = memref.load %assume_align[%arg0, %1669, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1671 = vector.broadcast %1670 : f32 to vector<8xf32>
      %1672 = vector.fma %1671, %90, %1641 : vector<8xf32>
      %1673 = affine.apply #map11()[%arg1]
      %1674 = memref.load %assume_align[%arg0, %1673, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1675 = vector.broadcast %1674 : f32 to vector<8xf32>
      %1676 = vector.fma %1675, %90, %1645 : vector<8xf32>
      %1677 = affine.apply #map12()[%arg1]
      %1678 = memref.load %assume_align[%arg0, %1677, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1679 = vector.broadcast %1678 : f32 to vector<8xf32>
      %1680 = vector.fma %1679, %90, %1649 : vector<8xf32>
      %1681 = affine.apply #map13()[%arg1]
      %1682 = memref.load %assume_align[%arg0, %1681, %c50] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1683 = vector.broadcast %1682 : f32 to vector<8xf32>
      %1684 = vector.fma %1683, %90, %1653 : vector<8xf32>
      %1685 = memref.load %assume_align[%arg0, %arg1, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1686 = vector.broadcast %1685 : f32 to vector<8xf32>
      %1687 = vector.fma %1686, %91, %1656 : vector<8xf32>
      %1688 = affine.apply #map7()[%arg1]
      %1689 = memref.load %assume_align[%arg0, %1688, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1690 = vector.broadcast %1689 : f32 to vector<8xf32>
      %1691 = vector.fma %1690, %91, %1660 : vector<8xf32>
      %1692 = affine.apply #map8()[%arg1]
      %1693 = memref.load %assume_align[%arg0, %1692, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1694 = vector.broadcast %1693 : f32 to vector<8xf32>
      %1695 = vector.fma %1694, %91, %1664 : vector<8xf32>
      %1696 = affine.apply #map9()[%arg1]
      %1697 = memref.load %assume_align[%arg0, %1696, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1698 = vector.broadcast %1697 : f32 to vector<8xf32>
      %1699 = vector.fma %1698, %91, %1668 : vector<8xf32>
      %1700 = affine.apply #map10()[%arg1]
      %1701 = memref.load %assume_align[%arg0, %1700, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1702 = vector.broadcast %1701 : f32 to vector<8xf32>
      %1703 = vector.fma %1702, %91, %1672 : vector<8xf32>
      %1704 = affine.apply #map11()[%arg1]
      %1705 = memref.load %assume_align[%arg0, %1704, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1706 = vector.broadcast %1705 : f32 to vector<8xf32>
      %1707 = vector.fma %1706, %91, %1676 : vector<8xf32>
      %1708 = affine.apply #map12()[%arg1]
      %1709 = memref.load %assume_align[%arg0, %1708, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1710 = vector.broadcast %1709 : f32 to vector<8xf32>
      %1711 = vector.fma %1710, %91, %1680 : vector<8xf32>
      %1712 = affine.apply #map13()[%arg1]
      %1713 = memref.load %assume_align[%arg0, %1712, %c51] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1714 = vector.broadcast %1713 : f32 to vector<8xf32>
      %1715 = vector.fma %1714, %91, %1684 : vector<8xf32>
      %1716 = memref.load %assume_align[%arg0, %arg1, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1717 = vector.broadcast %1716 : f32 to vector<8xf32>
      %1718 = vector.fma %1717, %92, %1687 : vector<8xf32>
      %1719 = affine.apply #map7()[%arg1]
      %1720 = memref.load %assume_align[%arg0, %1719, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1721 = vector.broadcast %1720 : f32 to vector<8xf32>
      %1722 = vector.fma %1721, %92, %1691 : vector<8xf32>
      %1723 = affine.apply #map8()[%arg1]
      %1724 = memref.load %assume_align[%arg0, %1723, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1725 = vector.broadcast %1724 : f32 to vector<8xf32>
      %1726 = vector.fma %1725, %92, %1695 : vector<8xf32>
      %1727 = affine.apply #map9()[%arg1]
      %1728 = memref.load %assume_align[%arg0, %1727, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1729 = vector.broadcast %1728 : f32 to vector<8xf32>
      %1730 = vector.fma %1729, %92, %1699 : vector<8xf32>
      %1731 = affine.apply #map10()[%arg1]
      %1732 = memref.load %assume_align[%arg0, %1731, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1733 = vector.broadcast %1732 : f32 to vector<8xf32>
      %1734 = vector.fma %1733, %92, %1703 : vector<8xf32>
      %1735 = affine.apply #map11()[%arg1]
      %1736 = memref.load %assume_align[%arg0, %1735, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1737 = vector.broadcast %1736 : f32 to vector<8xf32>
      %1738 = vector.fma %1737, %92, %1707 : vector<8xf32>
      %1739 = affine.apply #map12()[%arg1]
      %1740 = memref.load %assume_align[%arg0, %1739, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1741 = vector.broadcast %1740 : f32 to vector<8xf32>
      %1742 = vector.fma %1741, %92, %1711 : vector<8xf32>
      %1743 = affine.apply #map13()[%arg1]
      %1744 = memref.load %assume_align[%arg0, %1743, %c52] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1745 = vector.broadcast %1744 : f32 to vector<8xf32>
      %1746 = vector.fma %1745, %92, %1715 : vector<8xf32>
      %1747 = memref.load %assume_align[%arg0, %arg1, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1748 = vector.broadcast %1747 : f32 to vector<8xf32>
      %1749 = vector.fma %1748, %93, %1718 : vector<8xf32>
      %1750 = affine.apply #map7()[%arg1]
      %1751 = memref.load %assume_align[%arg0, %1750, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1752 = vector.broadcast %1751 : f32 to vector<8xf32>
      %1753 = vector.fma %1752, %93, %1722 : vector<8xf32>
      %1754 = affine.apply #map8()[%arg1]
      %1755 = memref.load %assume_align[%arg0, %1754, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1756 = vector.broadcast %1755 : f32 to vector<8xf32>
      %1757 = vector.fma %1756, %93, %1726 : vector<8xf32>
      %1758 = affine.apply #map9()[%arg1]
      %1759 = memref.load %assume_align[%arg0, %1758, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1760 = vector.broadcast %1759 : f32 to vector<8xf32>
      %1761 = vector.fma %1760, %93, %1730 : vector<8xf32>
      %1762 = affine.apply #map10()[%arg1]
      %1763 = memref.load %assume_align[%arg0, %1762, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1764 = vector.broadcast %1763 : f32 to vector<8xf32>
      %1765 = vector.fma %1764, %93, %1734 : vector<8xf32>
      %1766 = affine.apply #map11()[%arg1]
      %1767 = memref.load %assume_align[%arg0, %1766, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1768 = vector.broadcast %1767 : f32 to vector<8xf32>
      %1769 = vector.fma %1768, %93, %1738 : vector<8xf32>
      %1770 = affine.apply #map12()[%arg1]
      %1771 = memref.load %assume_align[%arg0, %1770, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1772 = vector.broadcast %1771 : f32 to vector<8xf32>
      %1773 = vector.fma %1772, %93, %1742 : vector<8xf32>
      %1774 = affine.apply #map13()[%arg1]
      %1775 = memref.load %assume_align[%arg0, %1774, %c53] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1776 = vector.broadcast %1775 : f32 to vector<8xf32>
      %1777 = vector.fma %1776, %93, %1746 : vector<8xf32>
      %1778 = memref.load %assume_align[%arg0, %arg1, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1779 = vector.broadcast %1778 : f32 to vector<8xf32>
      %1780 = vector.fma %1779, %94, %1749 : vector<8xf32>
      %1781 = affine.apply #map7()[%arg1]
      %1782 = memref.load %assume_align[%arg0, %1781, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1783 = vector.broadcast %1782 : f32 to vector<8xf32>
      %1784 = vector.fma %1783, %94, %1753 : vector<8xf32>
      %1785 = affine.apply #map8()[%arg1]
      %1786 = memref.load %assume_align[%arg0, %1785, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1787 = vector.broadcast %1786 : f32 to vector<8xf32>
      %1788 = vector.fma %1787, %94, %1757 : vector<8xf32>
      %1789 = affine.apply #map9()[%arg1]
      %1790 = memref.load %assume_align[%arg0, %1789, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1791 = vector.broadcast %1790 : f32 to vector<8xf32>
      %1792 = vector.fma %1791, %94, %1761 : vector<8xf32>
      %1793 = affine.apply #map10()[%arg1]
      %1794 = memref.load %assume_align[%arg0, %1793, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1795 = vector.broadcast %1794 : f32 to vector<8xf32>
      %1796 = vector.fma %1795, %94, %1765 : vector<8xf32>
      %1797 = affine.apply #map11()[%arg1]
      %1798 = memref.load %assume_align[%arg0, %1797, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1799 = vector.broadcast %1798 : f32 to vector<8xf32>
      %1800 = vector.fma %1799, %94, %1769 : vector<8xf32>
      %1801 = affine.apply #map12()[%arg1]
      %1802 = memref.load %assume_align[%arg0, %1801, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1803 = vector.broadcast %1802 : f32 to vector<8xf32>
      %1804 = vector.fma %1803, %94, %1773 : vector<8xf32>
      %1805 = affine.apply #map13()[%arg1]
      %1806 = memref.load %assume_align[%arg0, %1805, %c54] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1807 = vector.broadcast %1806 : f32 to vector<8xf32>
      %1808 = vector.fma %1807, %94, %1777 : vector<8xf32>
      %1809 = memref.load %assume_align[%arg0, %arg1, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1810 = vector.broadcast %1809 : f32 to vector<8xf32>
      %1811 = vector.fma %1810, %95, %1780 : vector<8xf32>
      %1812 = affine.apply #map7()[%arg1]
      %1813 = memref.load %assume_align[%arg0, %1812, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1814 = vector.broadcast %1813 : f32 to vector<8xf32>
      %1815 = vector.fma %1814, %95, %1784 : vector<8xf32>
      %1816 = affine.apply #map8()[%arg1]
      %1817 = memref.load %assume_align[%arg0, %1816, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1818 = vector.broadcast %1817 : f32 to vector<8xf32>
      %1819 = vector.fma %1818, %95, %1788 : vector<8xf32>
      %1820 = affine.apply #map9()[%arg1]
      %1821 = memref.load %assume_align[%arg0, %1820, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1822 = vector.broadcast %1821 : f32 to vector<8xf32>
      %1823 = vector.fma %1822, %95, %1792 : vector<8xf32>
      %1824 = affine.apply #map10()[%arg1]
      %1825 = memref.load %assume_align[%arg0, %1824, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1826 = vector.broadcast %1825 : f32 to vector<8xf32>
      %1827 = vector.fma %1826, %95, %1796 : vector<8xf32>
      %1828 = affine.apply #map11()[%arg1]
      %1829 = memref.load %assume_align[%arg0, %1828, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1830 = vector.broadcast %1829 : f32 to vector<8xf32>
      %1831 = vector.fma %1830, %95, %1800 : vector<8xf32>
      %1832 = affine.apply #map12()[%arg1]
      %1833 = memref.load %assume_align[%arg0, %1832, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1834 = vector.broadcast %1833 : f32 to vector<8xf32>
      %1835 = vector.fma %1834, %95, %1804 : vector<8xf32>
      %1836 = affine.apply #map13()[%arg1]
      %1837 = memref.load %assume_align[%arg0, %1836, %c55] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1838 = vector.broadcast %1837 : f32 to vector<8xf32>
      %1839 = vector.fma %1838, %95, %1808 : vector<8xf32>
      %1840 = memref.load %assume_align[%arg0, %arg1, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1841 = vector.broadcast %1840 : f32 to vector<8xf32>
      %1842 = vector.fma %1841, %96, %1811 : vector<8xf32>
      %1843 = affine.apply #map7()[%arg1]
      %1844 = memref.load %assume_align[%arg0, %1843, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1845 = vector.broadcast %1844 : f32 to vector<8xf32>
      %1846 = vector.fma %1845, %96, %1815 : vector<8xf32>
      %1847 = affine.apply #map8()[%arg1]
      %1848 = memref.load %assume_align[%arg0, %1847, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1849 = vector.broadcast %1848 : f32 to vector<8xf32>
      %1850 = vector.fma %1849, %96, %1819 : vector<8xf32>
      %1851 = affine.apply #map9()[%arg1]
      %1852 = memref.load %assume_align[%arg0, %1851, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1853 = vector.broadcast %1852 : f32 to vector<8xf32>
      %1854 = vector.fma %1853, %96, %1823 : vector<8xf32>
      %1855 = affine.apply #map10()[%arg1]
      %1856 = memref.load %assume_align[%arg0, %1855, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1857 = vector.broadcast %1856 : f32 to vector<8xf32>
      %1858 = vector.fma %1857, %96, %1827 : vector<8xf32>
      %1859 = affine.apply #map11()[%arg1]
      %1860 = memref.load %assume_align[%arg0, %1859, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1861 = vector.broadcast %1860 : f32 to vector<8xf32>
      %1862 = vector.fma %1861, %96, %1831 : vector<8xf32>
      %1863 = affine.apply #map12()[%arg1]
      %1864 = memref.load %assume_align[%arg0, %1863, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1865 = vector.broadcast %1864 : f32 to vector<8xf32>
      %1866 = vector.fma %1865, %96, %1835 : vector<8xf32>
      %1867 = affine.apply #map13()[%arg1]
      %1868 = memref.load %assume_align[%arg0, %1867, %c56] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1869 = vector.broadcast %1868 : f32 to vector<8xf32>
      %1870 = vector.fma %1869, %96, %1839 : vector<8xf32>
      %1871 = memref.load %assume_align[%arg0, %arg1, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1872 = vector.broadcast %1871 : f32 to vector<8xf32>
      %1873 = vector.fma %1872, %97, %1842 : vector<8xf32>
      %1874 = affine.apply #map7()[%arg1]
      %1875 = memref.load %assume_align[%arg0, %1874, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1876 = vector.broadcast %1875 : f32 to vector<8xf32>
      %1877 = vector.fma %1876, %97, %1846 : vector<8xf32>
      %1878 = affine.apply #map8()[%arg1]
      %1879 = memref.load %assume_align[%arg0, %1878, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1880 = vector.broadcast %1879 : f32 to vector<8xf32>
      %1881 = vector.fma %1880, %97, %1850 : vector<8xf32>
      %1882 = affine.apply #map9()[%arg1]
      %1883 = memref.load %assume_align[%arg0, %1882, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1884 = vector.broadcast %1883 : f32 to vector<8xf32>
      %1885 = vector.fma %1884, %97, %1854 : vector<8xf32>
      %1886 = affine.apply #map10()[%arg1]
      %1887 = memref.load %assume_align[%arg0, %1886, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1888 = vector.broadcast %1887 : f32 to vector<8xf32>
      %1889 = vector.fma %1888, %97, %1858 : vector<8xf32>
      %1890 = affine.apply #map11()[%arg1]
      %1891 = memref.load %assume_align[%arg0, %1890, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1892 = vector.broadcast %1891 : f32 to vector<8xf32>
      %1893 = vector.fma %1892, %97, %1862 : vector<8xf32>
      %1894 = affine.apply #map12()[%arg1]
      %1895 = memref.load %assume_align[%arg0, %1894, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1896 = vector.broadcast %1895 : f32 to vector<8xf32>
      %1897 = vector.fma %1896, %97, %1866 : vector<8xf32>
      %1898 = affine.apply #map13()[%arg1]
      %1899 = memref.load %assume_align[%arg0, %1898, %c57] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1900 = vector.broadcast %1899 : f32 to vector<8xf32>
      %1901 = vector.fma %1900, %97, %1870 : vector<8xf32>
      %1902 = memref.load %assume_align[%arg0, %arg1, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1903 = vector.broadcast %1902 : f32 to vector<8xf32>
      %1904 = vector.fma %1903, %98, %1873 : vector<8xf32>
      %1905 = affine.apply #map7()[%arg1]
      %1906 = memref.load %assume_align[%arg0, %1905, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1907 = vector.broadcast %1906 : f32 to vector<8xf32>
      %1908 = vector.fma %1907, %98, %1877 : vector<8xf32>
      %1909 = affine.apply #map8()[%arg1]
      %1910 = memref.load %assume_align[%arg0, %1909, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1911 = vector.broadcast %1910 : f32 to vector<8xf32>
      %1912 = vector.fma %1911, %98, %1881 : vector<8xf32>
      %1913 = affine.apply #map9()[%arg1]
      %1914 = memref.load %assume_align[%arg0, %1913, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1915 = vector.broadcast %1914 : f32 to vector<8xf32>
      %1916 = vector.fma %1915, %98, %1885 : vector<8xf32>
      %1917 = affine.apply #map10()[%arg1]
      %1918 = memref.load %assume_align[%arg0, %1917, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1919 = vector.broadcast %1918 : f32 to vector<8xf32>
      %1920 = vector.fma %1919, %98, %1889 : vector<8xf32>
      %1921 = affine.apply #map11()[%arg1]
      %1922 = memref.load %assume_align[%arg0, %1921, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1923 = vector.broadcast %1922 : f32 to vector<8xf32>
      %1924 = vector.fma %1923, %98, %1893 : vector<8xf32>
      %1925 = affine.apply #map12()[%arg1]
      %1926 = memref.load %assume_align[%arg0, %1925, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1927 = vector.broadcast %1926 : f32 to vector<8xf32>
      %1928 = vector.fma %1927, %98, %1897 : vector<8xf32>
      %1929 = affine.apply #map13()[%arg1]
      %1930 = memref.load %assume_align[%arg0, %1929, %c58] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1931 = vector.broadcast %1930 : f32 to vector<8xf32>
      %1932 = vector.fma %1931, %98, %1901 : vector<8xf32>
      %1933 = memref.load %assume_align[%arg0, %arg1, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1934 = vector.broadcast %1933 : f32 to vector<8xf32>
      %1935 = vector.fma %1934, %99, %1904 : vector<8xf32>
      %1936 = affine.apply #map7()[%arg1]
      %1937 = memref.load %assume_align[%arg0, %1936, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1938 = vector.broadcast %1937 : f32 to vector<8xf32>
      %1939 = vector.fma %1938, %99, %1908 : vector<8xf32>
      %1940 = affine.apply #map8()[%arg1]
      %1941 = memref.load %assume_align[%arg0, %1940, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1942 = vector.broadcast %1941 : f32 to vector<8xf32>
      %1943 = vector.fma %1942, %99, %1912 : vector<8xf32>
      %1944 = affine.apply #map9()[%arg1]
      %1945 = memref.load %assume_align[%arg0, %1944, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1946 = vector.broadcast %1945 : f32 to vector<8xf32>
      %1947 = vector.fma %1946, %99, %1916 : vector<8xf32>
      %1948 = affine.apply #map10()[%arg1]
      %1949 = memref.load %assume_align[%arg0, %1948, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1950 = vector.broadcast %1949 : f32 to vector<8xf32>
      %1951 = vector.fma %1950, %99, %1920 : vector<8xf32>
      %1952 = affine.apply #map11()[%arg1]
      %1953 = memref.load %assume_align[%arg0, %1952, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1954 = vector.broadcast %1953 : f32 to vector<8xf32>
      %1955 = vector.fma %1954, %99, %1924 : vector<8xf32>
      %1956 = affine.apply #map12()[%arg1]
      %1957 = memref.load %assume_align[%arg0, %1956, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1958 = vector.broadcast %1957 : f32 to vector<8xf32>
      %1959 = vector.fma %1958, %99, %1928 : vector<8xf32>
      %1960 = affine.apply #map13()[%arg1]
      %1961 = memref.load %assume_align[%arg0, %1960, %c59] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1962 = vector.broadcast %1961 : f32 to vector<8xf32>
      %1963 = vector.fma %1962, %99, %1932 : vector<8xf32>
      %1964 = memref.load %assume_align[%arg0, %arg1, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1965 = vector.broadcast %1964 : f32 to vector<8xf32>
      %1966 = vector.fma %1965, %100, %1935 : vector<8xf32>
      %1967 = affine.apply #map7()[%arg1]
      %1968 = memref.load %assume_align[%arg0, %1967, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1969 = vector.broadcast %1968 : f32 to vector<8xf32>
      %1970 = vector.fma %1969, %100, %1939 : vector<8xf32>
      %1971 = affine.apply #map8()[%arg1]
      %1972 = memref.load %assume_align[%arg0, %1971, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1973 = vector.broadcast %1972 : f32 to vector<8xf32>
      %1974 = vector.fma %1973, %100, %1943 : vector<8xf32>
      %1975 = affine.apply #map9()[%arg1]
      %1976 = memref.load %assume_align[%arg0, %1975, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1977 = vector.broadcast %1976 : f32 to vector<8xf32>
      %1978 = vector.fma %1977, %100, %1947 : vector<8xf32>
      %1979 = affine.apply #map10()[%arg1]
      %1980 = memref.load %assume_align[%arg0, %1979, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1981 = vector.broadcast %1980 : f32 to vector<8xf32>
      %1982 = vector.fma %1981, %100, %1951 : vector<8xf32>
      %1983 = affine.apply #map11()[%arg1]
      %1984 = memref.load %assume_align[%arg0, %1983, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1985 = vector.broadcast %1984 : f32 to vector<8xf32>
      %1986 = vector.fma %1985, %100, %1955 : vector<8xf32>
      %1987 = affine.apply #map12()[%arg1]
      %1988 = memref.load %assume_align[%arg0, %1987, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1989 = vector.broadcast %1988 : f32 to vector<8xf32>
      %1990 = vector.fma %1989, %100, %1959 : vector<8xf32>
      %1991 = affine.apply #map13()[%arg1]
      %1992 = memref.load %assume_align[%arg0, %1991, %c60] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1993 = vector.broadcast %1992 : f32 to vector<8xf32>
      %1994 = vector.fma %1993, %100, %1963 : vector<8xf32>
      %1995 = memref.load %assume_align[%arg0, %arg1, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %1996 = vector.broadcast %1995 : f32 to vector<8xf32>
      %1997 = vector.fma %1996, %101, %1966 : vector<8xf32>
      %1998 = affine.apply #map7()[%arg1]
      %1999 = memref.load %assume_align[%arg0, %1998, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2000 = vector.broadcast %1999 : f32 to vector<8xf32>
      %2001 = vector.fma %2000, %101, %1970 : vector<8xf32>
      %2002 = affine.apply #map8()[%arg1]
      %2003 = memref.load %assume_align[%arg0, %2002, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2004 = vector.broadcast %2003 : f32 to vector<8xf32>
      %2005 = vector.fma %2004, %101, %1974 : vector<8xf32>
      %2006 = affine.apply #map9()[%arg1]
      %2007 = memref.load %assume_align[%arg0, %2006, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2008 = vector.broadcast %2007 : f32 to vector<8xf32>
      %2009 = vector.fma %2008, %101, %1978 : vector<8xf32>
      %2010 = affine.apply #map10()[%arg1]
      %2011 = memref.load %assume_align[%arg0, %2010, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2012 = vector.broadcast %2011 : f32 to vector<8xf32>
      %2013 = vector.fma %2012, %101, %1982 : vector<8xf32>
      %2014 = affine.apply #map11()[%arg1]
      %2015 = memref.load %assume_align[%arg0, %2014, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2016 = vector.broadcast %2015 : f32 to vector<8xf32>
      %2017 = vector.fma %2016, %101, %1986 : vector<8xf32>
      %2018 = affine.apply #map12()[%arg1]
      %2019 = memref.load %assume_align[%arg0, %2018, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2020 = vector.broadcast %2019 : f32 to vector<8xf32>
      %2021 = vector.fma %2020, %101, %1990 : vector<8xf32>
      %2022 = affine.apply #map13()[%arg1]
      %2023 = memref.load %assume_align[%arg0, %2022, %c61] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2024 = vector.broadcast %2023 : f32 to vector<8xf32>
      %2025 = vector.fma %2024, %101, %1994 : vector<8xf32>
      %2026 = memref.load %assume_align[%arg0, %arg1, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2027 = vector.broadcast %2026 : f32 to vector<8xf32>
      %2028 = vector.fma %2027, %102, %1997 : vector<8xf32>
      %2029 = affine.apply #map7()[%arg1]
      %2030 = memref.load %assume_align[%arg0, %2029, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2031 = vector.broadcast %2030 : f32 to vector<8xf32>
      %2032 = vector.fma %2031, %102, %2001 : vector<8xf32>
      %2033 = affine.apply #map8()[%arg1]
      %2034 = memref.load %assume_align[%arg0, %2033, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2035 = vector.broadcast %2034 : f32 to vector<8xf32>
      %2036 = vector.fma %2035, %102, %2005 : vector<8xf32>
      %2037 = affine.apply #map9()[%arg1]
      %2038 = memref.load %assume_align[%arg0, %2037, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2039 = vector.broadcast %2038 : f32 to vector<8xf32>
      %2040 = vector.fma %2039, %102, %2009 : vector<8xf32>
      %2041 = affine.apply #map10()[%arg1]
      %2042 = memref.load %assume_align[%arg0, %2041, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2043 = vector.broadcast %2042 : f32 to vector<8xf32>
      %2044 = vector.fma %2043, %102, %2013 : vector<8xf32>
      %2045 = affine.apply #map11()[%arg1]
      %2046 = memref.load %assume_align[%arg0, %2045, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2047 = vector.broadcast %2046 : f32 to vector<8xf32>
      %2048 = vector.fma %2047, %102, %2017 : vector<8xf32>
      %2049 = affine.apply #map12()[%arg1]
      %2050 = memref.load %assume_align[%arg0, %2049, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2051 = vector.broadcast %2050 : f32 to vector<8xf32>
      %2052 = vector.fma %2051, %102, %2021 : vector<8xf32>
      %2053 = affine.apply #map13()[%arg1]
      %2054 = memref.load %assume_align[%arg0, %2053, %c62] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2055 = vector.broadcast %2054 : f32 to vector<8xf32>
      %2056 = vector.fma %2055, %102, %2025 : vector<8xf32>
      %2057 = memref.load %assume_align[%arg0, %arg1, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2058 = vector.broadcast %2057 : f32 to vector<8xf32>
      %2059 = vector.fma %2058, %103, %2028 : vector<8xf32>
      %2060 = vector.insert %2059, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
      %2061 = affine.apply #map7()[%arg1]
      %2062 = memref.load %assume_align[%arg0, %2061, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2063 = vector.broadcast %2062 : f32 to vector<8xf32>
      %2064 = vector.fma %2063, %103, %2032 : vector<8xf32>
      %2065 = vector.insert %2064, %2060 [1] : vector<8xf32> into vector<8x8xf32>
      %2066 = affine.apply #map8()[%arg1]
      %2067 = memref.load %assume_align[%arg0, %2066, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2068 = vector.broadcast %2067 : f32 to vector<8xf32>
      %2069 = vector.fma %2068, %103, %2036 : vector<8xf32>
      %2070 = vector.insert %2069, %2065 [2] : vector<8xf32> into vector<8x8xf32>
      %2071 = affine.apply #map9()[%arg1]
      %2072 = memref.load %assume_align[%arg0, %2071, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2073 = vector.broadcast %2072 : f32 to vector<8xf32>
      %2074 = vector.fma %2073, %103, %2040 : vector<8xf32>
      %2075 = vector.insert %2074, %2070 [3] : vector<8xf32> into vector<8x8xf32>
      %2076 = affine.apply #map10()[%arg1]
      %2077 = memref.load %assume_align[%arg0, %2076, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2078 = vector.broadcast %2077 : f32 to vector<8xf32>
      %2079 = vector.fma %2078, %103, %2044 : vector<8xf32>
      %2080 = vector.insert %2079, %2075 [4] : vector<8xf32> into vector<8x8xf32>
      %2081 = affine.apply #map11()[%arg1]
      %2082 = memref.load %assume_align[%arg0, %2081, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2083 = vector.broadcast %2082 : f32 to vector<8xf32>
      %2084 = vector.fma %2083, %103, %2048 : vector<8xf32>
      %2085 = vector.insert %2084, %2080 [5] : vector<8xf32> into vector<8x8xf32>
      %2086 = affine.apply #map12()[%arg1]
      %2087 = memref.load %assume_align[%arg0, %2086, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2088 = vector.broadcast %2087 : f32 to vector<8xf32>
      %2089 = vector.fma %2088, %103, %2052 : vector<8xf32>
      %2090 = vector.insert %2089, %2085 [6] : vector<8xf32> into vector<8x8xf32>
      %2091 = affine.apply #map13()[%arg1]
      %2092 = memref.load %assume_align[%arg0, %2091, %c63] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>
      %2093 = vector.broadcast %2092 : f32 to vector<8xf32>
      %2094 = vector.fma %2093, %103, %2056 : vector<8xf32>
      %2095 = vector.insert %2094, %2090 [7] : vector<8xf32> into vector<8x8xf32>
      %2096 = vector.reduction <maximumf>, %2059, %cst : vector<8xf32> into f32
      %2097 = vector.insert %2096, %cst_0 [0] : f32 into vector<8xf32>
      %2098 = vector.reduction <maximumf>, %2064, %cst : vector<8xf32> into f32
      %2099 = vector.insert %2098, %2097 [1] : f32 into vector<8xf32>
      %2100 = vector.reduction <maximumf>, %2069, %cst : vector<8xf32> into f32
      %2101 = vector.insert %2100, %2099 [2] : f32 into vector<8xf32>
      %2102 = vector.reduction <maximumf>, %2074, %cst : vector<8xf32> into f32
      %2103 = vector.insert %2102, %2101 [3] : f32 into vector<8xf32>
      %2104 = vector.reduction <maximumf>, %2079, %cst : vector<8xf32> into f32
      %2105 = vector.insert %2104, %2103 [4] : f32 into vector<8xf32>
      %2106 = vector.reduction <maximumf>, %2084, %cst : vector<8xf32> into f32
      %2107 = vector.insert %2106, %2105 [5] : f32 into vector<8xf32>
      %2108 = vector.reduction <maximumf>, %2089, %cst : vector<8xf32> into f32
      %2109 = vector.insert %2108, %2107 [6] : f32 into vector<8xf32>
      %2110 = vector.reduction <maximumf>, %2094, %cst : vector<8xf32> into f32
      %2111 = vector.insert %2110, %2109 [7] : f32 into vector<8xf32>
      %2112 = arith.subf %2111, %cst_2 : vector<8xf32>
      %2113 = math.exp2 %2112 : vector<8xf32>
      %2114 = vector.insert %2113, %2 [0] : vector<8xf32> into vector<1x8xf32>
      %2115 = vector.broadcast %2114 : vector<1x8xf32> to vector<8x8xf32>
      %2116 = arith.mulf %2115, %cst_1 : vector<8x8xf32>
      %2117 = vector.extract %2116[0] : vector<8xf32> from vector<8x8xf32>
      %2118 = vector.insert_strided_slice %2117, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2119 = vector.extract %2116[1] : vector<8xf32> from vector<8x8xf32>
      %2120 = vector.insert_strided_slice %2119, %2118 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2121 = vector.extract %2116[2] : vector<8xf32> from vector<8x8xf32>
      %2122 = vector.insert_strided_slice %2121, %2120 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2123 = vector.extract %2116[3] : vector<8xf32> from vector<8x8xf32>
      %2124 = vector.insert_strided_slice %2123, %2122 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2125 = vector.extract %2116[4] : vector<8xf32> from vector<8x8xf32>
      %2126 = vector.insert_strided_slice %2125, %2124 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2127 = vector.extract %2116[5] : vector<8xf32> from vector<8x8xf32>
      %2128 = vector.insert_strided_slice %2127, %2126 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2129 = vector.extract %2116[6] : vector<8xf32> from vector<8x8xf32>
      %2130 = vector.insert_strided_slice %2129, %2128 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2131 = vector.extract %2116[7] : vector<8xf32> from vector<8x8xf32>
      %2132 = vector.insert_strided_slice %2131, %2130 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2133 = vector.shuffle %2132, %2132 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
      %2134 = vector.extract_strided_slice %2133 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2135 = vector.extract_strided_slice %2133 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2136 = vector.extract_strided_slice %2133 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2137 = vector.extract_strided_slice %2133 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2138 = vector.extract_strided_slice %2133 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2139 = vector.extract_strided_slice %2133 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2140 = vector.extract_strided_slice %2133 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2141 = vector.extract_strided_slice %2133 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2142 = vector.insert_strided_slice %2111, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2143 = vector.insert_strided_slice %2111, %2142 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2144 = vector.insert_strided_slice %2111, %2143 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2145 = vector.insert_strided_slice %2111, %2144 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2146 = vector.insert_strided_slice %2111, %2145 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2147 = vector.insert_strided_slice %2111, %2146 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2148 = vector.insert_strided_slice %2111, %2147 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2149 = vector.insert_strided_slice %2111, %2148 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2150 = vector.shuffle %2149, %2149 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
      %2151 = vector.extract_strided_slice %2150 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2152 = vector.insert %2151, %0 [0] : vector<8xf32> into vector<8x8xf32>
      %2153 = vector.extract_strided_slice %2150 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2154 = vector.insert %2153, %2152 [1] : vector<8xf32> into vector<8x8xf32>
      %2155 = vector.extract_strided_slice %2150 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2156 = vector.insert %2155, %2154 [2] : vector<8xf32> into vector<8x8xf32>
      %2157 = vector.extract_strided_slice %2150 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2158 = vector.insert %2157, %2156 [3] : vector<8xf32> into vector<8x8xf32>
      %2159 = vector.extract_strided_slice %2150 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2160 = vector.insert %2159, %2158 [4] : vector<8xf32> into vector<8x8xf32>
      %2161 = vector.extract_strided_slice %2150 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2162 = vector.insert %2161, %2160 [5] : vector<8xf32> into vector<8x8xf32>
      %2163 = vector.extract_strided_slice %2150 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2164 = vector.insert %2163, %2162 [6] : vector<8xf32> into vector<8x8xf32>
      %2165 = vector.extract_strided_slice %2150 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2166 = vector.insert %2165, %2164 [7] : vector<8xf32> into vector<8x8xf32>
      %2167 = arith.subf %2095, %2166 : vector<8x8xf32>
      %2168 = math.exp2 %2167 : vector<8x8xf32>
      %2169 = vector.load %assume_align_4[%arg0, %arg3, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2170 = affine.apply #map(%arg3)
      %2171 = vector.load %assume_align_4[%arg0, %2170, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2172 = affine.apply #map1(%arg3)
      %2173 = vector.load %assume_align_4[%arg0, %2172, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2174 = affine.apply #map2(%arg3)
      %2175 = vector.load %assume_align_4[%arg0, %2174, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2176 = affine.apply #map3(%arg3)
      %2177 = vector.load %assume_align_4[%arg0, %2176, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2178 = affine.apply #map4(%arg3)
      %2179 = vector.load %assume_align_4[%arg0, %2178, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2180 = affine.apply #map5(%arg3)
      %2181 = vector.load %assume_align_4[%arg0, %2180, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2182 = affine.apply #map6(%arg3)
      %2183 = vector.load %assume_align_4[%arg0, %2182, %arg2] : memref<20x4096x64xf32, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2184 = vector.extract %2168[0, 0] : f32 from vector<8x8xf32>
      %2185 = vector.broadcast %2184 : f32 to vector<8xf32>
      %2186 = vector.fma %2185, %2169, %2134 : vector<8xf32>
      %2187 = vector.extract %2168[1, 0] : f32 from vector<8x8xf32>
      %2188 = vector.broadcast %2187 : f32 to vector<8xf32>
      %2189 = vector.fma %2188, %2169, %2135 : vector<8xf32>
      %2190 = vector.extract %2168[2, 0] : f32 from vector<8x8xf32>
      %2191 = vector.broadcast %2190 : f32 to vector<8xf32>
      %2192 = vector.fma %2191, %2169, %2136 : vector<8xf32>
      %2193 = vector.extract %2168[3, 0] : f32 from vector<8x8xf32>
      %2194 = vector.broadcast %2193 : f32 to vector<8xf32>
      %2195 = vector.fma %2194, %2169, %2137 : vector<8xf32>
      %2196 = vector.extract %2168[4, 0] : f32 from vector<8x8xf32>
      %2197 = vector.broadcast %2196 : f32 to vector<8xf32>
      %2198 = vector.fma %2197, %2169, %2138 : vector<8xf32>
      %2199 = vector.extract %2168[5, 0] : f32 from vector<8x8xf32>
      %2200 = vector.broadcast %2199 : f32 to vector<8xf32>
      %2201 = vector.fma %2200, %2169, %2139 : vector<8xf32>
      %2202 = vector.extract %2168[6, 0] : f32 from vector<8x8xf32>
      %2203 = vector.broadcast %2202 : f32 to vector<8xf32>
      %2204 = vector.fma %2203, %2169, %2140 : vector<8xf32>
      %2205 = vector.extract %2168[7, 0] : f32 from vector<8x8xf32>
      %2206 = vector.broadcast %2205 : f32 to vector<8xf32>
      %2207 = vector.fma %2206, %2169, %2141 : vector<8xf32>
      %2208 = vector.extract %2168[0, 1] : f32 from vector<8x8xf32>
      %2209 = vector.broadcast %2208 : f32 to vector<8xf32>
      %2210 = vector.fma %2209, %2171, %2186 : vector<8xf32>
      %2211 = vector.extract %2168[1, 1] : f32 from vector<8x8xf32>
      %2212 = vector.broadcast %2211 : f32 to vector<8xf32>
      %2213 = vector.fma %2212, %2171, %2189 : vector<8xf32>
      %2214 = vector.extract %2168[2, 1] : f32 from vector<8x8xf32>
      %2215 = vector.broadcast %2214 : f32 to vector<8xf32>
      %2216 = vector.fma %2215, %2171, %2192 : vector<8xf32>
      %2217 = vector.extract %2168[3, 1] : f32 from vector<8x8xf32>
      %2218 = vector.broadcast %2217 : f32 to vector<8xf32>
      %2219 = vector.fma %2218, %2171, %2195 : vector<8xf32>
      %2220 = vector.extract %2168[4, 1] : f32 from vector<8x8xf32>
      %2221 = vector.broadcast %2220 : f32 to vector<8xf32>
      %2222 = vector.fma %2221, %2171, %2198 : vector<8xf32>
      %2223 = vector.extract %2168[5, 1] : f32 from vector<8x8xf32>
      %2224 = vector.broadcast %2223 : f32 to vector<8xf32>
      %2225 = vector.fma %2224, %2171, %2201 : vector<8xf32>
      %2226 = vector.extract %2168[6, 1] : f32 from vector<8x8xf32>
      %2227 = vector.broadcast %2226 : f32 to vector<8xf32>
      %2228 = vector.fma %2227, %2171, %2204 : vector<8xf32>
      %2229 = vector.extract %2168[7, 1] : f32 from vector<8x8xf32>
      %2230 = vector.broadcast %2229 : f32 to vector<8xf32>
      %2231 = vector.fma %2230, %2171, %2207 : vector<8xf32>
      %2232 = vector.extract %2168[0, 2] : f32 from vector<8x8xf32>
      %2233 = vector.broadcast %2232 : f32 to vector<8xf32>
      %2234 = vector.fma %2233, %2173, %2210 : vector<8xf32>
      %2235 = vector.extract %2168[1, 2] : f32 from vector<8x8xf32>
      %2236 = vector.broadcast %2235 : f32 to vector<8xf32>
      %2237 = vector.fma %2236, %2173, %2213 : vector<8xf32>
      %2238 = vector.extract %2168[2, 2] : f32 from vector<8x8xf32>
      %2239 = vector.broadcast %2238 : f32 to vector<8xf32>
      %2240 = vector.fma %2239, %2173, %2216 : vector<8xf32>
      %2241 = vector.extract %2168[3, 2] : f32 from vector<8x8xf32>
      %2242 = vector.broadcast %2241 : f32 to vector<8xf32>
      %2243 = vector.fma %2242, %2173, %2219 : vector<8xf32>
      %2244 = vector.extract %2168[4, 2] : f32 from vector<8x8xf32>
      %2245 = vector.broadcast %2244 : f32 to vector<8xf32>
      %2246 = vector.fma %2245, %2173, %2222 : vector<8xf32>
      %2247 = vector.extract %2168[5, 2] : f32 from vector<8x8xf32>
      %2248 = vector.broadcast %2247 : f32 to vector<8xf32>
      %2249 = vector.fma %2248, %2173, %2225 : vector<8xf32>
      %2250 = vector.extract %2168[6, 2] : f32 from vector<8x8xf32>
      %2251 = vector.broadcast %2250 : f32 to vector<8xf32>
      %2252 = vector.fma %2251, %2173, %2228 : vector<8xf32>
      %2253 = vector.extract %2168[7, 2] : f32 from vector<8x8xf32>
      %2254 = vector.broadcast %2253 : f32 to vector<8xf32>
      %2255 = vector.fma %2254, %2173, %2231 : vector<8xf32>
      %2256 = vector.extract %2168[0, 3] : f32 from vector<8x8xf32>
      %2257 = vector.broadcast %2256 : f32 to vector<8xf32>
      %2258 = vector.fma %2257, %2175, %2234 : vector<8xf32>
      %2259 = vector.extract %2168[1, 3] : f32 from vector<8x8xf32>
      %2260 = vector.broadcast %2259 : f32 to vector<8xf32>
      %2261 = vector.fma %2260, %2175, %2237 : vector<8xf32>
      %2262 = vector.extract %2168[2, 3] : f32 from vector<8x8xf32>
      %2263 = vector.broadcast %2262 : f32 to vector<8xf32>
      %2264 = vector.fma %2263, %2175, %2240 : vector<8xf32>
      %2265 = vector.extract %2168[3, 3] : f32 from vector<8x8xf32>
      %2266 = vector.broadcast %2265 : f32 to vector<8xf32>
      %2267 = vector.fma %2266, %2175, %2243 : vector<8xf32>
      %2268 = vector.extract %2168[4, 3] : f32 from vector<8x8xf32>
      %2269 = vector.broadcast %2268 : f32 to vector<8xf32>
      %2270 = vector.fma %2269, %2175, %2246 : vector<8xf32>
      %2271 = vector.extract %2168[5, 3] : f32 from vector<8x8xf32>
      %2272 = vector.broadcast %2271 : f32 to vector<8xf32>
      %2273 = vector.fma %2272, %2175, %2249 : vector<8xf32>
      %2274 = vector.extract %2168[6, 3] : f32 from vector<8x8xf32>
      %2275 = vector.broadcast %2274 : f32 to vector<8xf32>
      %2276 = vector.fma %2275, %2175, %2252 : vector<8xf32>
      %2277 = vector.extract %2168[7, 3] : f32 from vector<8x8xf32>
      %2278 = vector.broadcast %2277 : f32 to vector<8xf32>
      %2279 = vector.fma %2278, %2175, %2255 : vector<8xf32>
      %2280 = vector.extract %2168[0, 4] : f32 from vector<8x8xf32>
      %2281 = vector.broadcast %2280 : f32 to vector<8xf32>
      %2282 = vector.fma %2281, %2177, %2258 : vector<8xf32>
      %2283 = vector.extract %2168[1, 4] : f32 from vector<8x8xf32>
      %2284 = vector.broadcast %2283 : f32 to vector<8xf32>
      %2285 = vector.fma %2284, %2177, %2261 : vector<8xf32>
      %2286 = vector.extract %2168[2, 4] : f32 from vector<8x8xf32>
      %2287 = vector.broadcast %2286 : f32 to vector<8xf32>
      %2288 = vector.fma %2287, %2177, %2264 : vector<8xf32>
      %2289 = vector.extract %2168[3, 4] : f32 from vector<8x8xf32>
      %2290 = vector.broadcast %2289 : f32 to vector<8xf32>
      %2291 = vector.fma %2290, %2177, %2267 : vector<8xf32>
      %2292 = vector.extract %2168[4, 4] : f32 from vector<8x8xf32>
      %2293 = vector.broadcast %2292 : f32 to vector<8xf32>
      %2294 = vector.fma %2293, %2177, %2270 : vector<8xf32>
      %2295 = vector.extract %2168[5, 4] : f32 from vector<8x8xf32>
      %2296 = vector.broadcast %2295 : f32 to vector<8xf32>
      %2297 = vector.fma %2296, %2177, %2273 : vector<8xf32>
      %2298 = vector.extract %2168[6, 4] : f32 from vector<8x8xf32>
      %2299 = vector.broadcast %2298 : f32 to vector<8xf32>
      %2300 = vector.fma %2299, %2177, %2276 : vector<8xf32>
      %2301 = vector.extract %2168[7, 4] : f32 from vector<8x8xf32>
      %2302 = vector.broadcast %2301 : f32 to vector<8xf32>
      %2303 = vector.fma %2302, %2177, %2279 : vector<8xf32>
      %2304 = vector.extract %2168[0, 5] : f32 from vector<8x8xf32>
      %2305 = vector.broadcast %2304 : f32 to vector<8xf32>
      %2306 = vector.fma %2305, %2179, %2282 : vector<8xf32>
      %2307 = vector.extract %2168[1, 5] : f32 from vector<8x8xf32>
      %2308 = vector.broadcast %2307 : f32 to vector<8xf32>
      %2309 = vector.fma %2308, %2179, %2285 : vector<8xf32>
      %2310 = vector.extract %2168[2, 5] : f32 from vector<8x8xf32>
      %2311 = vector.broadcast %2310 : f32 to vector<8xf32>
      %2312 = vector.fma %2311, %2179, %2288 : vector<8xf32>
      %2313 = vector.extract %2168[3, 5] : f32 from vector<8x8xf32>
      %2314 = vector.broadcast %2313 : f32 to vector<8xf32>
      %2315 = vector.fma %2314, %2179, %2291 : vector<8xf32>
      %2316 = vector.extract %2168[4, 5] : f32 from vector<8x8xf32>
      %2317 = vector.broadcast %2316 : f32 to vector<8xf32>
      %2318 = vector.fma %2317, %2179, %2294 : vector<8xf32>
      %2319 = vector.extract %2168[5, 5] : f32 from vector<8x8xf32>
      %2320 = vector.broadcast %2319 : f32 to vector<8xf32>
      %2321 = vector.fma %2320, %2179, %2297 : vector<8xf32>
      %2322 = vector.extract %2168[6, 5] : f32 from vector<8x8xf32>
      %2323 = vector.broadcast %2322 : f32 to vector<8xf32>
      %2324 = vector.fma %2323, %2179, %2300 : vector<8xf32>
      %2325 = vector.extract %2168[7, 5] : f32 from vector<8x8xf32>
      %2326 = vector.broadcast %2325 : f32 to vector<8xf32>
      %2327 = vector.fma %2326, %2179, %2303 : vector<8xf32>
      %2328 = vector.extract %2168[0, 6] : f32 from vector<8x8xf32>
      %2329 = vector.broadcast %2328 : f32 to vector<8xf32>
      %2330 = vector.fma %2329, %2181, %2306 : vector<8xf32>
      %2331 = vector.extract %2168[1, 6] : f32 from vector<8x8xf32>
      %2332 = vector.broadcast %2331 : f32 to vector<8xf32>
      %2333 = vector.fma %2332, %2181, %2309 : vector<8xf32>
      %2334 = vector.extract %2168[2, 6] : f32 from vector<8x8xf32>
      %2335 = vector.broadcast %2334 : f32 to vector<8xf32>
      %2336 = vector.fma %2335, %2181, %2312 : vector<8xf32>
      %2337 = vector.extract %2168[3, 6] : f32 from vector<8x8xf32>
      %2338 = vector.broadcast %2337 : f32 to vector<8xf32>
      %2339 = vector.fma %2338, %2181, %2315 : vector<8xf32>
      %2340 = vector.extract %2168[4, 6] : f32 from vector<8x8xf32>
      %2341 = vector.broadcast %2340 : f32 to vector<8xf32>
      %2342 = vector.fma %2341, %2181, %2318 : vector<8xf32>
      %2343 = vector.extract %2168[5, 6] : f32 from vector<8x8xf32>
      %2344 = vector.broadcast %2343 : f32 to vector<8xf32>
      %2345 = vector.fma %2344, %2181, %2321 : vector<8xf32>
      %2346 = vector.extract %2168[6, 6] : f32 from vector<8x8xf32>
      %2347 = vector.broadcast %2346 : f32 to vector<8xf32>
      %2348 = vector.fma %2347, %2181, %2324 : vector<8xf32>
      %2349 = vector.extract %2168[7, 6] : f32 from vector<8x8xf32>
      %2350 = vector.broadcast %2349 : f32 to vector<8xf32>
      %2351 = vector.fma %2350, %2181, %2327 : vector<8xf32>
      %2352 = vector.extract %2168[0, 7] : f32 from vector<8x8xf32>
      %2353 = vector.broadcast %2352 : f32 to vector<8xf32>
      %2354 = vector.fma %2353, %2183, %2330 : vector<8xf32>
      %2355 = vector.insert %2354, %cst_1 [0] : vector<8xf32> into vector<8x8xf32>
      %2356 = vector.extract %2168[1, 7] : f32 from vector<8x8xf32>
      %2357 = vector.broadcast %2356 : f32 to vector<8xf32>
      %2358 = vector.fma %2357, %2183, %2333 : vector<8xf32>
      %2359 = vector.insert %2358, %2355 [1] : vector<8xf32> into vector<8x8xf32>
      %2360 = vector.extract %2168[2, 7] : f32 from vector<8x8xf32>
      %2361 = vector.broadcast %2360 : f32 to vector<8xf32>
      %2362 = vector.fma %2361, %2183, %2336 : vector<8xf32>
      %2363 = vector.insert %2362, %2359 [2] : vector<8xf32> into vector<8x8xf32>
      %2364 = vector.extract %2168[3, 7] : f32 from vector<8x8xf32>
      %2365 = vector.broadcast %2364 : f32 to vector<8xf32>
      %2366 = vector.fma %2365, %2183, %2339 : vector<8xf32>
      %2367 = vector.insert %2366, %2363 [3] : vector<8xf32> into vector<8x8xf32>
      %2368 = vector.extract %2168[4, 7] : f32 from vector<8x8xf32>
      %2369 = vector.broadcast %2368 : f32 to vector<8xf32>
      %2370 = vector.fma %2369, %2183, %2342 : vector<8xf32>
      %2371 = vector.insert %2370, %2367 [4] : vector<8xf32> into vector<8x8xf32>
      %2372 = vector.extract %2168[5, 7] : f32 from vector<8x8xf32>
      %2373 = vector.broadcast %2372 : f32 to vector<8xf32>
      %2374 = vector.fma %2373, %2183, %2345 : vector<8xf32>
      %2375 = vector.insert %2374, %2371 [5] : vector<8xf32> into vector<8x8xf32>
      %2376 = vector.extract %2168[6, 7] : f32 from vector<8x8xf32>
      %2377 = vector.broadcast %2376 : f32 to vector<8xf32>
      %2378 = vector.fma %2377, %2183, %2348 : vector<8xf32>
      %2379 = vector.insert %2378, %2375 [6] : vector<8xf32> into vector<8x8xf32>
      %2380 = vector.extract %2168[7, 7] : f32 from vector<8x8xf32>
      %2381 = vector.broadcast %2380 : f32 to vector<8xf32>
      %2382 = vector.fma %2381, %2183, %2351 : vector<8xf32>
      %2383 = vector.insert %2382, %2379 [7] : vector<8xf32> into vector<8x8xf32>
      %2384 = arith.mulf %2113, %cst_0 : vector<8xf32>
      %2385 = vector.extract %2168[0] : vector<8xf32> from vector<8x8xf32>
      %2386 = vector.extract %2384[0] : f32 from vector<8xf32>
      %2387 = vector.reduction <add>, %2385, %2386 : vector<8xf32> into f32
      %2388 = vector.insert %2387, %cst_0 [0] : f32 into vector<8xf32>
      %2389 = vector.extract %2168[1] : vector<8xf32> from vector<8x8xf32>
      %2390 = vector.extract %2384[1] : f32 from vector<8xf32>
      %2391 = vector.reduction <add>, %2389, %2390 : vector<8xf32> into f32
      %2392 = vector.insert %2391, %2388 [1] : f32 into vector<8xf32>
      %2393 = vector.extract %2168[2] : vector<8xf32> from vector<8x8xf32>
      %2394 = vector.extract %2384[2] : f32 from vector<8xf32>
      %2395 = vector.reduction <add>, %2393, %2394 : vector<8xf32> into f32
      %2396 = vector.insert %2395, %2392 [2] : f32 into vector<8xf32>
      %2397 = vector.extract %2168[3] : vector<8xf32> from vector<8x8xf32>
      %2398 = vector.extract %2384[3] : f32 from vector<8xf32>
      %2399 = vector.reduction <add>, %2397, %2398 : vector<8xf32> into f32
      %2400 = vector.insert %2399, %2396 [3] : f32 into vector<8xf32>
      %2401 = vector.extract %2168[4] : vector<8xf32> from vector<8x8xf32>
      %2402 = vector.extract %2384[4] : f32 from vector<8xf32>
      %2403 = vector.reduction <add>, %2401, %2402 : vector<8xf32> into f32
      %2404 = vector.insert %2403, %2400 [4] : f32 into vector<8xf32>
      %2405 = vector.extract %2168[5] : vector<8xf32> from vector<8x8xf32>
      %2406 = vector.extract %2384[5] : f32 from vector<8xf32>
      %2407 = vector.reduction <add>, %2405, %2406 : vector<8xf32> into f32
      %2408 = vector.insert %2407, %2404 [5] : f32 into vector<8xf32>
      %2409 = vector.extract %2168[6] : vector<8xf32> from vector<8x8xf32>
      %2410 = vector.extract %2384[6] : f32 from vector<8xf32>
      %2411 = vector.reduction <add>, %2409, %2410 : vector<8xf32> into f32
      %2412 = vector.insert %2411, %2408 [6] : f32 into vector<8xf32>
      %2413 = vector.extract %2168[7] : vector<8xf32> from vector<8x8xf32>
      %2414 = vector.extract %2384[7] : f32 from vector<8xf32>
      %2415 = vector.reduction <add>, %2413, %2414 : vector<8xf32> into f32
      %2416 = vector.insert %2415, %2412 [7] : f32 into vector<8xf32>
      %2417 = vector.insert_strided_slice %2416, %1 {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2418 = vector.insert_strided_slice %2416, %2417 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2419 = vector.insert_strided_slice %2416, %2418 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2420 = vector.insert_strided_slice %2416, %2419 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2421 = vector.insert_strided_slice %2416, %2420 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2422 = vector.insert_strided_slice %2416, %2421 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2423 = vector.insert_strided_slice %2416, %2422 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2424 = vector.insert_strided_slice %2416, %2423 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
      %2425 = vector.shuffle %2424, %2424 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
      %2426 = vector.extract_strided_slice %2425 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2427 = vector.insert %2426, %0 [0] : vector<8xf32> into vector<8x8xf32>
      %2428 = vector.extract_strided_slice %2425 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2429 = vector.insert %2428, %2427 [1] : vector<8xf32> into vector<8x8xf32>
      %2430 = vector.extract_strided_slice %2425 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2431 = vector.insert %2430, %2429 [2] : vector<8xf32> into vector<8x8xf32>
      %2432 = vector.extract_strided_slice %2425 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2433 = vector.insert %2432, %2431 [3] : vector<8xf32> into vector<8x8xf32>
      %2434 = vector.extract_strided_slice %2425 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2435 = vector.insert %2434, %2433 [4] : vector<8xf32> into vector<8x8xf32>
      %2436 = vector.extract_strided_slice %2425 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2437 = vector.insert %2436, %2435 [5] : vector<8xf32> into vector<8x8xf32>
      %2438 = vector.extract_strided_slice %2425 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2439 = vector.insert %2438, %2437 [6] : vector<8xf32> into vector<8x8xf32>
      %2440 = vector.extract_strided_slice %2425 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
      %2441 = vector.insert %2440, %2439 [7] : vector<8xf32> into vector<8x8xf32>
      %2442 = arith.divf %2383, %2441 : vector<8x8xf32>
      %subview_7 = memref.subview %subview[0, 0, 0] [1, 8, 8] [1, 1, 1] : memref<1x8x8xf32, strided<[262144, 64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>
      %2443 = vector.extract %2442[0] : vector<8xf32> from vector<8x8xf32>
      vector.store %2443, %subview_7[%c0, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2444 = vector.extract %2442[1] : vector<8xf32> from vector<8x8xf32>
      vector.store %2444, %subview_7[%c1, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2445 = vector.extract %2442[2] : vector<8xf32> from vector<8x8xf32>
      vector.store %2445, %subview_7[%c2, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2446 = vector.extract %2442[3] : vector<8xf32> from vector<8x8xf32>
      vector.store %2446, %subview_7[%c3, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2447 = vector.extract %2442[4] : vector<8xf32> from vector<8x8xf32>
      vector.store %2447, %subview_7[%c4, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2448 = vector.extract %2442[5] : vector<8xf32> from vector<8x8xf32>
      vector.store %2448, %subview_7[%c5, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2449 = vector.extract %2442[6] : vector<8xf32> from vector<8x8xf32>
      vector.store %2449, %subview_7[%c6, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
      %2450 = vector.extract %2442[7] : vector<8xf32> from vector<8x8xf32>
      vector.store %2450, %subview_7[%c7, %c0] : memref<8x8xf32, #map14, #hal.descriptor_type<storage_buffer>>, vector<8xf32>
    } {mapping = [#iree_codegen.workgroup_mapping<z:1>, #iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
    return
  }
}
