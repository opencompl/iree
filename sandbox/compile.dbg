// -----// IR Dump After AutoInputConversionPipelinePass (iree-auto-input-conversion) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  func.func @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After IREEImportPublicPass (iree-import-public) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After ImportMLProgramPass (iree-import-ml-program) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After SanitizeModuleNamesPass (iree-sanitize-module-names) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After ConvertShardToFlowPass (iree-convert-shard-to-flow) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After DemoteF64ToF32Pass (iree-input-conversion-demote-f64-to-f32) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = util.call @_attention(%0, %1, %2) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16>
    %4 = hal.tensor.export %3 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
  util.func private @_attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> attributes {hal.abi.convention = #hal.abi.convention<synchronous>} {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant 1.250000e-01 : f32
    %0 = tensor.empty() : tensor<20x4096x4096xf32>
    %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %12 = arith.extf %in : f16 to f32
      %13 = arith.extf %in_2 : f16 to f32
      %14 = arith.mulf %12, %13 : f32
      %15 = arith.addf %14, %out : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    %3 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %12 = arith.mulf %in, %cst_1 : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %4 = tensor.empty() : tensor<20x4096xf32>
    %5 = tensor.empty() : tensor<20x4096x64xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %12 = arith.addf %arg3, %arg6 : f32
      %13 = arith.truncf %arg3 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg4 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg7 : f32
      iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %10 = tensor.empty() : tensor<20x4096x64xf16>
    %11 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %12 = arith.divf %in, %in_2 : f32
      %13 = arith.truncf %12 : f32 to f16
      linalg.yield %13 : f16
    } -> tensor<20x4096x64xf16>
    util.return %11 : tensor<20x4096x64xf16>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @_attention(%arg0: tensor<20x4096x64xf16>, %arg1: tensor<20x4096x64xf16>, %arg2: tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16> attributes {hal.abi.convention = #hal.abi.convention<synchronous>} {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant 1.250000e-01 : f32
  %0 = tensor.empty() : tensor<20x4096x4096xf32>
  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%1 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %12 = arith.extf %in : f16 to f32
    %13 = arith.extf %in_2 : f16 to f32
    %14 = arith.mulf %12, %13 : f32
    %15 = arith.addf %14, %out : f32
    linalg.yield %15 : f32
  } -> tensor<20x4096x4096xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%2 : tensor<20x4096x4096xf32>) outs(%0 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %12 = arith.mulf %in, %cst_1 : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %4 = tensor.empty() : tensor<20x4096xf32>
  %5 = tensor.empty() : tensor<20x4096x64xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %arg2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%6, %7, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %12 = arith.addf %arg3, %arg6 : f32
    %13 = arith.truncf %arg3 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg4 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg7 : f32
    iree_linalg_ext.yield %arg5, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %10 = tensor.empty() : tensor<20x4096x64xf16>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9#2, %9#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%10 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %12 = arith.divf %in, %in_2 : f32
    %13 = arith.truncf %12 : f32 to f16
    linalg.yield %13 : f16
  } -> tensor<20x4096x64xf16>
  util.return %11 : tensor<20x4096x64xf16>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = util.call @_attention(%0, %1, %2) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x64xf16>
  %4 = hal.tensor.export %3 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {hal.device.targets = [#device_target_local]} {
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {hal.device.targets = [#device_target_local]} {
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After AttrBasedPipelinePass (iree-preprocessing-attr-based-pipeline) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After WarnOnUninitializedValuesPass (iree-global-opt-warn-on-uninitialized-values) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedConvToConvPass (iree-global-opt-quantized-conv-to-conv) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedMatmulToMatmulPass (iree-global-opt-quantized-matmul-to-matmul) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After RemoveZeroExtentTensorsPass (iree-global-opt-remove-zero-extent-tensors) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOpsPass (iree-global-opt-detach-elementwise-from-named-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After SimplifyDepthwiseConvPass (simplify-depthwise-conv) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperandsPass (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapesPass (iree-global-opt-expand-tensor-shapes) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = tensor.empty() : tensor<20x4096x4096xf32>
    %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_2 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %6 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = tensor.empty() : tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %16 = arith.addf %arg3, %arg6 : f32
      %17 = arith.truncf %arg3 : f32 to f16
      %18 = arith.extf %17 : f16 to f32
      %19 = arith.extf %arg4 : f16 to f32
      %20 = arith.mulf %18, %19 : f32
      %21 = arith.addf %20, %arg7 : f32
      iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096x64xf16>
    %14 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %16 = arith.divf %in, %in_2 : f32
      %17 = arith.truncf %16 : f32 to f16
      linalg.yield %17 : f16
    } -> tensor<20x4096x64xf16>
    %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalgPass (convert-elementwise-to-linalg) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After DecomposeConcatPass (iree-global-opt-decompose-concat) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = tensor.empty() : tensor<20x4096x4096xf32>
  %4 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%4 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %16 = arith.extf %in : f16 to f32
    %17 = arith.extf %in_2 : f16 to f32
    %18 = arith.mulf %16, %17 : f32
    %19 = arith.addf %18, %out : f32
    linalg.yield %19 : f32
  } -> tensor<20x4096x4096xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%5 : tensor<20x4096x4096xf32>) outs(%3 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %16 = arith.mulf %in, %cst : f32
    linalg.yield %16 : f32
  } -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = tensor.empty() : tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %16 = arith.addf %arg3, %arg6 : f32
    %17 = arith.truncf %arg3 : f32 to f16
    %18 = arith.extf %17 : f16 to f32
    %19 = arith.extf %arg4 : f16 to f32
    %20 = arith.mulf %18, %19 : f32
    %21 = arith.addf %20, %arg7 : f32
    iree_linalg_ext.yield %arg5, %16, %21 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %13 = tensor.empty() : tensor<20x4096x64xf16>
  %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12#2, %12#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%13 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %16 = arith.divf %in, %in_2 : f32
    %17 = arith.truncf %16 : f32 to f16
    linalg.yield %17 : f16
  } -> tensor<20x4096x64xf16>
  %15 = hal.tensor.export %14 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %15 : !hal.buffer_view
}

// -----// IR Dump After InsertTensorBarriersPass (iree-dispatch-creation-insert-tensor-barriers) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-dispatch-creation-fold-unit-extent-dims) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteContractionInputsToBF16Pass (iree-global-opt-demote-contraction-inputs-to-bf16) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After PropagateLinalgTransposePass (iree-global-opt-propagate-linalg-transpose) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After ConvertStridedContractionToContractionPass (iree-global-opt-convert-strided-contraction-to-contraction) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After GlobalLoopInvariantCodeMotionPass (iree-global-opt-loop-invariant-code-motion) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobalsPass (iree-consteval-jit-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After TensorPadToTensorInsertSlicePass (iree-dispatch-creation-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After FusionPreprocessingPass (iree-dispatch-creation-fusion-preprocessing) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExpandShapesPass (iree-dispatch-creation-bubble-up-expand-shapes) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After SinkReshapesPass (iree-dispatch-creation-sink-reshapes) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After SplitReductionPass (iree-dispatch-creation-split-reduction-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FormSplitReductionDispatchesPass (iree-dispatch-creation-form-split-reduction-dispatches) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After TransposeGenericOpsPass (iree-dispatch-creation-transpose-generic-ops) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After PropagateEncodingsPass (iree-dispatch-creation-propagate-encodings) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1, d2) -> (d0, d1)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x4096xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %20 = arith.extf %in : f16 to f32
      %21 = arith.extf %in_2 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %out : f32
      linalg.yield %23 : f32
    } -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.mulf %in, %cst : f32
      linalg.yield %20 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = tensor.empty() : tensor<20x4096xf32>
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    %16 = tensor.empty() : tensor<20x4096x64xf16>
    %17 = linalg.generic {indexing_maps = [#map3, #map6, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %19 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatchesPass (iree-dispatch-creation-form-scalar-dispatches) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_2: f16, %out: f32):
    %20 = arith.extf %in : f16 to f32
    %21 = arith.extf %in_2 : f16 to f32
    %22 = arith.mulf %20, %21 : f32
    %23 = arith.addf %22, %out : f32
    linalg.yield %23 : f32
  } -> tensor<20x4096x4096xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %20 = arith.mulf %in, %cst : f32
    linalg.yield %20 : f32
  } -> tensor<20x4096x4096xf32>
  %10 = tensor.empty() : tensor<20x4096xf32>
  %11 = tensor.empty() : tensor<20x4096x64xf32>
  %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %14 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %15:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%9, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
    %20 = arith.addf %arg3, %arg6 : f32
    %21 = arith.truncf %arg3 : f32 to f16
    %22 = arith.extf %21 : f16 to f32
    %23 = arith.extf %arg4 : f16 to f32
    %24 = arith.mulf %22, %23 : f32
    %25 = arith.addf %24, %arg7 : f32
    iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  %16 = tensor.empty() : tensor<20x4096x64xf16>
  %17 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%15#2, %15#1 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%16 : tensor<20x4096x64xf16>) {
  ^bb0(%in: f32, %in_2: f32, %out: f16):
    %20 = arith.divf %in, %in_2 : f32
    %21 = arith.truncf %20 : f32 to f16
    linalg.yield %21 : f16
  } -> tensor<20x4096x64xf16>
  %18 = iree_tensor_ext.compute_barrier.end %17 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %19 = hal.tensor.export %18 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %19 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegionsPass (iree-dispatch-creation-form-dispatch-regions) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %21 = arith.extf %in : f16 to f32
      %22 = arith.extf %in_2 : f16 to f32
      %23 = arith.mulf %21, %22 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<20x4096x4096xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%19 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %21 = arith.mulf %in, %cst : f32
      linalg.yield %21 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %20 : tensor<20x4096x4096xf32>
  }
  %9 = tensor.empty() : tensor<20x4096xf32>
  %10 = tensor.empty() : tensor<20x4096x64xf32>
  %11 = linalg.fill ins(%cst_1 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %12 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %14:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %19:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%8, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%11, %12, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %19#1, %19#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %15 = tensor.empty() : tensor<20x4096x64xf16>
  %16 = flow.dispatch.region -> (tensor<20x4096x64xf16>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14#1, %14#0 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%15 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    flow.return %19 : tensor<20x4096x64xf16>
  }
  %17 = iree_tensor_ext.compute_barrier.end %16 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %18 = hal.tensor.export %17 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %18 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %21 = arith.extf %in : f16 to f32
      %22 = arith.extf %in_2 : f16 to f32
      %23 = arith.mulf %21, %22 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<20x4096x4096xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%19 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %21 = arith.mulf %in, %cst : f32
      linalg.yield %21 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %20 : tensor<20x4096x4096xf32>
  }
  %9 = tensor.empty() : tensor<20x4096xf32>
  %10 = tensor.empty() : tensor<20x4096x64xf32>
  %11 = linalg.fill ins(%cst_1 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %12 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %14:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %19:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%8, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%11, %12, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %19#1, %19#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %15 = tensor.empty() : tensor<20x4096x64xf16>
  %16 = flow.dispatch.region -> (tensor<20x4096x64xf16>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14#1, %14#0 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%15 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    flow.return %19 : tensor<20x4096x64xf16>
  }
  %17 = iree_tensor_ext.compute_barrier.end %16 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %18 = hal.tensor.export %17 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %18 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %cst_1 = arith.constant -3.40282347E+38 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %8 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %21 = arith.extf %in : f16 to f32
      %22 = arith.extf %in_2 : f16 to f32
      %23 = arith.mulf %21, %22 : f32
      %24 = arith.addf %23, %out : f32
      linalg.yield %24 : f32
    } -> tensor<20x4096x4096xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%19 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %21 = arith.mulf %in, %cst : f32
      linalg.yield %21 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %20 : tensor<20x4096x4096xf32>
  }
  %9 = tensor.empty() : tensor<20x4096xf32>
  %10 = tensor.empty() : tensor<20x4096x64xf32>
  %11 = linalg.fill ins(%cst_1 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %12 = linalg.fill ins(%cst_0 : f32) outs(%9 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %13 = linalg.fill ins(%cst_0 : f32) outs(%10 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %14:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %19:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%8, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%11, %12, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %20 = arith.addf %arg3, %arg6 : f32
      %21 = arith.truncf %arg3 : f32 to f16
      %22 = arith.extf %21 : f16 to f32
      %23 = arith.extf %arg4 : f16 to f32
      %24 = arith.mulf %22, %23 : f32
      %25 = arith.addf %24, %arg7 : f32
      iree_linalg_ext.yield %arg5, %20, %25 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %19#1, %19#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %15 = tensor.empty() : tensor<20x4096x64xf16>
  %16 = flow.dispatch.region -> (tensor<20x4096x64xf16>) {
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14#1, %14#0 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%15 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %20 = arith.divf %in, %in_2 : f32
      %21 = arith.truncf %20 : f32 to f16
      linalg.yield %21 : f16
    } -> tensor<20x4096x64xf16>
    flow.return %19 : tensor<20x4096x64xf16>
  }
  %17 = iree_tensor_ext.compute_barrier.end %16 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %18 = hal.tensor.export %17 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %18 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegionsPass (iree-dispatch-creation-clone-producers-into-dispatch-regions) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %11 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %12 = linalg.fill ins(%cst_0 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %15 = arith.extf %in : f16 to f32
      %16 = arith.extf %in_1 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.mulf %in, %cst : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %14 : tensor<20x4096x4096xf32>
  }
  %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %12 = tensor.empty() : tensor<20x4096xf32>
    %cst_0 = arith.constant -3.40282347E+38 : f32
    %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %17 = arith.addf %arg3, %arg6 : f32
      %18 = arith.truncf %arg3 : f32 to f16
      %19 = arith.extf %18 : f16 to f32
      %20 = arith.extf %arg4 : f16 to f32
      %21 = arith.mulf %19, %20 : f32
      %22 = arith.addf %21, %arg7 : f32
      iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %8 = flow.dispatch.region -> (tensor<20x4096x64xf16>) {
    %11 = tensor.empty() : tensor<20x4096x64xf16>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7#1, %7#0 : tensor<20x4096x64xf32>, tensor<20x4096xf32>) outs(%11 : tensor<20x4096x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %13 = arith.divf %in, %in_0 : f32
      %14 = arith.truncf %13 : f32 to f16
      linalg.yield %14 : f16
    } -> tensor<20x4096x64xf16>
    flow.return %12 : tensor<20x4096x64xf16>
  }
  %9 = iree_tensor_ext.compute_barrier.end %8 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensionsPass (iree-dispatch-creation-collapse-dimensions) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %11 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %12 = linalg.fill ins(%cst_1 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %15 = arith.extf %in : f16 to f32
      %16 = arith.extf %in_2 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.mulf %in, %cst : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %14 : tensor<20x4096x4096xf32>
  }
  %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %12 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %14 = linalg.fill ins(%cst_1 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %17 = arith.addf %arg3, %arg6 : f32
      %18 = arith.truncf %arg3 : f32 to f16
      %19 = arith.extf %18 : f16 to f32
      %20 = arith.extf %arg4 : f16 to f32
      %21 = arith.mulf %19, %20 : f32
      %22 = arith.addf %21, %arg7 : f32
      iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %collapsed = tensor.collapse_shape %7#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %7#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %8 = flow.dispatch.region -> (tensor<81920x64xf16>) {
    %11 = tensor.empty() : tensor<81920x64xf16>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%11 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %13 = arith.divf %in, %in_1 : f32
      %14 = arith.truncf %13 : f32 to f16
      linalg.yield %14 : f16
    } -> tensor<81920x64xf16>
    flow.return %12 : tensor<81920x64xf16>
  }
  %expanded = tensor.expand_shape %8 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %9 = iree_tensor_ext.compute_barrier.end %expanded : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After HoistUniformScalarComputePass (iree-dispatch-creation-hoist-uniform-scalar-compute) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %11 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %12 = linalg.fill ins(%cst_1 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %15 = arith.extf %in : f16 to f32
      %16 = arith.extf %in_2 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.mulf %in, %cst : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %14 : tensor<20x4096x4096xf32>
  }
  %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %12 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %14 = linalg.fill ins(%cst_1 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %17 = arith.addf %arg3, %arg6 : f32
      %18 = arith.truncf %arg3 : f32 to f16
      %19 = arith.extf %18 : f16 to f32
      %20 = arith.extf %arg4 : f16 to f32
      %21 = arith.mulf %19, %20 : f32
      %22 = arith.addf %21, %arg7 : f32
      iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %collapsed = tensor.collapse_shape %7#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %7#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %8 = flow.dispatch.region -> (tensor<81920x64xf16>) {
    %11 = tensor.empty() : tensor<81920x64xf16>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%11 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %13 = arith.divf %in, %in_1 : f32
      %14 = arith.truncf %13 : f32 to f16
      linalg.yield %14 : f16
    } -> tensor<81920x64xf16>
    flow.return %12 : tensor<81920x64xf16>
  }
  %expanded = tensor.expand_shape %8 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %9 = iree_tensor_ext.compute_barrier.end %expanded : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After FuseEncodingOpsIntoDispatchRegionsPass (iree-dispatch-creation-fuse-encoding-ops-into-dispatch-regions-pass) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %11 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %12 = linalg.fill ins(%cst_1 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %15 = arith.extf %in : f16 to f32
      %16 = arith.extf %in_2 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.mulf %in, %cst : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %14 : tensor<20x4096x4096xf32>
  }
  %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %12 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %14 = linalg.fill ins(%cst_1 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %17 = arith.addf %arg3, %arg6 : f32
      %18 = arith.truncf %arg3 : f32 to f16
      %19 = arith.extf %18 : f16 to f32
      %20 = arith.extf %arg4 : f16 to f32
      %21 = arith.mulf %19, %20 : f32
      %22 = arith.addf %21, %arg7 : f32
      iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %collapsed = tensor.collapse_shape %7#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %7#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %8 = flow.dispatch.region -> (tensor<81920x64xf16>) {
    %11 = tensor.empty() : tensor<81920x64xf16>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%11 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %13 = arith.divf %in, %in_1 : f32
      %14 = arith.truncf %13 : f32 to f16
      linalg.yield %14 : f16
    } -> tensor<81920x64xf16>
    flow.return %12 : tensor<81920x64xf16>
  }
  %expanded = tensor.expand_shape %8 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %9 = iree_tensor_ext.compute_barrier.end %expanded : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ConvertEncodingToFlowPass (iree-dispatch-creation-convert-encoding-to-flow) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %11 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %12 = linalg.fill ins(%cst_1 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %15 = arith.extf %in : f16 to f32
      %16 = arith.extf %in_2 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %out : f32
      linalg.yield %18 : f32
    } -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.mulf %in, %cst : f32
      linalg.yield %15 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %14 : tensor<20x4096x4096xf32>
  }
  %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %11 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %12 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %14 = linalg.fill ins(%cst_1 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %17 = arith.addf %arg3, %arg6 : f32
      %18 = arith.truncf %arg3 : f32 to f16
      %19 = arith.extf %18 : f16 to f32
      %20 = arith.extf %arg4 : f16 to f32
      %21 = arith.mulf %19, %20 : f32
      %22 = arith.addf %21, %arg7 : f32
      iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %collapsed = tensor.collapse_shape %7#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %7#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %8 = flow.dispatch.region -> (tensor<81920x64xf16>) {
    %11 = tensor.empty() : tensor<81920x64xf16>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%11 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %13 = arith.divf %in, %in_1 : f32
      %14 = arith.truncf %13 : f32 to f16
      linalg.yield %14 : f16
    } -> tensor<81920x64xf16>
    flow.return %12 : tensor<81920x64xf16>
  }
  %expanded = tensor.expand_shape %8 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %9 = iree_tensor_ext.compute_barrier.end %expanded : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
  %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = iree_tensor_ext.compute_barrier.start %2 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %4 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %5 = iree_tensor_ext.compute_barrier.start %4 : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %6 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
      %11 = tensor.empty() : tensor<20x4096x4096xf32>
      %cst = arith.constant 1.250000e-01 : f32
      %cst_1 = arith.constant 0.000000e+00 : f32
      %12 = linalg.fill ins(%cst_1 : f32) outs(%11 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %13 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%1, %3 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%12 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_2: f16, %out: f32):
        %15 = arith.extf %in : f16 to f32
        %16 = arith.extf %in_2 : f16 to f32
        %17 = arith.mulf %15, %16 : f32
        %18 = arith.addf %17, %out : f32
        linalg.yield %18 : f32
      } -> tensor<20x4096x4096xf32>
      %14 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%13 : tensor<20x4096x4096xf32>) outs(%11 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %15 = arith.mulf %in, %cst : f32
        linalg.yield %15 : f32
      } -> tensor<20x4096x4096xf32>
      flow.return %14 : tensor<20x4096x4096xf32>
    }
    %7:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      %11 = tensor.empty() : tensor<20x4096x64xf32>
      %cst = arith.constant 0.000000e+00 : f32
      %12 = tensor.empty() : tensor<20x4096xf32>
      %cst_1 = arith.constant -3.40282347E+38 : f32
      %13 = linalg.fill ins(%cst : f32) outs(%11 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %14 = linalg.fill ins(%cst_1 : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %15 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %16:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%6, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%14, %15, %13 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
        %17 = arith.addf %arg3, %arg6 : f32
        %18 = arith.truncf %arg3 : f32 to f16
        %19 = arith.extf %18 : f16 to f32
        %20 = arith.extf %arg4 : f16 to f32
        %21 = arith.mulf %19, %20 : f32
        %22 = arith.addf %21, %arg7 : f32
        iree_linalg_ext.yield %arg5, %17, %22 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      flow.return %16#1, %16#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
    }
    %collapsed = tensor.collapse_shape %7#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
    %collapsed_0 = tensor.collapse_shape %7#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
    %8 = flow.dispatch.region -> (tensor<81920x64xf16>) {
      %11 = tensor.empty() : tensor<81920x64xf16>
      %12 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%11 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_1: f32, %out: f16):
        %13 = arith.divf %in, %in_1 : f32
        %14 = arith.truncf %13 : f32 to f16
        linalg.yield %14 : f16
      } -> tensor<81920x64xf16>
      flow.return %12 : tensor<81920x64xf16>
    }
    %expanded = tensor.expand_shape %8 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
    %9 = iree_tensor_ext.compute_barrier.end %expanded : tensor<20x4096x64xf16> -> tensor<20x4096x64xf16>
    %10 = hal.tensor.export %9 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After RemoveTensorBarriersPass (iree-dispatch-creation-remove-tensor-barriers) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.region -> (tensor<20x4096x4096xf32>) {
    %7 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %8 = linalg.fill ins(%cst_1 : f32) outs(%7 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%8 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_2 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<20x4096x4096xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<20x4096x4096xf32>) outs(%7 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst : f32
      linalg.yield %11 : f32
    } -> tensor<20x4096x4096xf32>
    flow.return %10 : tensor<20x4096x4096xf32>
  }
  %4:2 = flow.dispatch.region -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    %7 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %8 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %10 = linalg.fill ins(%cst_1 : f32) outs(%8 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%8 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%3, %2 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%10, %11, %9 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg3: f32, %arg4: f16, %arg5: f32, %arg6: f32, %arg7: f32):
      %13 = arith.addf %arg3, %arg6 : f32
      %14 = arith.truncf %arg3 : f32 to f16
      %15 = arith.extf %14 : f16 to f32
      %16 = arith.extf %arg4 : f16 to f32
      %17 = arith.mulf %15, %16 : f32
      %18 = arith.addf %17, %arg7 : f32
      iree_linalg_ext.yield %arg5, %13, %18 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    flow.return %12#1, %12#2 : tensor<20x4096xf32>, tensor<20x4096x64xf32>
  }
  %collapsed = tensor.collapse_shape %4#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %4#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %5 = flow.dispatch.region -> (tensor<81920x64xf16>) {
    %7 = tensor.empty() : tensor<81920x64xf16>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%collapsed, %collapsed_0 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%7 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %9 = arith.divf %in, %in_1 : f32
      %10 = arith.truncf %9 : f32 to f16
      linalg.yield %10 : f16
    } -> tensor<81920x64xf16>
    flow.return %8 : tensor<81920x64xf16>
  }
  %expanded = tensor.expand_shape %5 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %6 = hal.tensor.export %expanded "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ConvertDispatchRegionsToWorkgroupsPass (iree-dispatch-creation-convert-dispatch-regions-to-workgroups) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %7 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %8 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %9 = tensor.empty() : tensor<20x4096x4096xf32>
    %cst = arith.constant 1.250000e-01 : f32
    %cst_1 = arith.constant 0.000000e+00 : f32
    %10 = linalg.fill ins(%cst_1 : f32) outs(%9 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%7, %8 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%10 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_2: f16, %out: f32):
      %13 = arith.extf %in : f16 to f32
      %14 = arith.extf %in_2 : f16 to f32
      %15 = arith.mulf %13, %14 : f32
      %16 = arith.addf %15, %out : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%11 : tensor<20x4096x4096xf32>) outs(%9 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.mulf %in, %cst : f32
      linalg.yield %13 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %12, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %7 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %8 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %9 = tensor.empty() : tensor<20x4096x64xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %10 = tensor.empty() : tensor<20x4096xf32>
    %cst_1 = arith.constant -3.40282347E+38 : f32
    %11 = linalg.fill ins(%cst : f32) outs(%9 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %12 = linalg.fill ins(%cst_1 : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%10 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %14:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%7, %8 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%12, %13, %11 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %15 = arith.addf %arg7, %arg10 : f32
      %16 = arith.truncf %arg7 : f32 to f16
      %17 = arith.extf %16 : f16 to f32
      %18 = arith.extf %arg8 : f16 to f32
      %19 = arith.mulf %17, %18 : f32
      %20 = arith.addf %19, %arg11 : f32
      iree_linalg_ext.yield %arg9, %15, %20 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %14#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %14#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  }
  %collapsed = tensor.collapse_shape %4#1 [[0, 1], [2]] : tensor<20x4096x64xf32> into tensor<81920x64xf32>
  %collapsed_0 = tensor.collapse_shape %4#0 [[0, 1]] : tensor<20x4096xf32> into tensor<81920xf32>
  %5 = flow.dispatch.workgroups(%collapsed, %collapsed_0) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %7 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %8 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %9 = tensor.empty() : tensor<81920x64xf16>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%7, %8 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%9 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_1: f32, %out: f16):
      %11 = arith.divf %in, %in_1 : f32
      %12 = arith.truncf %11 : f32 to f16
      linalg.yield %12 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %10, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  }
  %expanded = tensor.expand_shape %5 [[0, 1], [2]] output_shape [20, 4096, 64] : tensor<81920x64xf16> into tensor<20x4096x64xf16>
  %6 = hal.tensor.export %expanded "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ConvertTensorToFlowPass (iree-dispatch-creation-convert-tensor-to-flow) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After MaterializeDefaultWorkgroupCountRegionPass (iree-dispatch-creation-materialize-default-workgroup-count-region) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After BitcastUnsupportedElementTypesPass (iree-dispatch-creation-bitcast-unsupported-element-types) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After VerifyInputLegalityPass (iree-verify-input-legality) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x4096xf32>
      %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %14 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_1 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<20x4096x4096xf32>
      %15 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x64xf32>
      %13 = tensor.empty() : tensor<20x4096xf32>
      %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
        %18 = arith.addf %arg7, %arg10 : f32
        %19 = arith.truncf %arg7 : f32 to f16
        %20 = arith.extf %19 : f16 to f32
        %21 = arith.extf %arg8 : f16 to f32
        %22 = arith.mulf %20, %21 : f32
        %23 = arith.addf %22, %arg11 : f32
        iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %12 = tensor.empty() : tensor<81920x64xf16>
      %13 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %14 = arith.divf %in, %in_0 : f32
        %15 = arith.truncf %14 : f32 to f16
        linalg.yield %15 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x4096xf32>
      %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %14 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_1 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<20x4096x4096xf32>
      %15 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x64xf32>
      %13 = tensor.empty() : tensor<20x4096xf32>
      %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
        %18 = arith.addf %arg7, %arg10 : f32
        %19 = arith.truncf %arg7 : f32 to f16
        %20 = arith.extf %19 : f16 to f32
        %21 = arith.extf %arg8 : f16 to f32
        %22 = arith.mulf %20, %21 : f32
        %23 = arith.addf %22, %arg11 : f32
        iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %12 = tensor.empty() : tensor<81920x64xf16>
      %13 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %14 = arith.divf %in, %in_0 : f32
        %15 = arith.truncf %14 : f32 to f16
        linalg.yield %15 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After AttributeCallGraphPass (iree-util-attribute-call-graph) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x4096xf32>
      %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %14 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_1 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<20x4096x4096xf32>
      %15 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x64xf32>
      %13 = tensor.empty() : tensor<20x4096xf32>
      %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
        %18 = arith.addf %arg7, %arg10 : f32
        %19 = arith.truncf %arg7 : f32 to f16
        %20 = arith.extf %19 : f16 to f32
        %21 = arith.extf %arg8 : f16 to f32
        %22 = arith.mulf %20, %21 : f32
        %23 = arith.addf %22, %arg11 : f32
        iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %12 = tensor.empty() : tensor<81920x64xf16>
      %13 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %14 = arith.divf %in, %in_0 : f32
        %15 = arith.truncf %14 : f32 to f16
        linalg.yield %15 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After InitializeEmptyTensorsPass (iree-flow-initialize-empty-tensors) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CaptureDynamicDimsPass (iree-flow-capture-dynamic-dims) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x4096xf32>
    %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %16 = arith.extf %in : f16 to f32
      %17 = arith.extf %in_1 : f16 to f32
      %18 = arith.mulf %16, %17 : f32
      %19 = arith.addf %18, %out : f32
      linalg.yield %19 : f32
    } -> tensor<20x4096x4096xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.mulf %in, %cst_0 : f32
      linalg.yield %16 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %12 = tensor.empty() : tensor<20x4096x64xf32>
    %13 = tensor.empty() : tensor<20x4096xf32>
    %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
      %18 = arith.addf %arg7, %arg10 : f32
      %19 = arith.truncf %arg7 : f32 to f16
      %20 = arith.extf %19 : f16 to f32
      %21 = arith.extf %arg8 : f16 to f32
      %22 = arith.mulf %20, %21 : f32
      %23 = arith.addf %22, %arg11 : f32
      iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
      (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
    %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %12 = tensor.empty() : tensor<81920x64xf16>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %14 = arith.divf %in, %in_0 : f32
      %15 = arith.truncf %14 : f32 to f16
      linalg.yield %15 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchExternsPass (iree-flow-outline-dispatch-externs) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch.workgroups(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x4096xf32>
      %13 = linalg.fill ins(%cst : f32) outs(%12 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %14 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%10, %11 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%13 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_1 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<20x4096x4096xf32>
      %15 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<20x4096x4096xf32>) outs(%12 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %15, %arg5, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %4:2 = flow.dispatch.workgroups(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>) =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg6: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %12 = tensor.empty() : tensor<20x4096x64xf32>
      %13 = tensor.empty() : tensor<20x4096xf32>
      %14 = linalg.fill ins(%cst_0 : f32) outs(%12 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %15 = linalg.fill ins(%cst : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %16 = linalg.fill ins(%cst_0 : f32) outs(%13 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %17:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%10, %11 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%15, %16, %14 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg7: f32, %arg8: f16, %arg9: f32, %arg10: f32, %arg11: f32):
        %18 = arith.addf %arg7, %arg10 : f32
        %19 = arith.truncf %arg7 : f32 to f16
        %20 = arith.extf %19 : f16 to f32
        %21 = arith.extf %arg8 : f16 to f32
        %22 = arith.mulf %20, %21 : f32
        %23 = arith.addf %22, %arg11 : f32
        iree_linalg_ext.yield %arg9, %18, %23 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %17#1, %arg5, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %17#2, %arg6, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch.workgroups(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16> =
        (%arg3: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg4: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg5: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
      %10 = iree_tensor_ext.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %11 = iree_tensor_ext.dispatch.tensor.load %arg4, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %12 = tensor.empty() : tensor<81920x64xf16>
      %13 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%10, %11 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%12 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %14 = arith.divf %in, %in_0 : f32
        %15 = arith.truncf %14 : f32 to f16
        linalg.yield %15 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %13, %arg5, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineDispatchRegionsPass (iree-flow-outline-dispatch-regions) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchesPass (iree-flow-annotate-dispatches) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After StripDebugOpsPass (iree-util-strip-debug-ops) //----- //
flow.executable private @attention_dispatch_0 {
  flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %2 = tensor.empty() : tensor<20x4096x4096xf32>
      %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %6 = arith.extf %in : f16 to f32
        %7 = arith.extf %in_1 : f16 to f32
        %8 = arith.mulf %6, %7 : f32
        %9 = arith.addf %8, %out : f32
        linalg.yield %9 : f32
      } -> tensor<20x4096x4096xf32>
      %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %6 = arith.mulf %in, %cst_0 : f32
        linalg.yield %6 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      return
    }
  }
}

// -----// IR Dump After StripDebugOpsPass (iree-util-strip-debug-ops) //----- //
flow.executable private @attention_dispatch_1 {
  flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %2 = tensor.empty() : tensor<20x4096x64xf32>
      %3 = tensor.empty() : tensor<20x4096xf32>
      %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
        %8 = arith.addf %arg4, %arg7 : f32
        %9 = arith.truncf %arg4 : f32 to f16
        %10 = arith.extf %9 : f16 to f32
        %11 = arith.extf %arg5 : f16 to f32
        %12 = arith.mulf %10, %11 : f32
        %13 = arith.addf %12, %arg8 : f32
        iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      return
    }
  }
}

// -----// IR Dump After StripDebugOpsPass (iree-util-strip-debug-ops) //----- //
flow.executable private @attention_dispatch_2 {
  flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
      %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %2 = tensor.empty() : tensor<81920x64xf16>
      %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %4 = arith.divf %in, %in_0 : f32
        %5 = arith.truncf %4 : f32 to f16
        linalg.yield %5 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      return
    }
  }
}

// -----// IR Dump After DeduplicateExecutablesPass (iree-flow-deduplicate-executables) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CleanupTensorShapesPass (iree-flow-cleanup-tensor-shapes) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After OutlineConstantsPass (iree-flow-outline-constants) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputPass (iree-stream-verify-input) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
  %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
  %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
  %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
  %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
  %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
  %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
  %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After CloneToConsumersPass (iree-stream-clone-to-consumers) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  flow.executable private @attention_dispatch_0 {
    flow.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x4096xf32>
        %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %4 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%0, %1 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%3 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %6 = arith.extf %in : f16 to f32
          %7 = arith.extf %in_1 : f16 to f32
          %8 = arith.mulf %6, %7 : f32
          %9 = arith.addf %8, %out : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        %5 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : tensor<20x4096x4096xf32>) outs(%2 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.mulf %in, %cst_0 : f32
          linalg.yield %6 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %arg2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_1 {
    flow.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>, %arg3: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %2 = tensor.empty() : tensor<20x4096x64xf32>
        %3 = tensor.empty() : tensor<20x4096xf32>
        %4 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%3 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %7:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%0, %1 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%5, %6, %4 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %8 = arith.addf %arg4, %arg7 : f32
          %9 = arith.truncf %arg4 : f32 to f16
          %10 = arith.extf %9 : f16 to f32
          %11 = arith.extf %arg5 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %arg8 : f32
          iree_linalg_ext.yield %arg6, %8, %13 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %7#1, %arg2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %7#2, %arg3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  flow.executable private @attention_dispatch_2 {
    flow.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>) {
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %1 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %2 = tensor.empty() : tensor<81920x64xf16>
        %3 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%2 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %4 = arith.divf %in, %in_0 : f32
          %5 = arith.truncf %4 : f32 to f16
          linalg.yield %5 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %2 = hal.tensor.import %arg2 "input2" : !hal.buffer_view -> tensor<20x4096x64xf16>
    %3 = flow.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0, %1) : (tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) -> tensor<20x4096x4096xf32>
    %4:2 = flow.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3, %2) : (tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) -> (tensor<20x4096xf32>, tensor<20x4096x64xf32>)
    %5 = flow.tensor.reshape %4#1 : tensor<20x4096x64xf32> -> tensor<81920x64xf32>
    %6 = flow.tensor.reshape %4#0 : tensor<20x4096xf32> -> tensor<81920xf32>
    %7 = flow.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%5, %6) : (tensor<81920x64xf32>, tensor<81920xf32>) -> tensor<81920x64xf16>
    %8 = flow.tensor.reshape %7 : tensor<81920x64xf16> -> tensor<20x4096x64xf16>
    %9 = hal.tensor.export %8 "output0" : tensor<20x4096x64xf16> -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStreamPass (iree-stream-conversion) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c20 = arith.constant 20 : index
    %c4096 = arith.constant 4096 : index
    %c64 = arith.constant 64 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%0}
    %element_type_f16_0 = hal.element_type<f16> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    %c20_2 = arith.constant 20 : index
    %c4096_3 = arith.constant 4096 : index
    %c64_4 = arith.constant 64 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20_2, %c4096_3, %c64_4]) type(%element_type_f16_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%3}
    %element_type_f16_5 = hal.element_type<f16> : i32
    %dense_row_major_6 = hal.encoding_type<dense_row_major> : i32
    %c20_7 = arith.constant 20 : index
    %c4096_8 = arith.constant 4096 : index
    %c64_9 = arith.constant 64 : index
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20_7, %c4096_8, %c64_9]) type(%element_type_f16_5) encoding(%dense_row_major_6)
    %6 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %7 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%6}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %10 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %5) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%3}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%9}
    %11 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %13:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%10, %8) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf16> in !stream.resource<*>{%6}) -> (tensor<20x4096xf32> in !stream.resource<*>{%11}, tensor<20x4096x64xf32> in !stream.resource<*>{%12})
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %15 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %13#1 : tensor<20x4096x64xf32> in !stream.resource<*>{%12} -> tensor<81920x64xf32> in !stream.resource<*>{%14}
    %16 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %17 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %13#0 : tensor<20x4096xf32> in !stream.resource<*>{%11} -> tensor<81920xf32> in !stream.resource<*>{%16}
    %18 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %19 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%15, %17) : (tensor<81920x64xf32> in !stream.resource<*>{%14}, tensor<81920xf32> in !stream.resource<*>{%16}) -> tensor<81920x64xf16> in !stream.resource<*>{%18}
    %20 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %21 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %19 : tensor<81920x64xf16> in !stream.resource<*>{%18} -> tensor<20x4096x64xf16> in !stream.resource<*>{%20}
    %22 = stream.async.transfer %21 : !stream.resource<*>{%20} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%20}
    %23 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %22 : tensor<20x4096x64xf16> in !stream.resource<external>{%20} -> !hal.buffer_view
    util.return %23 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensorsPass (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c20 = arith.constant 20 : index
    %c4096 = arith.constant 4096 : index
    %c64 = arith.constant 64 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%0}
    %element_type_f16_0 = hal.element_type<f16> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    %c20_2 = arith.constant 20 : index
    %c4096_3 = arith.constant 4096 : index
    %c64_4 = arith.constant 64 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20_2, %c4096_3, %c64_4]) type(%element_type_f16_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%3}
    %element_type_f16_5 = hal.element_type<f16> : i32
    %dense_row_major_6 = hal.encoding_type<dense_row_major> : i32
    %c20_7 = arith.constant 20 : index
    %c4096_8 = arith.constant 4096 : index
    %c64_9 = arith.constant 64 : index
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20_7, %c4096_8, %c64_9]) type(%element_type_f16_5) encoding(%dense_row_major_6)
    %6 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %7 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%6}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %10 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %5) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%3}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%9}
    %11 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %13:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%10, %8) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf16> in !stream.resource<*>{%6}) -> (tensor<20x4096xf32> in !stream.resource<*>{%11}, tensor<20x4096x64xf32> in !stream.resource<*>{%12})
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %15 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %13#1 : tensor<20x4096x64xf32> in !stream.resource<*>{%12} -> tensor<81920x64xf32> in !stream.resource<*>{%14}
    %16 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %17 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %13#0 : tensor<20x4096xf32> in !stream.resource<*>{%11} -> tensor<81920xf32> in !stream.resource<*>{%16}
    %18 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %19 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%15, %17) : (tensor<81920x64xf32> in !stream.resource<*>{%14}, tensor<81920xf32> in !stream.resource<*>{%16}) -> tensor<81920x64xf16> in !stream.resource<*>{%18}
    %20 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %21 = stream.tensor.clone on(#hal.device.affinity<@__device_0>) %19 : tensor<81920x64xf16> in !stream.resource<*>{%18} -> tensor<20x4096x64xf16> in !stream.resource<*>{%20}
    %22 = stream.async.transfer %21 : !stream.resource<*>{%20} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%20}
    %23 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %22 : tensor<20x4096x64xf16> in !stream.resource<external>{%20} -> !hal.buffer_view
    util.return %23 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
  %cst = arith.constant 1.250000e-01 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -3.40282347E+38 : f32
  %c0 = arith.constant 0 : index
  %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
    %12 = arith.addf %arg4, %arg7 : f32
    %13 = arith.truncf %arg4 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg5 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg8 : f32
    iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
  %c0 = arith.constant 0 : index
  %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %element_type_f16_0 = hal.element_type<f16> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16_0) encoding(%dense_row_major_1)
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %element_type_f16_2 = hal.element_type<f16> : i32
  %dense_row_major_3 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16_2) encoding(%dense_row_major_3)
  %6 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %7 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%6}
  %8 = stream.async.clone on(#hal.device.affinity<@__device_0>) %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %10 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %5) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%3}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%9}
  %11 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %13:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%10, %8) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf16> in !stream.resource<*>{%6}) -> (tensor<20x4096xf32> in !stream.resource<*>{%11}, tensor<20x4096x64xf32> in !stream.resource<*>{%12})
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %15 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %16 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %17 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%13#1, %13#0) : (tensor<81920x64xf32> in !stream.resource<*>{%14}, tensor<81920xf32> in !stream.resource<*>{%15}) -> tensor<81920x64xf16> in !stream.resource<*>{%16}
  %18 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %19 = stream.async.clone on(#hal.device.affinity<@__device_0>) %17 : !stream.resource<*>{%18} -> !stream.resource<external>{%18}
  %20 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %19 : tensor<20x4096x64xf16> in !stream.resource<external>{%18} -> !hal.buffer_view
  util.return %20 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %element_type_f16_0 = hal.element_type<f16> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %element_type_f16_2 = hal.element_type<f16> : i32
    %dense_row_major_3 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16_2) encoding(%dense_row_major_3)
    %6 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %7 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%6}
    %8 = stream.async.clone on(#hal.device.affinity<@__device_0>) %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %10 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %5) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%3}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%9}
    %11 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %13:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%10, %8) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf16> in !stream.resource<*>{%6}) -> (tensor<20x4096xf32> in !stream.resource<*>{%11}, tensor<20x4096x64xf32> in !stream.resource<*>{%12})
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %15 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %16 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %17 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%13#1, %13#0) : (tensor<81920x64xf32> in !stream.resource<*>{%14}, tensor<81920xf32> in !stream.resource<*>{%15}) -> tensor<81920x64xf16> in !stream.resource<*>{%16}
    %18 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %19 = stream.async.clone on(#hal.device.affinity<@__device_0>) %17 : !stream.resource<*>{%18} -> !stream.resource<external>{%18}
    %20 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %19 : tensor<20x4096x64xf16> in !stream.resource<external>{%18} -> !hal.buffer_view
    util.return %20 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %element_type_f16_0 = hal.element_type<f16> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16_0) encoding(%dense_row_major_1)
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %element_type_f16_2 = hal.element_type<f16> : i32
  %dense_row_major_3 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16_2) encoding(%dense_row_major_3)
  %6 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %7 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%6}
  %8 = stream.async.clone on(#hal.device.affinity<@__device_0>) %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %10 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %5) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%3}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%9}
  %11 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %13:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%10, %8) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf16> in !stream.resource<*>{%6}) -> (tensor<20x4096xf32> in !stream.resource<*>{%11}, tensor<20x4096x64xf32> in !stream.resource<*>{%12})
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %15 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %16 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %17 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%13#1, %13#0) : (tensor<81920x64xf32> in !stream.resource<*>{%14}, tensor<81920xf32> in !stream.resource<*>{%15}) -> tensor<81920x64xf16> in !stream.resource<*>{%16}
  %18 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %19 = stream.async.clone on(#hal.device.affinity<@__device_0>) %17 : !stream.resource<*>{%18} -> !stream.resource<external>{%18}
  %20 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %19 : tensor<20x4096x64xf16> in !stream.resource<external>{%18} -> !hal.buffer_view
  util.return %20 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializersPass (iree-util-combine-initializers) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After SpecializeEncodingsPass (iree-stream-specialize-encodings) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
    %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
    %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
    %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
    %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
    %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
    %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
    %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
    %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
    %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @attention_dispatch_2 {
  stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %5 = tensor.empty() : tensor<81920x64xf16>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %7 = arith.divf %in, %in_0 : f32
        %8 = arith.truncf %7 : f32 to f16
        linalg.yield %8 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      return
    }
  }
}

// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @attention_dispatch_0 {
  stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
      %cst = arith.constant 1.250000e-01 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %5 = tensor.empty() : tensor<20x4096x4096xf32>
      %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %9 = arith.extf %in : f16 to f32
        %10 = arith.extf %in_1 : f16 to f32
        %11 = arith.mulf %9, %10 : f32
        %12 = arith.addf %11, %out : f32
        linalg.yield %12 : f32
      } -> tensor<20x4096x4096xf32>
      %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %9 = arith.mulf %in, %cst : f32
        linalg.yield %9 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      return
    }
  }
}

// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @attention_dispatch_1 {
  stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant -3.40282347E+38 : f32
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %6 = tensor.empty() : tensor<20x4096x64xf32>
      %7 = tensor.empty() : tensor<20x4096xf32>
      %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
        %12 = arith.addf %arg4, %arg7 : f32
        %13 = arith.truncf %arg4 : f32 to f16
        %14 = arith.extf %13 : f16 to f32
        %15 = arith.extf %arg5 : f16 to f32
        %16 = arith.mulf %14, %15 : f32
        %17 = arith.addf %16, %arg8 : f32
        iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      return
    }
  }
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf16> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %3 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %4 = stream.async.clone on(#hal.device.affinity<@__device_0>) %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %5 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%0}
  %6 = stream.async.clone on(#hal.device.affinity<@__device_0>) %5 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %7 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x4096xf32> : index
  %8 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%2, %4) : (tensor<20x4096x64xf16> in !stream.resource<*>{%0}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> tensor<20x4096x4096xf32> in !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096xf32> : index
  %10 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<20x4096x64xf32> : index
  %11:2 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%8, %6) : (tensor<20x4096x4096xf32> in !stream.resource<*>{%7}, tensor<20x4096x64xf16> in !stream.resource<*>{%0}) -> (tensor<20x4096xf32> in !stream.resource<*>{%9}, tensor<20x4096x64xf32> in !stream.resource<*>{%10})
  %12 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf32> : index
  %13 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920xf32> : index
  %14 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<81920x64xf16> : index
  %15 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%11#1, %11#0) : (tensor<81920x64xf32> in !stream.resource<*>{%12}, tensor<81920xf32> in !stream.resource<*>{%13}) -> tensor<81920x64xf16> in !stream.resource<*>{%14}
  %16 = stream.async.clone on(#hal.device.affinity<@__device_0>) %15 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %17 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %16 : tensor<20x4096x64xf16> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %17 : !hal.buffer_view
}

// -----// IR Dump After EncodeHostTensorsPass (iree-stream-encode-host-tensors) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After MaterializeEncodingsPass (iree-stream-materialize-encodings) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncResourcesPass (iree-stream-verify-lowering-to-async-resources) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWritePass (iree-stream-materialize-copy-on-write) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocationsPass (iree-stream-emplace-allocations) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<*>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c10485760}, !stream.resource<*>{%c10485760}) -> !stream.resource<*>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<*>{%c1342177280}, !stream.resource<*>{%c10485760}) -> (!stream.resource<*>{%c327680}, !stream.resource<*>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<*>{%c20971520}, !stream.resource<*>{%c327680}) -> !stream.resource<*>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<*>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After RefineUsagePass (iree-stream-refine-usage) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
    %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
    %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %4 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
  %6 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%1[%c0 to %c10485760 for %c10485760], %3[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %7:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%6[%c0 to %c1342177280 for %c1342177280], %5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %8 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%7#1[%c0 to %c20971520 for %c20971520], %7#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %9 = stream.async.clone on(#hal.device.affinity<@__device_0>) %8 : !stream.resource<external>{%c10485760} -> !stream.resource<external>{%c10485760}
  %10 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %9 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %10 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
  %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
  %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRangesPass (iree-stream-verify-async-access-ranges) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%0[%c0 to %c10485760 for %c10485760], %1[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %4:2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%3[%c0 to %c1342177280 for %c1342177280], %2[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %5 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%4#1[%c0 to %c20971520 for %c20971520], %4#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecutionPass (iree-stream-schedule-execution) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrencyPass (iree-stream-schedule-concurrency) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SyncInitializersPass (iree-stream-sync-initializers) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %7 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After PropagateTimepointsPass (iree-stream-propagate-timepoints) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.immediate => !stream.timepoint
    %5 = stream.timepoint.immediate => !stream.timepoint
    %6 = stream.timepoint.join max(%3, %4, %5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%6) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %9 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %10:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%9[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %11 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%10#1[%c0 to %c20971520 for %c20971520], %10#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %11 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %7 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltinsPass (iree-stream-materialize-builtins) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.immediate => !stream.timepoint
    %5 = stream.timepoint.immediate => !stream.timepoint
    %6 = stream.timepoint.join max(%3, %4, %5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%6) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %9 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %10:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%9[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %11 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%10#1[%c0 to %c20971520 for %c20971520], %10#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %11 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %7 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
    %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
    %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
    %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
    stream.yield %7 : !stream.resource<external>{%c10485760}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %7 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %7 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %7 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncPass (iree-stream-verify-lowering-to-async) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}) -> !stream.resource<external>{%c10485760} {
      %5 = stream.async.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg3[%c0 to %c10485760 for %c10485760], %arg4[%c0 to %c10485760 for %c10485760]) : (!stream.resource<external>{%c10485760}, !stream.resource<external>{%c10485760}) -> !stream.resource<transient>{%c1342177280}
      %6:2 = stream.async.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%5[%c0 to %c1342177280 for %c1342177280], %arg5[%c0 to %c10485760 for %c10485760]) : (!stream.resource<transient>{%c1342177280}, !stream.resource<external>{%c10485760}) -> (!stream.resource<transient>{%c327680}, !stream.resource<transient>{%c20971520})
      %7 = stream.async.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%6#1[%c0 to %c20971520 for %c20971520], %6#0[%c0 to %c327680 for %c327680]) : (!stream.resource<transient>{%c20971520}, !stream.resource<transient>{%c327680}) -> !stream.resource<external>{%c10485760}
      stream.yield %7 : !stream.resource<external>{%c10485760}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c10485760}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocationPass (iree-stream-schedule-allocation) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %3:4 = stream.resource.pack on(#hal.device.affinity<@__device_0>) slices({
      [0, 1] = %c1342177280,
      [1, 2] = %c327680,
      [1, 2] = %c20971520
    }) : index
    %result_1, %result_timepoint_2 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%3#0} => !stream.timepoint
    %4 = stream.timepoint.join max(%result_timepoint, %result_timepoint_2) => !stream.timepoint
    %5 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%4) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_1 as %arg7: !stream.resource<transient>{%3#0}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0},
        ro %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg6[%c0_0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %6 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%5) => %result_1 : !stream.resource<transient>{%3#0} => !stream.timepoint
    %7 = stream.timepoint.join max(%6, %5) => !stream.timepoint
    %8 = stream.timepoint.await %7 => %result : !stream.resource<external>{%c10485760}
    %9 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %8 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After EmplaceTransientsPass (iree-stream-emplace-transients) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %3:4 = stream.resource.pack on(#hal.device.affinity<@__device_0>) slices({
      [0, 1] = %c1342177280,
      [1, 2] = %c327680,
      [1, 2] = %c20971520
    }) : index
    %result_1, %result_timepoint_2 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%3#0} => !stream.timepoint
    %4 = stream.timepoint.join max(%result_timepoint, %result_timepoint_2) => !stream.timepoint
    %5 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%4) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_1 as %arg7: !stream.resource<transient>{%3#0}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0},
        ro %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg6[%c0_0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %6 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%5) => %result_1 : !stream.resource<transient>{%3#0} => !stream.timepoint
    %7 = stream.timepoint.join max(%6, %5) => !stream.timepoint
    %8 = stream.timepoint.await %7 => %result : !stream.resource<external>{%c10485760}
    %9 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %8 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTransientSizeQueriesPass (iree-stream-materialize-transient-size-queries) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %3:4 = stream.resource.pack on(#hal.device.affinity<@__device_0>) slices({
      [0, 1] = %c1342177280,
      [1, 2] = %c327680,
      [1, 2] = %c20971520
    }) : index
    %result_1, %result_timepoint_2 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%3#0} => !stream.timepoint
    %4 = stream.timepoint.join max(%result_timepoint, %result_timepoint_2) => !stream.timepoint
    %5 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%4) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_1 as %arg7: !stream.resource<transient>{%3#0}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0},
        ro %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
        wo %arg6[%c0_0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %6 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%5) => %result_1 : !stream.resource<transient>{%3#0} => !stream.timepoint
    %7 = stream.timepoint.join max(%6, %5) => !stream.timepoint
    %8 = stream.timepoint.await %7 => %result : !stream.resource<external>{%c10485760}
    %9 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %8 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstantsPass (iree-stream-pack-constants) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %3:4 = stream.resource.pack on(#hal.device.affinity<@__device_0>) slices({
    [0, 1] = %c1342177280,
    [1, 2] = %c327680,
    [1, 2] = %c20971520
  }) : index
  %result_1, %result_timepoint_2 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%3#0} => !stream.timepoint
  %4 = stream.timepoint.join max(%result_timepoint, %result_timepoint_2) => !stream.timepoint
  %5 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%4) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_1 as %arg7: !stream.resource<transient>{%3#0}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%3#1 for %c1342177280] : !stream.resource<transient>{%3#0},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
      wo %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%3#3 for %c20971520] : !stream.resource<transient>{%3#0},
      ro %arg7[%3#2 for %c327680] : !stream.resource<transient>{%3#0},
      wo %arg6[%c0_0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %6 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%5) => %result_1 : !stream.resource<transient>{%3#0} => !stream.timepoint
  %7 = stream.timepoint.join max(%6, %5) => !stream.timepoint
  %8 = stream.timepoint.await %7 => %result : !stream.resource<external>{%c10485760}
  %9 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %8 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %9 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlicesPass (iree-stream-layout-slices) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %c0_1 = arith.constant 0 : index
  %c1342177280_2 = arith.constant 1342177280 : index
  %c1342177280_3 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342504960_4 = arith.constant 1342504960 : index
  %c1363476480 = arith.constant 1363476480 : index
  %c1363476480_5 = arith.constant 1363476480 : index
  %result_6, %result_timepoint_7 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480_5} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_7) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_6 as %arg7: !stream.resource<transient>{%c1363476480_5}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0_1 for %c1342177280] : !stream.resource<transient>{%c1363476480_5}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0_1 for %c1342177280] : !stream.resource<transient>{%c1363476480_5},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280_3 for %c327680] : !stream.resource<transient>{%c1363476480_5},
      wo %arg7[%c1342504960_4 for %c20971520] : !stream.resource<transient>{%c1363476480_5}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960_4 for %c20971520] : !stream.resource<transient>{%c1363476480_5},
      ro %arg7[%c1342177280_3 for %c327680] : !stream.resource<transient>{%c1363476480_5},
      wo %arg6[%c0_0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_6 : !stream.resource<transient>{%c1363476480_5} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubrangesPass (iree-util-propagate-subranges) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After AutomaticReferenceCountingPass (iree-stream-automatic-reference-counting) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateConstantTransientSizePass (iree-stream-annotate-constant-transient-size) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmdPass (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ReuseAllocationsPass (iree-stream-reuse-allocations) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
  %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
  %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.join max(%5, %4) => !stream.timepoint
    %7 = stream.timepoint.await %6 => %result : !stream.resource<external>{%c10485760}
    %8 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %7 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.immediate => !stream.timepoint
    %7 = stream.timepoint.join max(%5, %6) => !stream.timepoint
    %8 = stream.timepoint.await %7 => %result : !stream.resource<external>{%c10485760}
    %9 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %8 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c20971520 = arith.constant 20971520 : index
  %c327680 = arith.constant 327680 : index
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
      ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 1 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 1 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 1 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {iree.fixedpoint.iteration = 1 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1342177280] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c1342504960 for %c20971520] : !stream.resource<transient>{%c1363476480},
        ro %arg7[%c1342177280 for %c327680] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindingsPass (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding, %arg4: index, %arg5: index, %arg6: index, %arg7: index) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%arg5] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%arg6] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%arg7] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg8: f32, %arg9: f16, %arg10: f32, %arg11: f32, %arg12: f32):
          %12 = arith.addf %arg8, %arg11 : f32
          %13 = arith.truncf %arg8 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg9 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg12 : f32
          iree_linalg_ext.yield %arg10, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %c0_2 = arith.constant 0 : index
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0, %c0, %c0 : index, index, index) {
        ro %arg3[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0, %c0, %c1342177280, %c1342504960 : index, index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960, %c1342177280, %c0 : index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArgumentsPass (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}) {
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst_0 : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}, %arg6: index {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]}, %arg7: index {stream.alignment = 65536 : index, stream.values = [1342504960 : index]}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%arg5] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%arg6] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%arg7] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg8: f32, %arg9: f16, %arg10: f32, %arg11: f32, %arg12: f32):
          %12 = arith.addf %arg8, %arg11 : f32
          %13 = arith.truncf %arg8 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg9 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg12 : f32
          iree_linalg_ext.yield %arg10, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: index {stream.alignment = 65536 : index, stream.values = [1342504960 : index]}, %arg3: index {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]}, %arg4: index {stream.values = [0 : index]}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %c0_2 = arith.constant 0 : index
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0, %c0, %c0 : index, index, index) {
        ro %arg3[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0, %c0, %c1342177280, %c1342504960 : index, index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960, %c1342177280, %c0 : index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchAssumptionsPass (iree-stream-annotate-dispatch-assumptions) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}) {
        %0:3 = util.assume.int
            %arg3<umin = 0, umax = 0>,
            %arg4<umin = 0, umax = 0>,
            %arg5<umin = 0, umax = 0>
          : index, index, index
        %cst = arith.constant 1.250000e-01 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %1 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg1[%0#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %3 = stream.binding.subspan %arg2[%0#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = iree_tensor_ext.dispatch.tensor.load %2, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x4096xf32>
        %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%4, %5 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%7 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %10 = arith.extf %in : f16 to f32
          %11 = arith.extf %in_1 : f16 to f32
          %12 = arith.mulf %10, %11 : f32
          %13 = arith.addf %12, %out : f32
          linalg.yield %13 : f32
        } -> tensor<20x4096x4096xf32>
        %9 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<20x4096x4096xf32>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %10 = arith.mulf %in, %cst : f32
          linalg.yield %10 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %9, %3, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}, %arg6: index {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]}, %arg7: index {stream.alignment = 65536 : index, stream.values = [1342504960 : index]}) {
        %0:4 = util.assume.int
            %arg4<umin = 0, umax = 0>,
            %arg5<umin = 0, umax = 0>,
            %arg6<umin = 1342177280, umax = 1342177280, udiv = 1342177280>,
            %arg7<umin = 1342504960, umax = 1342504960, udiv = 1342504960>
          : index, index, index, index
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %1 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %2 = stream.binding.subspan %arg1[%0#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %3 = stream.binding.subspan %arg2[%0#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %4 = stream.binding.subspan %arg3[%0#3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %6 = iree_tensor_ext.dispatch.tensor.load %2, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %7 = tensor.empty() : tensor<20x4096x64xf32>
        %8 = tensor.empty() : tensor<20x4096xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11 = linalg.fill ins(%cst : f32) outs(%8 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %12:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%5, %6 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%10, %11, %9 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg8: f32, %arg9: f16, %arg10: f32, %arg11: f32, %arg12: f32):
          %13 = arith.addf %arg8, %arg11 : f32
          %14 = arith.truncf %arg8 : f32 to f16
          %15 = arith.extf %14 : f16 to f32
          %16 = arith.extf %arg9 : f16 to f32
          %17 = arith.mulf %15, %16 : f32
          %18 = arith.addf %17, %arg12 : f32
          iree_linalg_ext.yield %arg10, %13, %18 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %12#1, %3, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %12#2, %4, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: index {stream.alignment = 65536 : index, stream.values = [1342504960 : index]}, %arg3: index {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]}, %arg4: index {stream.values = [0 : index]}) {
        %0:3 = util.assume.int
            %arg2<umin = 1342504960, umax = 1342504960, udiv = 1342504960>,
            %arg3<umin = 1342177280, umax = 1342177280, udiv = 1342177280>,
            %arg4<umin = 0, umax = 0>
          : index, index, index
        %c0 = arith.constant 0 : index
        %1 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %2 = stream.binding.subspan %arg0[%0#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %3 = stream.binding.subspan %arg1[%0#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %2, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %6 = tensor.empty() : tensor<81920x64xf16>
        %7 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%4, %5 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%6 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %8 = arith.divf %in, %in_0 : f32
          %9 = arith.truncf %8 : f32 to f16
          linalg.yield %9 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %c0_2 = arith.constant 0 : index
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0, %c0, %c0 : index, index, index) {
        ro %arg3[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0, %c0, %c1342177280, %c1342504960 : index, index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960, %c1342177280, %c0 : index, index, index) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperandsPass (iree-stream-pack-dispatch-operands) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int
            %4<umin = 0, umax = 0>,
            %9<umin = 0, umax = 0>,
            %14<umin = 0, umax = 0>
          : index, index, index
        %cst = arith.constant 1.250000e-01 : f32
        %cst_2 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %19 = iree_tensor_ext.dispatch.tensor.load %16, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %20 = iree_tensor_ext.dispatch.tensor.load %17, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %21 = tensor.empty() : tensor<20x4096x4096xf32>
        %22 = linalg.fill ins(%cst_2 : f32) outs(%21 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %23 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%19, %20 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%22 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_3: f16, %out: f32):
          %25 = arith.extf %in : f16 to f32
          %26 = arith.extf %in_3 : f16 to f32
          %27 = arith.mulf %25, %26 : f32
          %28 = arith.addf %27, %out : f32
          linalg.yield %28 : f32
        } -> tensor<20x4096x4096xf32>
        %24 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%23 : tensor<20x4096x4096xf32>) outs(%21 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %25 = arith.mulf %in, %cst : f32
          linalg.yield %25 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %24, %18, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg5 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg4 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg7 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg6 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg9 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg8 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]} : i64 to index
        %c32_i64_2 = arith.constant 32 : i64
        %15 = arith.extui %arg11 : i32 to i64
        %16 = arith.shli %15, %c32_i64_2 : i64
        %17 = arith.extui %arg10 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 {stream.alignment = 65536 : index, stream.values = [1342504960 : index]} : i64 to index
        %20:4 = util.assume.int
            %4<umin = 0, umax = 0>,
            %9<umin = 0, umax = 0>,
            %14<umin = 1342177280, umax = 1342177280, udiv = 1342177280>,
            %19<umin = 1342504960, umax = 1342504960, udiv = 1342504960>
          : index, index, index, index
        %cst = arith.constant 0.000000e+00 : f32
        %cst_3 = arith.constant -3.40282347E+38 : f32
        %c0 = arith.constant 0 : index
        %21 = stream.binding.subspan %arg0[%20#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %22 = stream.binding.subspan %arg1[%20#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %23 = stream.binding.subspan %arg2[%20#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %24 = stream.binding.subspan %arg3[%20#3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %25 = iree_tensor_ext.dispatch.tensor.load %21, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %26 = iree_tensor_ext.dispatch.tensor.load %22, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %27 = tensor.empty() : tensor<20x4096x64xf32>
        %28 = tensor.empty() : tensor<20x4096xf32>
        %29 = linalg.fill ins(%cst : f32) outs(%27 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %30 = linalg.fill ins(%cst_3 : f32) outs(%28 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %31 = linalg.fill ins(%cst : f32) outs(%28 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %32:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%25, %26 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%30, %31, %29 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg12: f32, %arg13: f16, %arg14: f32, %arg15: f32, %arg16: f32):
          %33 = arith.addf %arg12, %arg15 : f32
          %34 = arith.truncf %arg12 : f32 to f16
          %35 = arith.extf %34 : f16 to f32
          %36 = arith.extf %arg13 : f16 to f32
          %37 = arith.mulf %35, %36 : f32
          %38 = arith.addf %37, %arg16 : f32
          iree_linalg_ext.yield %arg14, %33, %38 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %32#1, %23, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %32#2, %24, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg2 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.alignment = 65536 : index, stream.values = [1342504960 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg4 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.alignment = 268435456 : index, stream.values = [1342177280 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg6 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int
            %4<umin = 1342504960, umax = 1342504960, udiv = 1342504960>,
            %9<umin = 1342177280, umax = 1342177280, udiv = 1342177280>,
            %14<umin = 0, umax = 0>
          : index, index, index
        %c0 = arith.constant 0 : index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %17 = stream.binding.subspan %arg0[%15#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %18 = stream.binding.subspan %arg1[%15#2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %19 = iree_tensor_ext.dispatch.tensor.load %16, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %20 = iree_tensor_ext.dispatch.tensor.load %17, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %21 = tensor.empty() : tensor<81920x64xf16>
        %22 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%19, %20 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%21 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_2: f32, %out: f16):
          %23 = arith.divf %in, %in_2 : f32
          %24 = arith.truncf %23 : f32 to f16
          linalg.yield %24 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %22, %18, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c20971520 = arith.constant 20971520 : index
    %c327680 = arith.constant 327680 : index
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %c0_2 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c0_i64_5 = arith.constant 0 : i64
    %c0_i32_6 = arith.constant 0 : i32
    %c32_i64_7 = arith.constant 32 : i64
    %c0_i64_8 = arith.constant 0 : i64
    %c0_i32_9 = arith.constant 0 : i32
    %c0_i64_10 = arith.constant 0 : i64
    %c0_i32_11 = arith.constant 0 : i32
    %c32_i64_12 = arith.constant 32 : i64
    %c0_i64_13 = arith.constant 0 : i64
    %c0_i32_14 = arith.constant 0 : i32
    %c0_i64_15 = arith.constant 0 : i64
    %c0_i32_16 = arith.constant 0 : i32
    %c32_i64_17 = arith.constant 32 : i64
    %c0_i64_18 = arith.constant 0 : i64
    %c0_i32_19 = arith.constant 0 : i32
    %c0_i64_20 = arith.constant 0 : i64
    %c0_i32_21 = arith.constant 0 : i32
    %c32_i64_22 = arith.constant 32 : i64
    %c0_i64_23 = arith.constant 0 : i64
    %c0_i32_24 = arith.constant 0 : i32
    %c1342177280_i64 = arith.constant 1342177280 : i64
    %c1342177280_i32 = arith.constant 1342177280 : i32
    %c32_i64_25 = arith.constant 32 : i64
    %c0_i64_26 = arith.constant 0 : i64
    %c0_i32_27 = arith.constant 0 : i32
    %c1342504960_i64 = arith.constant 1342504960 : i64
    %c1342504960_i32 = arith.constant 1342504960 : i32
    %c32_i64_28 = arith.constant 32 : i64
    %c0_i64_29 = arith.constant 0 : i64
    %c0_i32_30 = arith.constant 0 : i32
    %c1342504960_i64_31 = arith.constant 1342504960 : i64
    %c1342504960_i32_32 = arith.constant 1342504960 : i32
    %c32_i64_33 = arith.constant 32 : i64
    %c0_i64_34 = arith.constant 0 : i64
    %c0_i32_35 = arith.constant 0 : i32
    %c1342177280_i64_36 = arith.constant 1342177280 : i64
    %c1342177280_i32_37 = arith.constant 1342177280 : i32
    %c32_i64_38 = arith.constant 32 : i64
    %c0_i64_39 = arith.constant 0 : i64
    %c0_i32_40 = arith.constant 0 : i32
    %c0_i64_41 = arith.constant 0 : i64
    %c0_i32_42 = arith.constant 0 : i32
    %c32_i64_43 = arith.constant 32 : i64
    %c0_i64_44 = arith.constant 0 : i64
    %c0_i32_45 = arith.constant 0 : i32
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32_4, %c0_i32_6, %c0_i32_9, %c0_i32_11, %c0_i32_14 : i32, i32, i32, i32, i32, i32) {
        ro %arg3[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32_16, %c0_i32_19, %c0_i32_21, %c0_i32_24, %c1342177280_i32, %c0_i32_27, %c1342504960_i32, %c0_i32_30 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32_32, %c0_i32_35, %c1342177280_i32_37, %c0_i32_40, %c0_i32_42, %c0_i32_45 : i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0_2 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0_2 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1342504960_i32 = arith.constant 1342504960 : i32
  %c1342177280_i32 = arith.constant 1342177280 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1342504960_i32 = arith.constant 1342504960 : i32
  %c1342177280_i32 = arith.constant 1342177280 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1342504960_i32 = arith.constant 1342504960 : i32
  %c1342177280_i32 = arith.constant 1342177280 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1342504960_i32 = arith.constant 1342504960 : i32
  %c1342177280_i32 = arith.constant 1342177280 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1342504960_i32 = arith.constant 1342504960 : i32
  %c1342177280_i32 = arith.constant 1342177280 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg12: f32, %arg13: f16, %arg14: f32, %arg15: f32, %arg16: f32):
          %12 = arith.addf %arg12, %arg15 : f32
          %13 = arith.truncf %arg12 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg13 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg16 : f32
          iree_linalg_ext.yield %arg14, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1342504960_i32 = arith.constant 1342504960 : i32
    %c1342177280_i32 = arith.constant 1342177280 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg12: f32, %arg13: f16, %arg14: f32, %arg15: f32, %arg16: f32):
          %12 = arith.addf %arg12, %arg15 : f32
          %13 = arith.truncf %arg12 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg13 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg16 : f32
          iree_linalg_ext.yield %arg14, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1342504960_i32 = arith.constant 1342504960 : i32
    %c1342177280_i32 = arith.constant 1342177280 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg12: f32, %arg13: f16, %arg14: f32, %arg15: f32, %arg16: f32):
          %12 = arith.addf %arg12, %arg15 : f32
          %13 = arith.truncf %arg12 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg13 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg16 : f32
          iree_linalg_ext.yield %arg14, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1342504960_i32 = arith.constant 1342504960 : i32
    %c1342177280_i32 = arith.constant 1342177280 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c1342504960_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%c1342504960_i32, %c0_i32, %c1342177280_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperandsPass (iree-stream-fold-uniform-operands) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %c1342177280_i32 = arith.constant 1342177280 : i32
        %c1342504960_i32 = arith.constant 1342504960 : i32
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960_i32 = arith.constant 1342504960 : i32
        %c0_i32 = arith.constant 0 : i32
        %c1342177280_i32 = arith.constant 1342177280 : i32
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1342504960_i32 = arith.constant 1342504960 : i32
    %c1342177280_i32 = arith.constant 1342177280 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AttributeCallGraphPass (iree-util-attribute-call-graph) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignLegacyTargetDevicesPass (iree-hal-assign-legacy-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
  %c1363476480 = arith.constant 1363476480 : index
  %c0 = arith.constant 0 : index
  %c10485760 = arith.constant 10485760 : index
  %c64 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c20 = arith.constant 20 : index
  %element_type_f16 = hal.element_type<f16> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
  %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
  %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
  %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
    stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
      ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
    }
    stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
      ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
      wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
    }
  } => !stream.timepoint
  %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
  %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
  util.return %7 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  stream.executable private @attention_dispatch_0 {
    stream.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_1 {
    stream.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -3.40282347E+38 : f32
        %cst_0 = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c1342504960 = arith.constant 1342504960 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = stream.binding.subspan %arg2[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        %3 = stream.binding.subspan %arg3[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
        %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %6 = tensor.empty() : tensor<20x4096x64xf32>
        %7 = tensor.empty() : tensor<20x4096xf32>
        %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
        %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
        %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
        ^bb0(%arg4: f32, %arg5: f16, %arg6: f32, %arg7: f32, %arg8: f32):
          %12 = arith.addf %arg4, %arg7 : f32
          %13 = arith.truncf %arg4 : f32 to f16
          %14 = arith.extf %13 : f16 to f32
          %15 = arith.extf %arg5 : f16 to f32
          %16 = arith.mulf %14, %15 : f32
          %17 = arith.addf %16, %arg8 : f32
          iree_linalg_ext.yield %arg6, %12, %17 : f32, f32, f32
        } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
        iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
        iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
        return
      }
    }
  }
  stream.executable private @attention_dispatch_2 {
    stream.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c1342504960] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = stream.binding.subspan %arg0[%c1342177280] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#pipeline_layout1 = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#pipeline_layout2 = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  hal.executable private @attention_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#pipeline_layout) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
          %cst = arith.constant 0.000000e+00 : f32
          %cst_0 = arith.constant 1.250000e-01 : f32
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
          %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %5 = tensor.empty() : tensor<20x4096x4096xf32>
          %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
          %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
          ^bb0(%in: f16, %in_1: f16, %out: f32):
            %9 = arith.extf %in : f16 to f32
            %10 = arith.extf %in_1 : f16 to f32
            %11 = arith.mulf %9, %10 : f32
            %12 = arith.addf %11, %out : f32
            linalg.yield %12 : f32
          } -> tensor<20x4096x4096xf32>
          %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
          ^bb0(%in: f32, %out: f32):
            %9 = arith.mulf %in, %cst_0 : f32
            linalg.yield %9 : f32
          } -> tensor<20x4096x4096xf32>
          iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
          return
        }
      }
    }
  }
  hal.executable private @attention_dispatch_1 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 ordinal(0) layout(#pipeline_layout1) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
          %cst = arith.constant -3.40282347E+38 : f32
          %cst_0 = arith.constant 0.000000e+00 : f32
          %c0 = arith.constant 0 : index
          %c1342177280 = arith.constant 1342177280 : index
          %c1342504960 = arith.constant 1342504960 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
          %3 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
          %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
          %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %6 = tensor.empty() : tensor<20x4096x64xf32>
          %7 = tensor.empty() : tensor<20x4096xf32>
          %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
          %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
          %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
          %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
          ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
            %12 = arith.addf %arg0, %arg3 : f32
            %13 = arith.truncf %arg0 : f32 to f16
            %14 = arith.extf %13 : f16 to f32
            %15 = arith.extf %arg1 : f16 to f32
            %16 = arith.mulf %14, %15 : f32
            %17 = arith.addf %16, %arg4 : f32
            iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
          } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
          iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
          iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
          return
        }
      }
    }
  }
  hal.executable private @attention_dispatch_2 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#pipeline_layout2) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
          %c1342504960 = arith.constant 1342504960 : index
          %c1342177280 = arith.constant 1342177280 : index
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
          %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
          %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
          %5 = tensor.empty() : tensor<81920x64xf16>
          %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
          ^bb0(%in: f32, %in_0: f32, %out: f16):
            %7 = arith.divf %in, %in_0 : f32
            %8 = arith.truncf %7 : f32 to f16
            linalg.yield %8 : f16
          } -> tensor<81920x64xf16>
          iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
          return
        }
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@embedded_elf_x86_64::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@embedded_elf_x86_64::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@embedded_elf_x86_64::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>
#map5 = affine_map<(d0, d1, d2, d3) -> (d0, d1)>
#map6 = affine_map<(d0, d1) -> (d0, d1)>
#map7 = affine_map<(d0, d1) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#pipeline_layout1 = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#pipeline_layout2 = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  hal.executable private @attention_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#pipeline_layout) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
          %cst = arith.constant 0.000000e+00 : f32
          %cst_0 = arith.constant 1.250000e-01 : f32
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
          %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %5 = tensor.empty() : tensor<20x4096x4096xf32>
          %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
          %7 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
          ^bb0(%in: f16, %in_1: f16, %out: f32):
            %9 = arith.extf %in : f16 to f32
            %10 = arith.extf %in_1 : f16 to f32
            %11 = arith.mulf %9, %10 : f32
            %12 = arith.addf %11, %out : f32
            linalg.yield %12 : f32
          } -> tensor<20x4096x4096xf32>
          %8 = linalg.generic {indexing_maps = [#map3, #map3], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
          ^bb0(%in: f32, %out: f32):
            %9 = arith.mulf %in, %cst_0 : f32
            linalg.yield %9 : f32
          } -> tensor<20x4096x4096xf32>
          iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
          return
        }
      }
    }
  }
  hal.executable private @attention_dispatch_1 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 ordinal(0) layout(#pipeline_layout1) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
          %cst = arith.constant -3.40282347E+38 : f32
          %cst_0 = arith.constant 0.000000e+00 : f32
          %c0 = arith.constant 0 : index
          %c1342177280 = arith.constant 1342177280 : index
          %c1342504960 = arith.constant 1342504960 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
          %3 = hal.interface.binding.subspan layout(#pipeline_layout1) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
          %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
          %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
          %6 = tensor.empty() : tensor<20x4096x64xf32>
          %7 = tensor.empty() : tensor<20x4096xf32>
          %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
          %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
          %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
          %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [#map, #map4, #map5, #map5, #map2], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
          ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
            %12 = arith.addf %arg0, %arg3 : f32
            %13 = arith.truncf %arg0 : f32 to f16
            %14 = arith.extf %13 : f16 to f32
            %15 = arith.extf %arg1 : f16 to f32
            %16 = arith.mulf %14, %15 : f32
            %17 = arith.addf %16, %arg4 : f32
            iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
          } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
          iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
          iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
          return
        }
      }
    }
  }
  hal.executable private @attention_dispatch_2 {
    hal.executable.variant public @embedded_elf_x86_64 target(#executable_target_embedded_elf_x86_64) {
      hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#pipeline_layout2) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
          %c1342504960 = arith.constant 1342504960 : index
          %c1342177280 = arith.constant 1342177280 : index
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
          %2 = hal.interface.binding.subspan layout(#pipeline_layout2) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
          %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
          %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
          %5 = tensor.empty() : tensor<81920x64xf16>
          %6 = linalg.generic {indexing_maps = [#map6, #map7, #map6], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
          ^bb0(%in: f32, %in_0: f32, %out: f16):
            %7 = arith.divf %in, %in_0 : f32
            %8 = arith.truncf %7 : f32 to f16
            linalg.yield %8 : f16
          } -> tensor<81920x64xf16>
          iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
          return
        }
      }
    }
  }
  util.func public @attention(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @attention(%input0: tensor<20x4096x64xf16>, %input1: tensor<20x4096x64xf16>, %input2: tensor<20x4096x64xf16>) -> (%output0: tensor<20x4096x64xf16>)"}} {
    %c1363476480 = arith.constant 1363476480 : index
    %c0 = arith.constant 0 : index
    %c10485760 = arith.constant 10485760 : index
    %c64 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c20 = arith.constant 20 : index
    %element_type_f16 = hal.element_type<f16> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg1 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("input2") shape([%c20, %c4096, %c64]) type(%element_type_f16) encoding(%dense_row_major)
    %2 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg2 : !hal.buffer_view -> tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c10485760} => !stream.timepoint
    %result_0, %result_timepoint_1 = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %3 = stream.timepoint.join max(%result_timepoint, %result_timepoint_1) => !stream.timepoint
    %4 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%3) => with(%0 as %arg3: !stream.resource<external>{%c10485760}, %1 as %arg4: !stream.resource<external>{%c10485760}, %2 as %arg5: !stream.resource<external>{%c10485760}, %result as %arg6: !stream.resource<external>{%c10485760}, %result_0 as %arg7: !stream.resource<transient>{%c1363476480}) {
      stream.cmd.dispatch @attention_dispatch_0::@embedded_elf_x86_64::@attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 {
        ro %arg3[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        ro %arg4[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_1::@embedded_elf_x86_64::@attention_dispatch_1_exp_reduction_20x4096x4096xf32 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        ro %arg5[%c0 for %c10485760] : !stream.resource<external>{%c10485760},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480}
      }
      stream.cmd.dispatch @attention_dispatch_2::@embedded_elf_x86_64::@attention_dispatch_2_elementwise_81920x64_f32xf32xf16 {
        ro %arg7[%c0 for %c1363476480] : !stream.resource<transient>{%c1363476480},
        wo %arg6[%c0 for %c10485760] : !stream.resource<external>{%c10485760}
      }
    } => !stream.timepoint
    %5 = stream.resource.dealloca on(#hal.device.affinity<@__device_0>) await(%4) => %result_0 : !stream.resource<transient>{%c1363476480} => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c10485760}
    %7 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %6 : tensor<20x4096x64xf16> in !stream.resource<external>{%c10485760} -> !hal.buffer_view
    util.return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After SpecializeExportsPass (iree-codegen-specialize-exports) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %5 = tensor.empty() : tensor<81920x64xf16>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %7 = arith.divf %in, %in_0 : f32
        %8 = arith.truncf %7 : f32 to f16
        linalg.yield %8 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      return
    }
  }
}

// -----// IR Dump After SpecializeExportsPass (iree-codegen-specialize-exports) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_1_exp_reduction_20x4096x4096xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c1342504960 = arith.constant 1342504960 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
      %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %6 = tensor.empty() : tensor<20x4096x64xf32>
      %7 = tensor.empty() : tensor<20x4096xf32>
      %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
      %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
      %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
      ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
        %12 = arith.addf %arg0, %arg3 : f32
        %13 = arith.truncf %arg0 : f32 to f16
        %14 = arith.extf %13 : f16 to f32
        %15 = arith.extf %arg1 : f16 to f32
        %16 = arith.mulf %14, %15 : f32
        %17 = arith.addf %16, %arg4 : f32
        iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
      } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
      iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
      iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
      return
    }
  }
}

// -----// IR Dump After SpecializeExportsPass (iree-codegen-specialize-exports) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %5 = tensor.empty() : tensor<20x4096x4096xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %9 = arith.extf %in : f16 to f32
        %10 = arith.extf %in_1 : f16 to f32
        %11 = arith.mulf %9, %10 : f32
        %12 = arith.addf %11, %out : f32
        linalg.yield %12 : f32
      } -> tensor<20x4096x4096xf32>
      %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
      ^bb0(%in: f32, %out: f32):
        %9 = arith.mulf %in, %cst_0 : f32
        linalg.yield %9 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      return
    }
  }
}

// -----// IR Dump After TypePropagationPass (iree-codegen-type-propagation) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After TypePropagationPass (iree-codegen-type-propagation) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After TypePropagationPass (iree-codegen-type-propagation) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After BubbleUpOrdinalOpsPass (iree-codegen-bubble-up-ordinal-ops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After BubbleUpOrdinalOpsPass (iree-codegen-bubble-up-ordinal-ops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After BubbleUpOrdinalOpsPass (iree-codegen-bubble-up-ordinal-ops) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After DecomposeSoftmaxPass (iree-codegen-decompose-softmax) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After DecomposeSoftmaxPass (iree-codegen-decompose-softmax) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After DecomposeSoftmaxPass (iree-codegen-decompose-softmax) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After MaterializeUserConfigsPass (iree-codegen-materialize-user-configs) //----- //
module {
  func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
    %c1342504960 = arith.constant 1342504960 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %5 = tensor.empty() : tensor<81920x64xf16>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %7 = arith.divf %in, %in_0 : f32
      %8 = arith.truncf %7 : f32 to f16
      linalg.yield %8 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    return
  }
}

// -----// IR Dump After MaterializeUserConfigsPass (iree-codegen-materialize-user-configs) //----- //
module {
  func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %5 = tensor.empty() : tensor<20x4096x4096xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %9 = arith.extf %in : f16 to f32
      %10 = arith.extf %in_1 : f16 to f32
      %11 = arith.mulf %9, %10 : f32
      %12 = arith.addf %11, %out : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.mulf %in, %cst_0 : f32
      linalg.yield %9 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    return
  }
}

// -----// IR Dump After MaterializeUserConfigsPass (iree-codegen-materialize-user-configs) //----- //
module {
  func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
    %cst = arith.constant -3.40282347E+38 : f32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c1342504960 = arith.constant 1342504960 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
    %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %6 = tensor.empty() : tensor<20x4096x64xf32>
    %7 = tensor.empty() : tensor<20x4096xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
    %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
    %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
    ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
      %12 = arith.addf %arg0, %arg3 : f32
      %13 = arith.truncf %arg0 : f32 to f16
      %14 = arith.extf %13 : f16 to f32
      %15 = arith.extf %arg1 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %arg4 : f32
      iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
    } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
    iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
    iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
    return
  }
}

// -----// IR Dump After MaterializeDeviceEncodingPass (iree-codegen-materialize-device-encoding) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After MaterializeDeviceEncodingPass (iree-codegen-materialize-device-encoding) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After MaterializeDeviceEncodingPass (iree-codegen-materialize-device-encoding) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After CPUPropagateDataLayoutPass (iree-codegen-cpu-propagate-data-layout) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After CPUPropagateDataLayoutPass (iree-codegen-cpu-propagate-data-layout) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After CPUPropagateDataLayoutPass (iree-codegen-cpu-propagate-data-layout) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After RematerializeParallelOpsPass (iree-codegen-rematerialize-parallel-ops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After RematerializeParallelOpsPass (iree-codegen-rematerialize-parallel-ops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After RematerializeParallelOpsPass (iree-codegen-rematerialize-parallel-ops) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After ExpandF16OpToF32Pass (iree-llvmcpu-expand-f16-op-to-f32) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After ExpandF16OpToF32Pass (iree-llvmcpu-expand-f16-op-to-f32) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After ExpandF16OpToF32Pass (iree-llvmcpu-expand-f16-op-to-f32) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After ConvertAccGEMMToGEMMPass (iree-convert-accgemm-to-gemm) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After ConvertAccGEMMToGEMMPass (iree-convert-accgemm-to-gemm) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After ConvertAccGEMMToGEMMPass (iree-convert-accgemm-to-gemm) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRefPass (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) {
  ^bb0(%in: f32, %in_0: f32, %out: f16):
    %7 = arith.divf %in, %in_0 : f32
    %8 = arith.truncf %7 : f32 to f16
    linalg.yield %8 : f16
  } -> tensor<81920x64xf16>
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRefPass (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f16, %in_1: f16, %out: f32):
    %9 = arith.extf %in : f16 to f32
    %10 = arith.extf %in_1 : f16 to f32
    %11 = arith.mulf %9, %10 : f32
    %12 = arith.addf %11, %out : f32
    linalg.yield %12 : f32
  } -> tensor<20x4096x4096xf32>
  %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) {
  ^bb0(%in: f32, %out: f32):
    %9 = arith.mulf %in, %cst_0 : f32
    linalg.yield %9 : f32
  } -> tensor<20x4096x4096xf32>
  iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRefPass (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @attention_dispatch_1_exp_reduction_20x4096x4096xf32() {
  %cst = arith.constant -3.40282347E+38 : f32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c1342504960 = arith.constant 1342504960 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c1342177280) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(3) alignment(64) offset(%c1342504960) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  %4 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x4096xf32>> -> tensor<20x4096x4096xf32>
  %5 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x64xf32>
  %7 = tensor.empty() : tensor<20x4096xf32>
  %8 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<20x4096x64xf32>) -> tensor<20x4096x64xf32>
  %9 = linalg.fill ins(%cst : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %10 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<20x4096xf32>) -> tensor<20x4096xf32>
  %11:3 = iree_linalg_ext.exp_reduction{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d3, d2)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = [#iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<parallel>, #iree_linalg_ext.iterator_type<reduction>], exp_reduced_operands = [1, 2]} ins(%4, %5 : tensor<20x4096x4096xf32>, tensor<20x4096x64xf16>) outs(%9, %10, %8 : tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>) {
  ^bb0(%arg0: f32, %arg1: f16, %arg2: f32, %arg3: f32, %arg4: f32):
    %12 = arith.addf %arg0, %arg3 : f32
    %13 = arith.truncf %arg0 : f32 to f16
    %14 = arith.extf %13 : f16 to f32
    %15 = arith.extf %arg1 : f16 to f32
    %16 = arith.mulf %14, %15 : f32
    %17 = arith.addf %16, %arg4 : f32
    iree_linalg_ext.yield %arg2, %12, %17 : f32, f32, f32
  } -> tensor<20x4096xf32>, tensor<20x4096xf32>, tensor<20x4096x64xf32>
  iree_tensor_ext.dispatch.tensor.store %11#1, %2, offsets = [0, 0], sizes = [20, 4096], strides = [1, 1] : tensor<20x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096xf32>>
  iree_tensor_ext.dispatch.tensor.store %11#2, %3, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : tensor<20x4096x64xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x64xf32>>
  return
}

Please report issues to https://github.com/iree-org/iree/issues and include the crash backtrace.
// -----// IR Dump After LLVMCPUSelectLoweringStrategyPass (iree-llvmcpu-select-lowering-strategy) //----- //
module {
  func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
    %c1342504960 = arith.constant 1342504960 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %5 = tensor.empty() : tensor<81920x64xf16>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %7 = arith.divf %in, %in_0 : f32
      %8 = arith.truncf %7 : f32 to f16
      linalg.yield %8 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    return
  }
}

// -----// IR Dump After LLVMCPUSelectLoweringStrategyPass (iree-llvmcpu-select-lowering-strategy) //----- //
module {
  func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %5 = tensor.empty() : tensor<20x4096x4096xf32>
    %6 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %9 = arith.extf %in : f16 to f32
      %10 = arith.extf %in_1 : f16 to f32
      %11 = arith.mulf %9, %10 : f32
      %12 = arith.addf %11, %out : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.mulf %in, %cst_0 : f32
      linalg.yield %9 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    return
  }
}

// -----// IR Dump After ConfigureTargetExecutableVariantsPass (iree-hal-configure-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
      %5 = tensor.empty() : tensor<81920x64xf16>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_0: f32, %out: f16):
        %7 = arith.divf %in, %in_0 : f32
        %8 = arith.truncf %7 : f32 to f16
        linalg.yield %8 : f16
      } -> tensor<81920x64xf16>
      iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
      return
    }
  }
}

// -----// IR Dump After ConfigureTargetExecutableVariantsPass (iree-hal-configure-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
      %cst = arith.constant 0.000000e+00 : f32
      %cst_0 = arith.constant 1.250000e-01 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
      %5 = tensor.empty() : tensor<20x4096x4096xf32>
      %6 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
      %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
      ^bb0(%in: f16, %in_1: f16, %out: f32):
        %9 = arith.extf %in : f16 to f32
        %10 = arith.extf %in_1 : f16 to f32
        %11 = arith.mulf %9, %10 : f32
        %12 = arith.addf %11, %out : f32
        linalg.yield %12 : f32
      } -> tensor<20x4096x4096xf32>
      %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %9 = arith.mulf %in, %cst_0 : f32
        linalg.yield %9 : f32
      } -> tensor<20x4096x4096xf32>
      iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
      return
    }
  }
}

// -----// IR Dump After ConfigureExecutablesPass (iree-hal-configure-executables) //----- //
hal.executable private @attention_dispatch_2 {
  hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
    hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      hal.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
        %c1342504960 = arith.constant 1342504960 : index
        %c1342177280 = arith.constant 1342177280 : index
        %c0 = arith.constant 0 : index
        %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
        %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
        %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
        %5 = tensor.empty() : tensor<81920x64xf16>
        %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
        ^bb0(%in: f32, %in_0: f32, %out: f16):
          %7 = arith.divf %in, %in_0 : f32
          %8 = arith.truncf %7 : f32 to f16
          linalg.yield %8 : f16
        } -> tensor<81920x64xf16>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
        return
      }
    }
  }
}

// -----// IR Dump After ConfigureExecutablesPass (iree-hal-configure-executables) //----- //
hal.executable private @attention_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
    hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      hal.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
        %cst = arith.constant 0.000000e+00 : f32
        %cst_0 = arith.constant 1.250000e-01 : f32
        %c0 = arith.constant 0 : index
        %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
        %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
        %5 = tensor.empty() : tensor<20x4096x4096xf32>
        %6 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
        %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_1: f16, %out: f32):
          %9 = arith.extf %in : f16 to f32
          %10 = arith.extf %in_1 : f16 to f32
          %11 = arith.mulf %9, %10 : f32
          %12 = arith.addf %11, %out : f32
          linalg.yield %12 : f32
        } -> tensor<20x4096x4096xf32>
        %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
        ^bb0(%in: f32, %out: f32):
          %9 = arith.mulf %in, %cst_0 : f32
          linalg.yield %9 : f32
        } -> tensor<20x4096x4096xf32>
        iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
        return
      }
    }
  }
}

// -----// IR Dump After LowerExecutableUsingTransformDialectPass (iree-codegen-lower-executable-using-transform-dialect) //----- //
module {
  func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant 1.250000e-01 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
    %5 = tensor.empty() : tensor<20x4096x4096xf32>
    %6 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%5 : tensor<20x4096x4096xf32>) -> tensor<20x4096x4096xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%3, %4 : tensor<20x4096x64xf16>, tensor<20x4096x64xf16>) outs(%6 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_1: f16, %out: f32):
      %9 = arith.extf %in : f16 to f32
      %10 = arith.extf %in_1 : f16 to f32
      %11 = arith.mulf %9, %10 : f32
      %12 = arith.addf %11, %out : f32
      linalg.yield %12 : f32
    } -> tensor<20x4096x4096xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%7 : tensor<20x4096x4096xf32>) outs(%5 : tensor<20x4096x4096xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.mulf %in, %cst_0 : f32
      linalg.yield %9 : f32
    } -> tensor<20x4096x4096xf32>
    iree_tensor_ext.dispatch.tensor.store %8, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
    return
  }
}

// -----// IR Dump After LowerExecutableUsingTransformDialectPass (iree-codegen-lower-executable-using-transform-dialect) //----- //
module {
  func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
    %c1342504960 = arith.constant 1342504960 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
    %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
    %5 = tensor.empty() : tensor<81920x64xf16>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %4 : tensor<81920x64xf32>, tensor<81920xf32>) outs(%5 : tensor<81920x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f16):
      %7 = arith.divf %in, %in_0 : f32
      %8 = arith.truncf %7 : f32 to f16
      linalg.yield %8 : f16
    } -> tensor<81920x64xf16>
    iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
    return
  }
}

// -----// IR Dump After TileAndDistributeToWorkgroupsUsingForallOpPass (iree-codegen-tile-and-distribute-to-workgroups-using-forall-op) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>> -> tensor<81920x64xf32>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0], sizes = [81920], strides = [1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [81920, 64], strides = [1, 1] : tensor<81920x64xf16> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  return
}

// -----// IR Dump After BufferizeDispatchTensorLoadStorePass (iree-codegen-bufferize-dispatch-tensor-load-store) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920x64xf32>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<81920xf32>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<81920x64xf16>>
  %6 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %7 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %8 = tensor.empty() : tensor<81920x64xf16>
  %9 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %8) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %6[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %7[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %11 = arith.divf %in, %in_2 : f32
      %12 = arith.truncf %11 : f32 to f16
      linalg.yield %12 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After TileAndDistributeToWorkgroupsUsingForallOpPass (iree-codegen-tile-and-distribute-to-workgroups-using-forall-op) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %3 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %4 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0, 0], sizes = [20, 4096, 64], strides = [1, 1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0, 0, 0], sizes = [20, 4096, 4096], strides = [1, 1, 1] : tensor<20x4096x4096xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  return
}

// -----// IR Dump After CombineLayoutTransformationPass (iree-codegen-combine-layout-transformation) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After BufferizeDispatchTensorLoadStorePass (iree-codegen-bufferize-dispatch-tensor-load-store) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<20x4096x64xf16>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<20x4096x4096xf32>>
  %6 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %7 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %8 = tensor.empty() : tensor<20x4096x4096xf32>
  %9 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %8) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %6[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %7[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %10 = tensor.empty() : tensor<4x64x64xf32>
    %11 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%10 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%11 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %14 = arith.extf %in : f16 to f32
      %15 = arith.extf %in_3 : f16 to f32
      %16 = arith.mulf %14, %15 : f32
      %17 = arith.addf %16, %out : f32
      linalg.yield %17 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %14 = arith.mulf %in, %cst_0 : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %13 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %9, %4 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CombineLayoutTransformationPass (iree-codegen-combine-layout-transformation) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf32> to tensor<64x64xf32>
    %extracted_slice_0 = tensor.extract_slice %4[%arg0] [64] [1] : tensor<81920xf32> to tensor<64xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice, %extracted_slice_0 : tensor<64x64xf32>, tensor<64xf32>) outs(%extracted_slice_1 : tensor<64x64xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
    ^bb0(%in: f32, %in_2: f32, %out: f16):
      %8 = arith.divf %in, %in_2 : f32
      %9 = arith.truncf %8 : f32 to f16
      linalg.yield %9 : f16
    } -> tensor<64x64xf16>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice, %extracted_slice_1 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice_2 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %extracted_slice_1 = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_2 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %extracted_slice_1 = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_2 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %extracted_slice_1 = tensor.extract_slice %3[%arg0, %arg1, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %extracted_slice_2 = tensor.extract_slice %4[%arg0, %arg2, 0] [4, 64, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<4x64x64xf16>
    %7 = tensor.empty() : tensor<4x64x64xf32>
    %8 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%7 : tensor<4x64x64xf32>) -> tensor<4x64x64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<4x64x64xf16>, tensor<4x64x64xf16>) outs(%8 : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
    ^bb0(%in: f16, %in_3: f16, %out: f32):
      %11 = arith.extf %in : f16 to f32
      %12 = arith.extf %in_3 : f16 to f32
      %13 = arith.mulf %11, %12 : f32
      %14 = arith.addf %13, %out : f32
      linalg.yield %14 : f32
    } -> tensor<4x64x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%9 : tensor<4x64x64xf32>) outs(%extracted_slice : tensor<4x64x64xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
    ^bb0(%in: f32, %out: f32):
      %11 = arith.mulf %in, %cst_0 : f32
      linalg.yield %11 : f32
    } -> tensor<4x64x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %10 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
      %extracted_slice_1 = tensor.extract_slice %3[%8, %9, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
      %extracted_slice_2 = tensor.extract_slice %4[%10, %11, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %12 = tensor.empty() : tensor<1x1x1xf32>
      %13 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%12 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<1x1x64xf16>, tensor<1x1x64xf16>) outs(%13 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
      ^bb0(%in: f16, %in_4: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_4 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<1x1x1xf32>
      %extracted_slice_3 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x1x1xf32>) outs(%extracted_slice_3 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %15 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.forall (%arg2, %arg3) = (0, 0) to (64, 64) step (1, 4) shared_outs(%arg4 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_0 = tensor.extract_slice %3[%8, %arg3] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %extracted_slice_1 = tensor.extract_slice %4[%9] [1] [1] : tensor<81920xf32> to tensor<1xf32>
      %extracted_slice_2 = tensor.extract_slice %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
      ^bb0(%in: f32, %in_3: f32, %out: f16):
        %11 = arith.divf %in, %in_3 : f32
        %12 = arith.truncf %11 : f32 to f16
        linalg.yield %12 : f16
      } -> tensor<1x4xf16>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg4[%arg2, %arg3] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
      %extracted_slice_1 = tensor.extract_slice %3[%8, %9, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
      %extracted_slice_2 = tensor.extract_slice %4[%10, %11, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %12 = tensor.empty() : tensor<1x1x1xf32>
      %13 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%12 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<1x1x64xf16>, tensor<1x1x64xf16>) outs(%13 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
      ^bb0(%in: f16, %in_4: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_4 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<1x1x1xf32>
      %extracted_slice_3 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x1x1xf32>) outs(%extracted_slice_3 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %15 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ForallToForPass (iree-codegen-forall-to-for) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %c0_0 = arith.constant 0 : index
    %c0_1 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %c64_2 = arith.constant 64 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %7 = scf.for %arg2 = %c0_0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = scf.for %arg4 = %c0_1 to %c64_2 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_3 = tensor.extract_slice %3[%9, %arg4] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
        %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_4 = tensor.extract_slice %4[%10] [1] [1] : tensor<81920xf32> to tensor<1xf32>
        %extracted_slice_5 = tensor.extract_slice %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
        %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_3, %extracted_slice_4 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_5 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
        ^bb0(%in: f32, %in_6: f32, %out: f16):
          %12 = arith.divf %in, %in_6 : f32
          %13 = arith.truncf %12 : f32 to f16
          linalg.yield %13 : f16
        } -> tensor<1x4xf16>
        %inserted_slice = tensor.insert_slice %11 into %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
        scf.yield %inserted_slice : tensor<64x64xf16>
      }
      scf.yield %8 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
      %extracted_slice_1 = tensor.extract_slice %3[%8, %9, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
      %extracted_slice_2 = tensor.extract_slice %4[%10, %11, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %12 = tensor.empty() : tensor<1x1x1xf32>
      %13 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%12 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<1x1x64xf16>, tensor<1x1x64xf16>) outs(%13 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
      ^bb0(%in: f16, %in_4: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_4 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<1x1x1xf32>
      %extracted_slice_3 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x1x1xf32>) outs(%extracted_slice_3 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %15 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUPeelPass (iree-llvmcpu-peel) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_0 = tensor.extract_slice %3[%9, %arg4] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
        %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_1 = tensor.extract_slice %4[%10] [1] [1] : tensor<81920xf32> to tensor<1xf32>
        %extracted_slice_2 = tensor.extract_slice %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
        %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
        ^bb0(%in: f32, %in_3: f32, %out: f16):
          %12 = arith.divf %in, %in_3 : f32
          %13 = arith.truncf %12 : f32 to f16
          linalg.yield %13 : f16
        } -> tensor<1x4xf16>
        %inserted_slice = tensor.insert_slice %11 into %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
        scf.yield %inserted_slice : tensor<64x64xf16>
      }
      scf.yield %8 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUSplitReductionPass (iree-llvmcpu-split-reduction) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
      %extracted_slice_1 = tensor.extract_slice %3[%8, %9, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
      %extracted_slice_2 = tensor.extract_slice %4[%10, %11, 0] [1, 1, 64] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x64xf16>
      %12 = tensor.empty() : tensor<1x1x1xf32>
      %13 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%12 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_1, %extracted_slice_2 : tensor<1x1x64xf16>, tensor<1x1x64xf16>) outs(%13 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
      ^bb0(%in: f16, %in_4: f16, %out: f32):
        %16 = arith.extf %in : f16 to f32
        %17 = arith.extf %in_4 : f16 to f32
        %18 = arith.mulf %16, %17 : f32
        %19 = arith.addf %18, %out : f32
        linalg.yield %19 : f32
      } -> tensor<1x1x1xf32>
      %extracted_slice_3 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %15 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%14 : tensor<1x1x1xf32>) outs(%extracted_slice_3 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %16 = arith.mulf %in, %cst_0 : f32
        linalg.yield %16 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %15 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After TensorToVectorVectorizePadPass (iree-codegen-vectorize-tensor-pad) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_0 = tensor.extract_slice %3[%9, %arg4] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
        %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_1 = tensor.extract_slice %4[%10] [1] [1] : tensor<81920xf32> to tensor<1xf32>
        %extracted_slice_2 = tensor.extract_slice %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
        %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
        ^bb0(%in: f32, %in_3: f32, %out: f16):
          %12 = arith.divf %in, %in_3 : f32
          %13 = arith.truncf %12 : f32 to f16
          linalg.yield %13 : f16
        } -> tensor<1x4xf16>
        %inserted_slice = tensor.insert_slice %11 into %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
        scf.yield %inserted_slice : tensor<64x64xf16>
      }
      scf.yield %8 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileToVectorSizePass (iree-llvmcpu-tile-to-vector-size) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %5 = tensor.empty() : tensor<81920x64xf16>
  %6 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %5) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %7 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %8 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_0 = tensor.extract_slice %3[%9, %arg4] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
        %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_1 = tensor.extract_slice %4[%10] [1] [1] : tensor<81920xf32> to tensor<1xf32>
        %extracted_slice_2 = tensor.extract_slice %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
        %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_0, %extracted_slice_1 : tensor<1x4xf32>, tensor<1xf32>) outs(%extracted_slice_2 : tensor<1x4xf16>) attrs =  {lowering_config = #iree_cpu.lowering_config<distribution = [64, 64], vector_common_parallel = [1, 4]>} {
        ^bb0(%in: f32, %in_3: f32, %out: f16):
          %12 = arith.divf %in, %in_3 : f32
          %13 = arith.truncf %12 : f32 to f16
          linalg.yield %13 : f16
        } -> tensor<1x4xf16>
        %inserted_slice = tensor.insert_slice %11 into %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
        scf.yield %inserted_slice : tensor<64x64xf16>
      }
      scf.yield %8 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTilePass (iree-llvmcpu-tile) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileAndFuseProducerConsumerPass (iree-llvmcpu-tile-and-fuse-producer-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After FuseTensorPadWithConsumerPass (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ConcretizePadResultShapePass (iree-codegen-concretize-pad-result-shape) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.forall (%arg4, %arg5, %arg6) in (4, 64, 64) shared_outs(%arg7 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = tensor.empty() : tensor<1x1x1xf32>
      %9 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%8 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
      %10 = scf.for %arg8 = %c0 to %c64 step %c4 iter_args(%arg9 = %9) -> (tensor<1x1x1xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %extracted_slice_2 = tensor.extract_slice %3[%12, %13, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
        %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg2]
        %extracted_slice_3 = tensor.extract_slice %4[%14, %15, %arg8] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
        %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
        ^bb0(%in: f16, %in_4: f16, %out: f32):
          %17 = arith.extf %in : f16 to f32
          %18 = arith.extf %in_4 : f16 to f32
          %19 = arith.mulf %17, %18 : f32
          %20 = arith.addf %19, %out : f32
          linalg.yield %20 : f32
        } -> tensor<1x1x1xf32>
        scf.yield %16 : tensor<1x1x1xf32>
      }
      %extracted_slice_1 = tensor.extract_slice %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%10 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
      ^bb0(%in: f32, %out: f32):
        %12 = arith.mulf %in, %cst_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1x1xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %11 into %arg7[%arg4, %arg5, %arg6] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
      }
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ForallToForPass (iree-codegen-forall-to-for) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %c0_1 = arith.constant 0 : index
    %c0_2 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c4_4 = arith.constant 4 : index
    %c64_5 = arith.constant 64 : index
    %c64_6 = arith.constant 64 : index
    %c1 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %c1_8 = arith.constant 1 : index
    %7 = scf.for %arg4 = %c0_1 to %c4_4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = scf.for %arg6 = %c0_2 to %c64_5 step %c1_7 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %9 = scf.for %arg8 = %c0_3 to %c64_6 step %c1_8 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %10 = tensor.empty() : tensor<1x1x1xf32>
          %11 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%10 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
          %12 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %11) -> (tensor<1x1x1xf32>) {
            %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
            %extracted_slice_10 = tensor.extract_slice %3[%14, %15, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %16 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %17 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
            %extracted_slice_11 = tensor.extract_slice %4[%16, %17, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_10, %extracted_slice_11 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg11 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
            ^bb0(%in: f16, %in_12: f16, %out: f32):
              %19 = arith.extf %in : f16 to f32
              %20 = arith.extf %in_12 : f16 to f32
              %21 = arith.mulf %19, %20 : f32
              %22 = arith.addf %21, %out : f32
              linalg.yield %22 : f32
            } -> tensor<1x1x1xf32>
            scf.yield %18 : tensor<1x1x1xf32>
          }
          %extracted_slice_9 = tensor.extract_slice %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
          %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12 : tensor<1x1x1xf32>) outs(%extracted_slice_9 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
          ^bb0(%in: f32, %out: f32):
            %14 = arith.mulf %in, %cst_0 : f32
            linalg.yield %14 : f32
          } -> tensor<1x1x1xf32>
          %inserted_slice = tensor.insert_slice %13 into %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
          scf.yield %inserted_slice : tensor<4x64x64xf32>
        }
        scf.yield %9 : tensor<4x64x64xf32>
      }
      scf.yield %8 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After GenericVectorizationPass (iree-codegen-generic-vectorization) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = tensor.empty() : tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_0 = tensor.extract_slice %4[%10, %arg4] [1, 4] [1, 1] : tensor<81920x64xf32> to tensor<1x4xf32>
        %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
        %extracted_slice_1 = tensor.extract_slice %5[%11] [1] [1] : tensor<81920xf32> to tensor<1xf32>
        %extracted_slice_2 = tensor.extract_slice %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<64x64xf16> to tensor<1x4xf16>
        %12 = vector.transfer_read %extracted_slice_0[%c0, %c0], %0 {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
        %13 = vector.transfer_read %extracted_slice_1[%c0], %0 {in_bounds = [true]} : tensor<1xf32>, vector<1xf32>
        %14 = vector.broadcast %13 : vector<1xf32> to vector<4x1xf32>
        %15 = vector.transpose %14, [1, 0] : vector<4x1xf32> to vector<1x4xf32>
        %16 = arith.divf %12, %15 : vector<1x4xf32>
        %17 = arith.truncf %16 : vector<1x4xf32> to vector<1x4xf16>
        %18 = vector.transfer_write %17, %extracted_slice_2[%c0, %c0] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<1x4xf16>
        %inserted_slice = tensor.insert_slice %18 into %arg5[%arg2, %arg4] [1, 4] [1, 1] : tensor<1x4xf16> into tensor<64x64xf16>
        scf.yield %inserted_slice : tensor<64x64xf16>
      }
      scf.yield %9 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUPeelPass (iree-llvmcpu-peel) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %9 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %10 = tensor.empty() : tensor<1x1x1xf32>
          %11 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%10 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
          %12 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %11) -> (tensor<1x1x1xf32>) {
            %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
            %extracted_slice_2 = tensor.extract_slice %3[%14, %15, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %16 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %17 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
            %extracted_slice_3 = tensor.extract_slice %4[%16, %17, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg11 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
            ^bb0(%in: f16, %in_4: f16, %out: f32):
              %19 = arith.extf %in : f16 to f32
              %20 = arith.extf %in_4 : f16 to f32
              %21 = arith.mulf %19, %20 : f32
              %22 = arith.addf %21, %out : f32
              linalg.yield %22 : f32
            } -> tensor<1x1x1xf32>
            scf.yield %18 : tensor<1x1x1xf32>
          }
          %extracted_slice_1 = tensor.extract_slice %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
          %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
          ^bb0(%in: f32, %out: f32):
            %14 = arith.mulf %in, %cst_0 : f32
            linalg.yield %14 : f32
          } -> tensor<1x1x1xf32>
          %inserted_slice = tensor.insert_slice %13 into %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
          scf.yield %inserted_slice : tensor<4x64x64xf32>
        }
        scf.yield %9 : tensor<4x64x64xf32>
      }
      scf.yield %8 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = tensor.empty() : tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %11 = vector.transfer_read %5[%10], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %12 = vector.broadcast %11 : vector<1xf32> to vector<4x1xf32>
      %13 = vector.transpose %12, [1, 0] : vector<4x1xf32> to vector<1x4xf32>
      %14 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %15 = vector.transfer_read %4[%9, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %16 = arith.divf %15, %13 : vector<1x4xf32>
        %17 = arith.truncf %16 : vector<1x4xf32> to vector<1x4xf16>
        %18 = vector.transfer_write %17, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %18 : tensor<64x64xf16>
      }
      scf.yield %14 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After TensorToVectorVectorizePadPass (iree-codegen-vectorize-tensor-pad) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %9 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %10 = tensor.empty() : tensor<1x1x1xf32>
          %11 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%10 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
          %12 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %11) -> (tensor<1x1x1xf32>) {
            %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
            %extracted_slice_2 = tensor.extract_slice %3[%14, %15, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %16 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %17 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
            %extracted_slice_3 = tensor.extract_slice %4[%16, %17, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg11 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
            ^bb0(%in: f16, %in_4: f16, %out: f32):
              %19 = arith.extf %in : f16 to f32
              %20 = arith.extf %in_4 : f16 to f32
              %21 = arith.mulf %19, %20 : f32
              %22 = arith.addf %21, %out : f32
              linalg.yield %22 : f32
            } -> tensor<1x1x1xf32>
            scf.yield %18 : tensor<1x1x1xf32>
          }
          %extracted_slice_1 = tensor.extract_slice %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
          %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
          ^bb0(%in: f32, %out: f32):
            %14 = arith.mulf %in, %cst_0 : f32
            linalg.yield %14 : f32
          } -> tensor<1x1x1xf32>
          %inserted_slice = tensor.insert_slice %13 into %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
          scf.yield %inserted_slice : tensor<4x64x64xf32>
        }
        scf.yield %9 : tensor<4x64x64xf32>
      }
      scf.yield %8 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = tensor.empty() : tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %11 = vector.transfer_read %5[%10], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %12 = vector.broadcast %11 : vector<1xf32> to vector<1x4xf32>
      %13 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %14 = vector.transfer_read %4[%9, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %15 = arith.divf %14, %12 : vector<1x4xf32>
        %16 = arith.truncf %15 : vector<1x4xf32> to vector<1x4xf16>
        %17 = vector.transfer_write %16, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %17 : tensor<64x64xf16>
      }
      scf.yield %13 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUTileToVectorSizePass (iree-llvmcpu-tile-to-vector-size) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant 1.250000e-01 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %3 = iree_codegen.load_from_buffer %0 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = tensor.empty() : tensor<20x4096x4096xf32>
  %6 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %5) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %7 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %8 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %9 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %10 = tensor.empty() : tensor<1x1x1xf32>
          %11 = linalg.fill {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} ins(%cst : f32) outs(%10 : tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
          %12 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %11) -> (tensor<1x1x1xf32>) {
            %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %15 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
            %extracted_slice_2 = tensor.extract_slice %3[%14, %15, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %16 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %17 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
            %extracted_slice_3 = tensor.extract_slice %4[%16, %17, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %18 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%extracted_slice_2, %extracted_slice_3 : tensor<1x1x4xf16>, tensor<1x1x4xf16>) outs(%arg11 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64, 0], distribution = [4, 64, 64, 0], vector_common_parallel = [1, 1, 1, 0], vector_reduction = [0, 0, 0, 4]>} {
            ^bb0(%in: f16, %in_4: f16, %out: f32):
              %19 = arith.extf %in : f16 to f32
              %20 = arith.extf %in_4 : f16 to f32
              %21 = arith.mulf %19, %20 : f32
              %22 = arith.addf %21, %out : f32
              linalg.yield %22 : f32
            } -> tensor<1x1x1xf32>
            scf.yield %18 : tensor<1x1x1xf32>
          }
          %extracted_slice_1 = tensor.extract_slice %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
          %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%12 : tensor<1x1x1xf32>) outs(%extracted_slice_1 : tensor<1x1x1xf32>) attrs =  {lowering_config = #iree_cpu.lowering_config<cache_parallel = [4, 64, 64], vector_common_parallel = [1, 1, 1]>} {
          ^bb0(%in: f32, %out: f32):
            %14 = arith.mulf %in, %cst_0 : f32
            linalg.yield %14 : f32
          } -> tensor<1x1x1xf32>
          %inserted_slice = tensor.insert_slice %13 into %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
          scf.yield %inserted_slice : tensor<4x64x64xf32>
        }
        scf.yield %9 : tensor<4x64x64xf32>
      }
      scf.yield %8 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %2 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = tensor.empty() : tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %10 = vector.transfer_read %5[%9], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %11 = vector.broadcast %10 : vector<1xf32> to vector<1x4xf32>
      %12 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %13 = vector.transfer_read %4[%9, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %14 = arith.divf %13, %11 : vector<1x4xf32>
        %15 = arith.truncf %14 : vector<1x4xf32> to vector<1x4xf16>
        %16 = vector.transfer_write %15, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %16 : tensor<64x64xf16>
      }
      scf.yield %12 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMCPUVerifyVectorSizeLegalityPass (iree-llvmcpu-verify-vector-size-legality) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = tensor.empty() : tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %10 = vector.transfer_read %5[%9], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %11 = vector.broadcast %10 : vector<1xf32> to vector<1x4xf32>
      %12 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %13 = vector.transfer_read %4[%9, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %14 = arith.divf %13, %11 : vector<1x4xf32>
        %15 = arith.truncf %14 : vector<1x4xf32> to vector<1x4xf16>
        %16 = vector.transfer_write %15, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %16 : tensor<64x64xf16>
      }
      scf.yield %12 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After GenericVectorizationPass (iree-codegen-generic-vectorization) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %1 = ub.poison : f32
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = iree_codegen.load_from_buffer %3 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %7 = tensor.empty() : tensor<20x4096x4096xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %7) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %9 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %10 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %11 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %12 = tensor.empty() : tensor<1x1x1xf32>
          %13 = vector.transfer_write %cst_0, %12[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<1x1x1xf32>
          %14 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %13) -> (tensor<1x1x1xf32>) {
            %18 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %19 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
            %extracted_slice_2 = tensor.extract_slice %5[%18, %19, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %20 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
            %21 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
            %extracted_slice_3 = tensor.extract_slice %6[%20, %21, %arg10] [1, 1, 4] [1, 1, 1] : tensor<20x4096x64xf16> to tensor<1x1x4xf16>
            %22 = vector.transfer_read %extracted_slice_2[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x1x4xf16>, vector<1x1x4xf16>
            %23 = vector.transfer_read %extracted_slice_3[%c0, %c0, %c0], %0 {in_bounds = [true, true, true]} : tensor<1x1x4xf16>, vector<1x1x4xf16>
            %24 = vector.transfer_read %arg11[%c0, %c0, %c0], %1 {in_bounds = [true, true, true]} : tensor<1x1x1xf32>, vector<1x1x1xf32>
            %25 = arith.extf %22 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %26 = arith.extf %23 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %27 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %25, %26, %24 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            %28 = vector.transfer_write %27, %arg11[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<1x1x1xf32>
            scf.yield %28 : tensor<1x1x1xf32>
          }
          %extracted_slice_1 = tensor.extract_slice %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<4x64x64xf32> to tensor<1x1x1xf32>
          %15 = vector.transfer_read %14[%c0, %c0, %c0], %1 {in_bounds = [true, true, true]} : tensor<1x1x1xf32>, vector<1x1x1xf32>
          %16 = arith.mulf %15, %cst : vector<1x1x1xf32>
          %17 = vector.transfer_write %16, %extracted_slice_1[%c0, %c0, %c0] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<1x1x1xf32>
          %inserted_slice = tensor.insert_slice %17 into %arg9[%arg4, %arg6, %arg8] [1, 1, 1] [1, 1, 1] : tensor<1x1x1xf32> into tensor<4x64x64xf32>
          scf.yield %inserted_slice : tensor<4x64x64xf32>
        }
        scf.yield %11 : tensor<4x64x64xf32>
      }
      scf.yield %10 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %9 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %4 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After EliminateEmptyTensorsPass (iree-eliminate-empty-tensors) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = iree_codegen.load_from_buffer %3 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf16>
  %7 = tensor.empty() : tensor<81920x64xf16>
  %8 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %9 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %11 = vector.transfer_read %5[%10], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %12 = vector.broadcast %11 : vector<1xf32> to vector<1x4xf32>
      %13 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %14 = vector.transfer_read %4[%10, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %15 = arith.divf %14, %12 : vector<1x4xf32>
        %16 = arith.truncf %15 : vector<1x4xf32> to vector<1x4xf16>
        %17 = vector.transfer_write %16, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %17 : tensor<64x64xf16>
      }
      scf.yield %13 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %9 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %8 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %13 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %15 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %18 = vector.transfer_read %4[%9, %12, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = vector.transfer_read %5[%10, %14, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = arith.extf %19 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %22 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %20, %21, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %22 : vector<1x1x1xf32>
          }
          %16 = arith.mulf %15, %cst : vector<1x1x1xf32>
          %17 = vector.transfer_write %16, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %17 : tensor<4x64x64xf32>
        }
        scf.yield %13 : tensor<4x64x64xf32>
      }
      scf.yield %11 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After EmptyTensorToAllocTensorPass (empty-tensor-to-alloc-tensor) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf32>
  %5 = iree_codegen.load_from_buffer %2 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>> -> tensor<81920xf32>
  %6 = iree_codegen.load_from_buffer %3 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<81920x64xf16>
  %7 = scf.forall (%arg0) = (0) to (81920) step (64) shared_outs(%arg1 = %6) -> (tensor<81920x64xf16>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<81920x64xf16> to tensor<64x64xf16>
    %8 = scf.for %arg2 = %c0 to %c64 step %c1 iter_args(%arg3 = %extracted_slice) -> (tensor<64x64xf16>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %arg0]
      %10 = vector.transfer_read %5[%9], %0 {in_bounds = [true]} : tensor<81920xf32>, vector<1xf32>
      %11 = vector.broadcast %10 : vector<1xf32> to vector<1x4xf32>
      %12 = scf.for %arg4 = %c0 to %c64 step %c4 iter_args(%arg5 = %arg3) -> (tensor<64x64xf16>) {
        %13 = vector.transfer_read %4[%9, %arg4], %0 {in_bounds = [true, true]} : tensor<81920x64xf32>, vector<1x4xf32>
        %14 = arith.divf %13, %11 : vector<1x4xf32>
        %15 = arith.truncf %14 : vector<1x4xf32> to vector<1x4xf16>
        %16 = vector.transfer_write %15, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<1x4xf16>, tensor<64x64xf16>
        scf.yield %16 : tensor<64x64xf16>
      }
      scf.yield %12 : tensor<64x64xf16>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0, 0] [64, 64] [1, 1] : tensor<64x64xf16> into tensor<81920x64xf16>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<81920x64xf16> into memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %8 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %13 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %15 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %18 = vector.transfer_read %4[%9, %12, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = vector.transfer_read %5[%10, %14, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = arith.extf %19 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %22 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %20, %21, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %22 : vector<1x1x1xf32>
          }
          %16 = arith.mulf %15, %cst : vector<1x1x1xf32>
          %17 = vector.transfer_write %16, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %17 : tensor<4x64x64xf32>
        }
        scf.yield %13 : tensor<4x64x64xf32>
      }
      scf.yield %11 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After IREEComprehensiveBufferizePass (iree-codegen-iree-comprehensive-bufferize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %3[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg1 = %c0 to %c64 step %c1 iter_args(%arg2 = %subview) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %6 = vector.transfer_read %2[%5], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %7 = vector.broadcast %6 : vector<1xf32> to vector<1x4xf32>
      %8 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %arg2) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %9 = vector.transfer_read %1[%5, %arg3], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %10 = arith.divf %9, %7 : vector<1x4xf32>
        %11 = arith.truncf %10 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %11, %arg4[%arg1, %arg3] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        scf.yield %arg4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %8 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_0 = memref.subview %3[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_0 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f16, %out: f16):
      linalg.yield %in : f16
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) outs(%3 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f16, %out: f16):
    linalg.yield %in : f16
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %8 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %10 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %12 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %14 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %17 = vector.transfer_read %4[%9, %11, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %18 = vector.transfer_read %5[%9, %13, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = arith.extf %17 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %19, %20, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %21 : vector<1x1x1xf32>
          }
          %15 = arith.mulf %14, %cst : vector<1x1x1xf32>
          %16 = vector.transfer_write %15, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %16 : tensor<4x64x64xf32>
        }
        scf.yield %12 : tensor<4x64x64xf32>
      }
      scf.yield %10 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After IREEInjectAssumeAlignmentPass (iree-codegen-inject-assume-alignment) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg1 = %c0 to %c64 step %c1 iter_args(%arg2 = %subview) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %6 = vector.transfer_read %assume_align_0[%5], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %7 = vector.broadcast %6 : vector<1xf32> to vector<1x4xf32>
      %8 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %arg2) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %9 = vector.transfer_read %assume_align[%5, %arg3], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %10 = arith.divf %9, %7 : vector<1x4xf32>
        %11 = arith.truncf %10 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %11, %arg4[%arg1, %arg3] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        scf.yield %arg4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %8 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_2 = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f16, %out: f16):
      linalg.yield %in : f16
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%assume_align_1 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_1 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f16, %out: f16):
    linalg.yield %in : f16
  }
  return
}

// -----// IR Dump After LLVMCPUVerifyVectorSizeLegalityPass (iree-llvmcpu-verify-vector-size-legality) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = tensor.empty() : tensor<20x4096x4096xf32>
  %7 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %8 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %10 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %12 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %14 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %17 = vector.transfer_read %4[%9, %11, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %18 = vector.transfer_read %5[%9, %13, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = arith.extf %17 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %19, %20, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %21 : vector<1x1x1xf32>
          }
          %15 = arith.mulf %14, %cst : vector<1x1x1xf32>
          %16 = vector.transfer_write %15, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %16 : tensor<4x64x64xf32>
        }
        scf.yield %12 : tensor<4x64x64xf32>
      }
      scf.yield %10 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After ResolveShapedTypeResultDimsPass (resolve-shaped-type-result-dims) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg1 = %c0 to %c64 step %c1 iter_args(%arg2 = %subview) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %6 = vector.transfer_read %assume_align_0[%5], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %7 = vector.broadcast %6 : vector<1xf32> to vector<1x4xf32>
      %8 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %arg2) -> (memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %9 = vector.transfer_read %assume_align[%5, %arg3], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %10 = arith.divf %9, %7 : vector<1x4xf32>
        %11 = arith.truncf %10 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %11, %arg4[%arg1, %arg3] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        scf.yield %arg4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %8 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_2 = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%4 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f16, %out: f16):
      linalg.yield %in : f16
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%assume_align_1 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_1 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f16, %out: f16):
    linalg.yield %in : f16
  }
  return
}

// -----// IR Dump After EliminateEmptyTensorsPass (iree-eliminate-empty-tensors) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = iree_codegen.load_from_buffer %3 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x4096xf32>
  %7 = tensor.empty() : tensor<20x4096x4096xf32>
  %8 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %9 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %11 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %12 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %13 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %15 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %18 = vector.transfer_read %4[%10, %12, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = vector.transfer_read %5[%10, %14, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = arith.extf %19 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %22 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %20, %21, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %22 : vector<1x1x1xf32>
          }
          %16 = arith.mulf %15, %cst : vector<1x1x1xf32>
          %17 = vector.transfer_write %16, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %17 : tensor<4x64x64xf32>
        }
        scf.yield %13 : tensor<4x64x64xf32>
      }
      scf.yield %11 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %9 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
    %subview_2 = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f16, %out: f16):
      linalg.yield %in : f16
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After EmptyTensorToAllocTensorPass (empty-tensor-to-alloc-tensor) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %5 = iree_codegen.load_from_buffer %2 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x64xf16>
  %6 = iree_codegen.load_from_buffer %3 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> -> tensor<20x4096x4096xf32>
  %7 = scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) shared_outs(%arg3 = %6) -> (tensor<20x4096x4096xf32>) {
    %extracted_slice = tensor.extract_slice %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<20x4096x4096xf32> to tensor<4x64x64xf32>
    %8 = scf.for %arg4 = %c0 to %c4 step %c1 iter_args(%arg5 = %extracted_slice) -> (tensor<4x64x64xf32>) {
      %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg0]
      %10 = scf.for %arg6 = %c0 to %c64 step %c1 iter_args(%arg7 = %arg5) -> (tensor<4x64x64xf32>) {
        %11 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg6, %arg1]
        %12 = scf.for %arg8 = %c0 to %c64 step %c1 iter_args(%arg9 = %arg7) -> (tensor<4x64x64xf32>) {
          %13 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg8, %arg2]
          %14 = scf.for %arg10 = %c0 to %c64 step %c4 iter_args(%arg11 = %cst_0) -> (vector<1x1x1xf32>) {
            %17 = vector.transfer_read %4[%9, %11, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %18 = vector.transfer_read %5[%9, %13, %arg10], %0 {in_bounds = [true, true, true]} : tensor<20x4096x64xf16>, vector<1x1x4xf16>
            %19 = arith.extf %17 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %20 = arith.extf %18 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %21 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %19, %20, %arg11 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %21 : vector<1x1x1xf32>
          }
          %15 = arith.mulf %14, %cst : vector<1x1x1xf32>
          %16 = vector.transfer_write %15, %arg9[%arg4, %arg6, %arg8] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, tensor<4x64x64xf32>
          scf.yield %16 : tensor<4x64x64xf32>
        }
        scf.yield %12 : tensor<4x64x64xf32>
      }
      scf.yield %10 : tensor<4x64x64xf32>
    }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : tensor<4x64x64xf32> into tensor<20x4096x4096xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %3 : tensor<20x4096x4096xf32> into memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f16, %out: f16):
      linalg.yield %in : f16
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREEComprehensiveBufferizePass (iree-codegen-iree-comprehensive-bufferize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg3 = %c0 to %c4 step %c1 iter_args(%arg4 = %subview) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      %6 = scf.for %arg5 = %c0 to %c64 step %c1 iter_args(%arg6 = %arg4) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %7 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %8 = scf.for %arg7 = %c0 to %c64 step %c1 iter_args(%arg8 = %arg6) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
          %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg7, %arg2]
          %10 = scf.for %arg9 = %c0 to %c64 step %c4 iter_args(%arg10 = %cst_0) -> (vector<1x1x1xf32>) {
            %12 = vector.transfer_read %1[%5, %7, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %13 = vector.transfer_read %2[%5, %9, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %14 = arith.extf %12 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %15 = arith.extf %13 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %14, %15, %arg10 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %16 : vector<1x1x1xf32>
          }
          %11 = arith.mulf %10, %cst : vector<1x1x1xf32>
          vector.transfer_write %11, %arg8[%arg3, %arg5, %arg7] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          scf.yield %arg8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
        scf.yield %8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %6 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_1 = memref.subview %3[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_1 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%3 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) outs(%3 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREEInjectAssumeAlignmentPass (iree-codegen-inject-assume-alignment) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg3 = %c0 to %c4 step %c1 iter_args(%arg4 = %subview) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      %6 = scf.for %arg5 = %c0 to %c64 step %c1 iter_args(%arg6 = %arg4) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %7 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %8 = scf.for %arg7 = %c0 to %c64 step %c1 iter_args(%arg8 = %arg6) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
          %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg7, %arg2]
          %10 = scf.for %arg9 = %c0 to %c64 step %c4 iter_args(%arg10 = %cst_0) -> (vector<1x1x1xf32>) {
            %12 = vector.transfer_read %assume_align[%5, %7, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %13 = vector.transfer_read %assume_align_1[%5, %9, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %14 = arith.extf %12 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %15 = arith.extf %13 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %14, %15, %arg10 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %16 : vector<1x1x1xf32>
          }
          %11 = arith.mulf %10, %cst : vector<1x1x1xf32>
          vector.transfer_write %11, %arg8[%arg3, %arg5, %arg7] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          scf.yield %arg8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
        scf.yield %8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %6 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_3 = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_3 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%assume_align_2 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_2 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After ResolveShapedTypeResultDimsPass (resolve-shaped-type-result-dims) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = scf.for %arg3 = %c0 to %c4 step %c1 iter_args(%arg4 = %subview) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      %6 = scf.for %arg5 = %c0 to %c64 step %c1 iter_args(%arg6 = %arg4) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        %7 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg1]
        %8 = scf.for %arg7 = %c0 to %c64 step %c1 iter_args(%arg8 = %arg6) -> (memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
          %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg7, %arg2]
          %10 = scf.for %arg9 = %c0 to %c64 step %c4 iter_args(%arg10 = %cst_0) -> (vector<1x1x1xf32>) {
            %12 = vector.transfer_read %assume_align[%5, %7, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %13 = vector.transfer_read %assume_align_1[%5, %9, %arg9], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %14 = arith.extf %12 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %15 = arith.extf %13 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %14, %15, %arg10 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %16 : vector<1x1x1xf32>
          }
          %11 = arith.mulf %10, %cst : vector<1x1x1xf32>
          vector.transfer_write %11, %arg8[%arg3, %arg5, %arg7] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          scf.yield %arg8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
        scf.yield %8 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
      scf.yield %6 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    %subview_3 = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%4 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_3 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%assume_align_2 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) outs(%assume_align_2 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
    %subview_3 = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_3 : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After RemoveSingleIterationLoopPass (iree-codegen-remove-single-iteration-loop) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true, true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
        %8 = arith.divf %7, %6 : vector<1x4xf32>
        %9 = arith.truncf %8 : vector<1x4xf32> to vector<1x4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true, true]} : vector<1x4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
    linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel"]} ins(%subview : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After DropVectorUnitDimsPass (iree-codegen-drop-vector-unit-dims) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %8 = vector.shape_cast %6 : vector<1x4xf32> to vector<4xf32>
        %9 = arith.divf %7, %8 : vector<4xf32>
        %10 = arith.truncf %9 : vector<4xf32> to vector<4xf16>
        vector.transfer_write %10, %subview[%arg1, %arg2] {in_bounds = [true]} : vector<4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVirtualVectorLoweringPass (iree-llvmcpu-virtual-vector-lowering) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      %6 = vector.broadcast %5 : vector<1xf32> to vector<1x4xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %7 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %8 = vector.shape_cast %6 : vector<1x4xf32> to vector<4xf32>
        %9 = arith.divf %7, %8 : vector<4xf32>
        %10 = arith.truncf %9 : vector<4xf32> to vector<4xf16>
        vector.transfer_write %10, %subview[%arg1, %arg2] {in_bounds = [true]} : vector<4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : f32
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %5 = vector.transfer_read %assume_align_0[%4], %0 {in_bounds = [true]} : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %6 = vector.transfer_read %assume_align[%4, %arg2], %0 {in_bounds = [true]} : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
        %8 = arith.divf %6, %7 : vector<4xf32>
        %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
        vector.transfer_write %9, %subview[%arg1, %arg2] {in_bounds = [true]} : vector<4xf16>, memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After RemoveSingleIterationLoopPass (iree-codegen-remove-single-iteration-loop) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1x1x1xf32>
  %0 = ub.poison : f16
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1x1x1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true, true, true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<1x1x4xf16>
            %11 = arith.extf %9 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %12 = arith.extf %10 : vector<1x1x4xf16> to vector<1x1x4xf32>
            %13 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"], kind = #vector.kind<add>} %11, %12, %arg7 : vector<1x1x4xf32>, vector<1x1x4xf32> into vector<1x1x1xf32>
            scf.yield %13 : vector<1x1x1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1x1x1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true, true, true]} : vector<1x1x1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVectorTransposeLoweringPass (iree-llvmcpu-vector-transpose-lowering) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After DropVectorUnitDimsPass (iree-codegen-drop-vector-unit-dims) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %0 = ub.poison : f16
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %9 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %10 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = arith.extf %9 : vector<4xf16> to vector<4xf32>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = vector.broadcast %12 : vector<4xf32> to vector<1x4xf32>
            %14 = vector.contract {indexing_maps = [affine_map<(d0, d1) -> (d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"], kind = #vector.kind<add>} %11, %13, %arg7 : vector<4xf32>, vector<1x4xf32> into vector<1xf32>
            scf.yield %14 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          vector.transfer_write %8, %subview[%arg3, %arg4, %arg5] {in_bounds = [true]} : vector<1xf32>, memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVirtualVectorLoweringPass (iree-llvmcpu-virtual-vector-lowering) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %0 = ub.poison : f16
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %10 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = arith.extf %11 : vector<4xf16> to vector<4xf32>
            %14 = vector.broadcast %13 : vector<4xf32> to vector<1x4xf32>
            %15 = vector.transpose %14, [1, 0] : vector<1x4xf32> to vector<4x1xf32>
            %16 = vector.extract %15[0] : vector<1xf32> from vector<4x1xf32>
            %17 = vector.extract %12[0] : f32 from vector<4xf32>
            %18 = vector.broadcast %17 : f32 to vector<1xf32>
            %19 = vector.fma %16, %18, %arg7 : vector<1xf32>
            %20 = vector.extract %15[1] : vector<1xf32> from vector<4x1xf32>
            %21 = vector.extract %12[1] : f32 from vector<4xf32>
            %22 = vector.broadcast %21 : f32 to vector<1xf32>
            %23 = vector.fma %20, %22, %19 : vector<1xf32>
            %24 = vector.extract %15[2] : vector<1xf32> from vector<4x1xf32>
            %25 = vector.extract %12[2] : f32 from vector<4xf32>
            %26 = vector.broadcast %25 : f32 to vector<1xf32>
            %27 = vector.fma %24, %26, %23 : vector<1xf32>
            %28 = vector.extract %15[3] : vector<1xf32> from vector<4x1xf32>
            %29 = vector.extract %12[3] : f32 from vector<4xf32>
            %30 = vector.broadcast %29 : f32 to vector<1xf32>
            %31 = vector.fma %28, %30, %27 : vector<1xf32>
            scf.yield %31 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          %9 = vector.extract %8[0] : f32 from vector<1xf32>
          memref.store %9, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVectorShapeCastLoweringPass (iree-llvmcpu-vector-shape-cast-lowering) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %0 = ub.poison : f16
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %10 = vector.transfer_read %assume_align[%4, %5, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = vector.transfer_read %assume_align_1[%4, %6, %arg6], %0 {in_bounds = [true]} : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = arith.extf %11 : vector<4xf16> to vector<4xf32>
            %14 = vector.broadcast %13 : vector<4xf32> to vector<1x4xf32>
            %15 = vector.transpose %14, [1, 0] : vector<1x4xf32> to vector<4x1xf32>
            %16 = vector.extract %15[0] : vector<1xf32> from vector<4x1xf32>
            %17 = vector.extract %12[0] : f32 from vector<4xf32>
            %18 = vector.broadcast %17 : f32 to vector<1xf32>
            %19 = vector.fma %16, %18, %arg7 : vector<1xf32>
            %20 = vector.extract %15[1] : vector<1xf32> from vector<4x1xf32>
            %21 = vector.extract %12[1] : f32 from vector<4xf32>
            %22 = vector.broadcast %21 : f32 to vector<1xf32>
            %23 = vector.fma %20, %22, %19 : vector<1xf32>
            %24 = vector.extract %15[2] : vector<1xf32> from vector<4x1xf32>
            %25 = vector.extract %12[2] : f32 from vector<4xf32>
            %26 = vector.broadcast %25 : f32 to vector<1xf32>
            %27 = vector.fma %24, %26, %23 : vector<1xf32>
            %28 = vector.extract %15[3] : vector<1xf32> from vector<4x1xf32>
            %29 = vector.extract %12[3] : f32 from vector<4xf32>
            %30 = vector.broadcast %29 : f32 to vector<1xf32>
            %31 = vector.fma %28, %30, %27 : vector<1xf32>
            scf.yield %31 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          %9 = vector.extract %8[0] : f32 from vector<1xf32>
          memref.store %9, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPULowerExecutableTargetPass (iree-llvmcpu-lower-executable-target) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %6 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %9 = vector.load %assume_align[%3, %4, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %10 = vector.load %assume_align_1[%3, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = arith.extf %9 : vector<4xf16> to vector<4xf32>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = vector.broadcast %12 : vector<4xf32> to vector<1x4xf32>
            %14 = vector.transpose %13, [1, 0] : vector<1x4xf32> to vector<4x1xf32>
            %15 = vector.extract %14[0] : vector<1xf32> from vector<4x1xf32>
            %16 = vector.extract %11[0] : f32 from vector<4xf32>
            %17 = vector.broadcast %16 : f32 to vector<1xf32>
            %18 = vector.fma %15, %17, %arg7 : vector<1xf32>
            %19 = vector.extract %14[1] : vector<1xf32> from vector<4x1xf32>
            %20 = vector.extract %11[1] : f32 from vector<4xf32>
            %21 = vector.broadcast %20 : f32 to vector<1xf32>
            %22 = vector.fma %19, %21, %18 : vector<1xf32>
            %23 = vector.extract %14[2] : vector<1xf32> from vector<4x1xf32>
            %24 = vector.extract %11[2] : f32 from vector<4xf32>
            %25 = vector.broadcast %24 : f32 to vector<1xf32>
            %26 = vector.fma %23, %25, %22 : vector<1xf32>
            %27 = vector.extract %14[3] : vector<1xf32> from vector<4x1xf32>
            %28 = vector.extract %11[3] : f32 from vector<4xf32>
            %29 = vector.broadcast %28 : f32 to vector<1xf32>
            %30 = vector.fma %27, %29, %26 : vector<1xf32>
            scf.yield %30 : vector<1xf32>
          }
          %7 = arith.mulf %6, %cst : vector<1xf32>
          %8 = vector.extract %7[0] : f32 from vector<1xf32>
          memref.store %8, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VerifyWorkgroupDistributionPass (iree-codegen-verify-workgroup-distribution) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0) = (0) to (81920) step (64) {
    %subview = memref.subview %assume_align_1[%arg0, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %arg0]
      %4 = vector.load %assume_align_0[%3] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
      scf.for %arg2 = %c0 to %c64 step %c4 {
        %5 = vector.load %assume_align[%3, %arg2] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
        %6 = vector.broadcast %4 : vector<1xf32> to vector<4xf32>
        %7 = arith.divf %5, %6 : vector<4xf32>
        %8 = arith.truncf %7 : vector<4xf32> to vector<4xf16>
        vector.store %8, %subview[%arg1, %arg2] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMCPUVectorTransposeLoweringPass (iree-llvmcpu-vector-transpose-lowering) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %6 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %9 = vector.load %assume_align[%3, %4, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %10 = vector.load %assume_align_1[%3, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = arith.extf %9 : vector<4xf16> to vector<4xf32>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = vector.broadcast %12 : vector<4xf32> to vector<1x4xf32>
            %14 = vector.shape_cast %13 : vector<1x4xf32> to vector<4x1xf32>
            %15 = vector.extract %14[0] : vector<1xf32> from vector<4x1xf32>
            %16 = vector.extract %11[0] : f32 from vector<4xf32>
            %17 = vector.broadcast %16 : f32 to vector<1xf32>
            %18 = vector.fma %15, %17, %arg7 : vector<1xf32>
            %19 = vector.extract %14[1] : vector<1xf32> from vector<4x1xf32>
            %20 = vector.extract %11[1] : f32 from vector<4xf32>
            %21 = vector.broadcast %20 : f32 to vector<1xf32>
            %22 = vector.fma %19, %21, %18 : vector<1xf32>
            %23 = vector.extract %14[2] : vector<1xf32> from vector<4x1xf32>
            %24 = vector.extract %11[2] : f32 from vector<4xf32>
            %25 = vector.broadcast %24 : f32 to vector<1xf32>
            %26 = vector.fma %23, %25, %22 : vector<1xf32>
            %27 = vector.extract %14[3] : vector<1xf32> from vector<4x1xf32>
            %28 = vector.extract %11[3] : f32 from vector<4xf32>
            %29 = vector.broadcast %28 : f32 to vector<1xf32>
            %30 = vector.fma %27, %29, %26 : vector<1xf32>
            scf.yield %30 : vector<1xf32>
          }
          %7 = arith.mulf %6, %cst : vector<1xf32>
          %8 = vector.extract %7[0] : f32 from vector<1xf32>
          memref.store %8, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %3 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %6 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %9 = vector.load %assume_align[%3, %4, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %10 = vector.load %assume_align_1[%3, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = arith.extf %9 : vector<4xf16> to vector<4xf32>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = vector.shape_cast %12 : vector<4xf32> to vector<4x1xf32>
            %14 = vector.extract %13[0] : vector<1xf32> from vector<4x1xf32>
            %15 = vector.extract %11[0] : f32 from vector<4xf32>
            %16 = vector.broadcast %15 : f32 to vector<1xf32>
            %17 = vector.fma %14, %16, %arg7 : vector<1xf32>
            %18 = vector.extract %13[1] : vector<1xf32> from vector<4x1xf32>
            %19 = vector.extract %11[1] : f32 from vector<4xf32>
            %20 = vector.broadcast %19 : f32 to vector<1xf32>
            %21 = vector.fma %18, %20, %17 : vector<1xf32>
            %22 = vector.extract %13[2] : vector<1xf32> from vector<4x1xf32>
            %23 = vector.extract %11[2] : f32 from vector<4xf32>
            %24 = vector.broadcast %23 : f32 to vector<1xf32>
            %25 = vector.fma %22, %24, %21 : vector<1xf32>
            %26 = vector.extract %13[3] : vector<1xf32> from vector<4x1xf32>
            %27 = vector.extract %11[3] : f32 from vector<4xf32>
            %28 = vector.broadcast %27 : f32 to vector<1xf32>
            %29 = vector.fma %26, %28, %25 : vector<1xf32>
            scf.yield %29 : vector<1xf32>
          }
          %7 = arith.mulf %6, %cst : vector<1xf32>
          %8 = vector.extract %7[0] : f32 from vector<1xf32>
          memref.store %8, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After ReconcileTranslationInfoPass (iree-codegen-reconcile-translation-info) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c64 = arith.constant 64 : index
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %3 = affine.apply affine_map<()[s0] -> (s0 * 64)>()[%workgroup_id_x]
      %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c64 step %c1 {
        %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg0, %3]
        %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        scf.for %arg1 = %c0 to %c64 step %c4 {
          %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
          %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
          %8 = arith.divf %6, %7 : vector<4xf32>
          %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
          vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
        }
      }
      iree_codegen.workgroup_count_hint(1280)
      return
    }
  }
}

// -----// IR Dump After LLVMCPUVectorShapeCastLoweringPass (iree-llvmcpu-vector-shape-cast-lowering) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %10 = vector.load %assume_align[%4, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = vector.load %assume_align_1[%4, %6, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = arith.extf %11 : vector<4xf16> to vector<4xf32>
            %14 = vector.extract %13[0] : f32 from vector<4xf32>
            %15 = vector.insert %14, %0 [0, 0] : f32 into vector<4x1xf32>
            %16 = vector.extract %13[1] : f32 from vector<4xf32>
            %17 = vector.insert %16, %15 [1, 0] : f32 into vector<4x1xf32>
            %18 = vector.extract %13[2] : f32 from vector<4xf32>
            %19 = vector.insert %18, %17 [2, 0] : f32 into vector<4x1xf32>
            %20 = vector.extract %13[3] : f32 from vector<4xf32>
            %21 = vector.insert %20, %19 [3, 0] : f32 into vector<4x1xf32>
            %22 = vector.extract %21[0] : vector<1xf32> from vector<4x1xf32>
            %23 = vector.extract %12[0] : f32 from vector<4xf32>
            %24 = vector.broadcast %23 : f32 to vector<1xf32>
            %25 = vector.fma %22, %24, %arg7 : vector<1xf32>
            %26 = vector.extract %21[1] : vector<1xf32> from vector<4x1xf32>
            %27 = vector.extract %12[1] : f32 from vector<4xf32>
            %28 = vector.broadcast %27 : f32 to vector<1xf32>
            %29 = vector.fma %26, %28, %25 : vector<1xf32>
            %30 = vector.extract %21[2] : vector<1xf32> from vector<4x1xf32>
            %31 = vector.extract %12[2] : f32 from vector<4xf32>
            %32 = vector.broadcast %31 : f32 to vector<1xf32>
            %33 = vector.fma %30, %32, %29 : vector<1xf32>
            %34 = vector.extract %21[3] : vector<1xf32> from vector<4x1xf32>
            %35 = vector.extract %12[3] : f32 from vector<4xf32>
            %36 = vector.broadcast %35 : f32 to vector<1xf32>
            %37 = vector.fma %34, %36, %33 : vector<1xf32>
            scf.yield %37 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          %9 = vector.extract %8[0] : f32 from vector<1xf32>
          memref.store %9, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After ResolveWorkgroupCountHintsPass (iree-codegen-resolve-workgroup-count-hints) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c1280 = arith.constant 1280 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c1280, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c64 = arith.constant 64 : index
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %3 = affine.apply affine_map<()[s0] -> (s0 * 64)>()[%workgroup_id_x]
      %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c64 step %c1 {
        %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg0, %3]
        %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        scf.for %arg1 = %c0 to %c64 step %c4 {
          %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
          %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
          %8 = arith.divf %6, %7 : vector<4xf32>
          %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
          vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
        }
      }
      return
    }
  }
}

// -----// IR Dump After LLVMCPULowerExecutableTargetPass (iree-llvmcpu-lower-executable-target) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %10 = vector.load %assume_align[%4, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = vector.load %assume_align_1[%4, %6, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = arith.extf %11 : vector<4xf16> to vector<4xf32>
            %14 = vector.extract %13[0] : f32 from vector<4xf32>
            %15 = vector.insert %14, %0 [0, 0] : f32 into vector<4x1xf32>
            %16 = vector.extract %13[1] : f32 from vector<4xf32>
            %17 = vector.insert %16, %15 [1, 0] : f32 into vector<4x1xf32>
            %18 = vector.extract %13[2] : f32 from vector<4xf32>
            %19 = vector.insert %18, %17 [2, 0] : f32 into vector<4x1xf32>
            %20 = vector.extract %13[3] : f32 from vector<4xf32>
            %21 = vector.insert %20, %19 [3, 0] : f32 into vector<4x1xf32>
            %22 = vector.extract %21[0] : vector<1xf32> from vector<4x1xf32>
            %23 = vector.extract %12[0] : f32 from vector<4xf32>
            %24 = vector.broadcast %23 : f32 to vector<1xf32>
            %25 = vector.fma %22, %24, %arg7 : vector<1xf32>
            %26 = vector.extract %21[1] : vector<1xf32> from vector<4x1xf32>
            %27 = vector.extract %12[1] : f32 from vector<4xf32>
            %28 = vector.broadcast %27 : f32 to vector<1xf32>
            %29 = vector.fma %26, %28, %25 : vector<1xf32>
            %30 = vector.extract %21[2] : vector<1xf32> from vector<4x1xf32>
            %31 = vector.extract %12[2] : f32 from vector<4xf32>
            %32 = vector.broadcast %31 : f32 to vector<1xf32>
            %33 = vector.fma %30, %32, %29 : vector<1xf32>
            %34 = vector.extract %21[3] : vector<1xf32> from vector<4x1xf32>
            %35 = vector.extract %12[3] : f32 from vector<4xf32>
            %36 = vector.broadcast %35 : f32 to vector<1xf32>
            %37 = vector.fma %34, %36, %33 : vector<1xf32>
            scf.yield %37 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          %9 = vector.extract %8[0] : f32 from vector<1xf32>
          memref.store %9, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LowerAffinePass (lower-affine) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c1280 = arith.constant 1280 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c1280, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c64 = arith.constant 64 : index
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %c64_2 = arith.constant 64 : index
      %3 = arith.muli %workgroup_id_x, %c64_2 overflow<nsw> : index
      %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c64 step %c1 {
        %4 = arith.addi %arg0, %3 : index
        %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        scf.for %arg1 = %c0 to %c64 step %c4 {
          %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
          %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
          %8 = arith.divf %6, %7 : vector<4xf32>
          %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
          vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
        }
      }
      return
    }
  }
}

// -----// IR Dump After VerifyWorkgroupDistributionPass (iree-codegen-verify-workgroup-distribution) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() attributes {translation_info = #iree_codegen.translation_info<pipeline = CPUDoubleTilingExpert, {enable_loop_peeling}>} {
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1, %arg2) = (0, 0, 0) to (20, 4096, 4096) step (4, 64, 64) {
    %subview = memref.subview %assume_align_2[%arg0, %arg1, %arg2] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %4 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg3, %arg0]
      scf.for %arg4 = %c0 to %c64 step %c1 {
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg4, %arg1]
        scf.for %arg5 = %c0 to %c64 step %c1 {
          %6 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg5, %arg2]
          %7 = scf.for %arg6 = %c0 to %c64 step %c4 iter_args(%arg7 = %cst_0) -> (vector<1xf32>) {
            %10 = vector.load %assume_align[%4, %5, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %11 = vector.load %assume_align_1[%4, %6, %arg6] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
            %12 = arith.extf %10 : vector<4xf16> to vector<4xf32>
            %13 = arith.extf %11 : vector<4xf16> to vector<4xf32>
            %14 = vector.extract %13[0] : f32 from vector<4xf32>
            %15 = vector.insert %14, %0 [0, 0] : f32 into vector<4x1xf32>
            %16 = vector.extract %13[1] : f32 from vector<4xf32>
            %17 = vector.insert %16, %15 [1, 0] : f32 into vector<4x1xf32>
            %18 = vector.extract %13[2] : f32 from vector<4xf32>
            %19 = vector.insert %18, %17 [2, 0] : f32 into vector<4x1xf32>
            %20 = vector.extract %13[3] : f32 from vector<4xf32>
            %21 = vector.insert %20, %19 [3, 0] : f32 into vector<4x1xf32>
            %22 = vector.extract %21[0] : vector<1xf32> from vector<4x1xf32>
            %23 = vector.extract %12[0] : f32 from vector<4xf32>
            %24 = vector.broadcast %23 : f32 to vector<1xf32>
            %25 = vector.fma %22, %24, %arg7 : vector<1xf32>
            %26 = vector.extract %21[1] : vector<1xf32> from vector<4x1xf32>
            %27 = vector.extract %12[1] : f32 from vector<4xf32>
            %28 = vector.broadcast %27 : f32 to vector<1xf32>
            %29 = vector.fma %26, %28, %25 : vector<1xf32>
            %30 = vector.extract %21[2] : vector<1xf32> from vector<4x1xf32>
            %31 = vector.extract %12[2] : f32 from vector<4xf32>
            %32 = vector.broadcast %31 : f32 to vector<1xf32>
            %33 = vector.fma %30, %32, %29 : vector<1xf32>
            %34 = vector.extract %21[3] : vector<1xf32> from vector<4x1xf32>
            %35 = vector.extract %12[3] : f32 from vector<4xf32>
            %36 = vector.broadcast %35 : f32 to vector<1xf32>
            %37 = vector.fma %34, %36, %33 : vector<1xf32>
            scf.yield %37 : vector<1xf32>
          }
          %8 = arith.mulf %7, %cst : vector<1xf32>
          %9 = vector.extract %8[0] : f32 from vector<1xf32>
          memref.store %9, %subview[%arg3, %arg4, %arg5] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  } {mapping = [#iree_codegen.workgroup_mapping<z>, #iree_codegen.workgroup_mapping<y>, #iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After DropCompilerHintsPass (iree-util-drop-compiler-hints) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c1280 = arith.constant 1280 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c1280, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c64 = arith.constant 64 : index
      %c1342504960 = arith.constant 1342504960 : index
      %c1342177280 = arith.constant 1342177280 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %c64_2 = arith.constant 64 : index
      %3 = arith.muli %workgroup_id_x, %c64_2 overflow<nsw> : index
      %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16, #hal.descriptor_type<storage_buffer>> to memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c64 step %c1 {
        %4 = arith.addi %arg0, %3 : index
        %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1xf32>
        scf.for %arg1 = %c0 to %c64 step %c4 {
          %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf32>
          %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
          %8 = arith.divf %6, %7 : vector<4xf32>
          %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
          vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
        }
      }
      return
    }
  }
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRefPass (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %c64_2 = arith.constant 64 : index
  %3 = arith.muli %workgroup_id_x, %c64_2 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After ReconcileTranslationInfoPass (iree-codegen-reconcile-translation-info) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
      %0 = ub.poison : vector<4x1xf32>
      %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
      %c1 = arith.constant 1 : index
      %c4 = arith.constant 4 : index
      %c64 = arith.constant 64 : index
      %c0 = arith.constant 0 : index
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %4:3 = affine.delinearize_index %workgroup_id_x into (5, 64, 64) : index, index, index
      %5 = affine.apply affine_map<(d0) -> (d0 * 4)>(%4#0)
      %6 = affine.apply affine_map<(d0) -> (d0 * 64)>(%4#1)
      %7 = affine.apply affine_map<(d0) -> (d0 * 64)>(%4#2)
      %subview = memref.subview %assume_align_2[%5, %6, %7] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c4 step %c1 {
        %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg0, %5]
        scf.for %arg1 = %c0 to %c64 step %c1 {
          %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %6]
          scf.for %arg2 = %c0 to %c64 step %c1 {
            %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %7]
            %11 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
              %14 = vector.load %assume_align[%8, %9, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %15 = vector.load %assume_align_1[%8, %10, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %16 = arith.extf %14 : vector<4xf16> to vector<4xf32>
              %17 = arith.extf %15 : vector<4xf16> to vector<4xf32>
              %18 = vector.extract %17[0] : f32 from vector<4xf32>
              %19 = vector.insert %18, %0 [0, 0] : f32 into vector<4x1xf32>
              %20 = vector.extract %17[1] : f32 from vector<4xf32>
              %21 = vector.insert %20, %19 [1, 0] : f32 into vector<4x1xf32>
              %22 = vector.extract %17[2] : f32 from vector<4xf32>
              %23 = vector.insert %22, %21 [2, 0] : f32 into vector<4x1xf32>
              %24 = vector.extract %17[3] : f32 from vector<4xf32>
              %25 = vector.insert %24, %23 [3, 0] : f32 into vector<4x1xf32>
              %26 = vector.extract %25[0] : vector<1xf32> from vector<4x1xf32>
              %27 = vector.extract %16[0] : f32 from vector<4xf32>
              %28 = vector.broadcast %27 : f32 to vector<1xf32>
              %29 = vector.fma %26, %28, %arg4 : vector<1xf32>
              %30 = vector.extract %25[1] : vector<1xf32> from vector<4x1xf32>
              %31 = vector.extract %16[1] : f32 from vector<4xf32>
              %32 = vector.broadcast %31 : f32 to vector<1xf32>
              %33 = vector.fma %30, %32, %29 : vector<1xf32>
              %34 = vector.extract %25[2] : vector<1xf32> from vector<4x1xf32>
              %35 = vector.extract %16[2] : f32 from vector<4xf32>
              %36 = vector.broadcast %35 : f32 to vector<1xf32>
              %37 = vector.fma %34, %36, %33 : vector<1xf32>
              %38 = vector.extract %25[3] : vector<1xf32> from vector<4x1xf32>
              %39 = vector.extract %16[3] : f32 from vector<4xf32>
              %40 = vector.broadcast %39 : f32 to vector<1xf32>
              %41 = vector.fma %38, %40, %37 : vector<1xf32>
              scf.yield %41 : vector<1xf32>
            }
            %12 = arith.mulf %11, %cst : vector<1xf32>
            %13 = vector.extract %12[0] : f32 from vector<1xf32>
            memref.store %13, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
        }
      }
      iree_codegen.workgroup_count_hint(20480)
      return
    }
  }
}

// -----// IR Dump After LowerUKernelOpsToCallsPass (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c64 = arith.constant 64 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
    %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
    %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
    %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %c64_2 = arith.constant 64 : index
    %3 = arith.muli %workgroup_id_x, %c64_2 overflow<nsw> : index
    %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c64 step %c1 {
      %4 = arith.addi %arg0, %3 : index
      %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
      scf.for %arg1 = %c0 to %c64 step %c4 {
        %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
        %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
        %8 = arith.divf %6, %7 : vector<4xf32>
        %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
        vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
      }
    }
    return
  }
}

// -----// IR Dump After ResolveWorkgroupCountHintsPass (iree-codegen-resolve-workgroup-count-hints) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c20480 = arith.constant 20480 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c20480, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
      %0 = ub.poison : vector<4x1xf32>
      %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
      %c1 = arith.constant 1 : index
      %c4 = arith.constant 4 : index
      %c64 = arith.constant 64 : index
      %c0 = arith.constant 0 : index
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %4:3 = affine.delinearize_index %workgroup_id_x into (5, 64, 64) : index, index, index
      %5 = affine.apply affine_map<(d0) -> (d0 * 4)>(%4#0)
      %6 = affine.apply affine_map<(d0) -> (d0 * 64)>(%4#1)
      %7 = affine.apply affine_map<(d0) -> (d0 * 64)>(%4#2)
      %subview = memref.subview %assume_align_2[%5, %6, %7] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c4 step %c1 {
        %8 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg0, %5]
        scf.for %arg1 = %c0 to %c64 step %c1 {
          %9 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg1, %6]
          scf.for %arg2 = %c0 to %c64 step %c1 {
            %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%arg2, %7]
            %11 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
              %14 = vector.load %assume_align[%8, %9, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %15 = vector.load %assume_align_1[%8, %10, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %16 = arith.extf %14 : vector<4xf16> to vector<4xf32>
              %17 = arith.extf %15 : vector<4xf16> to vector<4xf32>
              %18 = vector.extract %17[0] : f32 from vector<4xf32>
              %19 = vector.insert %18, %0 [0, 0] : f32 into vector<4x1xf32>
              %20 = vector.extract %17[1] : f32 from vector<4xf32>
              %21 = vector.insert %20, %19 [1, 0] : f32 into vector<4x1xf32>
              %22 = vector.extract %17[2] : f32 from vector<4xf32>
              %23 = vector.insert %22, %21 [2, 0] : f32 into vector<4x1xf32>
              %24 = vector.extract %17[3] : f32 from vector<4xf32>
              %25 = vector.insert %24, %23 [3, 0] : f32 into vector<4x1xf32>
              %26 = vector.extract %25[0] : vector<1xf32> from vector<4x1xf32>
              %27 = vector.extract %16[0] : f32 from vector<4xf32>
              %28 = vector.broadcast %27 : f32 to vector<1xf32>
              %29 = vector.fma %26, %28, %arg4 : vector<1xf32>
              %30 = vector.extract %25[1] : vector<1xf32> from vector<4x1xf32>
              %31 = vector.extract %16[1] : f32 from vector<4xf32>
              %32 = vector.broadcast %31 : f32 to vector<1xf32>
              %33 = vector.fma %30, %32, %29 : vector<1xf32>
              %34 = vector.extract %25[2] : vector<1xf32> from vector<4x1xf32>
              %35 = vector.extract %16[2] : f32 from vector<4xf32>
              %36 = vector.broadcast %35 : f32 to vector<1xf32>
              %37 = vector.fma %34, %36, %33 : vector<1xf32>
              %38 = vector.extract %25[3] : vector<1xf32> from vector<4x1xf32>
              %39 = vector.extract %16[3] : f32 from vector<4xf32>
              %40 = vector.broadcast %39 : f32 to vector<1xf32>
              %41 = vector.fma %38, %40, %37 : vector<1xf32>
              scf.yield %41 : vector<1xf32>
            }
            %12 = arith.mulf %11, %cst : vector<1xf32>
            %13 = vector.extract %12[0] : f32 from vector<1xf32>
            memref.store %13, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
        }
      }
      return
    }
  }
}

// -----// IR Dump After LinalgExtToLoopsPass (iree-linalg-ext-to-loops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After LowerAffinePass (lower-affine) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c20480 = arith.constant 20480 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c20480, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
      %0 = ub.poison : vector<4x1xf32>
      %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
      %c1 = arith.constant 1 : index
      %c4 = arith.constant 4 : index
      %c64 = arith.constant 64 : index
      %c0 = arith.constant 0 : index
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %c64_3 = arith.constant 64 : index
      %c4096 = arith.constant 4096 : index
      %c0_4 = arith.constant 0 : index
      %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
      %5 = arith.remsi %workgroup_id_x, %c4096 : index
      %6 = arith.cmpi slt, %5, %c0_4 : index
      %7 = arith.addi %5, %c4096 overflow<nsw> : index
      %8 = arith.select %6, %7, %5 : index
      %9 = arith.divsi %8, %c64_3 : index
      %10 = arith.remsi %workgroup_id_x, %c64_3 : index
      %11 = arith.cmpi slt, %10, %c0_4 : index
      %12 = arith.addi %10, %c64_3 overflow<nsw> : index
      %13 = arith.select %11, %12, %10 : index
      %c4_5 = arith.constant 4 : index
      %14 = arith.muli %4, %c4_5 overflow<nsw> : index
      %c64_6 = arith.constant 64 : index
      %15 = arith.muli %9, %c64_6 overflow<nsw> : index
      %c64_7 = arith.constant 64 : index
      %16 = arith.muli %13, %c64_7 overflow<nsw> : index
      %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c4 step %c1 {
        %17 = arith.addi %arg0, %14 : index
        scf.for %arg1 = %c0 to %c64 step %c1 {
          %18 = arith.addi %arg1, %15 : index
          scf.for %arg2 = %c0 to %c64 step %c1 {
            %19 = arith.addi %arg2, %16 : index
            %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
              %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
              %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
              %27 = vector.extract %26[0] : f32 from vector<4xf32>
              %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
              %29 = vector.extract %26[1] : f32 from vector<4xf32>
              %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
              %31 = vector.extract %26[2] : f32 from vector<4xf32>
              %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
              %33 = vector.extract %26[3] : f32 from vector<4xf32>
              %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
              %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
              %36 = vector.extract %25[0] : f32 from vector<4xf32>
              %37 = vector.broadcast %36 : f32 to vector<1xf32>
              %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
              %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
              %40 = vector.extract %25[1] : f32 from vector<4xf32>
              %41 = vector.broadcast %40 : f32 to vector<1xf32>
              %42 = vector.fma %39, %41, %38 : vector<1xf32>
              %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
              %44 = vector.extract %25[2] : f32 from vector<4xf32>
              %45 = vector.broadcast %44 : f32 to vector<1xf32>
              %46 = vector.fma %43, %45, %42 : vector<1xf32>
              %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
              %48 = vector.extract %25[3] : f32 from vector<4xf32>
              %49 = vector.broadcast %48 : f32 to vector<1xf32>
              %50 = vector.fma %47, %49, %46 : vector<1xf32>
              scf.yield %50 : vector<1xf32>
            }
            %21 = arith.mulf %20, %cst : vector<1xf32>
            %22 = vector.extract %21[0] : f32 from vector<1xf32>
            memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
        }
      }
      return
    }
  }
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After DropCompilerHintsPass (iree-util-drop-compiler-hints) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c20480 = arith.constant 20480 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c20480, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
      %0 = ub.poison : vector<4x1xf32>
      %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
      %c1 = arith.constant 1 : index
      %c4 = arith.constant 4 : index
      %c64 = arith.constant 64 : index
      %c0 = arith.constant 0 : index
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %c64_3 = arith.constant 64 : index
      %c4096 = arith.constant 4096 : index
      %c0_4 = arith.constant 0 : index
      %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
      %5 = arith.remsi %workgroup_id_x, %c4096 : index
      %6 = arith.cmpi slt, %5, %c0_4 : index
      %7 = arith.addi %5, %c4096 overflow<nsw> : index
      %8 = arith.select %6, %7, %5 : index
      %9 = arith.divsi %8, %c64_3 : index
      %10 = arith.remsi %workgroup_id_x, %c64_3 : index
      %11 = arith.cmpi slt, %10, %c0_4 : index
      %12 = arith.addi %10, %c64_3 overflow<nsw> : index
      %13 = arith.select %11, %12, %10 : index
      %c4_5 = arith.constant 4 : index
      %14 = arith.muli %4, %c4_5 overflow<nsw> : index
      %c64_6 = arith.constant 64 : index
      %15 = arith.muli %9, %c64_6 overflow<nsw> : index
      %c64_7 = arith.constant 64 : index
      %16 = arith.muli %13, %c64_7 overflow<nsw> : index
      %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32, #hal.descriptor_type<storage_buffer>> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg0 = %c0 to %c4 step %c1 {
        %17 = arith.addi %arg0, %14 : index
        scf.for %arg1 = %c0 to %c64 step %c1 {
          %18 = arith.addi %arg1, %15 : index
          scf.for %arg2 = %c0 to %c64 step %c1 {
            %19 = arith.addi %arg2, %16 : index
            %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
              %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16, #hal.descriptor_type<storage_buffer>>, vector<4xf16>
              %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
              %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
              %27 = vector.extract %26[0] : f32 from vector<4xf32>
              %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
              %29 = vector.extract %26[1] : f32 from vector<4xf32>
              %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
              %31 = vector.extract %26[2] : f32 from vector<4xf32>
              %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
              %33 = vector.extract %26[3] : f32 from vector<4xf32>
              %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
              %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
              %36 = vector.extract %25[0] : f32 from vector<4xf32>
              %37 = vector.broadcast %36 : f32 to vector<1xf32>
              %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
              %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
              %40 = vector.extract %25[1] : f32 from vector<4xf32>
              %41 = vector.broadcast %40 : f32 to vector<1xf32>
              %42 = vector.fma %39, %41, %38 : vector<1xf32>
              %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
              %44 = vector.extract %25[2] : f32 from vector<4xf32>
              %45 = vector.broadcast %44 : f32 to vector<1xf32>
              %46 = vector.fma %43, %45, %42 : vector<1xf32>
              %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
              %48 = vector.extract %25[3] : f32 from vector<4xf32>
              %49 = vector.broadcast %48 : f32 to vector<1xf32>
              %50 = vector.fma %47, %49, %46 : vector<1xf32>
              scf.yield %50 : vector<1xf32>
            }
            %21 = arith.mulf %20, %cst : vector<1xf32>
            %22 = vector.extract %21[0] : f32 from vector<1xf32>
            memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
        }
      }
      return
    }
  }
}

// -----// IR Dump After ConvertLinalgToLoopsPass (convert-linalg-to-loops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRefPass (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %c64_3 = arith.constant 64 : index
  %c4096 = arith.constant 4096 : index
  %c0_4 = arith.constant 0 : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0_4 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64_3 : index
  %10 = arith.remsi %workgroup_id_x, %c64_3 : index
  %11 = arith.cmpi slt, %10, %c0_4 : index
  %12 = arith.addi %10, %c64_3 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %c4_5 = arith.constant 4 : index
  %14 = arith.muli %4, %c4_5 overflow<nsw> : index
  %c64_6 = arith.constant 64 : index
  %15 = arith.muli %9, %c64_6 overflow<nsw> : index
  %c64_7 = arith.constant 64 : index
  %16 = arith.muli %13, %c64_7 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After ConvertBf16ArithToF32Pass (iree-convert-bf16-arith-to-f32) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After LowerUKernelOpsToCallsPass (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
    %0 = ub.poison : vector<4x1xf32>
    %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c64 = arith.constant 64 : index
    %c0 = arith.constant 0 : index
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
    %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
    %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
    %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %c64_3 = arith.constant 64 : index
    %c4096 = arith.constant 4096 : index
    %c0_4 = arith.constant 0 : index
    %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
    %5 = arith.remsi %workgroup_id_x, %c4096 : index
    %6 = arith.cmpi slt, %5, %c0_4 : index
    %7 = arith.addi %5, %c4096 overflow<nsw> : index
    %8 = arith.select %6, %7, %5 : index
    %9 = arith.divsi %8, %c64_3 : index
    %10 = arith.remsi %workgroup_id_x, %c64_3 : index
    %11 = arith.cmpi slt, %10, %c0_4 : index
    %12 = arith.addi %10, %c64_3 overflow<nsw> : index
    %13 = arith.select %11, %12, %10 : index
    %c4_5 = arith.constant 4 : index
    %14 = arith.muli %4, %c4_5 overflow<nsw> : index
    %c64_6 = arith.constant 64 : index
    %15 = arith.muli %9, %c64_6 overflow<nsw> : index
    %c64_7 = arith.constant 64 : index
    %16 = arith.muli %13, %c64_7 overflow<nsw> : index
    %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c4 step %c1 {
      %17 = arith.addi %arg0, %14 : index
      scf.for %arg1 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg1, %15 : index
        scf.for %arg2 = %c0 to %c64 step %c1 {
          %19 = arith.addi %arg2, %16 : index
          %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
            %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
            %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
            %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
            %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
            %27 = vector.extract %26[0] : f32 from vector<4xf32>
            %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
            %29 = vector.extract %26[1] : f32 from vector<4xf32>
            %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
            %31 = vector.extract %26[2] : f32 from vector<4xf32>
            %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
            %33 = vector.extract %26[3] : f32 from vector<4xf32>
            %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
            %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
            %36 = vector.extract %25[0] : f32 from vector<4xf32>
            %37 = vector.broadcast %36 : f32 to vector<1xf32>
            %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
            %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
            %40 = vector.extract %25[1] : f32 from vector<4xf32>
            %41 = vector.broadcast %40 : f32 to vector<1xf32>
            %42 = vector.fma %39, %41, %38 : vector<1xf32>
            %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
            %44 = vector.extract %25[2] : f32 from vector<4xf32>
            %45 = vector.broadcast %44 : f32 to vector<1xf32>
            %46 = vector.fma %43, %45, %42 : vector<1xf32>
            %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
            %48 = vector.extract %25[3] : f32 from vector<4xf32>
            %49 = vector.broadcast %48 : f32 to vector<1xf32>
            %50 = vector.fma %47, %49, %46 : vector<1xf32>
            scf.yield %50 : vector<1xf32>
          }
          %21 = arith.mulf %20, %cst : vector<1xf32>
          %22 = vector.extract %21[0] : f32 from vector<1xf32>
          memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After ConvertBf16ToUInt16BuffersPass (iree-codegen-convert-bf16-to-uint16-buffers) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After LinalgExtToLoopsPass (iree-linalg-ext-to-loops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64 : index
  %10 = arith.remsi %workgroup_id_x, %c64 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c64 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.muli %4, %c4 overflow<nsw> : index
  %15 = arith.muli %9, %c64 overflow<nsw> : index
  %16 = arith.muli %13, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64 : index
  %10 = arith.remsi %workgroup_id_x, %c64 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c64 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.muli %4, %c4 overflow<nsw> : index
  %15 = arith.muli %9, %c64 overflow<nsw> : index
  %16 = arith.muli %13, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After IREEBufferizeConstantsPass (iree-codegen-iree-bufferize-constants) //----- //
module {
  func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c64 = arith.constant 64 : index
    %c1342504960 = arith.constant 1342504960 : index
    %c1342177280 = arith.constant 1342177280 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
    %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
    %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
    %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
    %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c64 step %c1 {
      %4 = arith.addi %arg0, %3 : index
      %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
      scf.for %arg1 = %c0 to %c64 step %c4 {
        %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
        %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
        %8 = arith.divf %6, %7 : vector<4xf32>
        %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
        vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
      }
    }
    return
  }
}

// -----// IR Dump After ConvertLinalgToLoopsPass (convert-linalg-to-loops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64 : index
  %10 = arith.remsi %workgroup_id_x, %c64 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c64 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.muli %4, %c4 overflow<nsw> : index
  %15 = arith.muli %9, %c64 overflow<nsw> : index
  %16 = arith.muli %13, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After FoldTensorExtractOpPass (iree-codegen-fold-tensor-extract-op) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After ConvertBf16ArithToF32Pass (iree-convert-bf16-arith-to-f32) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64 : index
  %10 = arith.remsi %workgroup_id_x, %c64 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c64 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.muli %4, %c4 overflow<nsw> : index
  %15 = arith.muli %9, %c64 overflow<nsw> : index
  %16 = arith.muli %13, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After ConvertComplexToStandardPass (convert-complex-to-standard) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After ConvertBf16ToUInt16BuffersPass (iree-codegen-convert-bf16-to-uint16-buffers) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %0 = ub.poison : vector<4x1xf32>
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<20x4096x64xf16>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %3, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %5 = arith.remsi %workgroup_id_x, %c4096 : index
  %6 = arith.cmpi slt, %5, %c0 : index
  %7 = arith.addi %5, %c4096 overflow<nsw> : index
  %8 = arith.select %6, %7, %5 : index
  %9 = arith.divsi %8, %c64 : index
  %10 = arith.remsi %workgroup_id_x, %c64 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c64 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.muli %4, %c4 overflow<nsw> : index
  %15 = arith.muli %9, %c64 overflow<nsw> : index
  %16 = arith.muli %13, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%14, %15, %16] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %17 = arith.addi %arg0, %14 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %18 = arith.addi %arg1, %15 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %19 = arith.addi %arg2, %16 : index
        %20 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %23 = vector.load %assume_align[%17, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = vector.load %assume_align_1[%17, %19, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = arith.extf %24 : vector<4xf16> to vector<4xf32>
          %27 = vector.extract %26[0] : f32 from vector<4xf32>
          %28 = vector.insert %27, %0 [0, 0] : f32 into vector<4x1xf32>
          %29 = vector.extract %26[1] : f32 from vector<4xf32>
          %30 = vector.insert %29, %28 [1, 0] : f32 into vector<4x1xf32>
          %31 = vector.extract %26[2] : f32 from vector<4xf32>
          %32 = vector.insert %31, %30 [2, 0] : f32 into vector<4x1xf32>
          %33 = vector.extract %26[3] : f32 from vector<4xf32>
          %34 = vector.insert %33, %32 [3, 0] : f32 into vector<4x1xf32>
          %35 = vector.extract %34[0] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %25[0] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %arg4 : vector<1xf32>
          %39 = vector.extract %34[1] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %25[1] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          %43 = vector.extract %34[2] : vector<1xf32> from vector<4x1xf32>
          %44 = vector.extract %25[2] : f32 from vector<4xf32>
          %45 = vector.broadcast %44 : f32 to vector<1xf32>
          %46 = vector.fma %43, %45, %42 : vector<1xf32>
          %47 = vector.extract %34[3] : vector<1xf32> from vector<4x1xf32>
          %48 = vector.extract %25[3] : f32 from vector<4xf32>
          %49 = vector.broadcast %48 : f32 to vector<1xf32>
          %50 = vector.fma %47, %49, %46 : vector<1xf32>
          scf.yield %50 : vector<1xf32>
        }
        %21 = arith.mulf %20, %cst : vector<1xf32>
        %22 = vector.extract %21[0] : f32 from vector<1xf32>
        memref.store %22, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After MathTransformPass (iree-codegen-math-transform) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_1[%3, 0] [64, 64] [1, 1] : memref<81920x64xf16> to memref<64x64xf16, strided<[64, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      vector.store %9, %subview[%arg0, %arg1] : memref<64x64xf16, strided<[64, 1], offset: ?>>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After FoldMemRefAliasOpsPass (fold-memref-alias-ops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %arg0]
      vector.store %9, %assume_align_1[%10, %arg1] : memref<81920x64xf16>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After IREEExpandStridedMetadataPass (iree-codegen-expand-strided-metadata) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %arg0]
      vector.store %9, %assume_align_1[%10, %arg1] : memref<81920x64xf16>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After IREEBufferizeConstantsPass (iree-codegen-iree-bufferize-constants) //----- //
module {
  func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
    %c4096 = arith.constant 4096 : index
    %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c64 = arith.constant 64 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
    %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
    %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
    %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
    %4 = arith.remsi %workgroup_id_x, %c4096 : index
    %5 = arith.cmpi slt, %4, %c0 : index
    %6 = arith.addi %4, %c4096 overflow<nsw> : index
    %7 = arith.select %5, %6, %4 : index
    %8 = arith.divsi %7, %c64 : index
    %9 = arith.remsi %workgroup_id_x, %c64 : index
    %10 = arith.cmpi slt, %9, %c0 : index
    %11 = arith.addi %9, %c64 overflow<nsw> : index
    %12 = arith.select %10, %11, %9 : index
    %13 = arith.muli %3, %c4 overflow<nsw> : index
    %14 = arith.muli %8, %c64 overflow<nsw> : index
    %15 = arith.muli %12, %c64 overflow<nsw> : index
    %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c4 step %c1 {
      %16 = arith.addi %arg0, %13 : index
      scf.for %arg1 = %c0 to %c64 step %c1 {
        %17 = arith.addi %arg1, %14 : index
        scf.for %arg2 = %c0 to %c64 step %c1 {
          %18 = arith.addi %arg2, %15 : index
          %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
            %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
            %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
            %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
            %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
            %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
            %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
            %28 = vector.extract %24[0] : f32 from vector<4xf32>
            %29 = vector.broadcast %28 : f32 to vector<1xf32>
            %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
            %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
            %32 = vector.extract %24[1] : f32 from vector<4xf32>
            %33 = vector.broadcast %32 : f32 to vector<1xf32>
            %34 = vector.fma %31, %33, %30 : vector<1xf32>
            %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
            %36 = vector.extract %24[2] : f32 from vector<4xf32>
            %37 = vector.broadcast %36 : f32 to vector<1xf32>
            %38 = vector.fma %35, %37, %34 : vector<1xf32>
            %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
            %40 = vector.extract %24[3] : f32 from vector<4xf32>
            %41 = vector.broadcast %40 : f32 to vector<1xf32>
            %42 = vector.fma %39, %41, %38 : vector<1xf32>
            scf.yield %42 : vector<1xf32>
          }
          %20 = arith.mulf %19, %cst : vector<1xf32>
          %21 = vector.extract %20[0] : f32 from vector<1xf32>
          memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %arg0]
      vector.store %9, %assume_align_1[%10, %arg1] : memref<81920x64xf16>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After LLVMCPUCheckIRBeforeLLVMConversionPass (iree-llvmcpu-check-ir-before-llvm-conversion) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c64 step %c1 {
    %4 = arith.addi %arg0, %3 : index
    %5 = vector.load %assume_align_0[%4] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
    scf.for %arg1 = %c0 to %c64 step %c4 {
      %6 = vector.load %assume_align[%4, %arg1] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
      %7 = vector.broadcast %5 : vector<1xf32> to vector<4xf32>
      %8 = arith.divf %6, %7 : vector<4xf32>
      %9 = arith.truncf %8 : vector<4xf32> to vector<4xf16>
      %10 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %arg0]
      vector.store %9, %assume_align_1[%10, %arg1] : memref<81920x64xf16>, vector<4xf16>
    }
  }
  return
}

// -----// IR Dump After FoldTensorExtractOpPass (iree-codegen-fold-tensor-extract-op) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertComplexToStandardPass (convert-complex-to-standard) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After MathTransformPass (iree-codegen-math-transform) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After FoldMemRefAliasOpsPass (fold-memref-alias-ops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  %subview = memref.subview %assume_align_2[%13, %14, %15] [4, 64, 64] [1, 1, 1] : memref<20x4096x4096xf32> to memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %22 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %23 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %24 = arith.extf %22 : vector<4xf16> to vector<4xf32>
          %25 = arith.extf %23 : vector<4xf16> to vector<4xf32>
          %26 = vector.shape_cast %25 : vector<4xf32> to vector<4x1xf32>
          %27 = vector.extract %26[0] : vector<1xf32> from vector<4x1xf32>
          %28 = vector.extract %24[0] : f32 from vector<4xf32>
          %29 = vector.broadcast %28 : f32 to vector<1xf32>
          %30 = vector.fma %27, %29, %arg4 : vector<1xf32>
          %31 = vector.extract %26[1] : vector<1xf32> from vector<4x1xf32>
          %32 = vector.extract %24[1] : f32 from vector<4xf32>
          %33 = vector.broadcast %32 : f32 to vector<1xf32>
          %34 = vector.fma %31, %33, %30 : vector<1xf32>
          %35 = vector.extract %26[2] : vector<1xf32> from vector<4x1xf32>
          %36 = vector.extract %24[2] : f32 from vector<4xf32>
          %37 = vector.broadcast %36 : f32 to vector<1xf32>
          %38 = vector.fma %35, %37, %34 : vector<1xf32>
          %39 = vector.extract %26[3] : vector<1xf32> from vector<4x1xf32>
          %40 = vector.extract %24[3] : f32 from vector<4xf32>
          %41 = vector.broadcast %40 : f32 to vector<1xf32>
          %42 = vector.fma %39, %41, %38 : vector<1xf32>
          scf.yield %42 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        memref.store %21, %subview[%arg0, %arg1, %arg2] : memref<4x64x64xf32, strided<[16777216, 4096, 1], offset: ?>>
      }
    }
  }
  return
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After FoldMemRefAliasOpsPass (fold-memref-alias-ops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %25 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %26 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %27 = arith.extf %25 : vector<4xf16> to vector<4xf32>
          %28 = arith.extf %26 : vector<4xf16> to vector<4xf32>
          %29 = vector.shape_cast %28 : vector<4xf32> to vector<4x1xf32>
          %30 = vector.extract %29[0] : vector<1xf32> from vector<4x1xf32>
          %31 = vector.extract %27[0] : f32 from vector<4xf32>
          %32 = vector.broadcast %31 : f32 to vector<1xf32>
          %33 = vector.fma %30, %32, %arg4 : vector<1xf32>
          %34 = vector.extract %29[1] : vector<1xf32> from vector<4x1xf32>
          %35 = vector.extract %27[1] : f32 from vector<4xf32>
          %36 = vector.broadcast %35 : f32 to vector<1xf32>
          %37 = vector.fma %34, %36, %33 : vector<1xf32>
          %38 = vector.extract %29[2] : vector<1xf32> from vector<4x1xf32>
          %39 = vector.extract %27[2] : f32 from vector<4xf32>
          %40 = vector.broadcast %39 : f32 to vector<1xf32>
          %41 = vector.fma %38, %40, %37 : vector<1xf32>
          %42 = vector.extract %29[3] : vector<1xf32> from vector<4x1xf32>
          %43 = vector.extract %27[3] : f32 from vector<4xf32>
          %44 = vector.broadcast %43 : f32 to vector<1xf32>
          %45 = vector.fma %42, %44, %41 : vector<1xf32>
          scf.yield %45 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        %22 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %arg0]
        %23 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %arg1]
        %24 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %arg2]
        memref.store %21, %assume_align_2[%22, %23, %24] : memref<20x4096x4096xf32>
      }
    }
  }
  return
}

// -----// IR Dump After ArithExpandOpsPass (arith-expand) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After IREEExpandStridedMetadataPass (iree-codegen-expand-strided-metadata) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %25 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %26 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %27 = arith.extf %25 : vector<4xf16> to vector<4xf32>
          %28 = arith.extf %26 : vector<4xf16> to vector<4xf32>
          %29 = vector.shape_cast %28 : vector<4xf32> to vector<4x1xf32>
          %30 = vector.extract %29[0] : vector<1xf32> from vector<4x1xf32>
          %31 = vector.extract %27[0] : f32 from vector<4xf32>
          %32 = vector.broadcast %31 : f32 to vector<1xf32>
          %33 = vector.fma %30, %32, %arg4 : vector<1xf32>
          %34 = vector.extract %29[1] : vector<1xf32> from vector<4x1xf32>
          %35 = vector.extract %27[1] : f32 from vector<4xf32>
          %36 = vector.broadcast %35 : f32 to vector<1xf32>
          %37 = vector.fma %34, %36, %33 : vector<1xf32>
          %38 = vector.extract %29[2] : vector<1xf32> from vector<4x1xf32>
          %39 = vector.extract %27[2] : f32 from vector<4xf32>
          %40 = vector.broadcast %39 : f32 to vector<1xf32>
          %41 = vector.fma %38, %40, %37 : vector<1xf32>
          %42 = vector.extract %29[3] : vector<1xf32> from vector<4x1xf32>
          %43 = vector.extract %27[3] : f32 from vector<4xf32>
          %44 = vector.broadcast %43 : f32 to vector<1xf32>
          %45 = vector.fma %42, %44, %41 : vector<1xf32>
          scf.yield %45 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        %22 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %arg0]
        %23 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %arg1]
        %24 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %arg2]
        memref.store %21, %assume_align_2[%22, %23, %24] : memref<20x4096x4096xf32>
      }
    }
  }
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %25 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %26 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %27 = arith.extf %25 : vector<4xf16> to vector<4xf32>
          %28 = arith.extf %26 : vector<4xf16> to vector<4xf32>
          %29 = vector.shape_cast %28 : vector<4xf32> to vector<4x1xf32>
          %30 = vector.extract %29[0] : vector<1xf32> from vector<4x1xf32>
          %31 = vector.extract %27[0] : f32 from vector<4xf32>
          %32 = vector.broadcast %31 : f32 to vector<1xf32>
          %33 = vector.fma %30, %32, %arg4 : vector<1xf32>
          %34 = vector.extract %29[1] : vector<1xf32> from vector<4x1xf32>
          %35 = vector.extract %27[1] : f32 from vector<4xf32>
          %36 = vector.broadcast %35 : f32 to vector<1xf32>
          %37 = vector.fma %34, %36, %33 : vector<1xf32>
          %38 = vector.extract %29[2] : vector<1xf32> from vector<4x1xf32>
          %39 = vector.extract %27[2] : f32 from vector<4xf32>
          %40 = vector.broadcast %39 : f32 to vector<1xf32>
          %41 = vector.fma %38, %40, %37 : vector<1xf32>
          %42 = vector.extract %29[3] : vector<1xf32> from vector<4x1xf32>
          %43 = vector.extract %27[3] : f32 from vector<4xf32>
          %44 = vector.broadcast %43 : f32 to vector<1xf32>
          %45 = vector.fma %42, %44, %41 : vector<1xf32>
          scf.yield %45 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        %22 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %arg0]
        %23 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %arg1]
        %24 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %arg2]
        memref.store %21, %assume_align_2[%22, %23, %24] : memref<20x4096x4096xf32>
      }
    }
  }
  return
}

// -----// IR Dump After EmulateNarrowTypePass (iree-codegen-emulate-narrow-type) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After LLVMCPUCheckIRBeforeLLVMConversionPass (iree-llvmcpu-check-ir-before-llvm-conversion) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  scf.for %arg0 = %c0 to %c4 step %c1 {
    %16 = arith.addi %arg0, %13 : index
    scf.for %arg1 = %c0 to %c64 step %c1 {
      %17 = arith.addi %arg1, %14 : index
      scf.for %arg2 = %c0 to %c64 step %c1 {
        %18 = arith.addi %arg2, %15 : index
        %19 = scf.for %arg3 = %c0 to %c64 step %c4 iter_args(%arg4 = %cst_0) -> (vector<1xf32>) {
          %25 = vector.load %assume_align[%16, %17, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %26 = vector.load %assume_align_1[%16, %18, %arg3] : memref<20x4096x64xf16>, vector<4xf16>
          %27 = arith.extf %25 : vector<4xf16> to vector<4xf32>
          %28 = arith.extf %26 : vector<4xf16> to vector<4xf32>
          %29 = vector.shape_cast %28 : vector<4xf32> to vector<4x1xf32>
          %30 = vector.extract %29[0] : vector<1xf32> from vector<4x1xf32>
          %31 = vector.extract %27[0] : f32 from vector<4xf32>
          %32 = vector.broadcast %31 : f32 to vector<1xf32>
          %33 = vector.fma %30, %32, %arg4 : vector<1xf32>
          %34 = vector.extract %29[1] : vector<1xf32> from vector<4x1xf32>
          %35 = vector.extract %27[1] : f32 from vector<4xf32>
          %36 = vector.broadcast %35 : f32 to vector<1xf32>
          %37 = vector.fma %34, %36, %33 : vector<1xf32>
          %38 = vector.extract %29[2] : vector<1xf32> from vector<4x1xf32>
          %39 = vector.extract %27[2] : f32 from vector<4xf32>
          %40 = vector.broadcast %39 : f32 to vector<1xf32>
          %41 = vector.fma %38, %40, %37 : vector<1xf32>
          %42 = vector.extract %29[3] : vector<1xf32> from vector<4x1xf32>
          %43 = vector.extract %27[3] : f32 from vector<4xf32>
          %44 = vector.broadcast %43 : f32 to vector<1xf32>
          %45 = vector.fma %42, %44, %41 : vector<1xf32>
          scf.yield %45 : vector<1xf32>
        }
        %20 = arith.mulf %19, %cst : vector<1xf32>
        %21 = vector.extract %20[0] : f32 from vector<1xf32>
        %22 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %arg0]
        %23 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %arg1]
        %24 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %arg2]
        memref.store %21, %assume_align_2[%22, %23, %24] : memref<20x4096x4096xf32>
      }
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%16: index):  // 2 preds: ^bb0, ^bb11
  %17 = arith.cmpi slt, %16, %c4 : index
  cf.cond_br %17, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %18 = arith.addi %16, %13 : index
  cf.br ^bb3(%c0 : index)
^bb3(%19: index):  // 2 preds: ^bb2, ^bb10
  %20 = arith.cmpi slt, %19, %c64 : index
  cf.cond_br %20, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %21 = arith.addi %19, %14 : index
  cf.br ^bb5(%c0 : index)
^bb5(%22: index):  // 2 preds: ^bb4, ^bb9
  %23 = arith.cmpi slt, %22, %c64 : index
  cf.cond_br %23, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %24 = arith.addi %22, %15 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%25: index, %26: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %27 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %27, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %28 = vector.load %assume_align[%18, %21, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %29 = vector.load %assume_align_1[%18, %24, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %30 = arith.extf %28 : vector<4xf16> to vector<4xf32>
  %31 = arith.extf %29 : vector<4xf16> to vector<4xf32>
  %32 = vector.shape_cast %31 : vector<4xf32> to vector<4x1xf32>
  %33 = vector.extract %32[0] : vector<1xf32> from vector<4x1xf32>
  %34 = vector.extract %30[0] : f32 from vector<4xf32>
  %35 = vector.broadcast %34 : f32 to vector<1xf32>
  %36 = vector.fma %33, %35, %26 : vector<1xf32>
  %37 = vector.extract %32[1] : vector<1xf32> from vector<4x1xf32>
  %38 = vector.extract %30[1] : f32 from vector<4xf32>
  %39 = vector.broadcast %38 : f32 to vector<1xf32>
  %40 = vector.fma %37, %39, %36 : vector<1xf32>
  %41 = vector.extract %32[2] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %30[2] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %40 : vector<1xf32>
  %45 = vector.extract %32[3] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %30[3] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = arith.addi %25, %c4 : index
  cf.br ^bb7(%49, %48 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %50 = arith.mulf %26, %cst : vector<1xf32>
  %51 = vector.extract %50[0] : f32 from vector<1xf32>
  %52 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %16]
  %53 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %19]
  %54 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %22]
  memref.store %51, %assume_align_2[%52, %53, %54] : memref<20x4096x4096xf32>
  %55 = arith.addi %22, %c1 : index
  cf.br ^bb5(%55 : index)
^bb10:  // pred: ^bb5
  %56 = arith.addi %19, %c1 : index
  cf.br ^bb3(%56 : index)
^bb11:  // pred: ^bb3
  %57 = arith.addi %16, %c1 : index
  cf.br ^bb1(%57 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16() {
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c64 = arith.constant 64 : index
  %c1342504960 = arith.constant 1342504960 : index
  %c1342177280 = arith.constant 1342177280 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342504960) flags("ReadOnly|Indirect") : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %assume_align = memref.assume_alignment %0, 64 : memref<81920x64xf32, strided<[64, 1], offset: ?>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c1342177280) flags("ReadOnly|Indirect") : memref<81920xf32, strided<[1], offset: ?>>
  %assume_align_0 = memref.assume_alignment %1, 64 : memref<81920xf32, strided<[1], offset: ?>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<81920x64xf16>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<81920x64xf16>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.muli %workgroup_id_x, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
  %5 = arith.cmpi slt, %4, %c64 : index
  cf.cond_br %5, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %6 = arith.addi %4, %3 : index
  %7 = vector.load %assume_align_0[%6] : memref<81920xf32, strided<[1], offset: ?>>, vector<1xf32>
  cf.br ^bb3(%c0 : index)
^bb3(%8: index):  // 2 preds: ^bb2, ^bb4
  %9 = arith.cmpi slt, %8, %c64 : index
  cf.cond_br %9, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %10 = vector.load %assume_align[%6, %8] : memref<81920x64xf32, strided<[64, 1], offset: ?>>, vector<4xf32>
  %11 = vector.broadcast %7 : vector<1xf32> to vector<4xf32>
  %12 = arith.divf %10, %11 : vector<4xf32>
  %13 = arith.truncf %12 : vector<4xf32> to vector<4xf16>
  %14 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%3, %4]
  vector.store %13, %assume_align_1[%14, %8] : memref<81920x64xf16>, vector<4xf16>
  %15 = arith.addi %8, %c4 : index
  cf.br ^bb3(%15 : index)
^bb5:  // pred: ^bb3
  %16 = arith.addi %4, %c1 : index
  cf.br ^bb1(%16 : index)
^bb6:  // pred: ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%16: index):  // 2 preds: ^bb0, ^bb11
  %17 = arith.cmpi slt, %16, %c4 : index
  cf.cond_br %17, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %18 = arith.addi %16, %13 : index
  cf.br ^bb3(%c0 : index)
^bb3(%19: index):  // 2 preds: ^bb2, ^bb10
  %20 = arith.cmpi slt, %19, %c64 : index
  cf.cond_br %20, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %21 = arith.addi %19, %14 : index
  cf.br ^bb5(%c0 : index)
^bb5(%22: index):  // 2 preds: ^bb4, ^bb9
  %23 = arith.cmpi slt, %22, %c64 : index
  cf.cond_br %23, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %24 = arith.addi %22, %15 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%25: index, %26: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %27 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %27, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %28 = vector.load %assume_align[%18, %21, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %29 = vector.load %assume_align_1[%18, %24, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %30 = arith.extf %28 : vector<4xf16> to vector<4xf32>
  %31 = arith.extf %29 : vector<4xf16> to vector<4xf32>
  %32 = vector.shape_cast %31 : vector<4xf32> to vector<4x1xf32>
  %33 = vector.extract %32[0] : vector<1xf32> from vector<4x1xf32>
  %34 = vector.extract %30[0] : f32 from vector<4xf32>
  %35 = vector.broadcast %34 : f32 to vector<1xf32>
  %36 = vector.fma %33, %35, %26 : vector<1xf32>
  %37 = vector.extract %32[1] : vector<1xf32> from vector<4x1xf32>
  %38 = vector.extract %30[1] : f32 from vector<4xf32>
  %39 = vector.broadcast %38 : f32 to vector<1xf32>
  %40 = vector.fma %37, %39, %36 : vector<1xf32>
  %41 = vector.extract %32[2] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %30[2] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %40 : vector<1xf32>
  %45 = vector.extract %32[3] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %30[3] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = arith.addi %25, %c4 : index
  cf.br ^bb7(%49, %48 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %50 = arith.mulf %26, %cst : vector<1xf32>
  %51 = vector.extract %50[0] : f32 from vector<1xf32>
  %52 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %16]
  %53 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %19]
  %54 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %22]
  memref.store %51, %assume_align_2[%52, %53, %54] : memref<20x4096x4096xf32>
  %55 = arith.addi %22, %c1 : index
  cf.br ^bb5(%55 : index)
^bb10:  // pred: ^bb5
  %56 = arith.addi %19, %c1 : index
  cf.br ^bb3(%56 : index)
^bb11:  // pred: ^bb3
  %57 = arith.addi %16, %c1 : index
  cf.br ^bb1(%57 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%16: index):  // 2 preds: ^bb0, ^bb11
  %17 = arith.cmpi slt, %16, %c4 : index
  cf.cond_br %17, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %18 = arith.addi %16, %13 : index
  cf.br ^bb3(%c0 : index)
^bb3(%19: index):  // 2 preds: ^bb2, ^bb10
  %20 = arith.cmpi slt, %19, %c64 : index
  cf.cond_br %20, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %21 = arith.addi %19, %14 : index
  cf.br ^bb5(%c0 : index)
^bb5(%22: index):  // 2 preds: ^bb4, ^bb9
  %23 = arith.cmpi slt, %22, %c64 : index
  cf.cond_br %23, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %24 = arith.addi %22, %15 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%25: index, %26: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %27 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %27, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %28 = vector.load %assume_align[%18, %21, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %29 = vector.load %assume_align_1[%18, %24, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %30 = arith.extf %28 : vector<4xf16> to vector<4xf32>
  %31 = arith.extf %29 : vector<4xf16> to vector<4xf32>
  %32 = vector.shape_cast %31 : vector<4xf32> to vector<4x1xf32>
  %33 = vector.extract %32[0] : vector<1xf32> from vector<4x1xf32>
  %34 = vector.extract %30[0] : f32 from vector<4xf32>
  %35 = vector.broadcast %34 : f32 to vector<1xf32>
  %36 = vector.fma %33, %35, %26 : vector<1xf32>
  %37 = vector.extract %32[1] : vector<1xf32> from vector<4x1xf32>
  %38 = vector.extract %30[1] : f32 from vector<4xf32>
  %39 = vector.broadcast %38 : f32 to vector<1xf32>
  %40 = vector.fma %37, %39, %36 : vector<1xf32>
  %41 = vector.extract %32[2] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %30[2] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %40 : vector<1xf32>
  %45 = vector.extract %32[3] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %30[3] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = arith.addi %25, %c4 : index
  cf.br ^bb7(%49, %48 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %50 = arith.mulf %26, %cst : vector<1xf32>
  %51 = vector.extract %50[0] : f32 from vector<1xf32>
  %52 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %16]
  %53 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %19]
  %54 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %22]
  memref.store %51, %assume_align_2[%52, %53, %54] : memref<20x4096x4096xf32>
  %55 = arith.addi %22, %c1 : index
  cf.br ^bb5(%55 : index)
^bb10:  // pred: ^bb5
  %56 = arith.addi %19, %c1 : index
  cf.br ^bb3(%56 : index)
^bb11:  // pred: ^bb3
  %57 = arith.addi %16, %c1 : index
  cf.br ^bb1(%57 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After FoldMemRefAliasOpsPass (fold-memref-alias-ops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%16: index):  // 2 preds: ^bb0, ^bb11
  %17 = arith.cmpi slt, %16, %c4 : index
  cf.cond_br %17, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %18 = arith.addi %16, %13 : index
  cf.br ^bb3(%c0 : index)
^bb3(%19: index):  // 2 preds: ^bb2, ^bb10
  %20 = arith.cmpi slt, %19, %c64 : index
  cf.cond_br %20, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %21 = arith.addi %19, %14 : index
  cf.br ^bb5(%c0 : index)
^bb5(%22: index):  // 2 preds: ^bb4, ^bb9
  %23 = arith.cmpi slt, %22, %c64 : index
  cf.cond_br %23, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %24 = arith.addi %22, %15 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%25: index, %26: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %27 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %27, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %28 = vector.load %assume_align[%18, %21, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %29 = vector.load %assume_align_1[%18, %24, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %30 = arith.extf %28 : vector<4xf16> to vector<4xf32>
  %31 = arith.extf %29 : vector<4xf16> to vector<4xf32>
  %32 = vector.shape_cast %31 : vector<4xf32> to vector<4x1xf32>
  %33 = vector.extract %32[0] : vector<1xf32> from vector<4x1xf32>
  %34 = vector.extract %30[0] : f32 from vector<4xf32>
  %35 = vector.broadcast %34 : f32 to vector<1xf32>
  %36 = vector.fma %33, %35, %26 : vector<1xf32>
  %37 = vector.extract %32[1] : vector<1xf32> from vector<4x1xf32>
  %38 = vector.extract %30[1] : f32 from vector<4xf32>
  %39 = vector.broadcast %38 : f32 to vector<1xf32>
  %40 = vector.fma %37, %39, %36 : vector<1xf32>
  %41 = vector.extract %32[2] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %30[2] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %40 : vector<1xf32>
  %45 = vector.extract %32[3] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %30[3] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = arith.addi %25, %c4 : index
  cf.br ^bb7(%49, %48 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %50 = arith.mulf %26, %cst : vector<1xf32>
  %51 = vector.extract %50[0] : f32 from vector<1xf32>
  %52 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %16]
  %53 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %19]
  %54 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %22]
  memref.store %51, %assume_align_2[%52, %53, %54] : memref<20x4096x4096xf32>
  %55 = arith.addi %22, %c1 : index
  cf.br ^bb5(%55 : index)
^bb10:  // pred: ^bb5
  %56 = arith.addi %19, %c1 : index
  cf.br ^bb3(%56 : index)
^bb11:  // pred: ^bb3
  %57 = arith.addi %16, %c1 : index
  cf.br ^bb1(%57 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After AffineExpandIndexOps (affine-expand-index-ops) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.floordivsi %workgroup_id_x, %c4096 : index
  %4 = arith.remsi %workgroup_id_x, %c4096 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c4096 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = arith.divsi %7, %c64 : index
  %9 = arith.remsi %workgroup_id_x, %c64 : index
  %10 = arith.cmpi slt, %9, %c0 : index
  %11 = arith.addi %9, %c64 overflow<nsw> : index
  %12 = arith.select %10, %11, %9 : index
  %13 = arith.muli %3, %c4 overflow<nsw> : index
  %14 = arith.muli %8, %c64 overflow<nsw> : index
  %15 = arith.muli %12, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%16: index):  // 2 preds: ^bb0, ^bb11
  %17 = arith.cmpi slt, %16, %c4 : index
  cf.cond_br %17, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %18 = arith.addi %16, %13 : index
  cf.br ^bb3(%c0 : index)
^bb3(%19: index):  // 2 preds: ^bb2, ^bb10
  %20 = arith.cmpi slt, %19, %c64 : index
  cf.cond_br %20, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %21 = arith.addi %19, %14 : index
  cf.br ^bb5(%c0 : index)
^bb5(%22: index):  // 2 preds: ^bb4, ^bb9
  %23 = arith.cmpi slt, %22, %c64 : index
  cf.cond_br %23, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %24 = arith.addi %22, %15 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%25: index, %26: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %27 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %27, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %28 = vector.load %assume_align[%18, %21, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %29 = vector.load %assume_align_1[%18, %24, %25] : memref<20x4096x64xf16>, vector<4xf16>
  %30 = arith.extf %28 : vector<4xf16> to vector<4xf32>
  %31 = arith.extf %29 : vector<4xf16> to vector<4xf32>
  %32 = vector.shape_cast %31 : vector<4xf32> to vector<4x1xf32>
  %33 = vector.extract %32[0] : vector<1xf32> from vector<4x1xf32>
  %34 = vector.extract %30[0] : f32 from vector<4xf32>
  %35 = vector.broadcast %34 : f32 to vector<1xf32>
  %36 = vector.fma %33, %35, %26 : vector<1xf32>
  %37 = vector.extract %32[1] : vector<1xf32> from vector<4x1xf32>
  %38 = vector.extract %30[1] : f32 from vector<4xf32>
  %39 = vector.broadcast %38 : f32 to vector<1xf32>
  %40 = vector.fma %37, %39, %36 : vector<1xf32>
  %41 = vector.extract %32[2] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %30[2] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %40 : vector<1xf32>
  %45 = vector.extract %32[3] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %30[3] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = arith.addi %25, %c4 : index
  cf.br ^bb7(%49, %48 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %50 = arith.mulf %26, %cst : vector<1xf32>
  %51 = vector.extract %50[0] : f32 from vector<1xf32>
  %52 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%13, %16]
  %53 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%14, %19]
  %54 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%15, %22]
  memref.store %51, %assume_align_2[%52, %53, %54] : memref<20x4096x4096xf32>
  %55 = arith.addi %22, %c1 : index
  cf.br ^bb5(%55 : index)
^bb10:  // pred: ^bb5
  %56 = arith.addi %19, %c1 : index
  cf.br ^bb3(%56 : index)
^bb11:  // pred: ^bb3
  %57 = arith.addi %16, %c1 : index
  cf.br ^bb1(%57 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After ArithExpandOpsPass (arith-expand) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %c4096 = arith.constant 4096 : index
  %cst = arith.constant dense<1.250000e-01> : vector<1xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.divsi %workgroup_id_x, %c4096 : index
  %4 = arith.muli %3, %c4096 : index
  %5 = arith.cmpi ne, %workgroup_id_x, %4 : index
  %c0_3 = arith.constant 0 : index
  %6 = arith.cmpi slt, %workgroup_id_x, %c0_3 : index
  %7 = arith.cmpi slt, %c4096, %c0_3 : index
  %8 = arith.cmpi ne, %6, %7 : i1
  %9 = arith.andi %5, %8 : i1
  %c-1 = arith.constant -1 : index
  %10 = arith.addi %3, %c-1 : index
  %11 = arith.select %9, %10, %3 : index
  %12 = arith.remsi %workgroup_id_x, %c4096 : index
  %13 = arith.cmpi slt, %12, %c0 : index
  %14 = arith.addi %12, %c4096 overflow<nsw> : index
  %15 = arith.select %13, %14, %12 : index
  %16 = arith.divsi %15, %c64 : index
  %17 = arith.remsi %workgroup_id_x, %c64 : index
  %18 = arith.cmpi slt, %17, %c0 : index
  %19 = arith.addi %17, %c64 overflow<nsw> : index
  %20 = arith.select %18, %19, %17 : index
  %21 = arith.muli %11, %c4 overflow<nsw> : index
  %22 = arith.muli %16, %c64 overflow<nsw> : index
  %23 = arith.muli %20, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%24: index):  // 2 preds: ^bb0, ^bb11
  %25 = arith.cmpi slt, %24, %c4 : index
  cf.cond_br %25, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %26 = arith.addi %24, %21 : index
  cf.br ^bb3(%c0 : index)
^bb3(%27: index):  // 2 preds: ^bb2, ^bb10
  %28 = arith.cmpi slt, %27, %c64 : index
  cf.cond_br %28, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %29 = arith.addi %27, %22 : index
  cf.br ^bb5(%c0 : index)
^bb5(%30: index):  // 2 preds: ^bb4, ^bb9
  %31 = arith.cmpi slt, %30, %c64 : index
  cf.cond_br %31, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %32 = arith.addi %30, %23 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%33: index, %34: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %35 = arith.cmpi slt, %33, %c64 : index
  cf.cond_br %35, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %36 = vector.load %assume_align[%26, %29, %33] : memref<20x4096x64xf16>, vector<4xf16>
  %37 = vector.load %assume_align_1[%26, %32, %33] : memref<20x4096x64xf16>, vector<4xf16>
  %38 = arith.extf %36 : vector<4xf16> to vector<4xf32>
  %39 = arith.extf %37 : vector<4xf16> to vector<4xf32>
  %40 = vector.shape_cast %39 : vector<4xf32> to vector<4x1xf32>
  %41 = vector.extract %40[0] : vector<1xf32> from vector<4x1xf32>
  %42 = vector.extract %38[0] : f32 from vector<4xf32>
  %43 = vector.broadcast %42 : f32 to vector<1xf32>
  %44 = vector.fma %41, %43, %34 : vector<1xf32>
  %45 = vector.extract %40[1] : vector<1xf32> from vector<4x1xf32>
  %46 = vector.extract %38[1] : f32 from vector<4xf32>
  %47 = vector.broadcast %46 : f32 to vector<1xf32>
  %48 = vector.fma %45, %47, %44 : vector<1xf32>
  %49 = vector.extract %40[2] : vector<1xf32> from vector<4x1xf32>
  %50 = vector.extract %38[2] : f32 from vector<4xf32>
  %51 = vector.broadcast %50 : f32 to vector<1xf32>
  %52 = vector.fma %49, %51, %48 : vector<1xf32>
  %53 = vector.extract %40[3] : vector<1xf32> from vector<4x1xf32>
  %54 = vector.extract %38[3] : f32 from vector<4xf32>
  %55 = vector.broadcast %54 : f32 to vector<1xf32>
  %56 = vector.fma %53, %55, %52 : vector<1xf32>
  %57 = arith.addi %33, %c4 : index
  cf.br ^bb7(%57, %56 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %58 = arith.mulf %34, %cst : vector<1xf32>
  %59 = vector.extract %58[0] : f32 from vector<1xf32>
  %60 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%21, %24]
  %61 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%22, %27]
  %62 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%23, %30]
  memref.store %59, %assume_align_2[%60, %61, %62] : memref<20x4096x4096xf32>
  %63 = arith.addi %30, %c1 : index
  cf.br ^bb5(%63 : index)
^bb10:  // pred: ^bb5
  %64 = arith.addi %27, %c1 : index
  cf.br ^bb3(%64 : index)
^bb11:  // pred: ^bb3
  %65 = arith.addi %24, %c1 : index
  cf.br ^bb1(%65 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After EmulateNarrowTypePass (iree-codegen-emulate-narrow-type) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 1.250000e-01 : f32
  %c-1 = arith.constant -1 : index
  %c4096 = arith.constant 4096 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.divsi %workgroup_id_x, %c4096 : index
  %4 = arith.muli %3, %c4096 : index
  %5 = arith.cmpi ne, %workgroup_id_x, %4 : index
  %6 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %7 = arith.andi %5, %6 : i1
  %8 = arith.addi %3, %c-1 : index
  %9 = arith.select %7, %8, %3 : index
  %10 = arith.remsi %workgroup_id_x, %c4096 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c4096 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.divsi %13, %c64 : index
  %15 = arith.remsi %workgroup_id_x, %c64 : index
  %16 = arith.cmpi slt, %15, %c0 : index
  %17 = arith.addi %15, %c64 overflow<nsw> : index
  %18 = arith.select %16, %17, %15 : index
  %19 = arith.muli %9, %c4 overflow<nsw> : index
  %20 = arith.muli %14, %c64 overflow<nsw> : index
  %21 = arith.muli %18, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%22: index):  // 2 preds: ^bb0, ^bb11
  %23 = arith.cmpi slt, %22, %c4 : index
  cf.cond_br %23, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %24 = arith.addi %22, %19 : index
  cf.br ^bb3(%c0 : index)
^bb3(%25: index):  // 2 preds: ^bb2, ^bb10
  %26 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %26, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %27 = arith.addi %25, %20 : index
  cf.br ^bb5(%c0 : index)
^bb5(%28: index):  // 2 preds: ^bb4, ^bb9
  %29 = arith.cmpi slt, %28, %c64 : index
  cf.cond_br %29, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %30 = arith.addi %28, %21 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%31: index, %32: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %33 = arith.cmpi slt, %31, %c64 : index
  cf.cond_br %33, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %34 = vector.load %assume_align[%24, %27, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %35 = vector.load %assume_align_1[%24, %30, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %36 = arith.extf %34 : vector<4xf16> to vector<4xf32>
  %37 = arith.extf %35 : vector<4xf16> to vector<4xf32>
  %38 = vector.shape_cast %37 : vector<4xf32> to vector<4x1xf32>
  %39 = vector.extract %38[0] : vector<1xf32> from vector<4x1xf32>
  %40 = vector.extract %36[0] : f32 from vector<4xf32>
  %41 = vector.broadcast %40 : f32 to vector<1xf32>
  %42 = vector.fma %39, %41, %32 : vector<1xf32>
  %43 = vector.extract %38[1] : vector<1xf32> from vector<4x1xf32>
  %44 = vector.extract %36[1] : f32 from vector<4xf32>
  %45 = vector.broadcast %44 : f32 to vector<1xf32>
  %46 = vector.fma %43, %45, %42 : vector<1xf32>
  %47 = vector.extract %38[2] : vector<1xf32> from vector<4x1xf32>
  %48 = vector.extract %36[2] : f32 from vector<4xf32>
  %49 = vector.broadcast %48 : f32 to vector<1xf32>
  %50 = vector.fma %47, %49, %46 : vector<1xf32>
  %51 = vector.extract %38[3] : vector<1xf32> from vector<4x1xf32>
  %52 = vector.extract %36[3] : f32 from vector<4xf32>
  %53 = vector.broadcast %52 : f32 to vector<1xf32>
  %54 = vector.fma %51, %53, %50 : vector<1xf32>
  %55 = arith.addi %31, %c4 : index
  cf.br ^bb7(%55, %54 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %56 = vector.extract %32[0] : f32 from vector<1xf32>
  %57 = arith.mulf %56, %cst : f32
  %58 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%19, %22]
  %59 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%20, %25]
  %60 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%21, %28]
  memref.store %57, %assume_align_2[%58, %59, %60] : memref<20x4096x4096xf32>
  %61 = arith.addi %28, %c1 : index
  cf.br ^bb5(%61 : index)
^bb10:  // pred: ^bb5
  %62 = arith.addi %25, %c1 : index
  cf.br ^bb3(%62 : index)
^bb11:  // pred: ^bb3
  %63 = arith.addi %22, %c1 : index
  cf.br ^bb1(%63 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 1.250000e-01 : f32
  %c-1 = arith.constant -1 : index
  %c4096 = arith.constant 4096 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.divsi %workgroup_id_x, %c4096 : index
  %4 = arith.muli %3, %c4096 : index
  %5 = arith.cmpi ne, %workgroup_id_x, %4 : index
  %6 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %7 = arith.andi %5, %6 : i1
  %8 = arith.addi %3, %c-1 : index
  %9 = arith.select %7, %8, %3 : index
  %10 = arith.remsi %workgroup_id_x, %c4096 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c4096 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.divsi %13, %c64 : index
  %15 = arith.remsi %workgroup_id_x, %c64 : index
  %16 = arith.cmpi slt, %15, %c0 : index
  %17 = arith.addi %15, %c64 overflow<nsw> : index
  %18 = arith.select %16, %17, %15 : index
  %19 = arith.muli %9, %c4 overflow<nsw> : index
  %20 = arith.muli %14, %c64 overflow<nsw> : index
  %21 = arith.muli %18, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%22: index):  // 2 preds: ^bb0, ^bb11
  %23 = arith.cmpi slt, %22, %c4 : index
  cf.cond_br %23, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %24 = arith.addi %22, %19 : index
  cf.br ^bb3(%c0 : index)
^bb3(%25: index):  // 2 preds: ^bb2, ^bb10
  %26 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %26, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %27 = arith.addi %25, %20 : index
  cf.br ^bb5(%c0 : index)
^bb5(%28: index):  // 2 preds: ^bb4, ^bb9
  %29 = arith.cmpi slt, %28, %c64 : index
  cf.cond_br %29, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %30 = arith.addi %28, %21 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%31: index, %32: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %33 = arith.cmpi slt, %31, %c64 : index
  cf.cond_br %33, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %34 = vector.load %assume_align[%24, %27, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %35 = vector.load %assume_align_1[%24, %30, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %36 = arith.extf %34 : vector<4xf16> to vector<4xf32>
  %37 = arith.extf %35 : vector<4xf16> to vector<4xf32>
  %38 = vector.shape_cast %37 : vector<4xf32> to vector<4x1xf32>
  %39 = vector.extract %38[0] : vector<1xf32> from vector<4x1xf32>
  %40 = vector.extract %36[0] : f32 from vector<4xf32>
  %41 = vector.broadcast %40 : f32 to vector<1xf32>
  %42 = vector.fma %39, %41, %32 : vector<1xf32>
  %43 = vector.extract %38[1] : vector<1xf32> from vector<4x1xf32>
  %44 = vector.extract %36[1] : f32 from vector<4xf32>
  %45 = vector.broadcast %44 : f32 to vector<1xf32>
  %46 = vector.fma %43, %45, %42 : vector<1xf32>
  %47 = vector.extract %38[2] : vector<1xf32> from vector<4x1xf32>
  %48 = vector.extract %36[2] : f32 from vector<4xf32>
  %49 = vector.broadcast %48 : f32 to vector<1xf32>
  %50 = vector.fma %47, %49, %46 : vector<1xf32>
  %51 = vector.extract %38[3] : vector<1xf32> from vector<4x1xf32>
  %52 = vector.extract %36[3] : f32 from vector<4xf32>
  %53 = vector.broadcast %52 : f32 to vector<1xf32>
  %54 = vector.fma %51, %53, %50 : vector<1xf32>
  %55 = arith.addi %31, %c4 : index
  cf.br ^bb7(%55, %54 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %56 = vector.extract %32[0] : f32 from vector<1xf32>
  %57 = arith.mulf %56, %cst : f32
  %58 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%19, %22]
  %59 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%20, %25]
  %60 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%21, %28]
  memref.store %57, %assume_align_2[%58, %59, %60] : memref<20x4096x4096xf32>
  %61 = arith.addi %28, %c1 : index
  cf.br ^bb5(%61 : index)
^bb10:  // pred: ^bb5
  %62 = arith.addi %25, %c1 : index
  cf.br ^bb3(%62 : index)
^bb11:  // pred: ^bb3
  %63 = arith.addi %22, %c1 : index
  cf.br ^bb1(%63 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32() {
  %cst = arith.constant 1.250000e-01 : f32
  %c-1 = arith.constant -1 : index
  %c4096 = arith.constant 4096 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c64 = arith.constant 64 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align = memref.assume_alignment %0, 64 : memref<20x4096x64xf16>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<20x4096x64xf16>
  %assume_align_1 = memref.assume_alignment %1, 64 : memref<20x4096x64xf16>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(2) alignment(64) offset(%c0) flags(Indirect) : memref<20x4096x4096xf32>
  %assume_align_2 = memref.assume_alignment %2, 64 : memref<20x4096x4096xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %3 = arith.divsi %workgroup_id_x, %c4096 : index
  %4 = arith.muli %3, %c4096 : index
  %5 = arith.cmpi ne, %workgroup_id_x, %4 : index
  %6 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %7 = arith.andi %5, %6 : i1
  %8 = arith.addi %3, %c-1 : index
  %9 = arith.select %7, %8, %3 : index
  %10 = arith.remsi %workgroup_id_x, %c4096 : index
  %11 = arith.cmpi slt, %10, %c0 : index
  %12 = arith.addi %10, %c4096 overflow<nsw> : index
  %13 = arith.select %11, %12, %10 : index
  %14 = arith.divsi %13, %c64 : index
  %15 = arith.remsi %workgroup_id_x, %c64 : index
  %16 = arith.cmpi slt, %15, %c0 : index
  %17 = arith.addi %15, %c64 overflow<nsw> : index
  %18 = arith.select %16, %17, %15 : index
  %19 = arith.muli %9, %c4 overflow<nsw> : index
  %20 = arith.muli %14, %c64 overflow<nsw> : index
  %21 = arith.muli %18, %c64 overflow<nsw> : index
  cf.br ^bb1(%c0 : index)
^bb1(%22: index):  // 2 preds: ^bb0, ^bb11
  %23 = arith.cmpi slt, %22, %c4 : index
  cf.cond_br %23, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %24 = arith.addi %22, %19 : index
  cf.br ^bb3(%c0 : index)
^bb3(%25: index):  // 2 preds: ^bb2, ^bb10
  %26 = arith.cmpi slt, %25, %c64 : index
  cf.cond_br %26, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %27 = arith.addi %25, %20 : index
  cf.br ^bb5(%c0 : index)
^bb5(%28: index):  // 2 preds: ^bb4, ^bb9
  %29 = arith.cmpi slt, %28, %c64 : index
  cf.cond_br %29, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %30 = arith.addi %28, %21 : index
  cf.br ^bb7(%c0, %cst_0 : index, vector<1xf32>)
^bb7(%31: index, %32: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %33 = arith.cmpi slt, %31, %c64 : index
  cf.cond_br %33, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %34 = vector.load %assume_align[%24, %27, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %35 = vector.load %assume_align_1[%24, %30, %31] : memref<20x4096x64xf16>, vector<4xf16>
  %36 = arith.extf %34 : vector<4xf16> to vector<4xf32>
  %37 = arith.extf %35 : vector<4xf16> to vector<4xf32>
  %38 = vector.shape_cast %37 : vector<4xf32> to vector<4x1xf32>
  %39 = vector.extract %38[0] : vector<1xf32> from vector<4x1xf32>
  %40 = vector.extract %36[0] : f32 from vector<4xf32>
  %41 = vector.broadcast %40 : f32 to vector<1xf32>
  %42 = vector.fma %39, %41, %32 : vector<1xf32>
  %43 = vector.extract %38[1] : vector<1xf32> from vector<4x1xf32>
  %44 = vector.extract %36[1] : f32 from vector<4xf32>
  %45 = vector.broadcast %44 : f32 to vector<1xf32>
  %46 = vector.fma %43, %45, %42 : vector<1xf32>
  %47 = vector.extract %38[2] : vector<1xf32> from vector<4x1xf32>
  %48 = vector.extract %36[2] : f32 from vector<4xf32>
  %49 = vector.broadcast %48 : f32 to vector<1xf32>
  %50 = vector.fma %47, %49, %46 : vector<1xf32>
  %51 = vector.extract %38[3] : vector<1xf32> from vector<4x1xf32>
  %52 = vector.extract %36[3] : f32 from vector<4xf32>
  %53 = vector.broadcast %52 : f32 to vector<1xf32>
  %54 = vector.fma %51, %53, %50 : vector<1xf32>
  %55 = arith.addi %31, %c4 : index
  cf.br ^bb7(%55, %54 : index, vector<1xf32>)
^bb9:  // pred: ^bb7
  %56 = vector.extract %32[0] : f32 from vector<1xf32>
  %57 = arith.mulf %56, %cst : f32
  %58 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%19, %22]
  %59 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%20, %25]
  %60 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%21, %28]
  memref.store %57, %assume_align_2[%58, %59, %60] : memref<20x4096x4096xf32>
  %61 = arith.addi %28, %c1 : index
  cf.br ^bb5(%61 : index)
^bb10:  // pred: ^bb5
  %62 = arith.addi %25, %c1 : index
  cf.br ^bb3(%62 : index)
^bb11:  // pred: ^bb3
  %63 = arith.addi %22, %c1 : index
  cf.br ^bb1(%63 : index)
^bb12:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertToLLVMPass (iree-convert-to-llvm) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<4xf32>
    %2 = llvm.mlir.constant(0 : i64) : i64
    %3 = llvm.mlir.constant(true) : i1
    %4 = llvm.mlir.constant(8 : i64) : i64
    %5 = llvm.mlir.constant(32 : i64) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(64 : index) : i64
    %9 = llvm.mlir.constant(1342504960 : index) : i64
    %10 = llvm.mlir.constant(1342177280 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
    %15 = llvm.mul %9, %4 : i64
    %16 = llvm.udiv %15, %5 : i64
    %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
    %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
    %21 = llvm.mul %10, %4 : i64
    %22 = llvm.udiv %21, %5 : i64
    %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.mul %30, %8 overflow<nsw> : i64
    llvm.br ^bb1(%11 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
    %33 = llvm.icmp "slt" %32, %8 : i64
    llvm.cond_br %33, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %34 = llvm.add %32, %31 : i64
    %35 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %36 = llvm.getelementptr %35[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %37 = llvm.load %36 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
    llvm.br ^bb3(%11 : i64)
  ^bb3(%38: i64):  // 2 preds: ^bb2, ^bb4
    %39 = llvm.icmp "slt" %38, %8 : i64
    llvm.cond_br %39, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %40 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %41 = llvm.mul %34, %8 : i64
    %42 = llvm.add %41, %38 : i64
    %43 = llvm.getelementptr %40[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %44 = llvm.load %43 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
    %45 = llvm.extractelement %37[%2 : i64] : vector<1xf32>
    %46 = llvm.insertelement %45, %1[%0 : i32] : vector<4xf32>
    %47 = llvm.shufflevector %46, %1 [0, 0, 0, 0] : vector<4xf32>
    %48 = llvm.fdiv %44, %47 : vector<4xf32>
    %49 = llvm.fptrunc %48 : vector<4xf32> to vector<4xf16>
    %50 = llvm.add %31, %32 : i64
    %51 = llvm.mul %50, %8 : i64
    %52 = llvm.add %51, %38 : i64
    %53 = llvm.getelementptr %27[%52] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    llvm.store %49, %53 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
    %54 = llvm.add %38, %6 : i64
    llvm.br ^bb3(%54 : i64)
  ^bb5:  // pred: ^bb3
    %55 = llvm.add %32, %7 : i64
    llvm.br ^bb1(%55 : i64)
  ^bb6:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After ReconcileUnrealizedCastsPass (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<4xf32>
    %2 = llvm.mlir.constant(0 : i64) : i64
    %3 = llvm.mlir.constant(true) : i1
    %4 = llvm.mlir.constant(8 : i64) : i64
    %5 = llvm.mlir.constant(32 : i64) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(64 : index) : i64
    %9 = llvm.mlir.constant(1342504960 : index) : i64
    %10 = llvm.mlir.constant(1342177280 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
    %15 = llvm.mul %9, %4 : i64
    %16 = llvm.udiv %15, %5 : i64
    %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
    %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
    %21 = llvm.mul %10, %4 : i64
    %22 = llvm.udiv %21, %5 : i64
    %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.mul %30, %8 overflow<nsw> : i64
    llvm.br ^bb1(%11 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
    %33 = llvm.icmp "slt" %32, %8 : i64
    llvm.cond_br %33, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %34 = llvm.add %32, %31 : i64
    %35 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %36 = llvm.getelementptr %35[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %37 = llvm.load %36 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
    llvm.br ^bb3(%11 : i64)
  ^bb3(%38: i64):  // 2 preds: ^bb2, ^bb4
    %39 = llvm.icmp "slt" %38, %8 : i64
    llvm.cond_br %39, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %40 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %41 = llvm.mul %34, %8 : i64
    %42 = llvm.add %41, %38 : i64
    %43 = llvm.getelementptr %40[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %44 = llvm.load %43 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
    %45 = llvm.extractelement %37[%2 : i64] : vector<1xf32>
    %46 = llvm.insertelement %45, %1[%0 : i32] : vector<4xf32>
    %47 = llvm.shufflevector %46, %1 [0, 0, 0, 0] : vector<4xf32>
    %48 = llvm.fdiv %44, %47 : vector<4xf32>
    %49 = llvm.fptrunc %48 : vector<4xf32> to vector<4xf16>
    %50 = llvm.add %31, %32 : i64
    %51 = llvm.mul %50, %8 : i64
    %52 = llvm.add %51, %38 : i64
    %53 = llvm.getelementptr %27[%52] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    llvm.store %49, %53 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
    %54 = llvm.add %38, %6 : i64
    llvm.br ^bb3(%54 : i64)
  ^bb5:  // pred: ^bb3
    %55 = llvm.add %32, %7 : i64
    llvm.br ^bb1(%55 : i64)
  ^bb6:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After LLVMCPUSynchronizeSymbolVisibilityPass (iree-llvmcpu-synchronize-symbol-visibility) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<4xf32>
    %2 = llvm.mlir.constant(0 : i64) : i64
    %3 = llvm.mlir.constant(true) : i1
    %4 = llvm.mlir.constant(8 : i64) : i64
    %5 = llvm.mlir.constant(32 : i64) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(64 : index) : i64
    %9 = llvm.mlir.constant(1342504960 : index) : i64
    %10 = llvm.mlir.constant(1342177280 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
    %15 = llvm.mul %9, %4 : i64
    %16 = llvm.udiv %15, %5 : i64
    %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
    %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
    %21 = llvm.mul %10, %4 : i64
    %22 = llvm.udiv %21, %5 : i64
    %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.mul %30, %8 overflow<nsw> : i64
    llvm.br ^bb1(%11 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
    %33 = llvm.icmp "slt" %32, %8 : i64
    llvm.cond_br %33, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %34 = llvm.add %32, %31 : i64
    %35 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %36 = llvm.getelementptr %35[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %37 = llvm.load %36 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
    llvm.br ^bb3(%11 : i64)
  ^bb3(%38: i64):  // 2 preds: ^bb2, ^bb4
    %39 = llvm.icmp "slt" %38, %8 : i64
    llvm.cond_br %39, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %40 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %41 = llvm.mul %34, %8 : i64
    %42 = llvm.add %41, %38 : i64
    %43 = llvm.getelementptr %40[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %44 = llvm.load %43 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
    %45 = llvm.extractelement %37[%2 : i64] : vector<1xf32>
    %46 = llvm.insertelement %45, %1[%0 : i32] : vector<4xf32>
    %47 = llvm.shufflevector %46, %1 [0, 0, 0, 0] : vector<4xf32>
    %48 = llvm.fdiv %44, %47 : vector<4xf32>
    %49 = llvm.fptrunc %48 : vector<4xf32> to vector<4xf16>
    %50 = llvm.add %31, %32 : i64
    %51 = llvm.mul %50, %8 : i64
    %52 = llvm.add %51, %38 : i64
    %53 = llvm.getelementptr %27[%52] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    llvm.store %49, %53 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
    %54 = llvm.add %38, %6 : i64
    llvm.br ^bb3(%54 : i64)
  ^bb5:  // pred: ^bb3
    %55 = llvm.add %32, %7 : i64
    llvm.br ^bb1(%55 : i64)
  ^bb6:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<4xf32>
    %2 = llvm.mlir.constant(0 : i64) : i64
    %3 = llvm.mlir.constant(true) : i1
    %4 = llvm.mlir.constant(8 : i64) : i64
    %5 = llvm.mlir.constant(32 : i64) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(64 : index) : i64
    %9 = llvm.mlir.constant(1342504960 : index) : i64
    %10 = llvm.mlir.constant(1342177280 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
    %15 = llvm.mul %9, %4 : i64
    %16 = llvm.udiv %15, %5 : i64
    %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
    %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
    %21 = llvm.mul %10, %4 : i64
    %22 = llvm.udiv %21, %5 : i64
    %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.mul %30, %8 overflow<nsw> : i64
    llvm.br ^bb1(%11 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
    %33 = llvm.icmp "slt" %32, %8 : i64
    llvm.cond_br %33, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %34 = llvm.add %32, %31 : i64
    %35 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %36 = llvm.getelementptr %35[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %37 = llvm.load %36 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
    llvm.br ^bb3(%11 : i64)
  ^bb3(%38: i64):  // 2 preds: ^bb2, ^bb4
    %39 = llvm.icmp "slt" %38, %8 : i64
    llvm.cond_br %39, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %40 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %41 = llvm.mul %34, %8 : i64
    %42 = llvm.add %41, %38 : i64
    %43 = llvm.getelementptr %40[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %44 = llvm.load %43 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
    %45 = llvm.extractelement %37[%2 : i64] : vector<1xf32>
    %46 = llvm.insertelement %45, %1[%0 : i32] : vector<4xf32>
    %47 = llvm.shufflevector %46, %1 [0, 0, 0, 0] : vector<4xf32>
    %48 = llvm.fdiv %44, %47 : vector<4xf32>
    %49 = llvm.fptrunc %48 : vector<4xf32> to vector<4xf16>
    %50 = llvm.add %31, %32 : i64
    %51 = llvm.mul %50, %8 : i64
    %52 = llvm.add %51, %38 : i64
    %53 = llvm.getelementptr %27[%52] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    llvm.store %49, %53 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
    %54 = llvm.add %38, %6 : i64
    llvm.br ^bb3(%54 : i64)
  ^bb5:  // pred: ^bb3
    %55 = llvm.add %32, %7 : i64
    llvm.br ^bb1(%55 : i64)
  ^bb6:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After ConvertToLLVMPass (iree-convert-to-llvm) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<1xf32>
    %2 = llvm.mlir.constant(3 : i64) : i64
    %3 = llvm.mlir.constant(2 : i64) : i64
    %4 = llvm.mlir.constant(1 : i64) : i64
    %5 = llvm.mlir.constant(0 : i64) : i64
    %6 = llvm.mlir.constant(16777216 : index) : i64
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(262144 : index) : i64
    %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(4096 : index) : i64
    %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.mlir.constant(4 : index) : i64
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.mlir.constant(0 : index) : i64
    %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.sdiv %30, %11 : i64
    %32 = llvm.mul %31, %11 : i64
    %33 = llvm.icmp "ne" %30, %32 : i64
    %34 = llvm.icmp "slt" %30, %16 : i64
    %35 = llvm.and %33, %34 : i1
    %36 = llvm.add %31, %10 : i64
    %37 = llvm.select %35, %36, %31 : i1, i64
    %38 = llvm.srem %30, %11 : i64
    %39 = llvm.icmp "slt" %38, %16 : i64
    %40 = llvm.add %38, %11 overflow<nsw> : i64
    %41 = llvm.select %39, %40, %38 : i1, i64
    %42 = llvm.sdiv %41, %15 : i64
    %43 = llvm.srem %30, %15 : i64
    %44 = llvm.icmp "slt" %43, %16 : i64
    %45 = llvm.add %43, %15 overflow<nsw> : i64
    %46 = llvm.select %44, %45, %43 : i1, i64
    %47 = llvm.mul %37, %14 overflow<nsw> : i64
    %48 = llvm.mul %42, %15 overflow<nsw> : i64
    %49 = llvm.mul %46, %15 overflow<nsw> : i64
    llvm.br ^bb1(%16 : i64)
  ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
    %51 = llvm.icmp "slt" %50, %14 : i64
    llvm.cond_br %51, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %52 = llvm.add %50, %47 : i64
    llvm.br ^bb3(%16 : i64)
  ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
    %54 = llvm.icmp "slt" %53, %15 : i64
    llvm.cond_br %54, ^bb4, ^bb11
  ^bb4:  // pred: ^bb3
    %55 = llvm.add %53, %48 : i64
    llvm.br ^bb5(%16 : i64)
  ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
    %57 = llvm.icmp "slt" %56, %15 : i64
    llvm.cond_br %57, ^bb6, ^bb10
  ^bb6:  // pred: ^bb5
    %58 = llvm.add %56, %49 : i64
    llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
  ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
    %61 = llvm.icmp "slt" %59, %15 : i64
    llvm.cond_br %61, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %62 = llvm.mul %52, %8 : i64
    %63 = llvm.mul %55, %15 : i64
    %64 = llvm.add %62, %63 : i64
    %65 = llvm.add %64, %59 : i64
    %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %68 = llvm.mul %52, %8 : i64
    %69 = llvm.mul %58, %15 : i64
    %70 = llvm.add %68, %69 : i64
    %71 = llvm.add %70, %59 : i64
    %72 = llvm.getelementptr %23[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %73 = llvm.load %72 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %74 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
    %75 = llvm.fpext %73 : vector<4xf16> to vector<4xf32>
    %76 = llvm.extractelement %75[%5 : i64] : vector<4xf32>
    %77 = llvm.insertelement %76, %1[%5 : i64] : vector<1xf32>
    %78 = llvm.extractelement %75[%4 : i64] : vector<4xf32>
    %79 = llvm.insertelement %78, %1[%5 : i64] : vector<1xf32>
    %80 = llvm.extractelement %75[%3 : i64] : vector<4xf32>
    %81 = llvm.insertelement %80, %1[%5 : i64] : vector<1xf32>
    %82 = llvm.extractelement %75[%2 : i64] : vector<4xf32>
    %83 = llvm.insertelement %82, %1[%5 : i64] : vector<1xf32>
    %84 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
    %85 = llvm.insertelement %84, %1[%0 : i32] : vector<1xf32>
    %86 = llvm.intr.fmuladd(%77, %85, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %87 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
    %88 = llvm.insertelement %87, %1[%0 : i32] : vector<1xf32>
    %89 = llvm.intr.fmuladd(%79, %88, %86) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %90 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
    %91 = llvm.insertelement %90, %1[%0 : i32] : vector<1xf32>
    %92 = llvm.intr.fmuladd(%81, %91, %89) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %93 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
    %94 = llvm.insertelement %93, %1[%0 : i32] : vector<1xf32>
    %95 = llvm.intr.fmuladd(%83, %94, %92) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %96 = llvm.add %59, %14 : i64
    llvm.br ^bb7(%96, %95 : i64, vector<1xf32>)
  ^bb9:  // pred: ^bb7
    %97 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
    %98 = llvm.fmul %97, %9 : f32
    %99 = llvm.add %47, %50 : i64
    %100 = llvm.add %48, %53 : i64
    %101 = llvm.add %49, %56 : i64
    %102 = llvm.mul %99, %6 overflow<nsw, nuw> : i64
    %103 = llvm.mul %100, %11 overflow<nsw, nuw> : i64
    %104 = llvm.add %102, %103 overflow<nsw, nuw> : i64
    %105 = llvm.add %104, %101 overflow<nsw, nuw> : i64
    %106 = llvm.getelementptr inbounds|nuw %27[%105] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %98, %106 : f32, !llvm.ptr
    %107 = llvm.add %56, %13 : i64
    llvm.br ^bb5(%107 : i64)
  ^bb10:  // pred: ^bb5
    %108 = llvm.add %53, %13 : i64
    llvm.br ^bb3(%108 : i64)
  ^bb11:  // pred: ^bb3
    %109 = llvm.add %50, %13 : i64
    llvm.br ^bb1(%109 : i64)
  ^bb12:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After CSE (cse) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<4xf32>
    %2 = llvm.mlir.constant(0 : i64) : i64
    %3 = llvm.mlir.constant(true) : i1
    %4 = llvm.mlir.constant(8 : i64) : i64
    %5 = llvm.mlir.constant(32 : i64) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(64 : index) : i64
    %9 = llvm.mlir.constant(1342504960 : index) : i64
    %10 = llvm.mlir.constant(1342177280 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
    %15 = llvm.mul %9, %4 : i64
    %16 = llvm.udiv %15, %5 : i64
    %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
    %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
    %21 = llvm.mul %10, %4 : i64
    %22 = llvm.udiv %21, %5 : i64
    %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.mul %30, %8 overflow<nsw> : i64
    llvm.br ^bb1(%11 : i64)
  ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
    %33 = llvm.icmp "slt" %32, %8 : i64
    llvm.cond_br %33, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %34 = llvm.add %32, %31 : i64
    %35 = llvm.getelementptr %23[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %36 = llvm.load %35 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
    llvm.br ^bb3(%11 : i64)
  ^bb3(%37: i64):  // 2 preds: ^bb2, ^bb4
    %38 = llvm.icmp "slt" %37, %8 : i64
    llvm.cond_br %38, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %39 = llvm.mul %34, %8 : i64
    %40 = llvm.add %39, %37 : i64
    %41 = llvm.getelementptr %17[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %42 = llvm.load %41 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
    %43 = llvm.extractelement %36[%2 : i64] : vector<1xf32>
    %44 = llvm.insertelement %43, %1[%0 : i32] : vector<4xf32>
    %45 = llvm.shufflevector %44, %1 [0, 0, 0, 0] : vector<4xf32>
    %46 = llvm.fdiv %42, %45 : vector<4xf32>
    %47 = llvm.fptrunc %46 : vector<4xf32> to vector<4xf16>
    %48 = llvm.getelementptr %27[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    llvm.store %47, %48 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
    %49 = llvm.add %37, %6 : i64
    llvm.br ^bb3(%49 : i64)
  ^bb5:  // pred: ^bb3
    %50 = llvm.add %32, %7 : i64
    llvm.br ^bb1(%50 : i64)
  ^bb6:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After ReconcileUnrealizedCastsPass (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<1xf32>
    %2 = llvm.mlir.constant(3 : i64) : i64
    %3 = llvm.mlir.constant(2 : i64) : i64
    %4 = llvm.mlir.constant(1 : i64) : i64
    %5 = llvm.mlir.constant(0 : i64) : i64
    %6 = llvm.mlir.constant(16777216 : index) : i64
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(262144 : index) : i64
    %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(4096 : index) : i64
    %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.mlir.constant(4 : index) : i64
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.mlir.constant(0 : index) : i64
    %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.sdiv %30, %11 : i64
    %32 = llvm.mul %31, %11 : i64
    %33 = llvm.icmp "ne" %30, %32 : i64
    %34 = llvm.icmp "slt" %30, %16 : i64
    %35 = llvm.and %33, %34 : i1
    %36 = llvm.add %31, %10 : i64
    %37 = llvm.select %35, %36, %31 : i1, i64
    %38 = llvm.srem %30, %11 : i64
    %39 = llvm.icmp "slt" %38, %16 : i64
    %40 = llvm.add %38, %11 overflow<nsw> : i64
    %41 = llvm.select %39, %40, %38 : i1, i64
    %42 = llvm.sdiv %41, %15 : i64
    %43 = llvm.srem %30, %15 : i64
    %44 = llvm.icmp "slt" %43, %16 : i64
    %45 = llvm.add %43, %15 overflow<nsw> : i64
    %46 = llvm.select %44, %45, %43 : i1, i64
    %47 = llvm.mul %37, %14 overflow<nsw> : i64
    %48 = llvm.mul %42, %15 overflow<nsw> : i64
    %49 = llvm.mul %46, %15 overflow<nsw> : i64
    llvm.br ^bb1(%16 : i64)
  ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
    %51 = llvm.icmp "slt" %50, %14 : i64
    llvm.cond_br %51, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %52 = llvm.add %50, %47 : i64
    llvm.br ^bb3(%16 : i64)
  ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
    %54 = llvm.icmp "slt" %53, %15 : i64
    llvm.cond_br %54, ^bb4, ^bb11
  ^bb4:  // pred: ^bb3
    %55 = llvm.add %53, %48 : i64
    llvm.br ^bb5(%16 : i64)
  ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
    %57 = llvm.icmp "slt" %56, %15 : i64
    llvm.cond_br %57, ^bb6, ^bb10
  ^bb6:  // pred: ^bb5
    %58 = llvm.add %56, %49 : i64
    llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
  ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
    %61 = llvm.icmp "slt" %59, %15 : i64
    llvm.cond_br %61, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %62 = llvm.mul %52, %8 : i64
    %63 = llvm.mul %55, %15 : i64
    %64 = llvm.add %62, %63 : i64
    %65 = llvm.add %64, %59 : i64
    %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %68 = llvm.mul %52, %8 : i64
    %69 = llvm.mul %58, %15 : i64
    %70 = llvm.add %68, %69 : i64
    %71 = llvm.add %70, %59 : i64
    %72 = llvm.getelementptr %23[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %73 = llvm.load %72 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %74 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
    %75 = llvm.fpext %73 : vector<4xf16> to vector<4xf32>
    %76 = llvm.extractelement %75[%5 : i64] : vector<4xf32>
    %77 = llvm.insertelement %76, %1[%5 : i64] : vector<1xf32>
    %78 = llvm.extractelement %75[%4 : i64] : vector<4xf32>
    %79 = llvm.insertelement %78, %1[%5 : i64] : vector<1xf32>
    %80 = llvm.extractelement %75[%3 : i64] : vector<4xf32>
    %81 = llvm.insertelement %80, %1[%5 : i64] : vector<1xf32>
    %82 = llvm.extractelement %75[%2 : i64] : vector<4xf32>
    %83 = llvm.insertelement %82, %1[%5 : i64] : vector<1xf32>
    %84 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
    %85 = llvm.insertelement %84, %1[%0 : i32] : vector<1xf32>
    %86 = llvm.intr.fmuladd(%77, %85, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %87 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
    %88 = llvm.insertelement %87, %1[%0 : i32] : vector<1xf32>
    %89 = llvm.intr.fmuladd(%79, %88, %86) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %90 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
    %91 = llvm.insertelement %90, %1[%0 : i32] : vector<1xf32>
    %92 = llvm.intr.fmuladd(%81, %91, %89) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %93 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
    %94 = llvm.insertelement %93, %1[%0 : i32] : vector<1xf32>
    %95 = llvm.intr.fmuladd(%83, %94, %92) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %96 = llvm.add %59, %14 : i64
    llvm.br ^bb7(%96, %95 : i64, vector<1xf32>)
  ^bb9:  // pred: ^bb7
    %97 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
    %98 = llvm.fmul %97, %9 : f32
    %99 = llvm.add %47, %50 : i64
    %100 = llvm.add %48, %53 : i64
    %101 = llvm.add %49, %56 : i64
    %102 = llvm.mul %99, %6 overflow<nsw, nuw> : i64
    %103 = llvm.mul %100, %11 overflow<nsw, nuw> : i64
    %104 = llvm.add %102, %103 overflow<nsw, nuw> : i64
    %105 = llvm.add %104, %101 overflow<nsw, nuw> : i64
    %106 = llvm.getelementptr inbounds|nuw %27[%105] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %98, %106 : f32, !llvm.ptr
    %107 = llvm.add %56, %13 : i64
    llvm.br ^bb5(%107 : i64)
  ^bb10:  // pred: ^bb5
    %108 = llvm.add %53, %13 : i64
    llvm.br ^bb3(%108 : i64)
  ^bb11:  // pred: ^bb3
    %109 = llvm.add %50, %13 : i64
    llvm.br ^bb1(%109 : i64)
  ^bb12:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After AddFastMathFlagsPass (iree-codegen-add-fast-math-flags) //----- //
llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %1 = llvm.mlir.poison : vector<4xf32>
  %2 = llvm.mlir.constant(0 : i64) : i64
  %3 = llvm.mlir.constant(true) : i1
  %4 = llvm.mlir.constant(8 : i64) : i64
  %5 = llvm.mlir.constant(32 : i64) : i64
  %6 = llvm.mlir.constant(4 : index) : i64
  %7 = llvm.mlir.constant(1 : index) : i64
  %8 = llvm.mlir.constant(64 : index) : i64
  %9 = llvm.mlir.constant(1342504960 : index) : i64
  %10 = llvm.mlir.constant(1342177280 : index) : i64
  %11 = llvm.mlir.constant(0 : index) : i64
  %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
  %15 = llvm.mul %9, %4 : i64
  %16 = llvm.udiv %15, %5 : i64
  %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
  %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
  %21 = llvm.mul %10, %4 : i64
  %22 = llvm.udiv %21, %5 : i64
  %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
  %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
  %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
  llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
  %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
  %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
  %30 = llvm.zext %29 : i32 to i64
  %31 = llvm.mul %30, %8 overflow<nsw> : i64
  llvm.br ^bb1(%11 : i64)
^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
  %33 = llvm.icmp "slt" %32, %8 : i64
  llvm.cond_br %33, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %34 = llvm.add %32, %31 : i64
  %35 = llvm.getelementptr %23[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %36 = llvm.load %35 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
  llvm.br ^bb3(%11 : i64)
^bb3(%37: i64):  // 2 preds: ^bb2, ^bb4
  %38 = llvm.icmp "slt" %37, %8 : i64
  llvm.cond_br %38, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %39 = llvm.mul %34, %8 : i64
  %40 = llvm.add %39, %37 : i64
  %41 = llvm.getelementptr %17[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %42 = llvm.load %41 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
  %43 = llvm.extractelement %36[%2 : i64] : vector<1xf32>
  %44 = llvm.insertelement %43, %1[%0 : i32] : vector<4xf32>
  %45 = llvm.shufflevector %44, %1 [0, 0, 0, 0] : vector<4xf32>
  %46 = llvm.fdiv %42, %45 : vector<4xf32>
  %47 = llvm.fptrunc %46 : vector<4xf32> to vector<4xf16>
  %48 = llvm.getelementptr %27[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f16
  llvm.store %47, %48 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
  %49 = llvm.add %37, %6 : i64
  llvm.br ^bb3(%49 : i64)
^bb5:  // pred: ^bb3
  %50 = llvm.add %32, %7 : i64
  llvm.br ^bb1(%50 : i64)
^bb6:  // pred: ^bb1
  llvm.return %0 : i32
}

// -----// IR Dump After LLVMCPUSynchronizeSymbolVisibilityPass (iree-llvmcpu-synchronize-symbol-visibility) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<1xf32>
    %2 = llvm.mlir.constant(3 : i64) : i64
    %3 = llvm.mlir.constant(2 : i64) : i64
    %4 = llvm.mlir.constant(1 : i64) : i64
    %5 = llvm.mlir.constant(0 : i64) : i64
    %6 = llvm.mlir.constant(16777216 : index) : i64
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(262144 : index) : i64
    %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(4096 : index) : i64
    %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.mlir.constant(4 : index) : i64
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.mlir.constant(0 : index) : i64
    %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.sdiv %30, %11 : i64
    %32 = llvm.mul %31, %11 : i64
    %33 = llvm.icmp "ne" %30, %32 : i64
    %34 = llvm.icmp "slt" %30, %16 : i64
    %35 = llvm.and %33, %34 : i1
    %36 = llvm.add %31, %10 : i64
    %37 = llvm.select %35, %36, %31 : i1, i64
    %38 = llvm.srem %30, %11 : i64
    %39 = llvm.icmp "slt" %38, %16 : i64
    %40 = llvm.add %38, %11 overflow<nsw> : i64
    %41 = llvm.select %39, %40, %38 : i1, i64
    %42 = llvm.sdiv %41, %15 : i64
    %43 = llvm.srem %30, %15 : i64
    %44 = llvm.icmp "slt" %43, %16 : i64
    %45 = llvm.add %43, %15 overflow<nsw> : i64
    %46 = llvm.select %44, %45, %43 : i1, i64
    %47 = llvm.mul %37, %14 overflow<nsw> : i64
    %48 = llvm.mul %42, %15 overflow<nsw> : i64
    %49 = llvm.mul %46, %15 overflow<nsw> : i64
    llvm.br ^bb1(%16 : i64)
  ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
    %51 = llvm.icmp "slt" %50, %14 : i64
    llvm.cond_br %51, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %52 = llvm.add %50, %47 : i64
    llvm.br ^bb3(%16 : i64)
  ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
    %54 = llvm.icmp "slt" %53, %15 : i64
    llvm.cond_br %54, ^bb4, ^bb11
  ^bb4:  // pred: ^bb3
    %55 = llvm.add %53, %48 : i64
    llvm.br ^bb5(%16 : i64)
  ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
    %57 = llvm.icmp "slt" %56, %15 : i64
    llvm.cond_br %57, ^bb6, ^bb10
  ^bb6:  // pred: ^bb5
    %58 = llvm.add %56, %49 : i64
    llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
  ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
    %61 = llvm.icmp "slt" %59, %15 : i64
    llvm.cond_br %61, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %62 = llvm.mul %52, %8 : i64
    %63 = llvm.mul %55, %15 : i64
    %64 = llvm.add %62, %63 : i64
    %65 = llvm.add %64, %59 : i64
    %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %68 = llvm.mul %52, %8 : i64
    %69 = llvm.mul %58, %15 : i64
    %70 = llvm.add %68, %69 : i64
    %71 = llvm.add %70, %59 : i64
    %72 = llvm.getelementptr %23[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %73 = llvm.load %72 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %74 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
    %75 = llvm.fpext %73 : vector<4xf16> to vector<4xf32>
    %76 = llvm.extractelement %75[%5 : i64] : vector<4xf32>
    %77 = llvm.insertelement %76, %1[%5 : i64] : vector<1xf32>
    %78 = llvm.extractelement %75[%4 : i64] : vector<4xf32>
    %79 = llvm.insertelement %78, %1[%5 : i64] : vector<1xf32>
    %80 = llvm.extractelement %75[%3 : i64] : vector<4xf32>
    %81 = llvm.insertelement %80, %1[%5 : i64] : vector<1xf32>
    %82 = llvm.extractelement %75[%2 : i64] : vector<4xf32>
    %83 = llvm.insertelement %82, %1[%5 : i64] : vector<1xf32>
    %84 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
    %85 = llvm.insertelement %84, %1[%0 : i32] : vector<1xf32>
    %86 = llvm.intr.fmuladd(%77, %85, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %87 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
    %88 = llvm.insertelement %87, %1[%0 : i32] : vector<1xf32>
    %89 = llvm.intr.fmuladd(%79, %88, %86) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %90 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
    %91 = llvm.insertelement %90, %1[%0 : i32] : vector<1xf32>
    %92 = llvm.intr.fmuladd(%81, %91, %89) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %93 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
    %94 = llvm.insertelement %93, %1[%0 : i32] : vector<1xf32>
    %95 = llvm.intr.fmuladd(%83, %94, %92) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %96 = llvm.add %59, %14 : i64
    llvm.br ^bb7(%96, %95 : i64, vector<1xf32>)
  ^bb9:  // pred: ^bb7
    %97 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
    %98 = llvm.fmul %97, %9 : f32
    %99 = llvm.add %47, %50 : i64
    %100 = llvm.add %48, %53 : i64
    %101 = llvm.add %49, %56 : i64
    %102 = llvm.mul %99, %6 overflow<nsw, nuw> : i64
    %103 = llvm.mul %100, %11 overflow<nsw, nuw> : i64
    %104 = llvm.add %102, %103 overflow<nsw, nuw> : i64
    %105 = llvm.add %104, %101 overflow<nsw, nuw> : i64
    %106 = llvm.getelementptr inbounds|nuw %27[%105] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %98, %106 : f32, !llvm.ptr
    %107 = llvm.add %56, %13 : i64
    llvm.br ^bb5(%107 : i64)
  ^bb10:  // pred: ^bb5
    %108 = llvm.add %53, %13 : i64
    llvm.br ^bb3(%108 : i64)
  ^bb11:  // pred: ^bb3
    %109 = llvm.add %50, %13 : i64
    llvm.br ^bb1(%109 : i64)
  ^bb12:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<1xf32>
    %2 = llvm.mlir.constant(3 : i64) : i64
    %3 = llvm.mlir.constant(2 : i64) : i64
    %4 = llvm.mlir.constant(1 : i64) : i64
    %5 = llvm.mlir.constant(0 : i64) : i64
    %6 = llvm.mlir.constant(16777216 : index) : i64
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(262144 : index) : i64
    %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(4096 : index) : i64
    %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.mlir.constant(4 : index) : i64
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.mlir.constant(0 : index) : i64
    %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.sdiv %30, %11 : i64
    %32 = llvm.mul %31, %11 : i64
    %33 = llvm.icmp "ne" %30, %32 : i64
    %34 = llvm.icmp "slt" %30, %16 : i64
    %35 = llvm.and %33, %34 : i1
    %36 = llvm.add %31, %10 : i64
    %37 = llvm.select %35, %36, %31 : i1, i64
    %38 = llvm.srem %30, %11 : i64
    %39 = llvm.icmp "slt" %38, %16 : i64
    %40 = llvm.add %38, %11 overflow<nsw> : i64
    %41 = llvm.select %39, %40, %38 : i1, i64
    %42 = llvm.sdiv %41, %15 : i64
    %43 = llvm.srem %30, %15 : i64
    %44 = llvm.icmp "slt" %43, %16 : i64
    %45 = llvm.add %43, %15 overflow<nsw> : i64
    %46 = llvm.select %44, %45, %43 : i1, i64
    %47 = llvm.mul %37, %14 overflow<nsw> : i64
    %48 = llvm.mul %42, %15 overflow<nsw> : i64
    %49 = llvm.mul %46, %15 overflow<nsw> : i64
    llvm.br ^bb1(%16 : i64)
  ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
    %51 = llvm.icmp "slt" %50, %14 : i64
    llvm.cond_br %51, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %52 = llvm.add %50, %47 : i64
    llvm.br ^bb3(%16 : i64)
  ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
    %54 = llvm.icmp "slt" %53, %15 : i64
    llvm.cond_br %54, ^bb4, ^bb11
  ^bb4:  // pred: ^bb3
    %55 = llvm.add %53, %48 : i64
    llvm.br ^bb5(%16 : i64)
  ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
    %57 = llvm.icmp "slt" %56, %15 : i64
    llvm.cond_br %57, ^bb6, ^bb10
  ^bb6:  // pred: ^bb5
    %58 = llvm.add %56, %49 : i64
    llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
  ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
    %61 = llvm.icmp "slt" %59, %15 : i64
    llvm.cond_br %61, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %62 = llvm.mul %52, %8 : i64
    %63 = llvm.mul %55, %15 : i64
    %64 = llvm.add %62, %63 : i64
    %65 = llvm.add %64, %59 : i64
    %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %68 = llvm.mul %52, %8 : i64
    %69 = llvm.mul %58, %15 : i64
    %70 = llvm.add %68, %69 : i64
    %71 = llvm.add %70, %59 : i64
    %72 = llvm.getelementptr %23[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %73 = llvm.load %72 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %74 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
    %75 = llvm.fpext %73 : vector<4xf16> to vector<4xf32>
    %76 = llvm.extractelement %75[%5 : i64] : vector<4xf32>
    %77 = llvm.insertelement %76, %1[%5 : i64] : vector<1xf32>
    %78 = llvm.extractelement %75[%4 : i64] : vector<4xf32>
    %79 = llvm.insertelement %78, %1[%5 : i64] : vector<1xf32>
    %80 = llvm.extractelement %75[%3 : i64] : vector<4xf32>
    %81 = llvm.insertelement %80, %1[%5 : i64] : vector<1xf32>
    %82 = llvm.extractelement %75[%2 : i64] : vector<4xf32>
    %83 = llvm.insertelement %82, %1[%5 : i64] : vector<1xf32>
    %84 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
    %85 = llvm.insertelement %84, %1[%0 : i32] : vector<1xf32>
    %86 = llvm.intr.fmuladd(%77, %85, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %87 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
    %88 = llvm.insertelement %87, %1[%0 : i32] : vector<1xf32>
    %89 = llvm.intr.fmuladd(%79, %88, %86) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %90 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
    %91 = llvm.insertelement %90, %1[%0 : i32] : vector<1xf32>
    %92 = llvm.intr.fmuladd(%81, %91, %89) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %93 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
    %94 = llvm.insertelement %93, %1[%0 : i32] : vector<1xf32>
    %95 = llvm.intr.fmuladd(%83, %94, %92) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %96 = llvm.add %59, %14 : i64
    llvm.br ^bb7(%96, %95 : i64, vector<1xf32>)
  ^bb9:  // pred: ^bb7
    %97 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
    %98 = llvm.fmul %97, %9 : f32
    %99 = llvm.add %47, %50 : i64
    %100 = llvm.add %48, %53 : i64
    %101 = llvm.add %49, %56 : i64
    %102 = llvm.mul %99, %6 overflow<nsw, nuw> : i64
    %103 = llvm.mul %100, %11 overflow<nsw, nuw> : i64
    %104 = llvm.add %102, %103 overflow<nsw, nuw> : i64
    %105 = llvm.add %104, %101 overflow<nsw, nuw> : i64
    %106 = llvm.getelementptr inbounds|nuw %27[%105] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %98, %106 : f32, !llvm.ptr
    %107 = llvm.add %56, %13 : i64
    llvm.br ^bb5(%107 : i64)
  ^bb10:  // pred: ^bb5
    %108 = llvm.add %53, %13 : i64
    llvm.br ^bb3(%108 : i64)
  ^bb11:  // pred: ^bb3
    %109 = llvm.add %50, %13 : i64
    llvm.br ^bb1(%109 : i64)
  ^bb12:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c1280 = arith.constant 1280 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c1280, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
      %0 = llvm.mlir.constant(0 : i32) : i32
      %1 = llvm.mlir.poison : vector<4xf32>
      %2 = llvm.mlir.constant(0 : i64) : i64
      %3 = llvm.mlir.constant(true) : i1
      %4 = llvm.mlir.constant(8 : i64) : i64
      %5 = llvm.mlir.constant(32 : i64) : i64
      %6 = llvm.mlir.constant(4 : index) : i64
      %7 = llvm.mlir.constant(1 : index) : i64
      %8 = llvm.mlir.constant(64 : index) : i64
      %9 = llvm.mlir.constant(1342504960 : index) : i64
      %10 = llvm.mlir.constant(1342177280 : index) : i64
      %11 = llvm.mlir.constant(0 : index) : i64
      %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
      %15 = llvm.mul %9, %4 : i64
      %16 = llvm.udiv %15, %5 : i64
      %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
      %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
      %21 = llvm.mul %10, %4 : i64
      %22 = llvm.udiv %21, %5 : i64
      %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
      %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
      llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
      %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %30 = llvm.zext %29 : i32 to i64
      %31 = llvm.mul %30, %8 overflow<nsw> : i64
      llvm.br ^bb1(%11 : i64)
    ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
      %33 = llvm.icmp "slt" %32, %8 : i64
      llvm.cond_br %33, ^bb2, ^bb6
    ^bb2:  // pred: ^bb1
      %34 = llvm.add %32, %31 : i64
      %35 = llvm.getelementptr %23[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %36 = llvm.load %35 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
      llvm.br ^bb3(%11 : i64)
    ^bb3(%37: i64):  // 2 preds: ^bb2, ^bb4
      %38 = llvm.icmp "slt" %37, %8 : i64
      llvm.cond_br %38, ^bb4, ^bb5
    ^bb4:  // pred: ^bb3
      %39 = llvm.mul %34, %8 : i64
      %40 = llvm.add %39, %37 : i64
      %41 = llvm.getelementptr %17[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %42 = llvm.load %41 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
      %43 = llvm.extractelement %36[%2 : i64] : vector<1xf32>
      %44 = llvm.insertelement %43, %1[%0 : i32] : vector<4xf32>
      %45 = llvm.shufflevector %44, %1 [0, 0, 0, 0] : vector<4xf32>
      %46 = llvm.fdiv %42, %45 : vector<4xf32>
      %47 = llvm.fptrunc %46 : vector<4xf32> to vector<4xf16>
      %48 = llvm.getelementptr %27[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f16
      llvm.store %47, %48 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
      %49 = llvm.add %37, %6 : i64
      llvm.br ^bb3(%49 : i64)
    ^bb5:  // pred: ^bb3
      %50 = llvm.add %32, %7 : i64
      llvm.br ^bb1(%50 : i64)
    ^bb6:  // pred: ^bb1
      llvm.return %0 : i32
    }
  }
}

// -----// IR Dump After CSE (cse) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.poison : vector<1xf32>
    %2 = llvm.mlir.constant(3 : i64) : i64
    %3 = llvm.mlir.constant(2 : i64) : i64
    %4 = llvm.mlir.constant(1 : i64) : i64
    %5 = llvm.mlir.constant(0 : i64) : i64
    %6 = llvm.mlir.constant(16777216 : index) : i64
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(262144 : index) : i64
    %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(4096 : index) : i64
    %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.mlir.constant(4 : index) : i64
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.mlir.constant(0 : index) : i64
    %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
    llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
    %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %30 = llvm.zext %29 : i32 to i64
    %31 = llvm.sdiv %30, %11 : i64
    %32 = llvm.mul %31, %11 : i64
    %33 = llvm.icmp "ne" %30, %32 : i64
    %34 = llvm.icmp "slt" %30, %16 : i64
    %35 = llvm.and %33, %34 : i1
    %36 = llvm.add %31, %10 : i64
    %37 = llvm.select %35, %36, %31 : i1, i64
    %38 = llvm.srem %30, %11 : i64
    %39 = llvm.icmp "slt" %38, %16 : i64
    %40 = llvm.add %38, %11 overflow<nsw> : i64
    %41 = llvm.select %39, %40, %38 : i1, i64
    %42 = llvm.sdiv %41, %15 : i64
    %43 = llvm.srem %30, %15 : i64
    %44 = llvm.icmp "slt" %43, %16 : i64
    %45 = llvm.add %43, %15 overflow<nsw> : i64
    %46 = llvm.select %44, %45, %43 : i1, i64
    %47 = llvm.mul %37, %14 overflow<nsw> : i64
    %48 = llvm.mul %42, %15 overflow<nsw> : i64
    %49 = llvm.mul %46, %15 overflow<nsw> : i64
    llvm.br ^bb1(%16 : i64)
  ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
    %51 = llvm.icmp "slt" %50, %14 : i64
    llvm.cond_br %51, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %52 = llvm.add %50, %47 : i64
    llvm.br ^bb3(%16 : i64)
  ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
    %54 = llvm.icmp "slt" %53, %15 : i64
    llvm.cond_br %54, ^bb4, ^bb11
  ^bb4:  // pred: ^bb3
    %55 = llvm.add %53, %48 : i64
    llvm.br ^bb5(%16 : i64)
  ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
    %57 = llvm.icmp "slt" %56, %15 : i64
    llvm.cond_br %57, ^bb6, ^bb10
  ^bb6:  // pred: ^bb5
    %58 = llvm.add %56, %49 : i64
    llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
  ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
    %61 = llvm.icmp "slt" %59, %15 : i64
    llvm.cond_br %61, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %62 = llvm.mul %52, %8 : i64
    %63 = llvm.mul %55, %15 : i64
    %64 = llvm.add %62, %63 : i64
    %65 = llvm.add %64, %59 : i64
    %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %68 = llvm.mul %58, %15 : i64
    %69 = llvm.add %62, %68 : i64
    %70 = llvm.add %69, %59 : i64
    %71 = llvm.getelementptr %23[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f16
    %72 = llvm.load %71 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
    %73 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
    %74 = llvm.fpext %72 : vector<4xf16> to vector<4xf32>
    %75 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
    %76 = llvm.insertelement %75, %1[%5 : i64] : vector<1xf32>
    %77 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
    %78 = llvm.insertelement %77, %1[%5 : i64] : vector<1xf32>
    %79 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
    %80 = llvm.insertelement %79, %1[%5 : i64] : vector<1xf32>
    %81 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
    %82 = llvm.insertelement %81, %1[%5 : i64] : vector<1xf32>
    %83 = llvm.extractelement %73[%5 : i64] : vector<4xf32>
    %84 = llvm.insertelement %83, %1[%0 : i32] : vector<1xf32>
    %85 = llvm.intr.fmuladd(%76, %84, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %86 = llvm.extractelement %73[%4 : i64] : vector<4xf32>
    %87 = llvm.insertelement %86, %1[%0 : i32] : vector<1xf32>
    %88 = llvm.intr.fmuladd(%78, %87, %85) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %89 = llvm.extractelement %73[%3 : i64] : vector<4xf32>
    %90 = llvm.insertelement %89, %1[%0 : i32] : vector<1xf32>
    %91 = llvm.intr.fmuladd(%80, %90, %88) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %92 = llvm.extractelement %73[%2 : i64] : vector<4xf32>
    %93 = llvm.insertelement %92, %1[%0 : i32] : vector<1xf32>
    %94 = llvm.intr.fmuladd(%82, %93, %91) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %95 = llvm.add %59, %14 : i64
    llvm.br ^bb7(%95, %94 : i64, vector<1xf32>)
  ^bb9:  // pred: ^bb7
    %96 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
    %97 = llvm.fmul %96, %9 : f32
    %98 = llvm.mul %52, %6 overflow<nsw, nuw> : i64
    %99 = llvm.mul %55, %11 overflow<nsw, nuw> : i64
    %100 = llvm.add %98, %99 overflow<nsw, nuw> : i64
    %101 = llvm.add %100, %58 overflow<nsw, nuw> : i64
    %102 = llvm.getelementptr inbounds|nuw %27[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %97, %102 : f32, !llvm.ptr
    %103 = llvm.add %56, %13 : i64
    llvm.br ^bb5(%103 : i64)
  ^bb10:  // pred: ^bb5
    %104 = llvm.add %53, %13 : i64
    llvm.br ^bb3(%104 : i64)
  ^bb11:  // pred: ^bb3
    %105 = llvm.add %50, %13 : i64
    llvm.br ^bb1(%105 : i64)
  ^bb12:  // pred: ^bb1
    llvm.return %0 : i32
  }
}

// -----// IR Dump After TranslateAllExecutablesPass (iree-hal-translate-all-executables) //----- //
hal.executable private @attention_dispatch_2 {
  hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
    hal.executable.export public @attention_dispatch_2_elementwise_81920x64_f32xf32xf16 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %c1280 = arith.constant 1280 : index
      %c1 = arith.constant 1 : index
      %c1_0 = arith.constant 1 : index
      hal.return %c1280, %c1, %c1_0 : index, index, index
    } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.func @attention_dispatch_2_elementwise_81920x64_f32xf32xf16(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
        %0 = llvm.mlir.constant(0 : i32) : i32
        %1 = llvm.mlir.poison : vector<4xf32>
        %2 = llvm.mlir.constant(0 : i64) : i64
        %3 = llvm.mlir.constant(true) : i1
        %4 = llvm.mlir.constant(8 : i64) : i64
        %5 = llvm.mlir.constant(32 : i64) : i64
        %6 = llvm.mlir.constant(4 : index) : i64
        %7 = llvm.mlir.constant(1 : index) : i64
        %8 = llvm.mlir.constant(64 : index) : i64
        %9 = llvm.mlir.constant(1342504960 : index) : i64
        %10 = llvm.mlir.constant(1342177280 : index) : i64
        %11 = llvm.mlir.constant(0 : index) : i64
        %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %13 = llvm.extractvalue %12[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %14 = llvm.load %13 : !llvm.ptr -> !llvm.ptr
        %15 = llvm.mul %9, %4 : i64
        %16 = llvm.udiv %15, %5 : i64
        %17 = llvm.getelementptr %14[%16] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        llvm.intr.assume %3 ["align"(%17, %8 : !llvm.ptr, i64)] : i1
        %18 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %19 = llvm.extractvalue %18[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %20 = llvm.load %19 : !llvm.ptr -> !llvm.ptr
        %21 = llvm.mul %10, %4 : i64
        %22 = llvm.udiv %21, %5 : i64
        %23 = llvm.getelementptr %20[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        llvm.intr.assume %3 ["align"(%23, %8 : !llvm.ptr, i64)] : i1
        %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %26 = llvm.getelementptr %25[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
        llvm.intr.assume %3 ["align"(%27, %8 : !llvm.ptr, i64)] : i1
        %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %30 = llvm.zext %29 : i32 to i64
        %31 = llvm.mul %30, %8 overflow<nsw> : i64
        llvm.br ^bb1(%11 : i64)
      ^bb1(%32: i64):  // 2 preds: ^bb0, ^bb5
        %33 = llvm.icmp "slt" %32, %8 : i64
        llvm.cond_br %33, ^bb2, ^bb6
      ^bb2:  // pred: ^bb1
        %34 = llvm.add %32, %31 : i64
        %35 = llvm.getelementptr %23[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %36 = llvm.load %35 {alignment = 4 : i64} : !llvm.ptr -> vector<1xf32>
        llvm.br ^bb3(%11 : i64)
      ^bb3(%37: i64):  // 2 preds: ^bb2, ^bb4
        %38 = llvm.icmp "slt" %37, %8 : i64
        llvm.cond_br %38, ^bb4, ^bb5
      ^bb4:  // pred: ^bb3
        %39 = llvm.mul %34, %8 : i64
        %40 = llvm.add %39, %37 : i64
        %41 = llvm.getelementptr %17[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %42 = llvm.load %41 {alignment = 4 : i64} : !llvm.ptr -> vector<4xf32>
        %43 = llvm.extractelement %36[%2 : i64] : vector<1xf32>
        %44 = llvm.insertelement %43, %1[%0 : i32] : vector<4xf32>
        %45 = llvm.shufflevector %44, %1 [0, 0, 0, 0] : vector<4xf32>
        %46 = llvm.fdiv %42, %45 : vector<4xf32>
        %47 = llvm.fptrunc %46 : vector<4xf32> to vector<4xf16>
        %48 = llvm.getelementptr %27[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f16
        llvm.store %47, %48 {alignment = 2 : i64} : vector<4xf16>, !llvm.ptr
        %49 = llvm.add %37, %6 : i64
        llvm.br ^bb3(%49 : i64)
      ^bb5:  // pred: ^bb3
        %50 = llvm.add %32, %7 : i64
        llvm.br ^bb1(%50 : i64)
      ^bb6:  // pred: ^bb1
        llvm.return %0 : i32
      }
    }
  }
}

// -----// IR Dump After AddFastMathFlagsPass (iree-codegen-add-fast-math-flags) //----- //
llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %1 = llvm.mlir.poison : vector<1xf32>
  %2 = llvm.mlir.constant(3 : i64) : i64
  %3 = llvm.mlir.constant(2 : i64) : i64
  %4 = llvm.mlir.constant(1 : i64) : i64
  %5 = llvm.mlir.constant(0 : i64) : i64
  %6 = llvm.mlir.constant(16777216 : index) : i64
  %7 = llvm.mlir.constant(true) : i1
  %8 = llvm.mlir.constant(262144 : index) : i64
  %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
  %10 = llvm.mlir.constant(-1 : index) : i64
  %11 = llvm.mlir.constant(4096 : index) : i64
  %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
  %13 = llvm.mlir.constant(1 : index) : i64
  %14 = llvm.mlir.constant(4 : index) : i64
  %15 = llvm.mlir.constant(64 : index) : i64
  %16 = llvm.mlir.constant(0 : index) : i64
  %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
  llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
  %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
  %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
  llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
  %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
  %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
  llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
  %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
  %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
  %30 = llvm.zext %29 : i32 to i64
  %31 = llvm.sdiv %30, %11 : i64
  %32 = llvm.mul %31, %11 : i64
  %33 = llvm.icmp "ne" %30, %32 : i64
  %34 = llvm.icmp "slt" %30, %16 : i64
  %35 = llvm.and %33, %34 : i1
  %36 = llvm.add %31, %10 : i64
  %37 = llvm.select %35, %36, %31 : i1, i64
  %38 = llvm.srem %30, %11 : i64
  %39 = llvm.icmp "slt" %38, %16 : i64
  %40 = llvm.add %38, %11 overflow<nsw> : i64
  %41 = llvm.select %39, %40, %38 : i1, i64
  %42 = llvm.sdiv %41, %15 : i64
  %43 = llvm.srem %30, %15 : i64
  %44 = llvm.icmp "slt" %43, %16 : i64
  %45 = llvm.add %43, %15 overflow<nsw> : i64
  %46 = llvm.select %44, %45, %43 : i1, i64
  %47 = llvm.mul %37, %14 overflow<nsw> : i64
  %48 = llvm.mul %42, %15 overflow<nsw> : i64
  %49 = llvm.mul %46, %15 overflow<nsw> : i64
  llvm.br ^bb1(%16 : i64)
^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
  %51 = llvm.icmp "slt" %50, %14 : i64
  llvm.cond_br %51, ^bb2, ^bb12
^bb2:  // pred: ^bb1
  %52 = llvm.add %50, %47 : i64
  llvm.br ^bb3(%16 : i64)
^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
  %54 = llvm.icmp "slt" %53, %15 : i64
  llvm.cond_br %54, ^bb4, ^bb11
^bb4:  // pred: ^bb3
  %55 = llvm.add %53, %48 : i64
  llvm.br ^bb5(%16 : i64)
^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
  %57 = llvm.icmp "slt" %56, %15 : i64
  llvm.cond_br %57, ^bb6, ^bb10
^bb6:  // pred: ^bb5
  %58 = llvm.add %56, %49 : i64
  llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
  %61 = llvm.icmp "slt" %59, %15 : i64
  llvm.cond_br %61, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %62 = llvm.mul %52, %8 : i64
  %63 = llvm.mul %55, %15 : i64
  %64 = llvm.add %62, %63 : i64
  %65 = llvm.add %64, %59 : i64
  %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
  %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
  %68 = llvm.mul %58, %15 : i64
  %69 = llvm.add %62, %68 : i64
  %70 = llvm.add %69, %59 : i64
  %71 = llvm.getelementptr %23[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f16
  %72 = llvm.load %71 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
  %73 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
  %74 = llvm.fpext %72 : vector<4xf16> to vector<4xf32>
  %75 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
  %76 = llvm.insertelement %75, %1[%5 : i64] : vector<1xf32>
  %77 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
  %78 = llvm.insertelement %77, %1[%5 : i64] : vector<1xf32>
  %79 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
  %80 = llvm.insertelement %79, %1[%5 : i64] : vector<1xf32>
  %81 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
  %82 = llvm.insertelement %81, %1[%5 : i64] : vector<1xf32>
  %83 = llvm.extractelement %73[%5 : i64] : vector<4xf32>
  %84 = llvm.insertelement %83, %1[%0 : i32] : vector<1xf32>
  %85 = llvm.intr.fmuladd(%76, %84, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
  %86 = llvm.extractelement %73[%4 : i64] : vector<4xf32>
  %87 = llvm.insertelement %86, %1[%0 : i32] : vector<1xf32>
  %88 = llvm.intr.fmuladd(%78, %87, %85) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
  %89 = llvm.extractelement %73[%3 : i64] : vector<4xf32>
  %90 = llvm.insertelement %89, %1[%0 : i32] : vector<1xf32>
  %91 = llvm.intr.fmuladd(%80, %90, %88) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
  %92 = llvm.extractelement %73[%2 : i64] : vector<4xf32>
  %93 = llvm.insertelement %92, %1[%0 : i32] : vector<1xf32>
  %94 = llvm.intr.fmuladd(%82, %93, %91) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
  %95 = llvm.add %59, %14 : i64
  llvm.br ^bb7(%95, %94 : i64, vector<1xf32>)
^bb9:  // pred: ^bb7
  %96 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
  %97 = llvm.fmul %96, %9 {fastmathFlags = #llvm.fastmath<contract>} : f32
  %98 = llvm.mul %52, %6 overflow<nsw, nuw> : i64
  %99 = llvm.mul %55, %11 overflow<nsw, nuw> : i64
  %100 = llvm.add %98, %99 overflow<nsw, nuw> : i64
  %101 = llvm.add %100, %58 overflow<nsw, nuw> : i64
  %102 = llvm.getelementptr inbounds|nuw %27[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %97, %102 : f32, !llvm.ptr
  %103 = llvm.add %56, %13 : i64
  llvm.br ^bb5(%103 : i64)
^bb10:  // pred: ^bb5
  %104 = llvm.add %53, %13 : i64
  llvm.br ^bb3(%104 : i64)
^bb11:  // pred: ^bb3
  %105 = llvm.add %50, %13 : i64
  llvm.br ^bb1(%105 : i64)
^bb12:  // pred: ^bb1
  llvm.return %0 : i32
}

// -----// IR Dump After TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
  hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c20480 = arith.constant 20480 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c20480, %c1, %c1_0 : index, index, index
  } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
      %0 = llvm.mlir.constant(0 : i32) : i32
      %1 = llvm.mlir.poison : vector<1xf32>
      %2 = llvm.mlir.constant(3 : i64) : i64
      %3 = llvm.mlir.constant(2 : i64) : i64
      %4 = llvm.mlir.constant(1 : i64) : i64
      %5 = llvm.mlir.constant(0 : i64) : i64
      %6 = llvm.mlir.constant(16777216 : index) : i64
      %7 = llvm.mlir.constant(true) : i1
      %8 = llvm.mlir.constant(262144 : index) : i64
      %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
      %10 = llvm.mlir.constant(-1 : index) : i64
      %11 = llvm.mlir.constant(4096 : index) : i64
      %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
      %13 = llvm.mlir.constant(1 : index) : i64
      %14 = llvm.mlir.constant(4 : index) : i64
      %15 = llvm.mlir.constant(64 : index) : i64
      %16 = llvm.mlir.constant(0 : index) : i64
      %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
      llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
      %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
      llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
      %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
      llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
      %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %30 = llvm.zext %29 : i32 to i64
      %31 = llvm.sdiv %30, %11 : i64
      %32 = llvm.mul %31, %11 : i64
      %33 = llvm.icmp "ne" %30, %32 : i64
      %34 = llvm.icmp "slt" %30, %16 : i64
      %35 = llvm.and %33, %34 : i1
      %36 = llvm.add %31, %10 : i64
      %37 = llvm.select %35, %36, %31 : i1, i64
      %38 = llvm.srem %30, %11 : i64
      %39 = llvm.icmp "slt" %38, %16 : i64
      %40 = llvm.add %38, %11 overflow<nsw> : i64
      %41 = llvm.select %39, %40, %38 : i1, i64
      %42 = llvm.sdiv %41, %15 : i64
      %43 = llvm.srem %30, %15 : i64
      %44 = llvm.icmp "slt" %43, %16 : i64
      %45 = llvm.add %43, %15 overflow<nsw> : i64
      %46 = llvm.select %44, %45, %43 : i1, i64
      %47 = llvm.mul %37, %14 overflow<nsw> : i64
      %48 = llvm.mul %42, %15 overflow<nsw> : i64
      %49 = llvm.mul %46, %15 overflow<nsw> : i64
      llvm.br ^bb1(%16 : i64)
    ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
      %51 = llvm.icmp "slt" %50, %14 : i64
      llvm.cond_br %51, ^bb2, ^bb12
    ^bb2:  // pred: ^bb1
      %52 = llvm.add %50, %47 : i64
      llvm.br ^bb3(%16 : i64)
    ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
      %54 = llvm.icmp "slt" %53, %15 : i64
      llvm.cond_br %54, ^bb4, ^bb11
    ^bb4:  // pred: ^bb3
      %55 = llvm.add %53, %48 : i64
      llvm.br ^bb5(%16 : i64)
    ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
      %57 = llvm.icmp "slt" %56, %15 : i64
      llvm.cond_br %57, ^bb6, ^bb10
    ^bb6:  // pred: ^bb5
      %58 = llvm.add %56, %49 : i64
      llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
    ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
      %61 = llvm.icmp "slt" %59, %15 : i64
      llvm.cond_br %61, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %62 = llvm.mul %52, %8 : i64
      %63 = llvm.mul %55, %15 : i64
      %64 = llvm.add %62, %63 : i64
      %65 = llvm.add %64, %59 : i64
      %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
      %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
      %68 = llvm.mul %58, %15 : i64
      %69 = llvm.add %62, %68 : i64
      %70 = llvm.add %69, %59 : i64
      %71 = llvm.getelementptr %23[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f16
      %72 = llvm.load %71 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
      %73 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
      %74 = llvm.fpext %72 : vector<4xf16> to vector<4xf32>
      %75 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
      %76 = llvm.insertelement %75, %1[%5 : i64] : vector<1xf32>
      %77 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
      %78 = llvm.insertelement %77, %1[%5 : i64] : vector<1xf32>
      %79 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
      %80 = llvm.insertelement %79, %1[%5 : i64] : vector<1xf32>
      %81 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
      %82 = llvm.insertelement %81, %1[%5 : i64] : vector<1xf32>
      %83 = llvm.extractelement %73[%5 : i64] : vector<4xf32>
      %84 = llvm.insertelement %83, %1[%0 : i32] : vector<1xf32>
      %85 = llvm.intr.fmuladd(%76, %84, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %86 = llvm.extractelement %73[%4 : i64] : vector<4xf32>
      %87 = llvm.insertelement %86, %1[%0 : i32] : vector<1xf32>
      %88 = llvm.intr.fmuladd(%78, %87, %85) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %89 = llvm.extractelement %73[%3 : i64] : vector<4xf32>
      %90 = llvm.insertelement %89, %1[%0 : i32] : vector<1xf32>
      %91 = llvm.intr.fmuladd(%80, %90, %88) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %92 = llvm.extractelement %73[%2 : i64] : vector<4xf32>
      %93 = llvm.insertelement %92, %1[%0 : i32] : vector<1xf32>
      %94 = llvm.intr.fmuladd(%82, %93, %91) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %95 = llvm.add %59, %14 : i64
      llvm.br ^bb7(%95, %94 : i64, vector<1xf32>)
    ^bb9:  // pred: ^bb7
      %96 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
      %97 = llvm.fmul %96, %9 {fastmathFlags = #llvm.fastmath<contract>} : f32
      %98 = llvm.mul %52, %6 overflow<nsw, nuw> : i64
      %99 = llvm.mul %55, %11 overflow<nsw, nuw> : i64
      %100 = llvm.add %98, %99 overflow<nsw, nuw> : i64
      %101 = llvm.add %100, %58 overflow<nsw, nuw> : i64
      %102 = llvm.getelementptr inbounds|nuw %27[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %97, %102 : f32, !llvm.ptr
      %103 = llvm.add %56, %13 : i64
      llvm.br ^bb5(%103 : i64)
    ^bb10:  // pred: ^bb5
      %104 = llvm.add %53, %13 : i64
      llvm.br ^bb3(%104 : i64)
    ^bb11:  // pred: ^bb3
      %105 = llvm.add %50, %13 : i64
      llvm.br ^bb1(%105 : i64)
    ^bb12:  // pred: ^bb1
      llvm.return %0 : i32
    }
  }
}

// -----// IR Dump After TranslateAllExecutablesPass (iree-hal-translate-all-executables) //----- //
hal.executable private @attention_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64 target(<"llvm-cpu", "embedded-elf-x86_64", {cpu = "", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 16 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>) {
    hal.executable.export public @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %c20480 = arith.constant 20480 : index
      %c1 = arith.constant 1 : index
      %c1_0 = arith.constant 1 : index
      hal.return %c20480, %c1, %c1_0 : index, index, index
    } attributes {workgroup_size = [1 : index, 1 : index, 1 : index]}
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.func @attention_dispatch_0_matmul_like_20x4096x4096x64_f16xf16xf32(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias, llvm.nonnull, llvm.noundef}) -> i32 {
        %0 = llvm.mlir.constant(0 : i32) : i32
        %1 = llvm.mlir.poison : vector<1xf32>
        %2 = llvm.mlir.constant(3 : i64) : i64
        %3 = llvm.mlir.constant(2 : i64) : i64
        %4 = llvm.mlir.constant(1 : i64) : i64
        %5 = llvm.mlir.constant(0 : i64) : i64
        %6 = llvm.mlir.constant(16777216 : index) : i64
        %7 = llvm.mlir.constant(true) : i1
        %8 = llvm.mlir.constant(262144 : index) : i64
        %9 = llvm.mlir.constant(1.250000e-01 : f32) : f32
        %10 = llvm.mlir.constant(-1 : index) : i64
        %11 = llvm.mlir.constant(4096 : index) : i64
        %12 = llvm.mlir.constant(dense<0.000000e+00> : vector<1xf32>) : vector<1xf32>
        %13 = llvm.mlir.constant(1 : index) : i64
        %14 = llvm.mlir.constant(4 : index) : i64
        %15 = llvm.mlir.constant(64 : index) : i64
        %16 = llvm.mlir.constant(0 : index) : i64
        %17 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %18 = llvm.extractvalue %17[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %19 = llvm.load %18 : !llvm.ptr -> !llvm.ptr
        llvm.intr.assume %7 ["align"(%19, %15 : !llvm.ptr, i64)] : i1
        %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %21 = llvm.extractvalue %20[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %22 = llvm.getelementptr %21[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %23 = llvm.load %22 : !llvm.ptr -> !llvm.ptr
        llvm.intr.assume %7 ["align"(%23, %15 : !llvm.ptr, i64)] : i1
        %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %25 = llvm.extractvalue %24[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %26 = llvm.getelementptr %25[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %27 = llvm.load %26 : !llvm.ptr -> !llvm.ptr
        llvm.intr.assume %7 ["align"(%27, %15 : !llvm.ptr, i64)] : i1
        %28 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %29 = llvm.extractvalue %28[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %30 = llvm.zext %29 : i32 to i64
        %31 = llvm.sdiv %30, %11 : i64
        %32 = llvm.mul %31, %11 : i64
        %33 = llvm.icmp "ne" %30, %32 : i64
        %34 = llvm.icmp "slt" %30, %16 : i64
        %35 = llvm.and %33, %34 : i1
        %36 = llvm.add %31, %10 : i64
        %37 = llvm.select %35, %36, %31 : i1, i64
        %38 = llvm.srem %30, %11 : i64
        %39 = llvm.icmp "slt" %38, %16 : i64
        %40 = llvm.add %38, %11 overflow<nsw> : i64
        %41 = llvm.select %39, %40, %38 : i1, i64
        %42 = llvm.sdiv %41, %15 : i64
        %43 = llvm.srem %30, %15 : i64
        %44 = llvm.icmp "slt" %43, %16 : i64
        %45 = llvm.add %43, %15 overflow<nsw> : i64
        %46 = llvm.select %44, %45, %43 : i1, i64
        %47 = llvm.mul %37, %14 overflow<nsw> : i64
        %48 = llvm.mul %42, %15 overflow<nsw> : i64
        %49 = llvm.mul %46, %15 overflow<nsw> : i64
        llvm.br ^bb1(%16 : i64)
      ^bb1(%50: i64):  // 2 preds: ^bb0, ^bb11
        %51 = llvm.icmp "slt" %50, %14 : i64
        llvm.cond_br %51, ^bb2, ^bb12
      ^bb2:  // pred: ^bb1
        %52 = llvm.add %50, %47 : i64
        llvm.br ^bb3(%16 : i64)
      ^bb3(%53: i64):  // 2 preds: ^bb2, ^bb10
        %54 = llvm.icmp "slt" %53, %15 : i64
        llvm.cond_br %54, ^bb4, ^bb11
      ^bb4:  // pred: ^bb3
        %55 = llvm.add %53, %48 : i64
        llvm.br ^bb5(%16 : i64)
      ^bb5(%56: i64):  // 2 preds: ^bb4, ^bb9
        %57 = llvm.icmp "slt" %56, %15 : i64
        llvm.cond_br %57, ^bb6, ^bb10
      ^bb6:  // pred: ^bb5
        %58 = llvm.add %56, %49 : i64
        llvm.br ^bb7(%16, %12 : i64, vector<1xf32>)
      ^bb7(%59: i64, %60: vector<1xf32>):  // 2 preds: ^bb6, ^bb8
        %61 = llvm.icmp "slt" %59, %15 : i64
        llvm.cond_br %61, ^bb8, ^bb9
      ^bb8:  // pred: ^bb7
        %62 = llvm.mul %52, %8 : i64
        %63 = llvm.mul %55, %15 : i64
        %64 = llvm.add %62, %63 : i64
        %65 = llvm.add %64, %59 : i64
        %66 = llvm.getelementptr %19[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f16
        %67 = llvm.load %66 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
        %68 = llvm.mul %58, %15 : i64
        %69 = llvm.add %62, %68 : i64
        %70 = llvm.add %69, %59 : i64
        %71 = llvm.getelementptr %23[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f16
        %72 = llvm.load %71 {alignment = 2 : i64} : !llvm.ptr -> vector<4xf16>
        %73 = llvm.fpext %67 : vector<4xf16> to vector<4xf32>
        %74 = llvm.fpext %72 : vector<4xf16> to vector<4xf32>
        %75 = llvm.extractelement %74[%5 : i64] : vector<4xf32>
        %76 = llvm.insertelement %75, %1[%5 : i64] : vector<1xf32>
        %77 = llvm.extractelement %74[%4 : i64] : vector<4xf32>
        %78 = llvm.insertelement %77, %1[%5 : i64] : vector<1xf32>
        %79 = llvm.extractelement %74[%3 : i64] : vector<4xf32>
        %80 = llvm.insertelement %79, %1[%5 : i64] : vector<1xf32>
        %81 = llvm.extractelement %74[%2 : i64] : vector<4xf32>
        %82 = llvm.insertelement %81, %1[%5 : i64] : vector<1xf32>
        %83 = llvm.extractelement %73[%5 : i64] : vector<4xf32>
        %84 = llvm.insertelement %83, %1[%0 : i32] : vector<1xf32>
        %85 = llvm.intr.fmuladd(%76, %84, %60) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %86 = llvm.extractelement %73[%4 : i64] : vector<4xf32>
        %87 = llvm.insertelement %86, %1[%0 : i32] : vector<1xf32>
        %88 = llvm.intr.fmuladd(%78, %87, %85) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %89 = llvm.extractelement %73[%3 : i64] : vector<4xf32>
        %90 = llvm.insertelement %89, %1[%0 : i32] : vector<1xf32>
        %91 = llvm.intr.fmuladd(%80, %90, %88) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %92 = llvm.extractelement %73[%2 : i64] : vector<4xf32>
        %93 = llvm.insertelement %92, %1[%0 : i32] : vector<1xf32>
        %94 = llvm.intr.fmuladd(%82, %93, %91) : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %95 = llvm.add %59, %14 : i64
        llvm.br ^bb7(%95, %94 : i64, vector<1xf32>)
      ^bb9:  // pred: ^bb7
        %96 = llvm.extractelement %60[%5 : i64] : vector<1xf32>
        %97 = llvm.fmul %96, %9 {fastmathFlags = #llvm.fastmath<contract>} : f32
        %98 = llvm.mul %52, %6 overflow<nsw, nuw> : i64
        %99 = llvm.mul %55, %11 overflow<nsw, nuw> : i64
        %100 = llvm.add %98, %99 overflow<nsw, nuw> : i64
        %101 = llvm.add %100, %58 overflow<nsw, nuw> : i64
        %102 = llvm.getelementptr inbounds|nuw %27[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        llvm.store %97, %102 : f32, !llvm.ptr
        %103 = llvm.add %56, %13 : i64
        llvm.br ^bb5(%103 : i64)
      ^bb10:  // pred: ^bb5
        %104 = llvm.add %53, %13 : i64
        llvm.br ^bb3(%104 : i64)
      ^bb11:  // pred: ^bb3
        %105 = llvm.add %50, %13 : i64
        llvm.br ^bb1(%105 : i64)
      ^bb12:  // pred: ^bb1
        llvm.return %0 : i32
      }
    }
  }
}

 #0 0x000079f8af39f242 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/workspaces/iree/build/lib/libIREECompiler.so+0x279f242)
 #1 0x000079f8af39bf22 SignalHandler(int, siginfo_t*, void*) Signals.cpp:0:0
 #2 0x000079f8aca33330 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x45330)
 #3 0x000079f8b315be0c mlir::iree_compiler::PartitionableLoopsInterface::getPartitionableLoops(std::optional<unsigned int>) (/workspaces/iree/build/lib/libIREECompiler.so+0x655be0c)
 #4 0x000079f8b176a37f mlir::iree_compiler::getDefaultDistributedLevelTileSizes(mlir::Operation*, mlir::iree_compiler::DistributionHeuristicConfig const&) KernelDispatch.cpp:0:0
 #5 0x000079f8b177be92 mlir::iree_compiler::initCPULaunchConfig(mlir::FunctionOpInterface) (/workspaces/iree/build/lib/libIREECompiler.so+0x4b7be92)
 #6 0x000079f8b1749f90 mlir::iree_compiler::(anonymous namespace)::LLVMCPUSelectLoweringStrategyPass::runOnOperation() LLVMCPUSelectLoweringStrategy.cpp:0:0
 #7 0x000079f8af9d9566 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9566)
 #8 0x000079f8af9d9808 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9808)
 #9 0x000079f8af9d8a55 mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd8a55)
#10 0x000079f8af9d9509 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9509)
#11 0x000079f8af9d9808 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9808)
#12 0x000079f8af9da52c mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::'lambda'(mlir::OpPassManager&, mlir::Operation*)::operator()(mlir::OpPassManager&, mlir::Operation*) const Pass.cpp:0:0
#13 0x000079f8b183da2d mlir::iree_compiler::IREE::HAL::(anonymous namespace)::ConfigureTargetExecutableVariantsPass::runOnOperation() ConfigureExecutables.cpp:0:0
#14 0x000079f8af9d9566 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9566)
#15 0x000079f8af9d9808 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9808)
#16 0x000079f8af9d8a55 mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd8a55)
#17 0x000079f8af9d9509 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9509)
#18 0x000079f8af9d9808 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9808)
#19 0x000079f8af9da52c mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::'lambda'(mlir::OpPassManager&, mlir::Operation*)::operator()(mlir::OpPassManager&, mlir::Operation*) const Pass.cpp:0:0
#20 0x000079f8b183f35d mlir::iree_compiler::IREE::HAL::(anonymous namespace)::ConfigureExecutablesPass::runOnOperation() ConfigureExecutables.cpp:0:0
#21 0x000079f8af9d9566 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9566)
#22 0x000079f8af9d9808 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/workspaces/iree/build/lib/libIREECompiler.so+0x2dd9808)
#23 0x000079f8af9da707 void llvm::detail::UniqueFunctionBase<void>::CallImpl<llvm::LogicalResult mlir::failableParallelForEach<__gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, void mlir::parallelForEach<__gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::'lambda'(mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo&)>(mlir::MLIRContext*, __gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, __gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::'lambda'(mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo&)&&)::'lambda'(__gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>&&)>(mlir::MLIRContext*, __gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, __gnu_cxx::__normal_iterator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo*, std::vector<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo, std::allocator<mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo>>>, mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::'lambda'(mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool)::OpPMInfo&)&&)::'lambda'()>(void*) Pass.cpp:0:0
#24 0x000079f8af4f903b std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, std::thread::_Invoker<std::tuple<llvm::unique_function<void ()>>>, void>>::_M_invoke(std::_Any_data const&) (/workspaces/iree/build/lib/libIREECompiler.so+0x28f903b)
#25 0x000079f8af4f8f2d std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*) (/workspaces/iree/build/lib/libIREECompiler.so+0x28f8f2d)
#26 0x000079f8aca8fed3 __pthread_once_slow ./nptl/pthread_once.c:118:7
#27 0x000079f8af4f8e7e std::__future_base::_Deferred_state<std::thread::_Invoker<std::tuple<llvm::unique_function<void ()>>>, void>::_M_complete_async() (/workspaces/iree/build/lib/libIREECompiler.so+0x28f8e7e)
#28 0x000079f8af4f8a60 void llvm::detail::UniqueFunctionBase<void>::CallImpl<std::shared_future<void> llvm::ThreadPoolInterface::asyncImpl<void>(llvm::unique_function<void ()>, llvm::ThreadPoolTaskGroup*)::'lambda'()>(void*) (/workspaces/iree/build/lib/libIREECompiler.so+0x28f8a60)
#29 0x000079f8af34250a llvm::StdThreadPool::processTasks(llvm::ThreadPoolTaskGroup*) (/workspaces/iree/build/lib/libIREECompiler.so+0x274250a)
#30 0x000079f8af343307 void* llvm::thread::ThreadProxy<std::tuple<llvm::StdThreadPool::grow(int)::'lambda'()>>(void*) ThreadPool.cpp:0:0
#31 0x000079f8aca8aaa4 start_thread ./nptl/pthread_create.c:447:8
#32 0x000079f8acb17c3c clone3 ./misc/../sysdeps/unix/sysv/linux/x86_64/clone3.S:80:0
